{
  "discussions": {
    "pageInfo": {
      "hasNextPage": true,
      "endCursor": "Y3Vyc29yOnYyOpK5MjAyMy0xMC0yNFQyMTozODoyMS0wNjowMM4AWBrE"
    },
    "edges": [
      {
        "node": {
          "title": "Free Radial Expansion BC - DisplacementAboutAxis",
          "author": {
            "login": "naabwxt"
          },
          "bodyText": "Is it possible to use the DisplacementAboutAxis BC to restrict a body to only radial/axial expansion? I assumed that I could do something similar to the following, but it just makes the displacements in x and y zero on the face.\n  [xdir]\n    type = DisplacementAboutAxis\n    boundary = 'back'\n    function = 0\n    angular_velocity = false\n    angle_units = degrees\n    axis_origin = '0. 0. 0.'\n    axis_direction = '0. 0. 1.'\n    component = 0\n    variable = 'disp_x'\n    displacements = 'disp_x disp_y disp_z'\n  []\n  [ydir]\n    type = DisplacementAboutAxis\n    boundary = 'back'\n    function = 0\n    angular_velocity = false\n    angle_units = degrees\n    axis_origin = '0. 0. 0.'\n    axis_direction = '0. 0. 1.'\n    component = 1\n    variable = 'disp_y'\n    displacements = 'disp_x disp_y disp_z'\n  []",
          "url": "https://github.com/idaholab/moose/discussions/25860",
          "updatedAt": "2023-10-26T18:10:42Z",
          "publishedAt": "2023-10-26T15:43:04Z",
          "category": {
            "name": "Q&A Modules: Solid mechanics"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "GiudGiud"
                  },
                  "bodyText": "@backmari @arovinelli",
                  "url": "https://github.com/idaholab/moose/discussions/25860#discussioncomment-7395653",
                  "updatedAt": "2023-10-26T17:44:14Z",
                  "publishedAt": "2023-10-26T17:44:13Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "author": {
                    "login": "backmari"
                  },
                  "bodyText": "I haven't used this in a long time, but the original purpose of the BC was to fix one end of a cylinder and twist the other end. See this test for an example: modules/tensor_mechanics/test/tests/torque_reaction/torque_reaction_cylinder.i",
                  "url": "https://github.com/idaholab/moose/discussions/25860#discussioncomment-7395802",
                  "updatedAt": "2023-10-26T18:04:18Z",
                  "publishedAt": "2023-10-26T18:04:17Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "naabwxt"
                          },
                          "bodyText": "So it really isn't meant to be used to prevent a cylinder from twisting but more to prescribe components of a torque?",
                          "url": "https://github.com/idaholab/moose/discussions/25860#discussioncomment-7395831",
                          "updatedAt": "2023-10-26T18:08:04Z",
                          "publishedAt": "2023-10-26T18:07:49Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "backmari"
                          },
                          "bodyText": "Yes",
                          "url": "https://github.com/idaholab/moose/discussions/25860#discussioncomment-7395850",
                          "updatedAt": "2023-10-26T18:10:06Z",
                          "publishedAt": "2023-10-26T18:10:05Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "naabwxt"
                          },
                          "bodyText": "ok thanks",
                          "url": "https://github.com/idaholab/moose/discussions/25860#discussioncomment-7395860",
                          "updatedAt": "2023-10-26T18:10:42Z",
                          "publishedAt": "2023-10-26T18:10:42Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "Gas Mixing simulation failing due to FACTOR_OUTMEMORY",
          "author": {
            "login": "gsgall"
          },
          "bodyText": "I am working on solving a single phase gas mixing simulation using FE-INS for the flow and modeling the gas mixing by modeling a mass fraction that varies spatially.\nIn this simulation I am using an effective fluid density and viscosity which is a function of this mass fraction in the form\nrho = w * rho_1 + (1 - w) * rho_2\nWhere rho_1 is the density of one gas and rho_2 is the density of another. I am using a similar equation for the viscosity as well.\nI am running into an issue where my simulation is solving with out any real issues until a a certain point and then it just begins to crash, with the linear solve reporting Linear solve did not converge due to DIVERGED_PC_FAILED iterations 0 PC failed due to FACTOR_OUTMEMORY and the non-linear solve subsequently reporting Nonlinear solve did not converge due to DIVERGED_FNORM_NAN iterations 0. I don't believe that this really a memory issue, when looking at my memory usage there is a decent bit available when the solver starts to report PC failed due to FACTOR_OUTMEMORY and #23274 references that lu often reports this even when it is simply failing.\nThis failure occurs quite late into the simulation and there are no obvious issues when looking at the solution in Paraview.\nI looked at the techniques used to resolve the issues in #22425 but adding off_diagonals_in_auto_scaling = true only resulted in Nonlinear solve did not converge due to DIVERGED_FNORM_NAN iterations 0occurring much faster than without it. I have also tried limiting the maximum time step taken with my adaptive time stepper but when the mixing profile develops to a similar point as without it I experience the same sort of crash.\nInput can be found here https://github.com/gsgall/zapdos/blob/marias_jet/jet_fluid_only/mixing_helium_air.i\nBelow I have included the final output before my dt begins to start cutting until it fails\n\nTime Step 450, time = 0.0228275, dt = 0.0005\n\nPerforming automatic scaling calculation\n\n 0 Nonlinear |R| = 2.246228e-03\n      0 Linear |R| = 2.246228e-03\n      1 Linear |R| = 2.767535e-08\n      2 Linear |R| = 1.291543e-17\n 1 Nonlinear |R| = 1.915105e-05\n      0 Linear |R| = 1.915105e-05\n      1 Linear |R| = 3.437917e-09\n      2 Linear |R| = 4.502965e-20\n 2 Nonlinear |R| = 3.476576e-05\n      0 Linear |R| = 3.476576e-05\n      1 Linear |R| = 5.903443e-16\n 3 Nonlinear |R| = 1.042973e-04\n      0 Linear |R| = 1.042973e-04\n      1 Linear |R| = 2.562989e-22\n 4 Nonlinear |R| = 1.129887e-04\n      0 Linear |R| = 1.129887e-04\n      1 Linear |R| = 1.537833e-23\n 5 Nonlinear |R| = 1.260259e-04\n      0 Linear |R| = 1.260259e-04\n      1 Linear |R| = 1.238041e-24\n 6 Nonlinear |R| = 5.649435e-05\n      0 Linear |R| = 5.649435e-05\n      1 Linear |R| = 3.097355e-26\n 7 Nonlinear |R| = 8.256867e-05\n      0 Linear |R| = 8.256867e-05\n      1 Linear |R| = 3.666786e-20\n 8 Nonlinear |R| = 7.822295e-05\n      0 Linear |R| = 7.822295e-05\n      1 Linear |R| = 1.532815e-26\n 9 Nonlinear |R| = 3.042004e-05\n      0 Linear |R| = 3.042004e-05\n      1 Linear |R| = 1.030051e-26\n10 Nonlinear |R| = 2.607432e-05\n      0 Linear |R| = 2.607432e-05\n      1 Linear |R| = 6.883952e-28\n11 Nonlinear |R| = 2.607432e-05\n      0 Linear |R| = 2.607432e-05\n      1 Linear |R| = 7.123209e-27\n12 Nonlinear |R| = 7.822295e-05\n      0 Linear |R| = 7.822295e-05\n      1 Linear |R| = 5.734877e-27\n13 Nonlinear |R| = 5.214863e-05\n      0 Linear |R| = 5.214863e-05\n      1 Linear |R| = 4.477586e-27\n14 Nonlinear |R| = 1.738288e-05\n      0 Linear |R| = 1.738288e-05\n      1 Linear |R| = 8.650959e-27\n15 Nonlinear |R| = 8.691439e-06\nNonlinear solve did not converge due to DIVERGED_MAX_IT iterations 15\n Solve Did NOT Converge!\n  Finished Solving                                                                       [ 37.22 s] [  345 MB]\nAborting as solve did not converge\n\nSolve failed, cutting timestep.\n\nTime Step 450, time = 0.0225775, dt = 0.00025\n\nPerforming automatic scaling calculation\n\n 0 Nonlinear |R| = 9.077309e-02\n      0 Linear |R| = 9.077309e-02\n      1 Linear |R| = 1.834745e-04\n      2 Linear |R| = 1.741485e-16\n 1 Nonlinear |R| = 1.815283e-01\n      0 Linear |R| = 1.815283e-01\n      1 Linear |R| = 1.917281e-09\n 2 Nonlinear |R| = 2.463599e-01\n      0 Linear |R| = 2.463599e-01\n      1 Linear |R| = 4.083445e-16\n 3 Nonlinear |R| = 2.074610e-01\n      0 Linear |R| = 2.074610e-01\n      1 Linear |R| = 1.019659e-20\n 4 Nonlinear |R| = 1.555957e-01\n      0 Linear |R| = 1.555957e-01\n      1 Linear |R| = 8.905297e-22\n 5 Nonlinear |R| = 4.408545e-01\n      0 Linear |R| = 4.408545e-01\n      1 Linear |R| = 1.957787e-16\n 6 Nonlinear |R| = 3.630567e-01\n      0 Linear |R| = 3.630567e-01\n      1 Linear |R| = 5.307043e-24\n 7 Nonlinear |R| = 9.602145e-16\n Solve Converged!\n  Finished Solving                                                                       [ 21.03 s] [  343 MB]\n\nOutlier Variable Residual Norms:\n  w_he: 9.251459e-16\n\nPostprocessor Values:\n+----------------+-------------------+\n| time           | pressure_integral |\n+----------------+-------------------+\n:                :                   :\n|   1.582753e-02 |     -6.352747e-22 |\n|   1.632753e-02 |     -2.964615e-21 |\n|   1.682753e-02 |     -6.988022e-21 |\n|   1.732753e-02 |     -6.352747e-22 |\n|   1.782753e-02 |     -1.270549e-21 |\n|   1.832753e-02 |     -2.329341e-21 |\n|   1.882753e-02 |     -2.541099e-21 |\n|   1.932753e-02 |      0.000000e+00 |\n|   1.982753e-02 |      2.117582e-21 |\n|   2.032753e-02 |     -8.470329e-22 |\n|   2.082753e-02 |      4.658681e-21 |\n|   2.132753e-02 |      2.964615e-21 |\n|   2.182753e-02 |     -8.470329e-22 |\n|   2.232753e-02 |     -1.482308e-21 |\n|   2.257753e-02 |      0.000000e+00 |\n+----------------+-------------------+\n\n\nScalar Variable Values:\n+----------------+----------------+\n| time           | lambda         |\n+----------------+----------------+\n:                :                :\n|   1.582753e-02 |  -1.168477e-01 |\n|   1.632753e-02 |  -1.168563e-01 |\n|   1.682753e-02 |  -1.168650e-01 |\n|   1.732753e-02 |  -1.168735e-01 |\n|   1.782753e-02 |  -1.168819e-01 |\n|   1.832753e-02 |  -1.168900e-01 |\n|   1.882753e-02 |  -1.168978e-01 |\n|   1.932753e-02 |  -1.169053e-01 |\n|   1.982753e-02 |  -1.169124e-01 |\n|   2.032753e-02 |  -1.169191e-01 |\n|   2.082753e-02 |  -1.169253e-01 |\n|   2.132753e-02 |  -1.169311e-01 |\n|   2.182753e-02 |  -1.169363e-01 |\n|   2.232753e-02 |  -1.169411e-01 |\n|   2.257753e-02 |  -1.169426e-01 |\n+----------------+----------------+\n\nSteady-State Relative Differential Norm: 0.602031\n\nTime Step 451, time = 0.0228275, dt = 0.00025\n\nPerforming automatic scaling calculation\n\n 0 Nonlinear |R| = 1.262764e-03\n      0 Linear |R| = 1.262764e-03\n  Linear solve did not converge due to DIVERGED_PC_FAILED iterations 0\n                 PC failed due to FACTOR_OUTMEMORY \nNonlinear solve did not converge due to DIVERGED_FNORM_NAN iterations 0\n Solve Did NOT Converge!\n  Finished Solving                                                                       [  5.08 s] [  351 MB]\nAborting as solve did not converge\n\nSolve failed, cutting timestep.\n\nTime Step 451, time = 0.0227025, dt = 0.000125\n\nPerforming automatic scaling calculation\n\nI have also included the solution of the gas fraction at the point when the solution has failed.",
          "url": "https://github.com/idaholab/moose/discussions/25820",
          "updatedAt": "2023-10-26T17:02:51Z",
          "publishedAt": "2023-10-23T20:08:08Z",
          "category": {
            "name": "Q&A General"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "GiudGiud"
                  },
                  "bodyText": "Hello\nIndeed, FACTOR_OUTMEMORY  is often reported for  non-memory related reasons.\nSince your solver takes you quite far already, I would make sure you have a checkpoint before it crashes, then try to restart from there and tweak the solver options.\nI wonder if the fixed factor shift is enough for example. Or if mumps can succeed where superlu_dist crashes.\nGuillaume",
                  "url": "https://github.com/idaholab/moose/discussions/25820#discussioncomment-7364291",
                  "updatedAt": "2023-10-24T00:25:06Z",
                  "publishedAt": "2023-10-24T00:25:06Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "gsgall"
                          },
                          "bodyText": "I have tried these suggestions with some positive results but my simulation is still not fully reaching the steady state.\nIncreasing the fixed factor shift by an order of magnitude helped the simulation progress but not very significantly. Similar results were seen when changing the solve type to mumps.\nOf all the things I have attempted the one that yielded the most progress was to change the order of the mass fraction variable from SECOND to FIRST.\nCurrently I have stared a solve that restarts from the point where a previous solve failed but with an increase in the fixed factor shift. This has allowed the simulation to progress slightly more but the adaptive time stepper will periodically increase to about 1e-3 and then crash to 1e-12 and this seems to continue with the solution changing very slowly. I don't think this is because it close to the steady state. Based on some previous similar work I completed I have a solid idea of what the steady state solution should look like and this solve needs more time to evolve to the true steady state.",
                          "url": "https://github.com/idaholab/moose/discussions/25820#discussioncomment-7373988",
                          "updatedAt": "2023-10-24T19:46:53Z",
                          "publishedAt": "2023-10-24T19:46:52Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "Looks like you have some scalar advection by the INSAD velocities\n@lindsayad is conservativeAdvection the right kernels for this? Should there be SUPG terms?\nI am not a big fan of the average value constraint btw. I think it hurts the numerical solve.\nI wonder if we can use the NSFVPressurePin, or a new NSPressure user object to achieve the same goal for FE Navier Stokes",
                          "url": "https://github.com/idaholab/moose/discussions/25820#discussioncomment-7374302",
                          "updatedAt": "2023-10-24T20:25:05Z",
                          "publishedAt": "2023-10-24T20:25:05Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "lindsayad"
                          },
                          "bodyText": "In theory if the scalar transport is expect to be advection dominated, then you should be applying SUPG stabilization. The problem is that we only have readily available kernels for SUPG stabilization of energy advection, not for passive scalar advection. Would be a good contribution!\nFor the immediate issue I would see what happens with -pc_factor_mat_solver_type superlu_dist or -pc_factor_mat_solver_type strumpack",
                          "url": "https://github.com/idaholab/moose/discussions/25820#discussioncomment-7374533",
                          "updatedAt": "2023-10-24T20:57:47Z",
                          "publishedAt": "2023-10-24T20:57:46Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "gsgall"
                          },
                          "bodyText": "I tried the strumpack option and had been using the superlu_dist but that didn't really make an impact.\nBased on what @GiudGiud said about the mean value zero method hurting the numerical solve I modified my fluid solve to use a pinned pressure node similar to the method in modules/navier_stokes/test/tests/finite_element/ins/RZ_cone/rz_cone_by_parts_steady_nobcbc.i this has resolved the issue I was having and I was able to achieve a steady state solve.\n@lindsayad Would you have any recommendations for literature on SUPG stabilization for passive scalar advection that I can look into?",
                          "url": "https://github.com/idaholab/moose/discussions/25820#discussioncomment-7381324",
                          "updatedAt": "2023-10-25T13:12:36Z",
                          "publishedAt": "2023-10-25T13:12:35Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "lindsayad"
                          },
                          "bodyText": "You've had problems in the past with a pressure pin creating artifacts in the solution. Did you experience any of that here?",
                          "url": "https://github.com/idaholab/moose/discussions/25820#discussioncomment-7384263",
                          "updatedAt": "2023-10-25T18:03:28Z",
                          "publishedAt": "2023-10-25T18:03:27Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "I was pitching a postprcessing pressure pin btw. Constraint pressure pin is not my favorite either, but whatever works",
                          "url": "https://github.com/idaholab/moose/discussions/25820#discussioncomment-7384293",
                          "updatedAt": "2023-10-25T18:07:53Z",
                          "publishedAt": "2023-10-25T18:07:52Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "lindsayad"
                          },
                          "bodyText": "There's not much special about passive scalar advection. Indeed, scalar advection was the first type of problem SUPG was developed for. I'm not finding the original paper on it, but this was probably one of the first few papers on SUPG (Thomas Hughes was the original creator of the method).\nYou could just follow what is done for temperature for the passive scalar, see the INSADEnergy kernels and the INSAD3Eqn and INSADStabilized3Eqn materials",
                          "url": "https://github.com/idaholab/moose/discussions/25820#discussioncomment-7384307",
                          "updatedAt": "2023-10-25T18:10:00Z",
                          "publishedAt": "2023-10-25T18:10:00Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "lindsayad"
                          },
                          "bodyText": "I was pitching a postprcessing pressure pin btw\n\nThe issue with this treatment is that in general a factorization-based preconditioner will not work with it (although exceptions may exist)",
                          "url": "https://github.com/idaholab/moose/discussions/25820#discussioncomment-7384315",
                          "updatedAt": "2023-10-25T18:11:06Z",
                          "publishedAt": "2023-10-25T18:11:06Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "gsgall"
                          },
                          "bodyText": "I did end up running into some artifacts with the pressure pin again. The first case I ran with a pressure pin didn't show any artifacts in the solution. However, the second geometry I am working on, it's the same as the first but the distance from the tip of the outlet of the jet to the target is increased is now failing in the mixing solve due to similar artifacts.\nI will start to also take a look at NSFVPressurePin and try to apply something similar for my FE solve.",
                          "url": "https://github.com/idaholab/moose/discussions/25820#discussioncomment-7384701",
                          "updatedAt": "2023-10-25T19:06:25Z",
                          "publishedAt": "2023-10-25T19:06:24Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "gsgall"
                          },
                          "bodyText": "I'll also take a look at that paper. Thank you for sharing!",
                          "url": "https://github.com/idaholab/moose/discussions/25820#discussioncomment-7384706",
                          "updatedAt": "2023-10-25T19:07:08Z",
                          "publishedAt": "2023-10-25T19:07:07Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "function of a variable",
          "author": {
            "login": "tqcthai"
          },
          "bodyText": "Dear all,\nI know that functions in moose depend only on spatial position and time: f(x,y,z,t). How can I define a function of a variable?\nI need to use it for AMR and this way doesn't work.\n``\n[Variables]\n  [c]\n  order = FIRST\n  family = LAGRANGE\n  []\n[]\n\n[Functions]\n  [I1]\n  type = ParsedFunction\n  expression = min(c,0.1)\n  []\n[]\n\n[Adaptivity]\n  marker = errorfrac\n  steps = 2\n  max_h_level = 5\n  [Indicators]\n    [error]\n      type = AnalyticalIndicator\n      variable = c\n      function = I1\n     #function = min(c, 0.1)\n    []\n  []\n  [Markers]\n    [errorfrac]\n      type = ErrorFractionMarker\n      coarsen = 0.0\n      indicator = error\n      refine = 1e-7\n    []\n  []\n[]`                  \n```",
          "url": "https://github.com/idaholab/moose/discussions/25812",
          "updatedAt": "2023-10-26T16:27:19Z",
          "publishedAt": "2023-10-22T23:07:06Z",
          "category": {
            "name": "Q&A Modules: General"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "GiudGiud"
                  },
                  "bodyText": "Hello\nIt likely should be a material property\nFor output only, you can also use an auxiliary variable.\nGuillaume",
                  "url": "https://github.com/idaholab/moose/discussions/25812#discussioncomment-7353378",
                  "updatedAt": "2023-10-22T23:08:06Z",
                  "publishedAt": "2023-10-22T23:08:06Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "tqcthai"
                          },
                          "bodyText": "Hi GuidGuid,\nI' ve tried\n[Functions]\n  [I1]\n  type = ParsedFunction\n  expression = min(elastic_energy,0.1)\n  []\n[]\n\n[Adaptivity]\n  marker = errorfrac\n  steps = 2\n  max_h_level = 4\n  [Indicators]\n    [error]\n      type = AnalyticalIndicator\n      variable = c\n      function = I1\n    []\n  []\n  [Markers]\n    [errorfrac]\n      type = ErrorFractionMarker\n      coarsen = 0.0\n      indicator = error\n      refine = 1e-7\n    []\n  []\n[]`\n\n\nwhere elastic_energy is a material property. This is the error message I got:\nERROR: FunctionParser is unable to parse expression: min(elastic_energy,0.1)\nSyntax error: Unknown identifier",
                          "url": "https://github.com/idaholab/moose/discussions/25812#discussioncomment-7385426",
                          "updatedAt": "2023-10-25T20:25:13Z",
                          "publishedAt": "2023-10-25T20:24:17Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "cant do that. A Parsed function can only be dependent on x y z t, postprocessors and other functions\nyou ll have to use a material property or an auxkernel (that fills an auxvariable) to do this operation.\nAn aux-variable can be used as an indicator",
                          "url": "https://github.com/idaholab/moose/discussions/25812#discussioncomment-7385441",
                          "updatedAt": "2023-10-25T20:30:46Z",
                          "publishedAt": "2023-10-25T20:25:33Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "tqcthai"
                          },
                          "bodyText": "Hello,\nI made it like this\n[Adaptivity]\n  marker = errorfrac\n  max_h_level = 4\n  [Indicators]\n    [error]\n      type = AnalyticalIndicator\n      variable = 'c_indicator'\n      function = '0'\n    []\n  []\n  [Markers]\n    [errorfrac]\n      type = ErrorFractionMarker\n       indicator = error\n      refine = 1e-3\n    []\n  []\n[]\n\n[AuxVariables]\n  [c_indicator]\n  []\n  [resid_x]\n  []\n[]\n[Material]\n  ....\n  output_properties = 'c_indicator'\n[]\n[Modules/TensorMechanics/Master]\n  [all]\n      ...\n     save_in = 'resid_x'\n  []\n[]\n\nI specified function of c_indicator inside the material file. Although there is no error in running, the value of c_indicator in the output is always zero. When I change the indicator as resid_x which is from the tensor mechanics module output, it works. I wonder how to make the output of c_indicator from materials block can be recognized as resid_x?",
                          "url": "https://github.com/idaholab/moose/discussions/25812#discussioncomment-7386579",
                          "updatedAt": "2023-10-25T23:53:26Z",
                          "publishedAt": "2023-10-25T23:53:26Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "Use a MaterialRealAux to move a material property to an auxiliary variable.\nwhat you have now is designed for the output to Exodus file of matrial properties",
                          "url": "https://github.com/idaholab/moose/discussions/25812#discussioncomment-7386735",
                          "updatedAt": "2023-10-26T00:21:11Z",
                          "publishedAt": "2023-10-26T00:21:11Z",
                          "isAnswer": true
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "tqcthai"
                          },
                          "bodyText": "It works. Thank you so much.",
                          "url": "https://github.com/idaholab/moose/discussions/25812#discussioncomment-7394939",
                          "updatedAt": "2023-10-26T16:27:20Z",
                          "publishedAt": "2023-10-26T16:27:19Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "Homogenisation MasterAction Issue",
          "author": {
            "login": "MarloF12"
          },
          "bodyText": "Dear Moose Developers,\nI am having quite a bit of trouble trying to utilise the tensor mechanics master action for homogenisation constraints in order to calculate the effective material properties of an RVE.\nMy issue seems to be a lack of convergence or slow convergence when I make the mesh finer (anything as fine or finer than the \"finer_mesh\" attached), running these on the hpc using the input file \"input_file.i\" attached, results in the solver hitting the max number of linear iterations (set to 10,000), results in file called \"Finer_Mesh_Output_console\". When using a coarser mesh, it solves no problem in 18 seconds with the same processing power(\"Coarser_Mesh_Output_console\" file). As you can see from the images there isn't much difference in the fineness of the mesh (Total Coarser Mesh elements = 7158, Total Finer Mesh elements = 11661)\n\n\n^Finer Mesh and Coarser Mesh Respectively^\nI have tried using a newton solve, messing around with the preconditioning, changing the petsc options, checking the meshes boundary condition nodes of the mesh, following the Troubleshooting Failed Solves MOOSE web page (where using Finite Differencing Preconditioning seemed to have fixed it implying there is an issue with the Jacobian but I was unable to run the analyzeJacobian python debugger as even with a very coarse mesh it took too long to run). I have attached the script and results using FDP (\"FDP_Finer_Mesh_Output_console\" file). Although using FDP fixes the issue, it is not my preferred way of fixing the issue as it's computationally expensive and I would like to understand the underlying issue. I have also tried to replicate the implementation used in issue#25408 (which uses a newton steady state solver) except applying it in 3D, this led to the non-linear solver not converging unless the mesh was 'alot' coarser.\nI have attached all files including meshes to a public repo which can be accessed here.\nI'd like to input a finer mesh so I can get more accurate effective material property results out, any ideas on what I am doing wrong here?\nMany thanks,\nMarlo",
          "url": "https://github.com/idaholab/moose/discussions/25861",
          "updatedAt": "2023-10-26T15:54:21Z",
          "publishedAt": "2023-10-26T15:48:15Z",
          "category": {
            "name": "Q&A Modules: Solid mechanics"
          },
          "comments": {
            "edges": []
          }
        }
      },
      {
        "node": {
          "title": "Bending and Tensile Stress Test",
          "author": {
            "login": "sreejitsarmac"
          },
          "bodyText": "How would you, from scratch, create a beam or a bar, mesh it, and find the bending deformation, bending stress, tensile deformation, and tensile stress? I'm an absolute newbie to MOOSE so please give a very detailed explanation with code. Thanks!",
          "url": "https://github.com/idaholab/moose/discussions/25851",
          "updatedAt": "2023-10-25T18:37:48Z",
          "publishedAt": "2023-10-25T18:36:40Z",
          "category": {
            "name": "Q&A Getting Started"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "GiudGiud"
                  },
                  "bodyText": "There should be an example somewhere. Can you look in the tensor mechanics module?",
                  "url": "https://github.com/idaholab/moose/discussions/25851#discussioncomment-7384520",
                  "updatedAt": "2023-10-25T18:37:48Z",
                  "publishedAt": "2023-10-25T18:37:48Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": []
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "Trouble installing raccoon/moose",
          "author": {
            "login": "ihernandezimbert"
          },
          "bodyText": "Hi everyone,\nI am getting multiple errors once reaching the make step in moose for installing raccoon. This is what the first few look like and I am not sure how to fix/work around this.\n/Users/iranhernandezimbert/projects/raccoon/moose/framework/src/utils/PetscDMMoose.C:420:22: error: format specifies type 'long long' but the argument has type 'std::vector<std::pair<std::string, std::string>>::size_type' (aka 'unsigned long') [-Werror,-Wformat]\n                     contacts.size(),\n                     ^~~~~~~~~~~~~~~~\n/Users/iranhernandezimbert/mambaforge3/envs/moose/libmesh/include/libmesh/petsc_macro.h:95:27: note: expanded from macro 'LIBMESH_SETERRQ2'\n# define LIBMESH_SETERRQ2 SETERRQ\n                          ^\n/Users/iranhernandezimbert/mambaforge3/envs/moose/include/petscerror.h:57:127: note: expanded from macro 'SETERRQ'\n    PetscErrorCode ierr_seterrq_petsc_ = PetscError(comm, __LINE__, PETSC_FUNCTION_NAME, __FILE__, ierr, PETSC_ERROR_INITIAL, __VA_ARGS__); \\\n\nReally appreciate the help!",
          "url": "https://github.com/idaholab/moose/discussions/25614",
          "updatedAt": "2023-10-25T14:54:12Z",
          "publishedAt": "2023-09-28T12:31:03Z",
          "category": {
            "name": "Q&A Getting Started"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "GiudGiud"
                  },
                  "bodyText": "Hello\nwe haven\u2019t seen that one before. Which platform are you installing on?\nCan you run the diagnostics script in moose/scripts?",
                  "url": "https://github.com/idaholab/moose/discussions/25614#discussioncomment-7133771",
                  "updatedAt": "2023-09-28T12:33:58Z",
                  "publishedAt": "2023-09-28T12:33:57Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "author": {
                    "login": "cticenhour"
                  },
                  "bodyText": "Racoon is using an older version of MOOSE (3 weeks ago), prior to the recent PETSc update. If you are following our conda instructions, you would be downloading the most recent set of packages, which doesn't work perfectly with that version of MOOSE.\nI recommend that you activate your MOOSE environment in conda and perform the following command:\nmamba install moose-dev=2023.08.29=build_0\n\nThis would install a set of packages aligned with the version of MOOSE currently used by Racoon.",
                  "url": "https://github.com/idaholab/moose/discussions/25614#discussioncomment-7135306",
                  "updatedAt": "2023-09-28T14:44:58Z",
                  "publishedAt": "2023-09-28T14:44:57Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "cticenhour"
                          },
                          "bodyText": "After getting the packages in place, I would then perform a clean of your MOOSE repository:\ncd /Users/iranhernandezimbert/projects/raccoon/moose\ngit clean -xfd\n\nIn order to clean out any old build artifacts that could cause erroneous follow-on issues.",
                          "url": "https://github.com/idaholab/moose/discussions/25614#discussioncomment-7135319",
                          "updatedAt": "2023-09-28T14:46:40Z",
                          "publishedAt": "2023-09-28T14:46:40Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "ihernandezimbert"
                          },
                          "bodyText": "Thank you - that did it!",
                          "url": "https://github.com/idaholab/moose/discussions/25614#discussioncomment-7382432",
                          "updatedAt": "2023-10-25T14:53:57Z",
                          "publishedAt": "2023-10-25T14:53:57Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "Internal Energy Value to a Postprocessor?",
          "author": {
            "login": "Vandenbg"
          },
          "bodyText": "Hello, I am looking for a way to output the internal energy to a post processor. This kernel calculates the internal energy but I am not sure how to connect this with a post processor.\n[kernels]\n  [heat_ie]\n    type = HeatConductionTimeDerivative\n    variable = temperature\n  []\n...\n\nInternal energy is not a material property or variable. I thought it would be relatively simple, however, I haven't found a solution. Any help would be appreciated.",
          "url": "https://github.com/idaholab/moose/discussions/25843",
          "updatedAt": "2023-10-25T13:24:16Z",
          "publishedAt": "2023-10-24T23:03:15Z",
          "category": {
            "name": "Q&A General"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "GiudGiud"
                  },
                  "bodyText": "Hello\nInternal energy depends on temperature so it s more of a field than a single value.\nDo you want to integrate it over a subdomain?\nGuillaume",
                  "url": "https://github.com/idaholab/moose/discussions/25843#discussioncomment-7375193",
                  "updatedAt": "2023-10-24T23:04:54Z",
                  "publishedAt": "2023-10-24T23:04:54Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "Vandenbg"
                          },
                          "bodyText": "Yes that would be ideal.",
                          "url": "https://github.com/idaholab/moose/discussions/25843#discussioncomment-7380833",
                          "updatedAt": "2023-10-25T12:28:09Z",
                          "publishedAt": "2023-10-25T12:28:08Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "are rho and cp constant or are they temperature-dependent (so kind of fields even if you have not defined them) as well?",
                          "url": "https://github.com/idaholab/moose/discussions/25843#discussioncomment-7380888",
                          "updatedAt": "2023-10-25T12:33:04Z",
                          "publishedAt": "2023-10-25T12:32:45Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "Vandenbg"
                          },
                          "bodyText": "They are temperature dependent, I haven't explicitly defined them. I can output them as material properties.",
                          "url": "https://github.com/idaholab/moose/discussions/25843#discussioncomment-7380974",
                          "updatedAt": "2023-10-25T12:42:47Z",
                          "publishedAt": "2023-10-25T12:42:46Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "You have two options:\nmake a material that defines the internal energy material property and output that\nor\nuse MaterialRealAux to output rho and cp to auxiliary variable then a ParsedAux to multiply all those.\nThe second one will be more approximate (averages rho, cp to elements instead of integrating rho cp T directly)",
                          "url": "https://github.com/idaholab/moose/discussions/25843#discussioncomment-7381064",
                          "updatedAt": "2023-10-25T12:51:32Z",
                          "publishedAt": "2023-10-25T12:51:32Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "this has been done for HeatStructure components in the TH module but you are not using that",
                          "url": "https://github.com/idaholab/moose/discussions/25843#discussioncomment-7381070",
                          "updatedAt": "2023-10-25T12:52:01Z",
                          "publishedAt": "2023-10-25T12:52:00Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "Vandenbg"
                          },
                          "bodyText": "Thank you, I'll give this a try. I will look at the TH module for reference.",
                          "url": "https://github.com/idaholab/moose/discussions/25843#discussioncomment-7381458",
                          "updatedAt": "2023-10-25T13:24:08Z",
                          "publishedAt": "2023-10-25T13:24:08Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "Auxkernel and postprocessor dependancy / run order",
          "author": {
            "login": "errikosMFB"
          },
          "bodyText": "Hi all,\nBelow is the input file for a generic example where I'm incrementing an auxvariable field by a value found in a postprocessor.\nI want to perform the following calculations on timestep_end, in order:\n\nSet the value of auxvariable \"vaux\" using an auxkernel\nCalculate the average of vaux using a postprocessor (\"vaux_avg\")\nAdd the two in another auxkernel and save to \"vaux2\"\n\n[Mesh]\n  [generated]\n    type = GeneratedMeshGenerator\n    dim = 2\n    xmin = 0\n    xmax = 1\n    ymin = 0\n    ymax = 1\n    nx = 40\n    ny = 40\n    elem_type = QUAD4\n  []\n[]\n\n\n[Variables]\n  [u]\n    # Dummy nonlinear system\n    family = LAGRANGE\n    order = FIRST\n  []\n[]\n\n[Kernels]\n  [null]\n    type = NullKernel\n    variable = u\n  []\n[]\n\n[AuxVariables]\n  [vaux]\n    family = MONOMIAL\n    order = CONSTANT\n  []\n  [vaux2]\n    family = MONOMIAL\n    order = CONSTANT\n  []\n[]\n\n[AuxKernels]\n  [k1]\n    # Sets the value of variable vaux\n    type = ConstantAux\n    variable = vaux\n    value = 0.1\n    execute_on = 'timestep_end'\n  []\n  [k2coupledtopp]\n    # Custom auxkernel. Simply couples to an auxvariable \"vaux\" and a postprocessor \"vaux_pp\" and returns the sum of the two\n    type = TestPPAux\n    variable = vaux2\n    vaux = vaux\n    vaux_pp = vaux_avg\n    execute_on = 'timestep_end'\n  []\n[] # AuxKernels\n\n[Preconditioning]\n  [SMP]\n    type = SMP\n    full = true\n  []\n[]\n\n[Executioner]\n  type = Transient\n  solve_type = 'NEWTON' \n  # line_search = 'none'\n  num_steps = 2\n  dt = 1.0\n\n  petsc_options_iname = '-pc_type -ksp_type'\n  petsc_options_value = 'lu preonly'\n[]\n\n[Postprocessors]\n  [vaux_avg]\n    type = ElementAverageValue\n    variable = vaux\n    execute_on = 'timestep_end'\n  []\n  [vaux2_avg]\n    type = ElementAverageValue\n    variable = vaux2\n    execute_on = 'timestep_end'\n  []\n[]\n\n[Outputs]\n  execute_on = 'timestep_end'\n  exodus = true\n[]\n\n\n[Debug]\n  show_execution_order = 'timestep_end'\n[]\n\nWe expect vaux to have a value of 0.1 and vaux2 to have a value of 0.2. However, at the end of the first timestep, vaux2 holds a value of 0.1 (and vaux holds a value of 0.0!):\nPostprocessor Values:\n+----------------+----------------+----------------+\n| time           | vaux2_avg      | vaux_avg       |\n+----------------+----------------+----------------+\n|   0.000000e+00 |   0.000000e+00 |   0.000000e+00 |\n|   1.000000e+00 |   1.000000e-01 |   0.000000e+00 |\n+----------------+----------------+----------------+\n\nThe debug output for the timestep_end order is as follows:\n[DBG] Computing elemental user objects on TIMESTEP_END\n[DBG] Execution order of objects types on each element then its sides:\n[DBG] - element user objects\n[DBG] - domain user objects\n[DBG] - element user objects contributing to the Jacobian\n[DBG] - side user objects\n[DBG] - domain user objects executing on sides\n[DBG] - side user objects contributing to the Jacobian\n[DBG] - internal side user objects\n[DBG] - domain user objects executing on internal sides\n[DBG] - interface user objects\n[DBG] - domain user objects executing at interfaces\n[DBG] Ordering of User Objects on block 0\n[DBG] Executing ElementUserObject on TIMESTEP_END\n[DBG] Order of execution:\n[DBG] vaux_avg\n                             \n[DBG] Only user objects active on local element/sides are executed\n[DBG] Executing auxiliary kernels on elements on TIMESTEP_END\n[DBG] Ordering of AuxKernels on block 0\n[DBG] k1 k2coupledtopp\n[DBG] Computing elemental user objects on TIMESTEP_END\n[DBG] Ordering of User Objects on block 0\n[DBG] Executing ElementUserObject on TIMESTEP_END\n[DBG] Order of execution:\n[DBG] vaux2_avg\n                             \n[DBG] Only user objects active on local element/sides are executed\n\nIt seems that the postprocessor \"vaux_avg\" runs before the value of the variable \"vaux\" is set in the \"k1\" kernel. So it stores the initial value (0.0), and not the updated value (0.1).\nI believe this is because in each \"execution block\" in moose, auxkernels run before postprocessors (as seen in the debug output above). Since an auxkernel depends on a PP value, a seperate block just with the PP is created and put before that one. Moose does not move the \"k1\" kernel to the first block as it does not see any dependancy between the postprocessor \"vaux_avg\" and the auxkernel \"k1\".\nIs there any way for me to manipulate the behaviour to get the order that I want?\n(I cannot use ICs to set the value of vaux, and this must all be done at timestep_end, because this is a simplification of the real code I'm working with, which has more complicated calculations than these).\nThanks!",
          "url": "https://github.com/idaholab/moose/discussions/25845",
          "updatedAt": "2023-11-02T16:34:35Z",
          "publishedAt": "2023-10-25T09:24:49Z",
          "category": {
            "name": "Q&A General"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "GiudGiud"
                  },
                  "bodyText": "Hello\n\nIs there any way for me to manipulate the behaviour to get the order that I want?\n\nyup that s what you're going to have to do.\nI would recommend running:\nvaux and vaux_avg on linear (or nonlinear)\nvaux2 on timestep2\nthat way the first two are going to be updated all the time and vaux2 can come in at any point and get the right value.\nIf you have multiapps there's other execute_on flags we can try.\nGuillaume",
                  "url": "https://github.com/idaholab/moose/discussions/25845#discussioncomment-7380760",
                  "updatedAt": "2023-10-25T12:22:14Z",
                  "publishedAt": "2023-10-25T12:22:13Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "errikosMFB"
                          },
                          "bodyText": "Hi Guillaume,\nThanks for the answer. I would like to not have to run vaux/vaux_avg on linear as they can be computationally expensive.\nI do have multiapps. The main app does this and then passes vaux2 to a FullSolveMultiapp that executes on timestep_end. The subapp then updates some iterative field updates and transfers back to the main app.\nAre there any flags between timestep_end and whenever the data gets transfered to the subapp that I could use? I am only aware of the ones found here : [https://mooseframework.inl.gov/source/interfaces/SetupInterface.html]https://mooseframework.inl.gov/source/interfaces/SetupInterface.html",
                          "url": "https://github.com/idaholab/moose/discussions/25845#discussioncomment-7380976",
                          "updatedAt": "2023-10-25T12:53:22Z",
                          "publishedAt": "2023-10-25T12:43:02Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "ah no there's not.\nThere's MULTIAPP_FIXED_POINT_END after TIMESTEP_END.\nYou could do:\nvaux on NONLINEAR\nvaux_avg on TIMESTEP_END with force_preaux = true\nvaux2 on TIMESTEP_END",
                          "url": "https://github.com/idaholab/moose/discussions/25845#discussioncomment-7381171",
                          "updatedAt": "2023-10-25T13:00:06Z",
                          "publishedAt": "2023-10-25T13:00:06Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "Seeking Guidance on Creating a Mapping from Grain ID to Container_Type Element ID",
          "author": {
            "login": "PengWei97"
          },
          "bodyText": "Dear @permcody and @laagesen,\nI hope this message finds you well. I have a question regarding a specific implementation in my project, and I would greatly appreciate your expertise and guidance on this matter.\nIn my current project, I'm working on creating a mapping structure that associates Grain IDs with container_type Element IDs. This mapping is similar to the existing '_entity_var_to_features' structure, and it is a crucial component for the functionality I am developing.\nHowever, I've encountered a challenge related to the 'FeatureData' structure. I've noticed that the data member 'container_type _local_ids' is only maintained on the local processor. Therefore, when executing parallel computations, I do not have access to all the element IDs contained within 'feature[i]._local_ids'. This limitation has brought up the need to introduce a new data member, which I'm thinking of naming 'container_type _global_ids' within the 'FeatureData' structure. This new data member would be used to store all the Element IDs associated with a particular feature or grain.\nMy question is twofold:\n\n\nIs it possible to add a new data member, 'container_type _global_ids,' to the 'FeatureData' structure for storing all the Element IDs associated with a feature? If so, what would be the most efficient way to implement this addition? Of course, I also know that this setting will require huge data to be transmitted between ranks and cause greater memory consumption.\n\n\nHow can I effectively merge the '_local_ids' from various processors into a single '_global_ids' structure, ensuring that I have a comprehensive list of all the Element IDs for each feature, regardless of the processor?\n\n\nI would greatly appreciate any insights, advice, or examples you can provide to help me address this challenge effectively. Your expertise in this matter is invaluable, and your guidance will significantly impact the success of my project.\nThank you in advance for your assistance, and I look forward to your response.\nBest regards,\nwei peng",
          "url": "https://github.com/idaholab/moose/discussions/25807",
          "updatedAt": "2023-10-25T07:55:56Z",
          "publishedAt": "2023-10-21T10:31:42Z",
          "category": {
            "name": "Q&A Modules: Phase field"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "GiudGiud"
                  },
                  "bodyText": "Hello\nFor 2)\n_local_ids is a std::vector<dof_id_type>\nthese are actually very easy (remains expensive if large) to expand on all processes using TIMPI.\nYou simply copy it into your new global container, then use the allgather:\n    _global_ids = _local_ids;\n    _communicator.allgather(_global_ids, /* identical buffer lengths = */ false);\n\nyou just need to make sure this is called right before you need the information\nGuillaume",
                  "url": "https://github.com/idaholab/moose/discussions/25807#discussioncomment-7346361",
                  "updatedAt": "2023-10-21T13:00:53Z",
                  "publishedAt": "2023-10-21T13:00:52Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "PengWei97"
                          },
                          "bodyText": "Hello @GiudGiud,\nThank you for your previous guidance. I greatly appreciate your help. I spent the entire day working on implementing your suggestions, but unfortunately, the issue is not fully resolved.\nFollowing your advice, I initially created a std::vector<std::vector<dof_id_type>> _grain_id_to_entity_ids_maps; to represent _grain_id_to_entity_ids_maps[grain._id] as a vector of entity ids corresponding to grain._id. I temporarily added the following code to GrainTracker::updateFieldInfo():\n_grain_id_to_entity_ids_maps.resize(_feature_sets.size());\n\nfor (const auto & grain : _feature_sets)\n{\n    std::cout << \"grain id: \" << grain._id << std::endl;\n    for (const auto & entity : grain._local_ids) \n    {\n        std::vector<dof_id_type> & entity_ids = _grain_id_to_entity_ids_maps[grain._id];\n        if (std::find(entity_ids.begin(), entity_ids.end(), entity) == entity_ids.end())\n            entity_ids.push_back(entity);\n    }\n}\n\n_communicator.allgather(_grain_id_to_entity_ids_maps);\n\nfor (unsigned int i = 0; i < _grain_id_to_entity_ids_maps.size(); ++i)\n    std::cout << \"grain id after allgather: \" << i << std::endl;\nHowever, I encountered an unexpected issue. When running the code in single-core mode, everything behaves as expected, and the size of _grain_id_to_entity_ids_maps is 6. But when running it on two cores, the size becomes 14, which is problematic. I have included a snippet of the output results.\n\nBest regards,\nwei",
                          "url": "https://github.com/idaholab/moose/discussions/25807#discussioncomment-7350431",
                          "updatedAt": "2023-10-22T10:44:08Z",
                          "publishedAt": "2023-10-22T10:44:08Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "PengWei97"
                          },
                          "bodyText": "Meanwhile, I believe this inconsistency is due to the allgather operation concatenating the _grain_id_to_entity_ids_maps from different rank without properly merging the individual _grain_id_to_entity_ids_maps[grain._id]. To address this, I attempted to create a std::map<unsigned int, std::vector<dof_id_type >>  type named `_var_index_maps, but I encountered a compilation error during the _communicator.allgather(_grain_id_to_entity_ids_maps) operation.\n/home/pw-moose/projects/moose/modules/phase_field/src/postprocessors/GrainTracker.C: In member function 'virtual void GrainTracker::updateFieldInfo()':\n/home/pw-moose/projects/moose/modules/phase_field/src/postprocessors/GrainTracker.C:1592:55: error: no matching function for call to 'libMesh::Parallel::Communicator::allgather(std::map<unsigned int, std::vector<long unsigned int> >&) const'\n 1592 |   _communicator.allgather(_grain_id_to_entity_ids_maps);\nFinally, I feel that there should be a step in GrainTracker or FeatureFloodCount to merge the _feature_sets or other data members on each rank into the primary rank to form a global _feature_sets or others. But unfortunately, I did not find the relevant code in communicateAndMerge(), broadcastAndUpdateGrainData() and updateFieldInfo(). This may be because I don't understand GrainTracker very well, but I'm sure the code should be there.\nIn general, I would greatly appreciate any further guidance or recommendations to address this issue. Your assistance is invaluable.",
                          "url": "https://github.com/idaholab/moose/discussions/25807#discussioncomment-7350460",
                          "updatedAt": "2023-10-22T11:03:56Z",
                          "publishedAt": "2023-10-22T10:52:16Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "Hello\nIf the gathering operation is working well, then you may perform the merging / \"unique\" operation on each rank considering all the data that was gathered. It s not a scalable operation but the communication step is not either\nDid you consider using a set since you want unique data? I m not sure what you need is implemented for _comm.allgather for a set\nGuillaume",
                          "url": "https://github.com/idaholab/moose/discussions/25807#discussioncomment-7350773",
                          "updatedAt": "2023-10-22T12:12:26Z",
                          "publishedAt": "2023-10-22T12:12:26Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "PengWei97"
                          },
                          "bodyText": "Hello,\nI believe the following schematic can help illustrate the dataset I'm trying to merge, which is represented by _grain_id_to_entity_ids_maps.\n\nAs shown in the diagram, let's assume that in a parallel computation, the computational domain containing Gr0 and Gr1 is divided into two parts by the red dashed line, with one part being calculated on Rank 0 and the other on Rank 1. Elements or entities belonging to Gr0 are represented by white dots, and there are three of them on both Rank 0 and Rank 1, with their element IDs stored in _feature_sets[0]._local_ids.\nNow, if only extract the mapping of the element id corresponding to gr0, the challenge is how to ensure that _grain_id_to_entity_ids_maps[0] = [0, 1, 2, 3, 4, 5] instead of _grain_id_to_entity_ids_maps[0] = [0, 1, 2] and _grain_id_to_entity_ids_maps[1] = [3, 4, 5].\nThank you,\nWei Peng",
                          "url": "https://github.com/idaholab/moose/discussions/25807#discussioncomment-7351022",
                          "updatedAt": "2023-10-22T13:13:12Z",
                          "publishedAt": "2023-10-22T13:13:11Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "You should try to do the gather operation on the map\nIf that does not work then do a reduction on a keys and a value vector",
                          "url": "https://github.com/idaholab/moose/discussions/25807#discussioncomment-7351373",
                          "updatedAt": "2023-10-22T14:18:42Z",
                          "publishedAt": "2023-10-22T14:18:41Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "PengWei97"
                          },
                          "bodyText": "Hi @GiudGiud, thank you very much for your further guidance. But I think you may be optimistic that I have the relevant understanding of MPI in moose and MPI itself. In fact, I don\u2019t know much about MPI. Of course, I also tried to learn MPI, but it seemed that what I saw was not the same as what I need to use in moose.\nSo, to be honest,\n\nIf that does not work then do a reduction on a keys and a value vector\n\nI don't know how to do it. In addition, I also look forward to your sharing of learning materials about the use of MPI in moose.\nI set the data type to std::map<unsigned int, std::vector<dof_id_type>> _grain_id_to_entity_ids_maps, and use the following code to run, but unfortunately, of course, when adding the red box selection code , still showing the same error mentioned above.\n\nThank you,\nWei Peng",
                          "url": "https://github.com/idaholab/moose/discussions/25807#discussioncomment-7356833",
                          "updatedAt": "2023-10-23T09:30:51Z",
                          "publishedAt": "2023-10-23T09:30:51Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "Looking at the TIMPI documentation there is no overload for maps of allgather, so that s why you get the error\nhttps://mooseframework.inl.gov/docs/doxygen/timpi/classTIMPI_1_1Communicator.html#af7a4310c8ff9eff4deee15382b4a1a62\n\nIf that does not work then do a reduction on a keys and a value vector\n\nYou can copy the grain ids and entity in separate vectors then gather those.\nOnce you have both on a rank you can work to merge the data\nIf this is for postprocessing purposes, I reckon you do not need allgather, you can get away with a simple gather to rank 0.",
                          "url": "https://github.com/idaholab/moose/discussions/25807#discussioncomment-7358377",
                          "updatedAt": "2023-10-23T12:30:58Z",
                          "publishedAt": "2023-10-23T12:30:57Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "PengWei97"
                          },
                          "bodyText": "I carefully read the link you shared with me and looked at the four defined gather templates. Unfortunately, I did not find that gather can handle such things as gather(0, std::vector & send_data, std::vector<std::vector> & recv_data). In other words, the gather operation can only merge the std::vector data on each rank into std::vector data, and cannot create a dimension based on different ranks to form std::vector. <std::vector> data_ranks;\n\nYou can copy the grain ids and entity in separate vectors then gather those.\n\nAccording to your suggestion, if they are stored separately and then transferred to rank 0, then I think the correspondence between grain id -> element ids will be lost during the transfer process.\nI believe you already have a good understanding of what I intend to implement, and I would greatly appreciate any additional suggestions or perhaps even some sample code.\nwei",
                          "url": "https://github.com/idaholab/moose/discussions/25807#discussioncomment-7359161",
                          "updatedAt": "2023-10-23T13:44:33Z",
                          "publishedAt": "2023-10-23T13:44:32Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              },
              {
                "node": {
                  "author": {
                    "login": "permcody"
                  },
                  "bodyText": "Sorry I\u2019m late to the conversation. I\u2019d like to understand more of why you\nbelieve you need non-local information on all ranks. If you do need that\ninformation. The best bet would be to gather it all on one rank or at least\na small subset of ranks to perform a calculation. As Guillaume mentioned,\ndoing an allgather is expensive! This won\u2019t scale to run on a larger 3D\nproblem.\n\nInstead consider performing a partial calculation on each processor and\nthen gathering the relevant information on the first rank for final\nprocessing. This what we do in the FeatureVolumeVectorPostprocessor.\n\nYou can proceed with doing the unique merge if you\u2019d like but there is a\nshortcut. We already have the complete grain information at the end of the\nmerge stage. We purposely split that up and only send local information to\neach rank. You could just skip that step and do a broadcast there instead\nof the \u201cscatter\u201d operation that\u2019s there.\n\u2026\nOn Sun, Oct 22, 2023 at 8:18\u202fAM Guillaume Giudicelli < ***@***.***> wrote:\n You should try to do the gather operation on the map\n\n If that does not work then do a reduction on a keys and a value vector\n\n \u2014\n Reply to this email directly, view it on GitHub\n <#25807 (reply in thread)>,\n or unsubscribe\n <https://github.com/notifications/unsubscribe-auth/AAXFOIERBQ3PMOYJRX73S2DYAUTMZAVCNFSM6AAAAAA6KBWZQGVHI2DSMVQWIX3LMV43SRDJONRXK43TNFXW4Q3PNVWWK3TUHM3TGNJRGM3TG>\n .\n You are receiving this because you were mentioned.Message ID:\n ***@***.***>",
                  "url": "https://github.com/idaholab/moose/discussions/25807#discussioncomment-7353692",
                  "updatedAt": "2023-10-23T00:51:38Z",
                  "publishedAt": "2023-10-23T00:51:37Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "PengWei97"
                          },
                          "bodyText": "Hi @permcody, thank you very much for your help and guidance many times. In fact, the purpose of collecting each feature_set._local_ids on all ranks is to calculate the average of a certain material property of all elements corresponding to each grain, such as Cauchy stress. After obtaining the average value corresponding to each particle, the model calculation is performed by calling the actual object, as mentioned in Chen Longqing's article AA.\nI'm also well aware that doing a full gathering is expensive! At the same time, I still have some questions about the two solutions proposed later, and  I would appreciate your insights.\nBased on FeatureVolumeVectorPostprocessor, how should the average value of each material parameter on each rank be calculated? That is, how to complete the calculation of \\sigma_{n_grain, n_rank, ave} = \\sum_{n_elem=1}^{N}\\sigma_{n_grain, n_rank, n_elem} for each grain (n_grain), where n_grain represents grain DI, n_rank represents rank ID, and n_elem represents element id. Then collect \\sigma_{n_grain, n_rank, ave} on each rank to calculate \\sigma_{n_rank, ave}.\nRegarding the second suggestion, you mentioned: \"We already have the complete grain information at the end of the merge stage. We purposely split that up and only send local information to each rank.\" Where is this part of the code located? Whether _feature_sets[i]._local_ids contains complete element ids information on primary rank before executing \"scattering\".\nMaybe I'll try the shortcuts first and then try the first optimal solution after the basic functionality is complete.\nBest regards,\nWei",
                          "url": "https://github.com/idaholab/moose/discussions/25807#discussioncomment-7353930",
                          "updatedAt": "2023-10-23T01:48:00Z",
                          "publishedAt": "2023-10-23T01:47:59Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "permcody"
                          },
                          "bodyText": "Based on FeatureVolumeVectorPostprocessor, how should the average value of each material parameter on each rank be calculated? That is, how to complete the calculation of \\sigma_{n_grain, n_rank, ave} = \\sum_{n_elem=1}^{N}\\sigma_{n_grain, n_rank, n_elem} for each grain (n_grain), where n_grain represents grain DI, n_rank represents rank ID, and n_elem represents element id. Then collect \\sigma_{n_grain, n_rank, ave} on each rank to calculate \\sigma_{n_rank, ave}.\n\nThis is exactly what we do in FeatureVolumeFectorPostprocessor. We still do a loop over all local elements on each processor. That's done here: \n  \n    \n      moose/modules/phase_field/src/vectorpostprocessors/FeatureVolumeVectorPostprocessor.C\n    \n    \n         Line 157\n      in\n      bdad35f\n    \n  \n  \n    \n\n        \n          \n           for (const auto & elem : _mesh.getMesh().active_local_element_ptr_range()) \n        \n    \n  \n\n Inside of that loop, we then calculate the quantity of interest using the shape functions representing that particular feature: \n  \n    \n      moose/modules/phase_field/src/vectorpostprocessors/FeatureVolumeVectorPostprocessor.C\n    \n    \n        Lines 233 to 234\n      in\n      bdad35f\n    \n  \n  \n    \n\n        \n          \n           for (unsigned int qp = 0; qp < _qrule->n_points(); ++qp) \n        \n\n        \n          \n             sum += _JxW[qp] * _coord[qp] * (*_coupled_sln[var_index])[qp]; \n        \n    \n  \n\n Finally, those partial quantities are summed across all elements by feature: \n  \n    \n      moose/modules/phase_field/src/vectorpostprocessors/FeatureVolumeVectorPostprocessor.C\n    \n    \n        Lines 175 to 180\n      in\n      bdad35f\n    \n  \n  \n    \n\n        \n          \n           void \n        \n\n        \n          \n           FeatureVolumeVectorPostprocessor::finalize() \n        \n\n        \n          \n           { \n        \n\n        \n          \n             // Do the parallel sum \n        \n\n        \n          \n             _communicator.sum(_feature_volumes); \n        \n\n        \n          \n           } \n        \n    \n  \n\n\nIn any case, let the individual processors do partial calculations and then sum everything together at the end. This is much more scalable in terms of time and space. All of the information you need for your calculation is available in that VPP already.",
                          "url": "https://github.com/idaholab/moose/discussions/25807#discussioncomment-7362374",
                          "updatedAt": "2023-10-23T18:58:31Z",
                          "publishedAt": "2023-10-23T18:57:36Z",
                          "isAnswer": true
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "PengWei97"
                          },
                          "bodyText": "Great, what I want to achieve has been initially solved. Thank you so much for your crucial guidance. Specifically, I implemented it by creating a new derived class FeatureMatePropVectorPostprocessor. The key is to introduce the material properties that need to be averaged:\nsum += _JxW[qp] * _coord[qp] * MetaPhysicL::raw_value(_mat_prop_qp[qp]) * (*_coupled_sln[var_index])[qp];\nSimultaneously, the entire code FeatureMatePropVectorPostprocessor has been uploaded to the remote repository. If you have any additional suggestions or insights, I would greatly appreciate your help.\nBest regards,\nwei peng",
                          "url": "https://github.com/idaholab/moose/discussions/25807#discussioncomment-7378271",
                          "updatedAt": "2023-10-25T07:54:35Z",
                          "publishedAt": "2023-10-25T07:54:35Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "How to couple vectorpostprocessor in header & source files ?",
          "author": {
            "login": "Minjiang-Zhu"
          },
          "bodyText": "As mentioned in title, I wonder if there is any instruction on how to couple vectorpostprocessor.",
          "url": "https://github.com/idaholab/moose/discussions/25841",
          "updatedAt": "2023-10-25T03:40:11Z",
          "publishedAt": "2023-10-24T22:32:20Z",
          "category": {
            "name": "Q&A General"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "Minjiang-Zhu"
                  },
                  "bodyText": "Seems there are several files in framework/(include or source)/vectorpostprocessors. I'll imitate the coding style and see if it shall work.",
                  "url": "https://github.com/idaholab/moose/discussions/25841#discussioncomment-7375129",
                  "updatedAt": "2023-10-24T22:49:46Z",
                  "publishedAt": "2023-10-24T22:49:45Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "author": {
                    "login": "GiudGiud"
                  },
                  "bodyText": "Most objects inherit VectorPostprocessorInterface from which you can call getVectorPostprocessorXYZ to retrieve whatever you want.\nMost likely you want the value",
                  "url": "https://github.com/idaholab/moose/discussions/25841#discussioncomment-7375184",
                  "updatedAt": "2023-10-24T23:01:21Z",
                  "publishedAt": "2023-10-24T23:01:20Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "Minjiang-Zhu"
                          },
                          "bodyText": "Thank you! I imitated the codes in \"LeastSquareFit\", referenced this site  and obtained what I want.",
                          "url": "https://github.com/idaholab/moose/discussions/25841#discussioncomment-7376581",
                          "updatedAt": "2023-10-25T03:39:29Z",
                          "publishedAt": "2023-10-25T03:38:21Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      }
    ]
  }
}