{
  "discussions": {
    "pageInfo": {
      "hasNextPage": true,
      "endCursor": "Y3Vyc29yOnYyOpK5MjAyNS0wMS0yMlQxMDo0Nzo0NS0wNzowMM4Ad8s0"
    },
    "edges": [
      {
        "node": {
          "title": "Timoshenko beam element",
          "author": {
            "login": "kiliyan"
          },
          "bodyText": "Is there a special Timoshenko beam element or do I define it like how it is mentioned on https://mooseframework.inl.gov/modules/solid_mechanics/beam_vandv.html\nI did see the https://mooseframework.inl.gov/modules/solid_mechanics/C0TimoshenkoBeam.html but wanted to confirm there isn't an element type = Timoshenko beam or something along those lines.",
          "url": "https://github.com/idaholab/moose/discussions/29756",
          "updatedAt": "2025-01-27T20:48:32Z",
          "publishedAt": "2025-01-27T19:33:34Z",
          "category": {
            "name": "Q&A Modules: Solid mechanics"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "GiudGiud"
                  },
                  "bodyText": "There is not. You ll want to follow the example you found",
                  "url": "https://github.com/idaholab/moose/discussions/29756#discussioncomment-11975614",
                  "updatedAt": "2025-01-27T20:43:00Z",
                  "publishedAt": "2025-01-27T20:42:59Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": []
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "Extrusion of element type QUADSHELL4 error",
          "author": {
            "login": "garcs2"
          },
          "bodyText": "Hello,\nI'm currently trying to extrude a mesh of a 2D slice of a core for heat conduction. The mesh was generated in cubit and I'm attempting to extrude it in MOOSE. Below is an image of the mesh in paraview:\n\nAll I need is to extrude the mesh in the z direction, with some slight variation in the extrusion layer heights. To do this I use AdvancedExtruderGenerator and get the following error:\n\nExtrusion is not implemented for element type QUADSHELL4\ufffd[39m```\n\nIs there any way around this? Am I to understand that QUADSHELL4 isn't supported for any extrusions in `MeshGenerator`?",
          "url": "https://github.com/idaholab/moose/discussions/29753",
          "updatedAt": "2025-01-27T15:47:51Z",
          "publishedAt": "2025-01-27T15:42:49Z",
          "category": {
            "name": "Q&A Meshing"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "GiudGiud"
                  },
                  "bodyText": "in cubit you should specify the element type to be QUAD4 instead of QUADSHELL4",
                  "url": "https://github.com/idaholab/moose/discussions/29753#discussioncomment-11971718",
                  "updatedAt": "2025-01-27T15:47:51Z",
                  "publishedAt": "2025-01-27T15:47:51Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": []
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "granularity of multiapp transfer and update",
          "author": {
            "login": "mcacace"
          },
          "bodyText": "Check these boxes if you have followed the posting rules.\n\n Q&A General is the most appropriate section for my question\n I have consulted the posting Guidelines on the Discussions front page\n I have searched the Discussions forum and my question has not been asked before\n I have searched the MOOSE website and the documentation does not answer my question\n I have formatted my post following the posting guidelines (screenshots as a last resort, triple back quotes around pasted text)\n\nQuestion\nDear all,\nI might have a naive question, but  ... I'm working on linking an external library to a moose application, doing that via the multiapp system. My moose app runs as master and the external library as sub app at timestep_end. Coupling is done via transfer from the master to the sub (all is fine) and then back from the sub to the master (and here my question). The sub app passes a source/sink contribution as a auxvariable (monomial) which I then use in the master app to compute a kernel contribution). So my question: given that the transfer is done at the timestep_end, what would be the value of the auxvariable in the master app at the new time step? Is the value I passed from the previous solve? Or, should I \"lag in time\" the auxvariable (taking the old value)? Or, how can I control the syncing between the two?\nThanks for any feedback,\nmauro",
          "url": "https://github.com/idaholab/moose/discussions/29740",
          "updatedAt": "2025-01-27T09:44:59Z",
          "publishedAt": "2025-01-24T09:13:56Z",
          "category": {
            "name": "Q&A General"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "GiudGiud"
                  },
                  "bodyText": "Hello\nUse Problem/verbose_multiapps to see when the transfers and multiapps are being executed and that will let you know which field is at the end of the time step and which field is at the beginning.\nIf you use fixed point iterations between the two applications, by setting fixed_point_max_its in the executioner. That can help you do an implicit coupling between the two solves\nLagging is not always a bad idea, but it s usually first order in time. As in the time integration scheme error will be first order of the time step\nGuillaume",
                  "url": "https://github.com/idaholab/moose/discussions/29740#discussioncomment-11946467",
                  "updatedAt": "2025-01-24T18:32:44Z",
                  "publishedAt": "2025-01-24T18:32:43Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "mcacace"
                          },
                          "bodyText": "Thanks @GiudGiud. Will try to follow your suggestion. Sure I'll be back as my coding (slowly) develops further.",
                          "url": "https://github.com/idaholab/moose/discussions/29740#discussioncomment-11966926",
                          "updatedAt": "2025-01-27T09:44:59Z",
                          "publishedAt": "2025-01-27T09:44:58Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "Overwriting material property with region average",
          "author": {
            "login": "RPitsinger"
          },
          "bodyText": "Check these boxes if you have followed the posting rules.\n\n Q&A General is the most appropriate section for my question\n I have consulted the posting Guidelines on the Discussions front page\n I have searched the Discussions forum and my question has not been asked before\n I have searched the MOOSE website and the documentation does not answer my question\n I have formatted my post following the posting guidelines (screenshots as a last resort, triple back quotes around pasted text)\n\nQuestion\nI have a mesh in which a material property (logG) varies spatially (by element - monomial constant variables - ) over the ROI and is 0 elsewhere. Inside that same mesh, I also have a scale variable, which is 1 inside the ROI and 0 elsewhere. I want to compute the average of logG over the ROI and then overwrite the material property (logG) with this averaged value across the ROI and output this new mesh.\nLike this formula :\n\nAny idea how to implement this in a __.i file?",
          "url": "https://github.com/idaholab/moose/discussions/29750",
          "updatedAt": "2025-01-26T10:59:26Z",
          "publishedAt": "2025-01-25T21:49:35Z",
          "category": {
            "name": "Q&A General"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "GiudGiud"
                  },
                  "bodyText": "I would set up logG and scale as auxiliary variables using a ParsedAux (setting the 0 outside the ROI can be done here btw, as long as the definition of the ROI can be done in a if statement)\nThen integrate them separately using an ElementIntegralVariablePostprocessor.\nIf either of these are already available as material properties, you can skip the ParsedAux step and use an ElementIntegralMaterialPostprocessor.\nThen use a ParsedPostprocessor to perform the quotient between the two integrals",
                  "url": "https://github.com/idaholab/moose/discussions/29750#discussioncomment-11955135",
                  "updatedAt": "2025-01-26T00:07:05Z",
                  "publishedAt": "2025-01-26T00:07:04Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "RPitsinger"
                          },
                          "bodyText": "Yup, that worked, thanks.\nI read the variable from the mesh with UserObject - SolutionUserObject\nRead that into an AuxKernel - SolutionAux.\nPerformed integral on the (Aux) variable with Postprocessor - ElementIntegralVariablePostprocessor\nDid the quotient with Postprocessor - ParsedPostprocessor.\nOverwrote the variable with ParsedAux - AuxKernel, where I call the quotient value with functor_names.",
                          "url": "https://github.com/idaholab/moose/discussions/29750#discussioncomment-11957403",
                          "updatedAt": "2025-01-26T10:59:23Z",
                          "publishedAt": "2025-01-26T10:59:22Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "non converging phase field fracture test",
          "author": {
            "login": "amassaf"
          },
          "bodyText": "Hi I have a phase field fracture test tension-compression on a holed square plate (mesh attached) but it is not converging properly. Could it be a problem with the executioner ?\n02mesh.inp.txt\n[Mesh]\n    [file]\n    type = FileMeshGenerator\n    file = 02mesh.inp\n  []\n  [cornernode]\n    type = ExtraNodesetGenerator\n    new_boundary = BL\n    coord = '0 0 0'\n    input = file\n  []\n[]\n\n[GlobalParams]\n  displacements = 'disp_x disp_y'\n[]\n\n[Variables]\n  [./disp_x]\n  [../]\n  [./disp_y]\n  [../]\n  [./c]\n  [../]\n[]\n[AuxKernels]\n[./stress_xx]\n    type = RankTwoAux\n    variable = stress_xx\n    rank_two_tensor = stress\n    index_j = 0\n    index_i = 0\n    execute_on = timestep_end\n  [../]\n[./stress_xy]\n    type = RankTwoAux\n    variable = stress_xy\n    rank_two_tensor = stress\n    index_j = 0\n    index_i = 1\n    execute_on = timestep_end\n  [../]\n\n [./Von_Mises_stress]\n    type = RankTwoScalarAux\n    variable = Von_Mises_stress\n    rank_two_tensor = stress\n    scalar_type = VonMisesStress\n  [../]\n [./total_strain_yy]\n    type = RankTwoAux\n    rank_two_tensor = total_strain\n    variable = total_strain_yy\n    index_i = 1\n    index_j = 1\n  [../]\n[./total_strain_xx]\n    type = RankTwoAux\n    rank_two_tensor = total_strain\n    variable = total_strain_xx\n    index_i = 0\n    index_j = 0\n  [../]\n[./total_strain_xy]\n    type = RankTwoAux\n    rank_two_tensor = total_strain\n    variable = total_strain_xy\n    index_i = 0\n    index_j = 1\n  [../]\n[]\n\n[AuxVariables]\n  [./resid_x]\n  [../]\n  [./resid_y]\n  [../]\n  [./bounds_dummy]\n    order = FIRST\n    family = LAGRANGE\n  [../]\n[./stress_xx]\n    order = CONSTANT\n    family = MONOMIAL\n  [../]\n[./stress_xy]\n    order = CONSTANT\n    family = MONOMIAL\n  [../]\n [./Von_Mises_stress]\n    family = MONOMIAL\n    order = CONSTANT\n  [../]\n [./total_strain_yy]\n    order = CONSTANT\n    family = MONOMIAL\n  [../]\n  [./total_strain_xx]\n    order = CONSTANT\n    family = MONOMIAL\n  [../]\n[./total_strain_xy]\n    order = CONSTANT\n    family = MONOMIAL\n  [../]\n\n[]\n\n\n[Modules]\n  [./TensorMechanics]\n    [./Master]\n      [./All]\n        add_variables = true\n        strain = SMALL\n        additional_generate_output = 'strain_yy stress_yy'\n        planar_formulation = PLANE_STRAIN\n        save_in = 'resid_x resid_y'\n      [../]\n    [../]\n  [../]\n[]\n\n[Kernels]\n  [./solid_x]\n    type = PhaseFieldFractureMechanicsOffDiag\n    variable = disp_x\n    component = 0\n    c = c\n  [../]\n  [./solid_y]\n    type = PhaseFieldFractureMechanicsOffDiag\n    variable = disp_y\n    component = 1\n    c = c\n  [../]\n    [./off_disp]\n    type = AllenCahnElasticEnergyOffDiag\n    variable = c \n    displacements = 'disp_x disp_y'\n    mob_name = L\n  [../]\n   [./ACbulk]\n    type = AllenCahn\n    variable = c\n    f_name = F\n  [../]\n  [./ACInterfaceCleavageFracture]\n    type = ACInterface\n    variable = c\n  [../]\n\n[]\n\n[BCs]\n  [./ydisp]\n    type = FunctionDirichletBC\n    variable = disp_y\n    boundary = top\n    function = 'fux'\n  [../]\n  [./yfix]\n    type = DirichletBC\n    variable = disp_y \n    boundary = bottom\n    value = 0 \n  [../]\n  [./xfix]\n    type = DirichletBC\n    variable = disp_x\n    boundary = BL\n    value = 0\n  [../]\n[]\n\n[Functions]\n [./fux]\n   type = PiecewiseLinear\n   x =  '0.0  1.0e-2  2.0e-2   3e-2'\n   y =  '0.0  0.010   0.0      -0.010'\n[]\n[]\n\n[Materials]\n  [./pfbulkmat]\n    type = GenericConstantMaterial\n    prop_names = 'gc_prop l visco'\n    prop_values = '2.7 0.03  1e-5'\n  [../]\n  [./elasticity_tensor]\n    type = ComputeElasticityTensor\n    C_ijkl = '120.0e3 80.e3'\n    fill_method = symmetric_isotropic\n  [../]\n  [./damage_stress]\n    type = ComputeLinearElasticPFFractureStress\n    c = c\n    E_name = 'elastic_energy'\n    D_name = 'degradation'\n    F_name = 'local_fracture_energy'\n    decomposition_type = stress_spectral \n    use_snes_vi_solver = true\n  [../]\n  [./degradation]\n    type = DerivativeParsedMaterial\n    f_name = degradation\n    args = 'c'\n    function = '(1.0-c)^2*(1.0 - eta) + eta'\n    constant_names       = 'eta'\n    constant_expressions =  '1.0e-6'\n    derivative_order = 2\n  [../]\n  [./define_mobility]\n    type = ParsedMaterial\n    material_property_names = 'gc_prop visco'\n    f_name = L\n    function = '1.0/(gc_prop * visco)'\n  [../]\n  [./define_kappa]\n    type = ParsedMaterial\n    material_property_names = 'gc_prop l'\n    f_name = kappa_op\n    function = 'gc_prop * l * 3 / 4' #gc_prop * l'\n  [../]\n  [./local_fracture_energy]\n    type = DerivativeParsedMaterial\n    f_name = local_fracture_energy\n    args = 'c'\n    material_property_names = 'gc_prop l'\n    function = '3 * gc_prop / (8 * l) * c' \n    derivative_order = 2\n  [../]\n  [./fracture_driving_energy]\n    type = DerivativeSumMaterial\n    args = c\n    sum_materials = 'elastic_energy local_fracture_energy'\n    derivative_order = 2\n    f_name = F\n  [../]\n[]\n\n[Postprocessors]\n [./top_x]\n    type = NodalExtremeValue\n    variable = disp_x\n    boundary = top\n    value_type = max\n  [../]\n\n[./top_y]\n    type = NodalExtremeValue\n    variable = disp_y\n    boundary = top\n    value_type = max\n  [../]\n\n  [./resid_x]\n    type = NodalSum\n    variable = resid_x\n    boundary = bottom\n  [../]\n  [./resid_y]\n    type = NodalSum\n    variable = resid_y\n    boundary = bottom\n  [../]\n[]\n\n\n[Bounds]\n  [./c_upper_bound]\n    type = ConstantBoundsAux\n    variable = bounds_dummy\n    bounded_variable = c\n    bound_type = upper\n    bound_value = 1.0\n  [../]\n  [./c_lower_bound]\n    type = VariableOldValueBoundsAux\n    variable = bounds_dummy\n    bounded_variable = c\n    bound_type = lower\n  [../]\n[]\n\n\n[Preconditioning]\n  [./smp]\n    type = SMP\n    full = true\n  [../]\n[]\n\n[Executioner]\n  type = Transient\n  #solve_type = newton #PJFNK\n  #scheme=BDF2\n  petsc_options_iname = '-pc_type -pc_factor_mat_solver_package -snes_type'\n  petsc_options_value = 'lu       mumps                  vinewtonrsls'\n  nl_rel_tol = 1e-6\n  nl_abs_tol = 1e-10\n  dt = 5e-5\n  end_time = 0.2\n  automatic_scaling = true\n[]\n\n\n\n[Outputs]\n  exodus = true\n  csv = true\n[]",
          "url": "https://github.com/idaholab/moose/discussions/29717",
          "updatedAt": "2025-01-25T08:59:04Z",
          "publishedAt": "2025-01-21T08:31:07Z",
          "category": {
            "name": "Q&A Modules: Solid mechanics"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "selarem"
                  },
                  "bodyText": "Very strange ! The strain_spectral decomposition generally works fine in tension and in compression. Here it does not converge even in tension.",
                  "url": "https://github.com/idaholab/moose/discussions/29717#discussioncomment-11916678",
                  "updatedAt": "2025-01-22T13:25:20Z",
                  "publishedAt": "2025-01-22T13:25:19Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "author": {
                    "login": "selarem"
                  },
                  "bodyText": "@jiangwen84\ndo you have any idea, on why this have convergence issues ?\nregards,",
                  "url": "https://github.com/idaholab/moose/discussions/29717#discussioncomment-11940739",
                  "updatedAt": "2025-01-24T09:16:42Z",
                  "publishedAt": "2025-01-24T09:16:41Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "author": {
                    "login": "GiudGiud"
                  },
                  "bodyText": "hello\n\nbut it is not converging properly.\n\ncan you please attach the log?\nwhich techniques have you tried here?\nhttps://mooseframework.inl.gov/application_usage/failed_solves.html",
                  "url": "https://github.com/idaholab/moose/discussions/29717#discussioncomment-11944487",
                  "updatedAt": "2025-01-24T15:16:39Z",
                  "publishedAt": "2025-01-24T15:16:38Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "amassaf"
                          },
                          "bodyText": "Hello\nit seems to be due to the nonlinear solve fail. I've tried using the line_search = 'none' and setting a nl_abs_tol=1e-10 and the nl_rel_tol=1e-6, set automatic_scale = true and I've also tried the solve_type = Newton. I've also tried having a finer mesh and changing the phase field problem parameters like gc or l but it seems that the problem with the non-linear convergence emerges when the time is around 0.1 (when there is a tension to compression transition but it sometimes also fails before then - by fail i mean the solve doesn't converge and time step is reduced to reach dt_min) I didn't have the problem with the other non spectral decomposition methods in the ComputeLinearElasticPFFractureStress.\nthe log : moose_trial.txt",
                          "url": "https://github.com/idaholab/moose/discussions/29717#discussioncomment-11945830",
                          "updatedAt": "2025-01-24T17:22:05Z",
                          "publishedAt": "2025-01-24T17:22:04Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "Why is the c variable residual never going down?\nDid you set super loose tolerances that allow convergence with any value of that residual?",
                          "url": "https://github.com/idaholab/moose/discussions/29717#discussioncomment-11946655",
                          "updatedAt": "2025-01-24T18:51:56Z",
                          "publishedAt": "2025-01-24T18:51:55Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "amassaf"
                          },
                          "bodyText": "The units are mm MPa s so I think the nl_abs_tol=1e-10 and the nl_rel_tol=1e-6 are fine, or is there other tolerances for the phase field problem specifically ?",
                          "url": "https://github.com/idaholab/moose/discussions/29717#discussioncomment-11946679",
                          "updatedAt": "2025-01-24T18:54:52Z",
                          "publishedAt": "2025-01-24T18:54:51Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "This does not explain the residual staying above 1.\nIf it s not the tolerances maybe it s the number of iterations.\nCan you set nl_forced_its to 10 and see if the residual goes down for c ?",
                          "url": "https://github.com/idaholab/moose/discussions/29717#discussioncomment-11946700",
                          "updatedAt": "2025-01-24T18:57:19Z",
                          "publishedAt": "2025-01-24T18:57:18Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "amassaf"
                          },
                          "bodyText": "I added the nl_forced_its = 10, but nothing has changed, c residual is still at 1, goes down to 0.8 for some iterations :\nmoose_trial.txt",
                          "url": "https://github.com/idaholab/moose/discussions/29717#discussioncomment-11946848",
                          "updatedAt": "2025-01-24T19:16:27Z",
                          "publishedAt": "2025-01-24T19:16:26Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "this isn't normal.\nTry the \"Ill-conditioned or ill-posed problem\" instructions on that page\nhttps://mooseframework.inl.gov/application_usage/failed_solves.html\nI think you ll find the problem is ill-posed in some capacity\nEither that or something with bounds is not showing us the true residual. In that case we should try adding -ksp_monitor_true_residual on the command line or in petsc options",
                          "url": "https://github.com/idaholab/moose/discussions/29717#discussioncomment-11947470",
                          "updatedAt": "2025-01-24T20:47:48Z",
                          "publishedAt": "2025-01-24T20:47:48Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "amassaf"
                          },
                          "bodyText": "The -ksp_monitor_true_residual gives this log:\nmoose_trial.txt",
                          "url": "https://github.com/idaholab/moose/discussions/29717#discussioncomment-11947666",
                          "updatedAt": "2025-01-24T21:15:10Z",
                          "publishedAt": "2025-01-24T21:15:09Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "amassaf"
                          },
                          "bodyText": "and using this executioner:\n[Executioner]\n  type = Transient\n  #solve_type = newton #PJFNK\n  #scheme=BDF2\n  petsc_options = '-pc_svd_monitor '\n  petsc_options_iname = '-pc_type -pc_factor_mat_solver_package -snes_type'\n  petsc_options_value = 'svd       mumps                  vinewtonrsls'\n\n#petsc_options = '-ksp_monitor_true_residual'\n\n#petsc_options_iname = '-pc_type -snes_linesearch_damping -ksp_gmres_restart -pc_factor_mat_solver_package -snes_type'\n#petsc_options_value = 'lu  0.5 1000    mumps                  vinewtonrsls'\n\n # line_search = 'basic'\n line_search = none\n\n  nl_rel_tol = 1e-6\n  #nl_abs_tol = 1e-10\n  dt = 5e-4\n  end_time = 0.2\n  automatic_scaling = true\n  nl_forced_its = 20\n[]\n\ngives me this:\n  Executioner:             Transient\n  TimeStepper:             ConstantDT\n  TimeIntegrator:          ImplicitEuler\n  Solver Mode:             Preconditioned JFNK\n  PETSc Preconditioner:    svd \n  MOOSE Preconditioner:    SMP\n\n\nTime Step 0, time = 0\n\nPostprocessor Values:\n+----------------+----------------+----------------+----------------+----------------+\n| time           | resid_x        | resid_y        | top_x          | top_y          |\n+----------------+----------------+----------------+----------------+----------------+\n|   0.000000e+00 |   0.000000e+00 |   0.000000e+00 |   0.000000e+00 |   0.000000e+00 |\n+----------------+----------------+----------------+----------------+----------------+\n\n\nTime Step 1, time = 0.0005, dt = 0.0005\n\nPerforming automatic scaling calculation\n\n    |residual|_2 of individual variables:\n                     disp_x: 0.000175511\n                     disp_y: 0.00248219\n                     c:      1.17445\n 0 Nonlinear |R| = 2.488389e-03\n\n===================================================================================\n=   BAD TERMINATION OF ONE OF YOUR APPLICATION PROCESSES\n=   PID 2707847 RUNNING AT \n=   EXIT CODE: 9\n=   CLEANING UP REMAINING PROCESSES\n=   YOU CAN IGNORE THE BELOW CLEANUP MESSAGES\n===================================================================================\nYOUR APPLICATION TERMINATED WITH THE EXIT STRING: Killed (signal 9)\nThis typically refers to a problem with your application.\nPlease see the FAQ page for debugging suggestions",
                          "url": "https://github.com/idaholab/moose/discussions/29717#discussioncomment-11947710",
                          "updatedAt": "2025-01-24T21:22:02Z",
                          "publishedAt": "2025-01-24T21:22:02Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "YOUR APPLICATION TERMINATED WITH THE EXIT STRING: Killed (signal 9)\n\nyou are runnig out of memory. make the mesh a lot smaller to run SVD, down to 1-5k elements max",
                          "url": "https://github.com/idaholab/moose/discussions/29717#discussioncomment-11948192",
                          "updatedAt": "2025-01-24T22:23:17Z",
                          "publishedAt": "2025-01-24T22:23:16Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "amassaf"
                          },
                          "bodyText": "Ok, thanks it worked, I got this:\nmoose_trial.txt\nTime Step 1, time = 0.0005, dt = 0.0005\n\nPerforming automatic scaling calculation\n\n    |residual|_2 of individual variables:\n                     disp_x: 9.61617e-05\n                     disp_y: 0.000970133\n                     c:      5.62412\n 0 Nonlinear |R| = 9.748876e-04\n      SVD: condition number 2.002505168263e+04, 0 of 990 singular values are (nearly) zero\n      SVD: smallest singular values: 9.121985765161e-05 7.583532795909e-04 3.134453905996e-03 4.096421736808e-03 5.132670171111e-03\n      SVD: largest singular values : 1.768595240078e+00 1.773327750385e+00 1.790825275654e+00 1.810794194333e+00 1.826682363956e+00\n      0 Linear |R| = 9.748876e-04\n      1 Linear |R| = 2.344575e-17\n    |residual|_2 of individual variables:\n                     disp_x: 1.66047e-17\n                     disp_y: 1.67193e-17\n                     c:      5.62412\n 1 Nonlinear |R| = 2.356378e-17\n  Finished Solving                                                                       [ 11.80 s] [  192 MB]\n Solve Converged!\n\nOutlier Variable Residual Norms:\n  disp_x: 1.660470e-17\n  disp_y: 1.671932e-17\n  c: 5.624117e+00\n\nPostprocessor Values:\n+----------------+----------------+----------------+----------------+----------------+\n| time           | resid_x        | resid_y        | top_x          | top_y          |\n+----------------+----------------+----------------+----------------+----------------+\n|   0.000000e+00 |   0.000000e+00 |   0.000000e+00 |   0.000000e+00 |   0.000000e+00 |\n|   5.000000e-04 |  -7.810948e-13 |  -8.176373e+01 |  -2.311164e-07 |   5.000000e-04 |\n+----------------+----------------+----------------+----------------+----------------+\n\n\nTime Step 2, time = 0.001, dt = 0.0005\n    |residual|_2 of individual variables:\n                     disp_x: 9.61617e-05\n                     disp_y: 0.000970133\n                     c:      5.61655\n 0 Nonlinear |R| = 9.748876e-04",
                          "url": "https://github.com/idaholab/moose/discussions/29717#discussioncomment-11948416",
                          "updatedAt": "2025-01-24T22:59:58Z",
                          "publishedAt": "2025-01-24T22:59:57Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "Debuging UMAT",
          "author": {
            "login": "M16R24"
          },
          "bodyText": "A custom UMAT is used to get the material response under compressive loading with symmetric boundary conditions.  The issue I am facing is that after a certain amount of strain is reached, the simulation diverges in terms of \"dt\" and stops. I have tried debugging using gdb and rectified certain things. But I also want to check the Jacobian as well. So, how can I debug the Jacobian matrix that goes back into MOOSE?",
          "url": "https://github.com/idaholab/moose/discussions/29725",
          "updatedAt": "2025-01-25T05:31:44Z",
          "publishedAt": "2025-01-22T09:51:00Z",
          "category": {
            "name": "Q&A Modules: Solid mechanics"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "GiudGiud"
                  },
                  "bodyText": "Hello\nSee the troubleshooting failed solves instructions on the website\nThe Jacobian tester will tell you which coefficient is wrong then the dofmap output will tell you to which variables it is tied",
                  "url": "https://github.com/idaholab/moose/discussions/29725#discussioncomment-11949798",
                  "updatedAt": "2025-01-25T05:31:45Z",
                  "publishedAt": "2025-01-25T05:31:44Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": []
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "MultiApp transfer variable to initial condition of subapp",
          "author": {
            "login": "garcs2"
          },
          "bodyText": "Check these boxes if you have followed the posting rules.\n\n Q&A General is the most appropriate section for my question\n I have consulted the posting Guidelines on the Discussions front page\n I have searched the Discussions forum and my question has not been asked before\n I have searched the MOOSE website and the documentation does not answer my question\n I have formatted my post following the posting guidelines (screenshots as a last resort, triple back quotes around pasted text)\n\nQuestion\nHello everyone,\nI am working on making a neutronics-heat transfer-thermohydraulics coupled simulation, using Griffin as the neutronics solver and heat transfer-thermohydraulics (HT-TH) being solved with the base modules in MOOSE. I have Griffin and HT-TH running successfuly separately. The HT-TH is solved using TransientMultiApp where HT acts as the main app and TH is the sub-app. Ideally, the workflow would look like the following:\n\nFor clarity, the FullSolveMultiApp executes on timestep_end so that Griffin solves first, then transfers the power density to HT-TH where HT solves first. My question is then: how do I designate the initial condition of HT to be the transferred power density? Since the power density is a scalar, I would like to use ConstantIC but a value is required as input. Below is the relevant portion of my input file, with the IC block not filled in since I don't know what to do:\n[Variables]\n  [T]\n  []\n[]\n[AuxVariables]\n  [fluid_temp]\n  initial_condition = '${inlet_T}'\n  []\n  [flux]\n    family = MONOMIAL\n    order = CONSTANT\n  []\n  [power_density]\n    family = L2_LAGRANGE\n    order = First\n    block = ${fuel_blocks}\n  []\n[]\n[Kernels]\n  [diffusion]\n    type = HeatConduction\n    variable = T\n  []\n  [source]\n    type = CoupledForce\n    variable = T\n    v = power_density\n    block = ${fuel_blocks}\n  []\n[]\n\n[BCs]\n  [pin_outer]\n    type = MatchedValueBC\n    variable = T\n    v = fluid_temp\n    boundary = 'fluid_solid_interface'\n  []\n[]\n\n[ICs]\n  [power_density]\n    type = ConstantIC\n    variable = power_density\n    value = ???\n    block = ${fuel_blocks}\n  []\n[]",
          "url": "https://github.com/idaholab/moose/discussions/29676",
          "updatedAt": "2025-01-24T06:34:45Z",
          "publishedAt": "2025-01-10T20:37:53Z",
          "category": {
            "name": "Q&A General"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "GiudGiud"
                  },
                  "bodyText": "hello\nInstead of using a ConstantIC, if you want a value from another application, you should transfer it.\nTransfers can be executed on INITIAL.\nbut here you should be good already?\n\nthe FullSolveMultiApp executes on timestep_end so that Griffin solves first, then transfers the power density to HT-TH where HT solves first\n\nsince Griffin executes first and sends its power field to the HT solve, the HT solve has the updated power density already for its first solve?\nGuillaume",
                  "url": "https://github.com/idaholab/moose/discussions/29676#discussioncomment-11802418",
                  "updatedAt": "2025-01-10T20:49:26Z",
                  "publishedAt": "2025-01-10T20:49:26Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "garcs2"
                          },
                          "bodyText": "Hi Guillaume\nI see so what you're saying is that because I already transfer power density from Griffin, then there is no need to designate an IC explicitly. I was under the impression that I had to tell MOOSE explicitly where the IC was coming from if that makes sense. This helps and now the job is at least running, I just deleted the ICs block. I will ask more follow-up questions on this thread if any come up.",
                          "url": "https://github.com/idaholab/moose/discussions/29676#discussioncomment-11803093",
                          "updatedAt": "2025-01-10T23:26:55Z",
                          "publishedAt": "2025-01-10T22:10:58Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "garcs2"
                          },
                          "bodyText": "Hi Guillaume,\nThe input file is now running and I get a complete run of Griffin-HT-TH. However, I'm finding that the power_density computed via Griffin is not being transferred correctly into HT. My solution in Griffin completes and then transfers to HT. I realized that since Griffin technically computes a time step by setting up the transfer I have to have the multi app execute on FINAL. After the Griffin solution is computed I find that I'm getting this as part of the output as HT-TH step forward in time:\n\ufffd[36mGriffin_htm0: \ufffd[39m+----------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+\n\ufffd[36mGriffin_htm0: \ufffd[39m| time           | flux_integral  | htm_Tfuel      | htm_Tref       | max_fuel_T     | max_power      | min_power      | power_source   |\n\ufffd[36mGriffin_htm0: \ufffd[39m+----------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+\n\ufffd[36mGriffin_htm0: \ufffd[39m|   0.000000e+00 |   0.000000e+00 |   0.000000e+00 |   0.000000e+00 |   0.000000e+00 |   0.000000e+00 |   0.000000e+00 |   0.000000e+00 |\n\ufffd[36mGriffin_htm0: \ufffd[39m|   5.000000e-02 |  -8.876084e-05 |   8.660000e+02 |   8.660000e+02 |   8.660000e+02 |   0.000000e+00 |   0.000000e+00 |   0.000000e+00 |\n\ufffd[36mGriffin_htm0: \ufffd[39m+----------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+\n\nIs there something that I'm doing incorrectly that comes to mind for you? For reference this is my multiapp and transfer blocks in my Griffin input:\n[MultiApps]\n    [Griffin_htm]\n    type = FullSolveMultiApp\n    #app_type = GriffinApp\n    input_files = 'SNAP_solid_test3_1.i'\n    positions = '0 0 0'\n    execute_on = 'FINAL'\n    []\n[]\n\n[Transfers]\n    [to_htm_power_density]\n        type = MultiAppProjectionTransfer\n        to_multi_app = Griffin_htm\n        source_variable = griffin_power_density\n        variable = power_density\n    []\n[]",
                          "url": "https://github.com/idaholab/moose/discussions/29676#discussioncomment-11848082",
                          "updatedAt": "2025-01-15T21:46:21Z",
                          "publishedAt": "2025-01-15T21:46:21Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "execute_on = 'FINAL'\n\n\nthis seems weird. Griffin should not be using time steps as power iterations. Maybe you are using an old executioner in Griffin?\nWhich executioner / transport systems are you using in Griffin?",
                          "url": "https://github.com/idaholab/moose/discussions/29676#discussioncomment-11849278",
                          "updatedAt": "2025-01-16T01:16:47Z",
                          "publishedAt": "2025-01-16T01:16:47Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "garcs2"
                          },
                          "bodyText": "For the executioner I'm using SweepUpdate and for the transport system it's an eigenvalue problem where I'm using DFEM-SN. I can also copy my transport system and executioner blocks here, I wasn't sure if I'm able to since Griffin is export-controlled.",
                          "url": "https://github.com/idaholab/moose/discussions/29676#discussioncomment-11855184",
                          "updatedAt": "2025-01-16T13:49:42Z",
                          "publishedAt": "2025-01-16T13:49:41Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "Do you have a contact in the Griffin team?\nWhich institution are you affiliated with?\nYes we are fairly limited in what we can say about Griffin code here.",
                          "url": "https://github.com/idaholab/moose/discussions/29676#discussioncomment-11855200",
                          "updatedAt": "2025-01-16T13:51:18Z",
                          "publishedAt": "2025-01-16T13:51:17Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "garcs2"
                          },
                          "bodyText": "I do not have contact with the Griffin team, though I can post to their discussion board. I thought this was more of a transfers issue not specific to Griffin which is why I made the post here. I am affiliated with UW-Madison.",
                          "url": "https://github.com/idaholab/moose/discussions/29676#discussioncomment-11856125",
                          "updatedAt": "2025-01-16T15:14:51Z",
                          "publishedAt": "2025-01-16T15:14:50Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "Alright so try:\n\ndont use execute_on FINAL, use TIMESTEP_END\nplay with the richardson iterations parameters to get the multiapp executed inside the power iteration loop",
                          "url": "https://github.com/idaholab/moose/discussions/29676#discussioncomment-11857787",
                          "updatedAt": "2025-01-16T17:51:07Z",
                          "publishedAt": "2025-01-16T17:51:07Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "garcs2"
                          },
                          "bodyText": "Okay so I've done what you suggested, and I've made the Griffin execution verbose to track the solver. This is part of the output where you see that the power_source in HT is not updated but that the multiapp is being executed within the power iteration loop:\nTransfers on TIMESTEP_END To MultiApps\ufffd[39m:\n----------------------------------------------------------------------------\n|         Name         |            Type            |  From  |     To      |\n----------------------------------------------------------------------------\n| to_htm_power_density | MultiAppProjectionTransfer | Parent | Griffin_htm |\n----------------------------------------------------------------------------\n  Currently Executing Transfers\n    Transferring variables through projection                                            [\ufffd[33m 11.38 s\ufffd[39m] [\ufffd[33m12424 MB\ufffd[39m]\n\ufffd[36mTransfers on TIMESTEP_END Are Finished\n\ufffd[39m\n\ufffd[36m\nNo Transfers on TIMESTEP_END Between MultiApps\n\ufffd[39m\n\ufffd[36m\nExecuting MultiApps on TIMESTEP_END\ufffd[39m\n  Finished Executing Transfers                                                           [\ufffd[33m 11.39 s\ufffd[39m] [\ufffd[33m12424 MB\ufffd[39m]\nWarning, Exodus files cannot have titles longer than 80 characters.  Your title will be truncated.\n\ufffd[36mGriffin_htm0: \ufffd[39mOutputting\ufffd[36mGriffin_htm0: \ufffd[39m\n\ufffd[36mGriffin_htm0: \ufffd[39m  Outputting Step                                                          [\ufffd[33m  9.04 s\ufffd[39m] [\ufffd[33m12424 MB\ufffd[39m]\n\ufffd[36mGriffin_htm0: \ufffd[39m\n\ufffd[36mGriffin_htm0: \ufffd[39mTime Step 0, time = 0\n\ufffd[36mGriffin_htm0: \ufffd[39m\n\ufffd[36mGriffin_htm0: \ufffd[39mPostprocessor Values:\n\ufffd[36mGriffin_htm0: \ufffd[39m+----------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+\n\ufffd[36mGriffin_htm0: \ufffd[39m| time           | flux_integral  | htm_Tfuel      | htm_Tref       | max_fuel_T     | max_power      | min_power      | power_source   |\n\ufffd[36mGriffin_htm0: \ufffd[39m+----------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+\n\ufffd[36mGriffin_htm0: \ufffd[39m|   0.000000e+00 |   0.000000e+00 |   0.000000e+00 |   0.000000e+00 |   0.000000e+00 |   0.000000e+00 |   0.000000e+00 |   0.000000e+00 |\n\ufffd[36mGriffin_htm0: \ufffd[39m+----------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+\n\ufffd[36mGriffin_htm0: \ufffd[39m\n\ufffd[36mGriffin_htm0: \ufffd[39mFinished Outputting                                                        [\ufffd[33m  9.05 s\ufffd[39m] [\ufffd[33m12424 MB\ufffd[39m]\n\ufffd[36mGriffin_htm0: \ufffd[39m\n\ufffd[36mGriffin_htm0: \ufffd[39mTime Step 1, time = 0.05\n\ufffd[36mGriffin_htm0: \ufffd[39m         old time = 0\n\ufffd[36mGriffin_htm0: \ufffd[39m               dt = 0.05\n\ufffd[36mGriffin_htm0: \ufffd[39m           old dt = 0.05\n\ufffd[36mGriffin_htm0: \ufffd[39m\n\ufffd[36mGriffin_htm0: \ufffd[39m 0 Nonlinear |R| = \ufffd[32m4.001707e+05\ufffd[39m\n\ufffd[36mGriffin_htm0: \ufffd[39m 1 Nonlinear |R| = \ufffd[32m2.515758e+03\ufffd[39m\n\ufffd[36mGriffin_htm0: \ufffd[39m 2 Nonlinear |R| = \ufffd[32m1.600207e-01\ufffd[39m\n\ufffd[36mGriffin_htm0: \ufffd[39m 3 Nonlinear |R| = \ufffd[32m2.271778e-06\ufffd[39m\n\ufffd[36mGriffin_htm0: \ufffd[39m\ufffd[32m Solve Converged!\ufffd[39m\n\ufffd[36mGriffin_htm0: \ufffd[39mFinished Solving                                                           [\ufffd[33m 56.94 s\ufffd[39m] [\ufffd[33m12424 MB\ufffd[39m]\n\ufffd[36mGriffin_htm0_thm0: \ufffd[39m\n\ufffd[36mGriffin_htm0_thm0: \ufffd[39mTime Step 1, time = 0.05\n\ufffd[36mGriffin_htm0_thm0: \ufffd[39m         old time = 0\n\ufffd[36mGriffin_htm0_thm0: \ufffd[39m               dt = 0.05\n\ufffd[36mGriffin_htm0_thm0: \ufffd[39m           old dt = 0.05\n\ufffd[36mGriffin_htm0_thm0: \ufffd[39m\n\ufffd[36mGriffin_htm0_thm0: \ufffd[39m 0 Nonlinear |R| = \ufffd[32m4.064714e+05\ufffd[39m\n\ufffd[36mGriffin_htm0_thm0: \ufffd[39m 1 Nonlinear |R| = \ufffd[32m4.700860e+01\ufffd[39m\n\ufffd[36mGriffin_htm0_thm0: \ufffd[39m 2 Nonlinear |R| = \ufffd[32m1.092626e-03\ufffd[39m\n\ufffd[36mGriffin_htm0_thm0: \ufffd[39m\ufffd[32m Solve Converged!\ufffd[39m\n\ufffd[36mGriffin_htm0_thm0: \ufffd[39m\n\ufffd[36mGriffin_htm0_thm0: \ufffd[39mPostprocessor Values:\n\ufffd[36mGriffin_htm0_thm0: \ufffd[39m+----------------+----------------+----------------+----------------+----------------+----------------+----------------+\n\ufffd[36mGriffin_htm0_thm0: \ufffd[39m| time           | Nu_avg         | Re_avg         | T_avg          | T_wall_avg     | coolant_T_in   | coolant_T_out  |\n\ufffd[36mGriffin_htm0_thm0: \ufffd[39m+----------------+----------------+----------------+----------------+----------------+----------------+----------------+\n\ufffd[36mGriffin_htm0_thm0: \ufffd[39m|   0.000000e+00 |   0.000000e+00 |   0.000000e+00 |   8.660000e+02 |   0.000000e+00 |   8.660000e+02 |   8.660000e+02 |\n\ufffd[36mGriffin_htm0_thm0: \ufffd[39m|   5.000000e-02 |   3.263650e+00 |   7.514410e+03 |   8.660000e+02 |   8.660000e+02 |   8.660000e+02 |   8.660000e+02 |\n\ufffd[36mGriffin_htm0_thm0: \ufffd[39m+----------------+----------------+----------------+----------------+----------------+----------------+----------------+\n\ufffd[36mGriffin_htm0_thm0: \ufffd[39m+----------------+----------------+----------------+----------------+----------------+----------------+----------------+\n\ufffd[36mGriffin_htm0_thm0: \ufffd[39m| time           | coolant_p_in   | coolant_p_out  | f_avg          | htc_avg        | q_avg          | vel_avg        |\n\ufffd[36mGriffin_htm0_thm0: \ufffd[39m+----------------+----------------+----------------+----------------+----------------+----------------+----------------+\n\ufffd[36mGriffin_htm0_thm0: \ufffd[39m|   0.000000e+00 |   2.537271e+05 |   2.537271e+05 |   1.940000e-02 |   0.000000e+00 |   0.000000e+00 |   0.000000e+00 |\n\ufffd[36mGriffin_htm0_thm0: \ufffd[39m|   5.000000e-02 |   2.561549e+05 |   2.537894e+05 |   1.940000e-02 |   2.914777e+04 |  -1.354264e-05 |   5.203557e-01 |\n\ufffd[36mGriffin_htm0_thm0: \ufffd[39m+----------------+----------------+----------------+----------------+----------------+----------------+----------------+\n\ufffd[36mGriffin_htm0_thm0: \ufffd[39m\n\ufffd[36mGriffin_htm0: \ufffd[39m\n\ufffd[36mGriffin_htm0: \ufffd[39mPostprocessor Values:\n\ufffd[36mGriffin_htm0: \ufffd[39m+----------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+\n\ufffd[36mGriffin_htm0: \ufffd[39m| time           | flux_integral  | htm_Tfuel      | htm_Tref       | max_fuel_T     | max_power      | min_power      | power_source   |\n\ufffd[36mGriffin_htm0: \ufffd[39m+----------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+\n\ufffd[36mGriffin_htm0: \ufffd[39m|   0.000000e+00 |   0.000000e+00 |   0.000000e+00 |   0.000000e+00 |   0.000000e+00 |   0.000000e+00 |   0.000000e+00 |   0.000000e+00 |\n\ufffd[36mGriffin_htm0: \ufffd[39m|   5.000000e-02 |  -8.876084e-05 |   8.660000e+02 |   8.660000e+02 |   8.660000e+02 |   0.000000e+00 |   0.000000e+00 |   0.000000e+00 |\n\ufffd[36mGriffin_htm0: \ufffd[39m+----------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+\n\ufffd[36mGriffin_htm0: \ufffd[39m\n\ufffd[36mGriffin_htm0: \ufffd[39mSteady-State Relative Differential Norm: 20\n\ufffd[36mGriffin_htm0: \ufffd[39m\n\ufffd[36mGriffin_htm0: \ufffd[39mTime Step 2, time = 0.1\n\ufffd[36mGriffin_htm0: \ufffd[39m         old time = 0.05\n\ufffd[36mGriffin_htm0: \ufffd[39m               dt = 0.05\n\ufffd[36mGriffin_htm0: \ufffd[39m           old dt = 0.05\n\ufffd[36mGriffin_htm0: \ufffd[39m\n\ufffd[36mGriffin_htm0: \ufffd[39m 0 Nonlinear |R| = \ufffd[32m1.380532e-02\ufffd[39m\n\ufffd[36mGriffin_htm0: \ufffd[39m 1 Nonlinear |R| = \ufffd[32m1.249788e-06\ufffd[39m\n\ufffd[36mGriffin_htm0: \ufffd[39m 2 Nonlinear |R| = \ufffd[32m4.534208e-10\ufffd[39m\n\ufffd[36mGriffin_htm0: \ufffd[39m\ufffd[32m Solve Converged!\ufffd[39m\n\ufffd[36mGriffin_htm0: \ufffd[39mFinished Solving                                                           [\ufffd[33m 31.89 s\ufffd[39m] [\ufffd[33m12432 MB\ufffd[39m]\n\ufffd[36mGriffin_htm0_thm0: \ufffd[39m\n\ufffd[36mGriffin_htm0_thm0: \ufffd[39mTime Step 2, time = 0.1\n\ufffd[36mGriffin_htm0_thm0: \ufffd[39m         old time = 0.05\n\ufffd[36mGriffin_htm0_thm0: \ufffd[39m               dt = 0.05\n\ufffd[36mGriffin_htm0_thm0: \ufffd[39m           old dt = 0.05\n\ufffd[36mGriffin_htm0_thm0: \ufffd[39m\n\ufffd[36mGriffin_htm0_thm0: \ufffd[39m 0 Nonlinear |R| = \ufffd[32m9.826201e+00\ufffd[39m\n\ufffd[36mGriffin_htm0_thm0: \ufffd[39m 1 Nonlinear |R| = \ufffd[32m8.550787e-06\ufffd[39m\n\ufffd[36mGriffin_htm0_thm0: \ufffd[39m\ufffd[32m Solve Converged!\ufffd[39m\n\ufffd[36mGriffin_htm0_thm0: \ufffd[39m\n\ufffd[36mGriffin_htm0_thm0: \ufffd[39mPostprocessor Values:\n\ufffd[36mGriffin_htm0_thm0: \ufffd[39m+----------------+----------------+----------------+----------------+----------------+----------------+----------------+\n\ufffd[36mGriffin_htm0_thm0: \ufffd[39m| time           | Nu_avg         | Re_avg         | T_avg          | T_wall_avg     | coolant_T_in   | coolant_T_out  |\n\ufffd[36mGriffin_htm0_thm0: \ufffd[39m+----------------+----------------+----------------+----------------+----------------+----------------+----------------+\n\ufffd[36mGriffin_htm0_thm0: \ufffd[39m|   0.000000e+00 |   0.000000e+00 |   0.000000e+00 |   8.660000e+02 |   0.000000e+00 |   8.660000e+02 |   8.660000e+02 |\n\ufffd[36mGriffin_htm0_thm0: \ufffd[39m|   5.000000e-02 |   3.263650e+00 |   7.514410e+03 |   8.660000e+02 |   8.660000e+02 |   8.660000e+02 |   8.660000e+02 |\n\ufffd[36mGriffin_htm0_thm0: \ufffd[39m|   1.000000e-01 |   3.263650e+00 |   7.514410e+03 |   8.660001e+02 |   8.660001e+02 |   8.660000e+02 |   8.660001e+02 |\n\ufffd[36mGriffin_htm0_thm0: \ufffd[39m+----------------+----------------+----------------+----------------+----------------+----------------+----------------+\n\ufffd[36mGriffin_htm0_thm0: \ufffd[39m+----------------+----------------+----------------+----------------+----------------+----------------+----------------+\n\ufffd[36mGriffin_htm0_thm0: \ufffd[39m| time           | coolant_p_in   | coolant_p_out  | f_avg          | htc_avg        | q_avg          | vel_avg        |\n\ufffd[36mGriffin_htm0_thm0: \ufffd[39m+----------------+----------------+----------------+----------------+----------------+----------------+----------------+\n\ufffd[36mGriffin_htm0_thm0: \ufffd[39m|   0.000000e+00 |   2.537271e+05 |   2.537271e+05 |   1.940000e-02 |   0.000000e+00 |   0.000000e+00 |   0.000000e+00 |\n\ufffd[36mGriffin_htm0_thm0: \ufffd[39m|   5.000000e-02 |   2.561549e+05 |   2.537894e+05 |   1.940000e-02 |   2.914777e+04 |  -1.354264e-05 |   5.203557e-01 |\n\ufffd[36mGriffin_htm0_thm0: \ufffd[39m|   1.000000e-01 |   2.566503e+05 |   2.538021e+05 |   1.940000e-02 |   2.914777e+04 |  -1.819328e-04 |   5.203580e-01 |\n\ufffd[36mGriffin_htm0_thm0: \ufffd[39m+----------------+----------------+----------------+----------------+----------------+----------------+----------------+\n\ufffd[36mGriffin_htm0_thm0: \ufffd[39m\n\ufffd[36mGriffin_htm0: \ufffd[39m\n\ufffd[36mGriffin_htm0: \ufffd[39mPostprocessor Values:\n\ufffd[36mGriffin_htm0: \ufffd[39m+----------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+\n\ufffd[36mGriffin_htm0: \ufffd[39m| time           | flux_integral  | htm_Tfuel      | htm_Tref       | max_fuel_T     | max_power      | min_power      | power_source   |\n\ufffd[36mGriffin_htm0: \ufffd[39m+----------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+\n\ufffd[36mGriffin_htm0: \ufffd[39m|   0.000000e+00 |   0.000000e+00 |   0.000000e+00 |   0.000000e+00 |   0.000000e+00 |   0.000000e+00 |   0.000000e+00 |   0.000000e+00 |\n\ufffd[36mGriffin_htm0: \ufffd[39m|   5.000000e-02 |  -8.876084e-05 |   8.660000e+02 |   8.660000e+02 |   8.660000e+02 |   0.000000e+00 |   0.000000e+00 |   0.000000e+00 |\n\ufffd[36mGriffin_htm0: \ufffd[39m|   1.000000e-01 |  -1.291114e-09 |   8.660000e+02 |   8.660000e+02 |   8.660000e+02 |   0.000000e+00 |   0.000000e+00 |   0.000000e+00 |\n\ufffd[36mGriffin_htm0: \ufffd[39m+----------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+\n\ufffd[36mGriffin_htm0: \ufffd[39m\n\ufffd[36mGriffin_htm0: \ufffd[39mSteady-State Solution Achieved at time: 0.1\n\ufffd[32mSubapp Griffin_htm0 solve converged!\ufffd[39m\n    Finished Executing MultiApps                                                         [\ufffd[33m109.79 s\ufffd[39m] [\ufffd[33m12432 MB\ufffd[39m]\n\ufffd[36mFinished Executing MultiApps on TIMESTEP_END\n\ufffd[39m\n  Finished Executing MultiApps                                                           [\ufffd[33m109.79 s\ufffd[39m] [\ufffd[33m12432 MB\ufffd[39m]\n\ufffd[36m\nTransfers on TIMESTEP_END From MultiApps\ufffd[39m:\n----------------------------------------------------------------------\n|      Name      |            Type            |    From     |   To   |\n----------------------------------------------------------------------\n| from_htm_Tfuel | MultiAppUserObjectTransfer | Griffin_htm | Parent |\n----------------------------------------------------------------------\n\ufffd[36mTransfers on TIMESTEP_END Are Finished\n\ufffd[39m\n  Performing Richardson Iteration\n\nI cut the output before and after it goes back to the power iteration in Griffin. In summary:\n\ntransfer occurs on TIMESTEP_END\nthe multiapp is executed inside the power iteration loop\nthe transfer seems to be happening within MOOSE but the value itself isn't properly transferred",
                          "url": "https://github.com/idaholab/moose/discussions/29676#discussioncomment-11868491",
                          "updatedAt": "2025-01-17T15:37:30Z",
                          "publishedAt": "2025-01-17T15:34:32Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "so transfers is not often enough?\nYou can try MULTIAPP_FIXED_POINT_END instead then",
                          "url": "https://github.com/idaholab/moose/discussions/29676#discussioncomment-11868525",
                          "updatedAt": "2025-01-17T15:37:24Z",
                          "publishedAt": "2025-01-17T15:37:23Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "garcs2"
                          },
                          "bodyText": "I tried MULTIAPP_FIXED_POINT_END and I'm still not getting the transfer to pass on properly, I also tried different configurations between TIMESTEP_END and MULTIAPP_FIXED_POINT_END between the main app and sub app and haven't gotten the transfers to function the way that I would like to. Given this issue I'm considering having the scheme shift in the other direction, where HT-TH solve first (with  the power density set in HT) and then pass that information onto Griffin. I figure this would work as when I explicitly provide an IC HT-TH solve just fine, but I'm still curious why the transfer isn't solving the way that I was originally intending.",
                          "url": "https://github.com/idaholab/moose/discussions/29676#discussioncomment-11870851",
                          "updatedAt": "2025-01-17T19:37:08Z",
                          "publishedAt": "2025-01-17T19:32:43Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "Parallel debugging on MacOS Sequoia",
          "author": {
            "login": "gambka"
          },
          "bodyText": "I need to debug a simulation that only hits a segfault when using a split-mesh. Once split, you have to run on the same number of processes as splits of the mesh. I follow the instructions here for parallel debugging and I'm running into issues with this command:\nmpiexec -n 4 ./yourapp-dbg -i inputfile.i --start-in-debugger='sudo lldb'\n\nAfter changing to myapp-dbg and the input file name of interest. I receive\nsh: xterm: command not found\nsh: xterm: command not found\nsh: xterm: command not found\nsh: xterm: command not found\n\nand the simulation just continues in the terminal as a normal run of the dbg executable.\nI think this is because --start-in-debugger uses xterm, however, on Sequoia if you do an echo $TERM it reports xterm-256color. Is there a way to  use --start-in-debugger with xterm-256color instead of xterm?",
          "url": "https://github.com/idaholab/moose/discussions/29730",
          "updatedAt": "2025-01-23T20:33:01Z",
          "publishedAt": "2025-01-22T18:53:50Z",
          "category": {
            "name": "Q&A Tools"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "GiudGiud"
                  },
                  "bodyText": "Not that I know. Did you try aliasing xterm to xterm-256color?",
                  "url": "https://github.com/idaholab/moose/discussions/29730#discussioncomment-11920592",
                  "updatedAt": "2025-01-22T19:03:43Z",
                  "publishedAt": "2025-01-22T19:03:42Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "gambka"
                          },
                          "bodyText": "That didn't work.",
                          "url": "https://github.com/idaholab/moose/discussions/29730#discussioncomment-11920947",
                          "updatedAt": "2025-01-22T19:39:08Z",
                          "publishedAt": "2025-01-22T19:39:07Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "gambka"
                          },
                          "bodyText": "The issue here was due to an issue with the internally provided XQuartz installation upon upgrading from Sonoma to Sequoia as well as xterm not being properly added to the PATH. This can be closed.",
                          "url": "https://github.com/idaholab/moose/discussions/29730#discussioncomment-11932063",
                          "updatedAt": "2025-01-23T16:08:28Z",
                          "publishedAt": "2025-01-23T16:08:27Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "General Implementation of Generalized-alpha time integration method",
          "author": {
            "login": "Silverwing747"
          },
          "bodyText": "Check these boxes if you have followed the posting rules.\n\n Q&A General is the most appropriate section for my question\n I have consulted the posting Guidelines on the Discussions front page\n I have searched the Discussions forum and my question has not been asked before\n I have searched the MOOSE website and the documentation does not answer my question\n I have formatted my post following the posting guidelines (screenshots as a last resort, triple back quotes around pasted text)\n\nQuestion\nHello Everyone,\nI have recently attempted to implement the Generalized-alpha time integration method for a first-order system (reference: DOI: 10.1016/S0045-7825(00)00203-6).\nI noticed that MOOSE already includes the HHT-alpha method for solid mechanics. However, this implementation is not general and requires modifications to the Kernel object, which is not ideal for broader applications.\nTo address this, I am trying to develop a more general version of these alpha-methods in MOOSE. The implementation is structured as follows:\n\nFor a general implementation, I believe the presolve and postsolve functions from TimeIntegrator.h need to be utilized. Specifically:\n\u2022\tIn presolve, the alpha-stage vector can be computed and passed to the solver.\n\u2022\tIn postsolve, the actual solution (_solution) can be updated using the alpha-stage vector.\nI have two questions regarding this approach:\n1.\tCan the _solution be updated in the TimeIntegrator object? I noticed that it is cast as const, const NumericVector<Number> * const & _solution;. What is the reasoning behind this design choice?\n2.\tAre there any existing examples of how to utilize the presolve and postsolve functions? I imagine the implementation might be similar to that in PETSc, but I couldn\u2019t find any examples in MOOSE.\nThank you for your help!",
          "url": "https://github.com/idaholab/moose/discussions/29683",
          "updatedAt": "2025-01-22T21:47:03Z",
          "publishedAt": "2025-01-13T15:39:32Z",
          "category": {
            "name": "Q&A General"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "GiudGiud"
                  },
                  "bodyText": "Hello\n\n\nCan the _solution be updated in the TimeIntegrator object? I noticed that it is cast as const, const NumericVector * const & _solution;. What is the reasoning behind this design choice?\n\n\nThe original idea for modifying the solution would be to do in a Predictor object (before taking the step), or a Corrector user object (after)\nGuillaume",
                  "url": "https://github.com/idaholab/moose/discussions/29683#discussioncomment-11821779",
                  "updatedAt": "2025-01-13T16:03:09Z",
                  "publishedAt": "2025-01-13T16:03:08Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "Silverwing747"
                          },
                          "bodyText": "Hello Guillaume,\nI have implemented generalized alpha under my NSCH code. The implementation uses presolve and postsolve functions in the timeintegrator object, instead of using the predictor and corrector object you mentioned. The convergence test shows my implementation is second order. However, since I am very new to MOOSE framework, I am not completely sure if this is the right way to go. Let me know if you have any comments.",
                          "url": "https://github.com/idaholab/moose/discussions/29683#discussioncomment-11922140",
                          "updatedAt": "2025-01-22T21:44:40Z",
                          "publishedAt": "2025-01-22T21:44:39Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "Checking the order of convergence is a great verification step.\nNext you should verify against analytical solutions if there are any available for your problem.",
                          "url": "https://github.com/idaholab/moose/discussions/29683#discussioncomment-11922161",
                          "updatedAt": "2025-01-22T21:47:04Z",
                          "publishedAt": "2025-01-22T21:47:03Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "how to model inlet and outlet in a flow channel",
          "author": {
            "login": "waaizhaq"
          },
          "bodyText": "Check these boxes if you have followed the posting rules.\n\n Q&A Navier Stokes is the most appropriate category for my question\n I have consulted the posting Guidelines on the Discussions front page\n I have searched the Discussions forum and my question has not been asked before\n I have searched the MOOSE website and the documentation does not answer my question\n I have formatted my post following the posting guidelines (avoid screenshots if possible, triple back quotes before/after pasted text, etc)\n\nQuestion\nHi, I'm trying to model natural convection flow between two heated walls (representing heated fuel rods) entering from the bottom (inlet) and exiting out the top (outlet). But whenever I run the input, it stops converging after a few timesteps. By viewing the output in Paraview, it seems that the flow turns back around near the top boundary. This would also explain why my fluid temperatures are so high when my simulation stops converging (~1e3 Kelvin).\nI'm not sure if there's a specific way to set an inlet and outlet channel, but I just have a DirichletBC for the bottom boundary and 0 flow initial condition since it's natural convection.\nInput:\nbundle_flow.txt\nAdditional information\nMesh size and type:\nReynolds number:\nDiscretization (finite element CG/DG, finite volume, etc):\nModels (turbulence, porous media, etc):\nSolver method (fully coupled, segregated, multiapps, etc):\nBase input you started from:",
          "url": "https://github.com/idaholab/moose/discussions/29715",
          "updatedAt": "2025-01-22T17:47:45Z",
          "publishedAt": "2025-01-20T22:42:49Z",
          "category": {
            "name": "Q&A Modules: Navier-Stokes"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "GiudGiud"
                  },
                  "bodyText": "hello\n\n0 flow initial condition\n\nyou'll want a small initial velocity to avoid the v = 0 point in the energy advection equation\n\nDirichletBC for the bottom boundary\n\nyou ll want to use noslip or free-slip bcs for velocity and dirichlet or heat flux for temperature",
                  "url": "https://github.com/idaholab/moose/discussions/29715#discussioncomment-11919187",
                  "updatedAt": "2025-01-22T16:52:07Z",
                  "publishedAt": "2025-01-22T16:52:07Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "waaizhaq"
                          },
                          "bodyText": "I see, I was actually able to resolve the issue by using a MomentumOutflowBC at the exit, heat fluxes and no-slip bcs at the left and right walls, and temperature DirichletBC at the inlet. I forgot to include no-slip at the inlet.\nI also didn't realize that including a small initial velocity would be a factor. Do you think 1e-4 is a good value?",
                          "url": "https://github.com/idaholab/moose/discussions/29715#discussioncomment-11919438",
                          "updatedAt": "2025-01-22T17:12:18Z",
                          "publishedAt": "2025-01-22T17:12:17Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "I forgot to include no-slip at the inlet.\n\ninlet should not be no-slip. There are inlet BCs.\n1e-4 is fine. we use 1e-10",
                          "url": "https://github.com/idaholab/moose/discussions/29715#discussioncomment-11919555",
                          "updatedAt": "2025-01-22T17:23:23Z",
                          "publishedAt": "2025-01-22T17:23:22Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "waaizhaq"
                          },
                          "bodyText": "Gotcha, like an inlet velocity BC?",
                          "url": "https://github.com/idaholab/moose/discussions/29715#discussioncomment-11919644",
                          "updatedAt": "2025-01-22T17:32:36Z",
                          "publishedAt": "2025-01-22T17:32:35Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "for example, if you know the inlet velocity",
                          "url": "https://github.com/idaholab/moose/discussions/29715#discussioncomment-11919768",
                          "updatedAt": "2025-01-22T17:44:29Z",
                          "publishedAt": "2025-01-22T17:44:28Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "waaizhaq"
                          },
                          "bodyText": "Got it, thank you!",
                          "url": "https://github.com/idaholab/moose/discussions/29715#discussioncomment-11919793",
                          "updatedAt": "2025-01-22T17:47:45Z",
                          "publishedAt": "2025-01-22T17:47:45Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      }
    ]
  }
}