{
  "discussions": {
    "pageInfo": {
      "hasNextPage": true,
      "endCursor": "Y3Vyc29yOnYyOpK5MjAyMS0wMS0yNFQxOTowODo1OC0wNzowMM2C_g=="
    },
    "edges": [
      {
        "node": {
          "title": "Hide (some) postprocessors from console?",
          "author": {
            "login": "aprilnovak"
          },
          "bodyText": "Hi all,\nIs it possible to hide individual postprocessors from being output to the screen? For instance, if all I care about is the value of LinearCombinationPostprocessor, that combines multiple other postprocessors into something meaningful, is it possible to hide the postprocessors that just went into the calculation of the LinearCombinationPostprocessor? This would make it easier to monitor the solution progression so I don't have loads of screen output.\nI know I can hide them from the Exodus file with hide- is there something similar for the screen output?\nThanks!\n-April",
          "url": "https://github.com/idaholab/moose/discussions/16815",
          "updatedAt": "2023-10-12T15:33:16Z",
          "publishedAt": "2021-01-26T21:41:19Z",
          "category": {
            "name": "Q&A General"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "hugary1995"
                  },
                  "bodyText": "Does this work?\n[Outputs]\n  [foo]\n    type = Console\n    hide = 'bar baz'\n  []\n[]",
                  "url": "https://github.com/idaholab/moose/discussions/16815#discussioncomment-312720",
                  "updatedAt": "2023-10-12T15:33:16Z",
                  "publishedAt": "2021-01-26T21:45:50Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "aprilnovak"
                          },
                          "bodyText": "Yes! Wonderful, thank you :)",
                          "url": "https://github.com/idaholab/moose/discussions/16815#discussioncomment-312746",
                          "updatedAt": "2023-10-12T15:33:30Z",
                          "publishedAt": "2021-01-26T21:48:40Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "aeslaughter"
                          },
                          "bodyText": "You can also put \"outputs = none\" in the PP/VPP block as well.",
                          "url": "https://github.com/idaholab/moose/discussions/16815#discussioncomment-312805",
                          "updatedAt": "2023-10-12T15:33:30Z",
                          "publishedAt": "2021-01-26T22:10:53Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "Cholesky decomposition error for boundary restricted AuxKernel",
          "author": {
            "login": "aprilnovak"
          },
          "bodyText": "Hi all,\nI'd like to apply the DiffusionFluxAux auxkernel to a MONOMIAL auxvariable of FIRST order on a boundary. However, when I try this, I get the following error:\nTime Step 1, time = 1, dt = 1\nError! Can only use Cholesky decomposition with symmetric positive definite matrices.\nStack frames: 26\n0: libMesh::print_trace(std::ostream&)\n1: libMesh::MacroFunctions::report_error(char const*, int, char const*, char const*)\n2: libMesh::DenseMatrix<double>::_cholesky_decompose()\n3: void libMesh::DenseMatrix<double>::cholesky_solve<double>(libMesh::DenseVector<double> const&, libMesh::DenseVector<double>&)\n4: AuxKernelTempl<double>::compute()\n5: ComputeElemAuxBcsThread<AuxKernelTempl<double> >::operator()(libMesh::StoredRange<MooseMesh::const_bnd_elem_iterator, BndElement const*> const&)\n6: void libMesh::Threads::parallel_reduce<libMesh::StoredRange<MooseMesh::const_bnd_elem_iterator, BndElement const*>, ComputeElemAuxBcsThread<AuxKernelTempl<double> > >(libMesh::StoredRange<MooseMesh::const_bnd_elem_iterator, BndElement const*> const&, ComputeElemAuxBcsThread<AuxKernelTempl<double> >&)\n7: void AuxiliarySystem::computeElementalVarsHelper<AuxKernelTempl<double> >(MooseObjectWarehouse<AuxKernelTempl<double> > const&, std::vector<std::vector<MooseVariableFieldBase*, std::allocator<MooseVariableFieldBase*> >, std::allocator<std::vector<MooseVariableFieldBase*, std::allocator<MooseVariableFieldBase*> > > > const&, unsigned int)\n8: AuxiliarySystem::computeElementalVars(MooseEnumItem)\n9: AuxiliarySystem::compute(MooseEnumItem)\n10: FEProblemBase::computeResidualTags(std::set<unsigned int, std::less<unsigned int>, std::allocator<unsigned int> > const&)\n11: FEProblemBase::computeResidualInternal(libMesh::NumericVector<double> const&, libMesh::NumericVector<double>&, std::set<unsigned int, std::less<unsigned int>, std::allocator<unsigned int> > const&)\n12: FEProblemBase::computeResidualSys(libMesh::NonlinearImplicitSystem&, libMesh::NumericVector<double> const&, libMesh::NumericVector<double>&)\n13: NonlinearSystem::solve()\n14: FEProblemBase::solve()\n15: FEProblemSolve::solve()\n16: PicardSolve::solveStep(double, double&, double, double&, bool, std::set<unsigned int, std::less<unsigned int>, std::allocator<unsigned int> > const&)\n17: PicardSolve::solve()\n18: TimeStepper::step()\n19: Transient::takeStep(double)\n20: Transient::execute()\n21: MooseApp::executeExecutioner()\n22: MooseApp::run()\n23: ../../../../cardinal-opt(+0x5eaf) [0x56135c9a5eaf]\n24: __libc_start_main\n25: ../../../../cardinal-opt(+0x60ae) [0x56135c9a60ae]\n[0] ./include/libmesh/dense_matrix_impl.h, line 1001, compiled Dec 18 2020 at 12:35:12\napplication called MPI_Abort(MPI_COMM_WORLD, 1) - process 0\n[unset]: write_line error; fd=-1 buf=:cmd=abort exitcode=1\n\nAfter playing around a bit, I've found two different settings that affect whether or not I see this error:\n\nIf I change the order to order = CONSTANT, but keep the boundary restriction (boundary = '1'), I don't see the error.\nIf I remove the boundary restriction (remove boundary='1'), I don't see the error for either order = CONSTANT or order = FIRST.\n\nI'm having a hard time trying to reason out whether if I just shouldn't be trying to apply this AuxKernel in this manner, or if there's a bug here. I would have thought that any order elemental auxvariable might complain about a boundary-restricted auxkernel, but order = CONSTANT is fine. If I'm doing something erroneous here, I think a more narrowly-focused error message would be helpful.\nI've attached a minimal example that shows this error. The error disappears if you (A) change the avg_flux order to CONSTANT, or (B) remove boundary='1' for the DiffusionFluxAux kernel.\nThanks,\n-April",
          "url": "https://github.com/idaholab/moose/discussions/16562",
          "updatedAt": "2022-08-08T02:52:01Z",
          "publishedAt": "2020-12-21T22:01:11Z",
          "category": {
            "name": "Q&A General"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "aprilnovak"
                  },
                  "bodyText": "example.txt",
                  "url": "https://github.com/idaholab/moose/discussions/16562#discussioncomment-232114",
                  "updatedAt": "2022-08-08T02:52:03Z",
                  "publishedAt": "2020-12-21T22:02:14Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "fdkong"
                          },
                          "bodyText": "This simply means the matrix is not symmetric anymore when the DiffusionFluxAux kernel is restricted on boundary.",
                          "url": "https://github.com/idaholab/moose/discussions/16562#discussioncomment-237927",
                          "updatedAt": "2022-08-08T02:52:03Z",
                          "publishedAt": "2020-12-23T18:23:15Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "aprilnovak"
                          },
                          "bodyText": "Gotcha. Is that error supposed to kill the program though? I would have thought that there's not really any solves going on with the auxvariables - just compute them from other variables.",
                          "url": "https://github.com/idaholab/moose/discussions/16562#discussioncomment-237935",
                          "updatedAt": "2022-08-08T02:52:03Z",
                          "publishedAt": "2020-12-23T18:29:34Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "fdkong"
                          },
                          "bodyText": "Here is the code:\n  else /* high-order */\n    {\n      _local_re.resize(_n_local_dofs);\n      _local_re.zero();\n      _local_ke.resize(_n_local_dofs, _n_local_dofs);\n      _local_ke.zero();\n\n      // assemble the local mass matrix and the load\n      for (unsigned int i = 0; i < _test.size(); i++)\n        for (_qp = 0; _qp < _qrule->n_points(); _qp++)\n        {\n          ComputeValueType t = _JxW[_qp] * _coord[_qp] * _test[i][_qp];\n          _local_re(i) += t * computeValue();\n          for (unsigned int j = 0; j < _test.size(); j++)\n            _local_ke(i, j) += t * _test[j][_qp];\n        }\n\n      // mass matrix is always SPD\n      _local_sol.resize(_n_local_dofs);\n      _local_ke.cholesky_solve(_local_re, _local_sol);\n\n      _var.setDofValues(_local_sol);\n    }\n\nIt has nothing to do with PETSc solver for the nonlinear system. It is trying to inverse a small element matrix system to get RHS. If this fails, the computation can not keep going.",
                          "url": "https://github.com/idaholab/moose/discussions/16562#discussioncomment-237975",
                          "updatedAt": "2022-08-08T02:52:03Z",
                          "publishedAt": "2020-12-23T18:41:28Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "aprilnovak"
                          },
                          "bodyText": "Would an error like the following always catch when this happens? I guess I am wishing that the error message were more instructive.\n// in AuxKernel constructor?\nif (order > CONSTANT && isParamValid(\"boundary\"))\n  mooseError(\"Auxvariable orders higher than CONSTANT are not supported with boundary-restricted AuxKernels\");",
                          "url": "https://github.com/idaholab/moose/discussions/16562#discussioncomment-238363",
                          "updatedAt": "2020-12-23T20:00:55Z",
                          "publishedAt": "2020-12-23T20:00:34Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "aeslaughter"
                          },
                          "bodyText": "You can make it a paramError(\"boundary\", \"AuxVariable orders...\") and it will report a line number in the error report.",
                          "url": "https://github.com/idaholab/moose/discussions/16562#discussioncomment-240259",
                          "updatedAt": "2020-12-24T16:11:05Z",
                          "publishedAt": "2020-12-24T16:11:05Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "fdkong"
                          },
                          "bodyText": "Would an error like the following always catch when this happens? I guess I am wishing that the error message were more instructive.\n\n\n// in AuxKernel constructor?\nif (order > CONSTANT && isParamValid(\"boundary\"))\nmooseError(\"Auxvariable orders higher than CONSTANT are not supported with boundary-restricted AuxKernels\");\n\nIt is a great idea to add these checks. At the same time, I am still trying to understand why the mass matrix is not symmetric when it is restricted on a boundary.",
                          "url": "https://github.com/idaholab/moose/discussions/16562#discussioncomment-240276",
                          "updatedAt": "2020-12-24T16:21:20Z",
                          "publishedAt": "2020-12-24T16:21:20Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "aprilnovak"
                          },
                          "bodyText": "@fdkong, any update on why the mass matrix wouldn't be symmetric on a boundary?\nFor Cardinal, we're currently restricted to using a CONSTANT MONOMIAL to transfer heat flux into nekRS (because nodal auxvariables don't support gradients, and the Cholesky error is preventing me from using FIRST MONOMIAL). Our BISON mesh for the fuel pins are generally much coarser than the nekRS meshes for the surrounding fluid. Being restricted to a constant heat flux in each BISON element is distorting the heat flux going into nekRS so that we're needing to use really fine BISON meshes (for the solid) just to match the results of a standalone reference nekRS solution (i.e. nekRS solving for both the fluid and solid).\nMaybe there's another approach I haven't thought of to retain that spatial resolution of the flux coming from MOOSE?",
                          "url": "https://github.com/idaholab/moose/discussions/16562#discussioncomment-302999",
                          "updatedAt": "2021-01-22T17:45:30Z",
                          "publishedAt": "2021-01-22T17:45:30Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "fdkong"
                          },
                          "bodyText": "@aprilnovak If you could send me an example, I will look into this.",
                          "url": "https://github.com/idaholab/moose/discussions/16562#discussioncomment-309745",
                          "updatedAt": "2021-01-25T20:23:08Z",
                          "publishedAt": "2021-01-25T20:23:08Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "YaqiWang"
                          },
                          "bodyText": "Do we have any test covering this case in MOOSE? The matrix could be rank deficient because we are only assembling it with the quadrature points on the boundary side. We may need the pseudo inverse for this. But I am surprised we do not see any error before if this is the case.",
                          "url": "https://github.com/idaholab/moose/discussions/16562#discussioncomment-310035",
                          "updatedAt": "2021-01-25T23:54:15Z",
                          "publishedAt": "2021-01-25T22:29:41Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "aprilnovak"
                          },
                          "bodyText": "Sure, thanks a bunch! I've attached an example here. This will show you that changing from CONSTANT MONOMIAL to FIRST MONOMIAL throws the error.\nAfter thinking about this more, I realize that I have a second question. It relates to my original question, so I thought I'd ask it here, but if it'd be better as a new discussion let me know! I'll illustrate my question with an example:\nThe Problem and Reference Solution\nI have a 2-region cylinder heat conduction problem. In the center cylinder, I have a super asymmetrical heat source (to exaggerate the results), while in the outer cylinder there is no heat source. Other than that, there is just heat conduction. To get a reference solution with a single application, I ran two different meshes (I actually made new meshes for each, and didn't just use uniform_refine):\nCoarse mesh, with 9128 elements:\n\nFine mesh, with 235420 elements:\n\nThe reference temperature distribution on the super fine mesh looks like:\n\nThe temperature on the finer reference mesh is visually identical, so I don't repeat it. On the interface between the two cylinders, the maximum and minimum temperatures for the reference cases are:\n\n\n\nMesh\nNumber of elements\nMax temp\nMin temp\n\n\n\n\nCoarse reference\n9128\n1959.62\n1340.72\n\n\nFine reference\n235420\n1961.22\n1341.78\n\n\n\nMy point in showing two reference solutions is to prove that the results I'm trying to replicate are converged. And it's important that the coarse mesh of ~9000 elements is very close to the fine result, so for my intent I consider the 9000 element mesh to be converged.\nSolving as Two Regions\nSo, suppose that I want to match those max/min temperatures for the same physics, but I'm solving each cylinder with a different App. This approximates what I'm doing with the nekRS wrapping - one App solves for the inner cylinder, while a different App solves for the outer cylinder. For instance, here are two meshes - the top one would be solved by the master app (where a MatchedValueBC is set on the outer surface), while the bottom one would be solved by the sub app (where a CoupledVarNeumannBC is set on the inner surface). Same physics, and with iteration, I should match the reference two-region problem.\nApp 1 domain and solution:\n\nApp 2 domain and solution:\n\nThe Problem:\nThe problem is that, even when using meshes of similar resolution as the reference meshes, the fact that I'm limited to a CONSTANT MONOMIAL heat flux going in to the outer cylinder means that I need a super fine mesh just to represent the data transfer. This table shows examples of what I'm talking about: I gradually refine the meshes in the nek_master.i and nek.i input files (I always match them perfectly at the interface to avoid anything weird with needing to normalize incoming flux values). When the number of elements is similar to the number used in the reference mesh, errors are on the order of 25 K. Even when using meshes with 3x as many elements as the reference mesh, errors are still on the order of 8 K.\n\n\n\nMesh\nNumber of elements\nMax temp ERROR\nMin temp ERROR\n\n\n\n\n2 coupled apps\n9000\n23.5\n6.1\n\n\n2 coupled apps\n12000\n13.0\n3.3\n\n\n2 coupled apps\n18000\n9.2\n2.3\n\n\n2 coupled apps\n24000\n8.0\n1.6\n\n\n\nHere's the finest mesh I'm using:\n\nThis is way finer than the coarse mesh I'm comparing against (i.e. picture 1), so I would expect good agreement.\nThe Question\nHow can I solve two coupled Apps and get similar results as the fully-coupled two-region problem, without needing > 3x finer meshes in the coupled App case?\nIs it impossible? From my original question, my motivation was getting around this super fine mesh issue, which is really the root of what I'm interested in addressing.",
                          "url": "https://github.com/idaholab/moose/discussions/16562#discussioncomment-310042",
                          "updatedAt": "2021-01-25T22:50:49Z",
                          "publishedAt": "2021-01-25T22:34:55Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              },
              {
                "node": {
                  "author": {
                    "login": "aeslaughter"
                  },
                  "bodyText": "@fdkong Can you help with this?",
                  "url": "https://github.com/idaholab/moose/discussions/16562#discussioncomment-232426",
                  "updatedAt": "2022-08-08T02:52:09Z",
                  "publishedAt": "2020-12-21T22:50:42Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "author": {
                    "login": "YaqiWang"
                  },
                  "bodyText": "This change can produce the error on my Mac:\ndiff --git a/test/tests/auxkernels/element_aux_boundary/element_aux_boundary.i b/test/tests/auxkernels/element_aux_boundary/element_aux_boundary.i\nindex 3a8bbd227a..de6b47fe36 100644\n--- a/test/tests/auxkernels/element_aux_boundary/element_aux_boundary.i\n+++ b/test/tests/auxkernels/element_aux_boundary/element_aux_boundary.i\n@@ -13,7 +13,7 @@\n [AuxVariables]\n   [./real_property]\n     family = MONOMIAL\n-    order = CONSTANT\n+    order = SECOND\n   [../]\n []\n\nSupposedly with order=FIRST we should see the same error, but I check the code in libMesh,\n              libmesh_error_msg_if(A(i,j) <= 0.0,\n                                   \"Error! Can only use Cholesky decomposition with symmetric positive definite matrices.\");\n\npossibly it is very sensitive to numerical round-off comparing with 0, thus we did not see the error with the first order. Possibly due to the same reason, you did not see errors in some of your calculations. I checked several moose tests, they are all using constant monomial unfortunately. The fix will be using different lapack function to find a special solution for the singular mass matrix. For example, replace\n_local_ke.cholesky_solve(_local_re, _local_sol);\n\nin AuxKernel.C with\n_local_ke.svd_solve(_local_re, _local_sol);\n\ncan temporarily solve the problem. We choose cholesky_solve because we think mass matrix is SPD and Cholesky is more efficient.",
                  "url": "https://github.com/idaholab/moose/discussions/16562#discussioncomment-310466",
                  "updatedAt": "2022-08-08T02:52:10Z",
                  "publishedAt": "2021-01-26T04:14:05Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "aprilnovak"
                          },
                          "bodyText": "thus we did not see the error with the first order\n\nI actually did see the error with FIRST order - but it's interesting that you didn't! That's definitely a good insight. In any case, it would probably be a good idea to include some non-CONSTANT monomial tests in MOOSE.",
                          "url": "https://github.com/idaholab/moose/discussions/16562#discussioncomment-310482",
                          "updatedAt": "2022-08-08T02:52:12Z",
                          "publishedAt": "2021-01-26T04:26:49Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "YaqiWang"
                          },
                          "bodyText": "Good to hear that. You can try svd_solve for now if your task is urgent.",
                          "url": "https://github.com/idaholab/moose/discussions/16562#discussioncomment-310487",
                          "updatedAt": "2022-09-21T13:14:36Z",
                          "publishedAt": "2021-01-26T04:29:10Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "YaqiWang"
                          },
                          "bodyText": "Also April, not sure if you noticed my warning in my previous post. I did not check your model, but be sure you do not hit the situation I described in #5061.",
                          "url": "https://github.com/idaholab/moose/discussions/16562#discussioncomment-310496",
                          "updatedAt": "2022-09-21T13:14:37Z",
                          "publishedAt": "2021-01-26T04:36:15Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "Issue compiling project on HPC",
          "author": {
            "login": "ajsummers"
          },
          "bodyText": "I previously posted an installation problem here: #16711\nFollowing from this, I have run into an error while running make for the first time on a project:\nCompiling C++ (in opt mode) /home/ajs0201/projects/moose/framework/build/unity_src/outputs_Unity.C...\n/usr/bin/ld: BFD version 2.20.51.0.2-5.48.el6_10.1 20100205 internal error, aborting at reloc.c line 443 in bfd_get_reloc_size\n\n/usr/bin/ld: Please report this bug.\n\ncollect2: error: ld returned 1 exit status\nmake: *** [/home/ajs0201/projects/moose/modules/module_loader/lib/libmodule_loader_with-opt.la] Error 1\nmake: *** Waiting for unfinished jobs....\n/usr/bin/ld: warning: libgfortran.so.4, needed by /home/ajs0201/miniconda3/envs/moose/lib/libpetsc.so, not found (try using -rpath or -rpath-link)\n\nThe operating system of the HPC is CentOS 6.10.\nI have the following modules loaded into the environment:\n\ngcc/8.1.0\nmpich/3.2.1\ncmake/gcc/3.12.3\nmpc/1.0.3\n\nThanks again in advance for any help!",
          "url": "https://github.com/idaholab/moose/discussions/16802",
          "updatedAt": "2022-11-17T18:40:12Z",
          "publishedAt": "2021-01-24T00:02:50Z",
          "category": {
            "name": "Q&A Getting Started"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "ngrilli"
                  },
                  "bodyText": "Dear @ajsummers\nTry the manual installation instructions:\nhttps://mooseframework.inl.gov/getting_started/installation/manual_installation_gcc.html\nIt works better for us on CentOS.\nBest Regards,\nNicol\u00f2 Grilli\nNational University of Singapore",
                  "url": "https://github.com/idaholab/moose/discussions/16802#discussioncomment-305654",
                  "updatedAt": "2022-11-17T18:40:16Z",
                  "publishedAt": "2021-01-24T02:25:13Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "author": {
                    "login": "milljm"
                  },
                  "bodyText": "Going over your old post and this one, it looks like you did both a Conda and a Manual Install:\nI started off using the standard Linux installation method. Installed Miniconda and the Moose environment, then cloned in the repository. After this, I followed the GCC/MPICH manual installation method.\nThe error in question is from using Conda's moose-petsc, in conflict with compilers provided by your system:\n    gcc/8.1.0\n    mpich/3.2.1\n    cmake/gcc/3.12.3\n    mpc/1.0.3\n\nThese will conflict, as moose-petsc (10 days ago) was built with GCC 7.3.0 (Conda's compilers at the time: libgfortran.so.4). Today if you were to start over, you would see that moose-petsc is now using Conda's latest GCC compilers. -but that is neither here nor there. However, there would still be a conflict...\nWhen deciding which set of instructions to follow, it is important to follow only one set. This is because:\n\nWhen using Conda (and specifically the moose packages moose-libmesh, or moose-petsc), there is no reason to build PETSc (or libMesh).\nWhen following the Manual Installation method, you have to build everything manually (possibly gcc and mpich. Certainly PETSc, libMesh).\n\nBecause it looks like you were able to successfully build PETSc back in the old thread, I would recommend uninstalling (or simply not using) the moose environment you installed with Conda. If you followed the Conda instructions to the letter, that would mean you should do:\nconda deactivate\nconda env remove -n moose\n\nNext, we should re-build libMesh, MOOSE and your application cleanly.\nClose your terminals (for good measure). Re-open them, and clean moose and your application (note! be sure to commit your changes or this will delete them!)\ncd /home/ajs0201/projects/moose\ngit clean -xfd\ncd yourapp #<-- where ever this may be\ngit clean -xfd     # Note: again, be sure to commit any changes. This command deletes un-tracked files.\n\nThe above will purge any stale libraries lingering around, possibly still built with Conda's compilers.\nNext, re-build libMesh, MOOSE and your app using your system compilers:\nmodule purge\nmodule load gcc/8.1.0 mpich/3.2.1 cmake/gcc/3.12.3 mpc/1.0.3\ncd /home/ajs0201/projects/moose/scripts\n./update_and_rebuild_libmesh.sh\ncd yourapp\nmake",
                  "url": "https://github.com/idaholab/moose/discussions/16802#discussioncomment-308667",
                  "updatedAt": "2022-11-17T18:42:36Z",
                  "publishedAt": "2021-01-25T14:32:44Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "ajsummers"
                          },
                          "bodyText": "Thank you for your response. I will try this and update the thread. Should I recompile petsc as well?",
                          "url": "https://github.com/idaholab/moose/discussions/16802#discussioncomment-310055",
                          "updatedAt": "2023-08-04T02:29:37Z",
                          "publishedAt": "2021-01-25T22:38:52Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "ajsummers"
                          },
                          "bodyText": "I followed the directions in this post and got the following message while performing make in the test directory:\nThere appears to be a libMesh update in progress for\nthe branch of MOOSE you are operating on (only the\nmaster branch contains publicly available moose-libmesh\npackages).\n\nYou must provide your own libMesh either by:\n\n    1. Uninstall moose-libmesh and build it manually via\n       moose/scripts/update_and_rebuild_libmesh.sh\nor\n    2. Use `conda build` to build your own moose-libmesh\n       package.\n\nI've decided to remove Anaconda entirely and restart the GCC/MPICH installation from scratch.",
                          "url": "https://github.com/idaholab/moose/discussions/16802#discussioncomment-310277",
                          "updatedAt": "2023-08-04T02:29:47Z",
                          "publishedAt": "2021-01-26T01:09:22Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "milljm"
                          },
                          "bodyText": "should i recompile petsc\nNo need to rebuild PETSc, as I think you have that built correctly.\nIt may be that you have conda-build available. Honestly that little check is causing more issues than it solves... Is there a way you can create a new vanilla conda environment, so as not to have conda-build available?\nconda create -n bare -q -y\nconda activate bare\n\nShould be pretty blank. Unless someone added some defaults that get installed with new environment created...\nSorry for the delayed response!",
                          "url": "https://github.com/idaholab/moose/discussions/16802#discussioncomment-312360",
                          "updatedAt": "2023-08-04T02:29:49Z",
                          "publishedAt": "2021-01-26T19:10:11Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "milljm"
                          },
                          "bodyText": "Oh! I didn't see this little tidbit here:\nI've decided to remove Anaconda entirely and restart the GCC/MPICH installation from scratch.\nThat's fine, sorry I wasn't able to respond in a timely manner. If you do happen to run into that \"There appears to be a libMesh update...\", please try the above conda bare environment trick (however, without Anaconda even installed, I foresee no issues). If that doesn't work, I know exactly where that little hiccup is happening in MOOSE, and we can avoid it (line 8 or ~10 in moose/framework/moose.mk). You will see it calling a conda verify script in moose/scripts. That is our culprit.\nIt is normally only triggered if someone has conda-build installed in their conda environment (what we use to build moose-libmesh). And such, it sometimes gets in the way of legitimate builders trying to manually build the libraries such as yourself.",
                          "url": "https://github.com/idaholab/moose/discussions/16802#discussioncomment-312515",
                          "updatedAt": "2023-08-04T02:29:51Z",
                          "publishedAt": "2021-01-26T20:30:13Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "When are materials evaluated?",
          "author": {
            "login": "matthiasneuner"
          },
          "bodyText": "Hello, I am trying to figuring out how and when materials are evaluated during a transient simulation using the classical NEWTON scheme.\nAssume that I have a simple linear stress-strain material for the tensor mechanics module. Within computeQpProperties(),  both the 1) current stress and 2) the derivative Jacobian_mult for assembling the Jacobian are computed simultaneously. Such a simultaneous computation is reasonable for e.g., plasticity models, where the jacobian is computed as a byproduct of the return mapping algorithm.\nConsidering a single element with a single quadrature point, a simple print statement gives me following output:\nTime Step 0, time = 0                                                                                                                                                                    \n                                                                                                                                                                                         \nTime Step 1, time = 0.1, dt = 0.1                                                                                                                                                        \nMaterial @ qp 0 evaluated                         # evaluation n.1 with zero strain                                                                                                                                                          \nMaterial @ qp 0 evaluated                         # evaluation n.2  for computing the residual                                                                                                                                       \n 0 Nonlinear |R| = 1.414214e-01                                                                                                                                                          \nMaterial @ qp 0 evaluated                         # evaluation n.3 for computing the Jacobian                                                                                                                                      \n      0 Linear |R| = 1.414214e-01                                                                                                                                                        \n      1 Linear |R| = 2.220446e-17                                                                                                                                                        \n  Linear solve converged due to CONVERGED_RTOL iterations 1                                                                                                                              \nMaterial @ qp 0 evaluated                         # evaluation n.4 for checking convergence after solving                                                                                                                                       \n 1 Nonlinear |R| = 3.925231e-17                                                                                                                                                            \nNonlinear solve converged due to CONVERGED_FNORM_ABS iterations 1                                                                                                                        \n Solve Converged!                                                                                                                                                                        \n                                                                                                                                                                                         \nOutlier Variable Residual Norms:                                                                                                                                                         \n  disp_x: 3.925231e-17\n\nTime Step 2, time = 0.2, dt = 0.1\nMaterial @ qp 0 evaluated \nMaterial @ qp 0 evaluated \n 0 Nonlinear |R| = 1.414214e-01\nMaterial @ qp 0 evaluated \n      0 Linear |R| = 1.414214e-01\n      1 Linear |R| = 2.220446e-17\n  Linear solve converged due to CONVERGED_RTOL iterations 1\nMaterial @ qp 0 evaluated \n 1 Nonlinear |R| = 0.000000e+00\nNonlinear solve converged due to CONVERGED_FNORM_ABS iterations 1\n Solve Converged!\n\nSo, within each time step, the material is evaluated 4 times (!), which seems a lot for a linear simulation.\n\nThe first evaluation is unclear to me,\nthe second one is for computing the residual,\nthe third one is for computing the Jacobian,\nand the fourth one is for checking convergence (which is trivially satisfied after one iteration in this example).\n\nMy questions are:\n\nWhy is the first evaluation performed in each time step with a zero strain increment?\nWhy are evaluation 2 and evaluation 3 separated, although properties stress and Jacobian_mult are computed simultenously (which means that it is readily available after evaluation 2, evalation 3 is performed with the exact same solution and accordingly, produces the same result)?\n\nThank you in advance !",
          "url": "https://github.com/idaholab/moose/discussions/16710",
          "updatedAt": "2022-07-07T00:39:24Z",
          "publishedAt": "2021-01-15T17:29:21Z",
          "category": {
            "name": "Q&A General"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "GiudGiud"
                  },
                  "bodyText": "@rwcarlsen might be able to help on this as I think he's looking into this now",
                  "url": "https://github.com/idaholab/moose/discussions/16710#discussioncomment-299211",
                  "updatedAt": "2022-07-07T00:39:28Z",
                  "publishedAt": "2021-01-21T14:39:01Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "author": {
                    "login": "rwcarlsen"
                  },
                  "bodyText": "Evaluations 2 and 3 (residual and jac) are indeed a (known) underoptimization in the framework with AD (automatic differentiation) at least.  But it looks like you are using material objects that manually calculate a jacobian contribution along with every residual evaluation. In that case - the material object just needs to be smarter.  Materials can ask the framework what operation (residual/jac) is triggering a given material evaluation - those materials could be updated to query that state and omit unnecessary calcs accordingly.\nWith respect to the redundant work when using AD - there are some subtleties about how the residual and jacobian calcs are integrated between MOOSE and PETSc that make it not quite as straight forward for us to combine them into one evaluation so instead we compute the residual during residual evaluation and then compute the residual and jacobian together during the jacobian evaluation (even though we don't need the residual again).\nI honestly can't remember what the detail is around the 1st evaluation.  Probably @lindsayad or @fdkong could clarify that one.",
                  "url": "https://github.com/idaholab/moose/discussions/16710#discussioncomment-309199",
                  "updatedAt": "2022-07-07T00:39:28Z",
                  "publishedAt": "2021-01-25T17:11:57Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "lindsayad"
                          },
                          "bodyText": "There are two residual evaluations done before the first jacobian evaluation. The first residual evaluation is done by MOOSE; the second is done by PETSc. This is another known place of under-optimization, at least pending some criteria regarding preset boundary conditions.\nIf you are running a real problem with PJFNK, then the extra residual evaluation in the beginning is not very impactful since you may be doing 10 to 30 residual evaluations per nonlinear iteration.",
                          "url": "https://github.com/idaholab/moose/discussions/16710#discussioncomment-309466",
                          "updatedAt": "2022-07-07T00:39:32Z",
                          "publishedAt": "2021-01-25T18:24:13Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              },
              {
                "node": {
                  "author": {
                    "login": "fdkong"
                  },
                  "bodyText": "Why is the first evaluation performed in each time step with a zero strain increment?\n\nWe knew this. It could be optimized out in the future for some cases\n\nWhy are evaluation 2 and evaluation 3 separated, although properties stress and Jacobian_mult are computed simultenously (which means that it is readily available after evaluation 2, evalation 3 is performed with the exact same solution and accordingly, produces the same result)?\n\nJacobian and Residual evaluations are involved from PETSc side via two different call-back functions. The Jacobian evaluation needs to compute material again because we do not store the materials from the earlier residual computation. Materials are expensive to store. That being said, storing materials might use a lot of memory when considering the values at each quadrature point are needed.",
                  "url": "https://github.com/idaholab/moose/discussions/16710#discussioncomment-309700",
                  "updatedAt": "2022-07-07T00:39:33Z",
                  "publishedAt": "2021-01-25T20:00:54Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "author": {
                    "login": "matthiasneuner"
                  },
                  "bodyText": "Thank you all for the elaborate answers!\nI am dealing mostly with complex (expensive) plasticity models. As mentioned, for such models the (consistent algorithmic) Jacobian is computed as a byproduct along with the return mapping algorithm. A separate computing would require to completely repeat the return mapping algorithm. Accordingly, I believe the same concerns as for AD materials apply.\nHowever, despite the expensive nature of those material models, I am currently surprised that for large scale simulations the overhead of the multiple material evaluation only has negligible influence (In my case: An accumulated Residual/Jacobian percentage of 25% compared to ~75% taken by the linear solve). So I agree that there is not very much potential for optimization.",
                  "url": "https://github.com/idaholab/moose/discussions/16710#discussioncomment-310757",
                  "updatedAt": "2022-07-07T00:39:35Z",
                  "publishedAt": "2021-01-26T08:24:11Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": []
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "INL partners with Coreform to improve open-source modeling and simulation tool MOOSE",
          "author": {
            "login": "aeslaughter"
          },
          "bodyText": "https://inl.gov/article/inl-partners-with-coreform-to-improve-open-source-modeling-and-simulation-tool-moose/",
          "url": "https://github.com/idaholab/moose/discussions/16774",
          "updatedAt": "2022-07-07T20:26:50Z",
          "publishedAt": "2021-01-21T13:31:49Z",
          "category": {
            "name": "News"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "mangerij"
                  },
                  "bodyText": "Very cool, does this mean there will be some sort of MOOSE system in the works that uses Coreform's tool to optimize simulations?",
                  "url": "https://github.com/idaholab/moose/discussions/16774#discussioncomment-299110",
                  "updatedAt": "2022-07-07T20:26:50Z",
                  "publishedAt": "2021-01-21T14:05:37Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "permcody"
                          },
                          "bodyText": "Not in the short term. The immediate focus will be making Cubit a good pre/post processing tool for use with MOOSE.",
                          "url": "https://github.com/idaholab/moose/discussions/16774#discussioncomment-300802",
                          "updatedAt": "2022-07-07T20:26:51Z",
                          "publishedAt": "2021-01-21T21:45:03Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              },
              {
                "node": {
                  "author": {
                    "login": "WilkAndy"
                  },
                  "bodyText": "Details?  This sounds important, but i'm not sure exactly what it means to me.\n\na\n\u2026\n________________________________________\nFrom: John <notifications@github.com>\nSent: Friday, 22 January 2021 12:05 AM\nTo: idaholab/moose\nCc: Subscribed\nSubject: Re: [idaholab/moose] INL partners with Coreform to improve open-source modeling and simulation tool MOOSE (#16774)\n\nVery cool, does this mean there will be some sort of MOOSE system in the works that uses Coreform's tool to optimize simulations?\n\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub<#16774 (comment)>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/ABS6CVJ46772MQ5M4HHY3NLS3AYEHANCNFSM4WM3W5MA>.",
                  "url": "https://github.com/idaholab/moose/discussions/16774#discussioncomment-300589",
                  "updatedAt": "2022-07-07T20:26:51Z",
                  "publishedAt": "2021-01-21T20:04:52Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "permcody"
                          },
                          "bodyText": "Cubit now has a limited free product available. We are continuing to negotiate with Coreform to negotiate both of our business models.",
                          "url": "https://github.com/idaholab/moose/discussions/16774#discussioncomment-300804",
                          "updatedAt": "2022-07-07T20:27:00Z",
                          "publishedAt": "2021-01-21T21:46:01Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GregVernon"
                          },
                          "bodyText": "@WilkAndy To add to what Cody has mentioned, we at Coreform have been collaborating with INL to get smooth-splines supported by MOOSE - via Bezier extraction.  We've been helping/partnering with Roy Stogner to support these elements in libMesh (see GitHub issue), developing a solution for Exodus to support Bezier extraction data-structures (see GitHub issue), we've added support for Bezier cells (the piecewise components of splines) in VTK and they're now supported in ParaView 5.8 and later (see KitWare blog post), and we will soon support exporting Bezier extraction from Coreform Cubit - as a native capability.\nWhat does this mean?  Bezier extraction is the method that links traditional FEM with spline-based FEM.  Thus support of Bezier extraction throughout the FEM workflow (Meshing tool: Cubit; Mesh file: Exodus; FEM library: libMesh; Post-processing: ParaView) enables spline-based FEM to a broad audience. You can think of spline-based FEM as a generalization of FEM that allows for use of smooth basis functions.  Smoothness of the basis can provide benefits like having defined derivatives (face-normals) at element boundaries - making things like contact, ray-tracing, etc. more well-behaved.  Smooth splines have been recognized as being useful for FEM at least since this insightful review paper by Gilbert Strang (1973) of Richard Courant's development of FEM.  We're hopeful that our collaboration will finally enable practical FEM analyses using spline basis functions - and implemented within MOOSE!",
                          "url": "https://github.com/idaholab/moose/discussions/16774#discussioncomment-309423",
                          "updatedAt": "2022-07-07T20:27:01Z",
                          "publishedAt": "2021-01-25T18:06:23Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "fdkong"
                          },
                          "bodyText": "It is an exciting path",
                          "url": "https://github.com/idaholab/moose/discussions/16774#discussioncomment-309729",
                          "updatedAt": "2022-07-07T20:27:17Z",
                          "publishedAt": "2021-01-25T20:12:54Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "MPI - Fatal Error",
          "author": {
            "login": "12arya129"
          },
          "bodyText": "Hello,\nCan anyone help me with this one? I tried using MPI on one of the examples from Moose Virtual Workshop - Summer 2020, it's working fine with no MPI.\nAm also attaching core numbers.\nThank you",
          "url": "https://github.com/idaholab/moose/discussions/16799",
          "updatedAt": "2022-11-24T17:49:12Z",
          "publishedAt": "2021-01-23T12:43:30Z",
          "category": {
            "name": "Q&A General"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "GiudGiud"
                  },
                  "bodyText": "Hi\nHave you tried the solutions proposed in stack_overflow_mpich ?\nIt has to do with the local hosts.\nBest,\nGuillaume",
                  "url": "https://github.com/idaholab/moose/discussions/16799#discussioncomment-304547",
                  "updatedAt": "2023-01-10T21:42:27Z",
                  "publishedAt": "2021-01-23T12:51:38Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "12arya129"
                          },
                          "bodyText": "Thanks a lot for the link, yes it worked. I changed that hostname of terminal from \"sudo hostnamectl set-hostname xyz\" and edited hostname file with \"sudo nano /etc/hosts\"",
                          "url": "https://github.com/idaholab/moose/discussions/16799#discussioncomment-308266",
                          "updatedAt": "2023-01-10T21:42:36Z",
                          "publishedAt": "2021-01-25T11:34:38Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "12arya129"
                          },
                          "bodyText": "The problem still persists, that earlier code ran but next one gave me the same error. I check the hostname which was same for terminal and the file.\n\nAny suggestions?",
                          "url": "https://github.com/idaholab/moose/discussions/16799#discussioncomment-308613",
                          "updatedAt": "2023-01-10T21:42:36Z",
                          "publishedAt": "2021-01-25T14:11:54Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "milljm"
                          },
                          "bodyText": "What is the contents of your hosts file?\ncat /etc/hosts\n\nAlso, would it be possible to not post pictures of text? The reason for this, is because when searching for relevant issues on the discussion board, it's impossible to search for text inside pictures, and so your issue never comes up (gethostbyname is no-where in this discussion until just now because I wrote it).",
                          "url": "https://github.com/idaholab/moose/discussions/16799#discussioncomment-308718",
                          "updatedAt": "2023-01-10T21:54:38Z",
                          "publishedAt": "2021-01-25T14:45:42Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "12arya129"
                          },
                          "bodyText": "Oh thanks for the advice. Below are the contents\n127.0.0.1 Arya\nThe following lines are desirable for IPv6 capable hosts\n::1     ip6-localhost ip6-loopback\nfe00::0 ip6-localnet\nff00::0 ip6-mcastprefix\nff02::1 ip6-allnodes\nff02::2 ip6-allrouters",
                          "url": "https://github.com/idaholab/moose/discussions/16799#discussioncomment-309586",
                          "updatedAt": "2023-01-10T21:54:37Z",
                          "publishedAt": "2021-01-25T19:09:23Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "fdkong"
                          },
                          "bodyText": "It is interesting. What is the result of  command-line: hostname?\nYou might then = add whatever result you get from the command line to /etc/hosts",
                          "url": "https://github.com/idaholab/moose/discussions/16799#discussioncomment-309723",
                          "updatedAt": "2023-01-10T21:54:37Z",
                          "publishedAt": "2021-01-25T20:10:22Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "warnings when adding DerivativeTwoPhaseMaterial to KKS example",
          "author": {
            "login": "jessecarterMOOSE"
          },
          "bodyText": "If I add a DerivativeTwoPhaseMaterial to a KKS example problem using this block:\n  [./two_phase]\n    type = DerivativeTwoPhaseMaterial\n    f_name = Fsum\n    args = 'cl cs'\n    eta = eta\n    derivative_order = 2\n    fa_name = fl\n    fb_name = fs\n  [../]    \n\nI get some warnings from the kernels when running the problem:\n*** Warning ***\nMissing coupled variables {eta} (add them to args parameter of ChemPotSolute)\n\n\n*** Warning ***\nMissing coupled variables {eta} (add them to args parameter of ChemPotSolute)\n\n\n*** Warning ***\nMissing coupled variables {eta, cs} (add them to args parameter of CHBulk)\n\nI'm curious why this is. I see now that the kernels mentioned in the warnings take the single-phase chemical energy materials and do not need eta, so the DerivativeTwoPhaseMaterial is adding a global dependency on eta? Is this something I need to worry about? I wouldn't imagine that adding extra variable dependences would matter (except maybe in terms of performance) but wanted to check that this is expected behavior.",
          "url": "https://github.com/idaholab/moose/discussions/16766",
          "updatedAt": "2022-07-18T22:43:46Z",
          "publishedAt": "2021-01-20T20:13:01Z",
          "category": {
            "name": "Q&A Modules: Phase field"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "laagesen"
                  },
                  "bodyText": "Hey Jesse, these warnings are triggered by the validateNonlinearCoupling function in initialSetup() for both these kernels. Are you supplying Fsum to these kernels after you added it? I'm guessing not but just wanted to make sure.",
                  "url": "https://github.com/idaholab/moose/discussions/16766#discussioncomment-300987",
                  "updatedAt": "2022-07-18T22:44:01Z",
                  "publishedAt": "2021-01-22T00:00:11Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "jessecarterMOOSE"
                          },
                          "bodyText": "No I left everything else the same. I'm only making some extra materials for validation/postprocessing reasons.",
                          "url": "https://github.com/idaholab/moose/discussions/16766#discussioncomment-301021",
                          "updatedAt": "2022-07-18T22:44:13Z",
                          "publishedAt": "2021-01-22T00:28:36Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "jessecarterMOOSE"
                          },
                          "bodyText": "@laagesen the results come out the same either way, so is it safe to ignore the warnings? Would that always be the case?",
                          "url": "https://github.com/idaholab/moose/discussions/16766#discussioncomment-309057",
                          "updatedAt": "2022-07-18T22:44:13Z",
                          "publishedAt": "2021-01-25T16:31:12Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "laagesen"
                          },
                          "bodyText": "Yes it should be safe to ignore it. Although the message is a bit confusing and we will try to look into why it's getting triggered in this situation, which is not desired. In general this warning is only telling you that you are missing coupled variables which might be needed for a calculation of Jacobians. So it should not affect the results you get even in a situation where you are actually missing something. It could potentially make convergence worse, but should not affect the answer you get (assuming convergences tolerances are set to reasonable values).",
                          "url": "https://github.com/idaholab/moose/discussions/16766#discussioncomment-309427",
                          "updatedAt": "2022-07-18T22:44:13Z",
                          "publishedAt": "2021-01-25T18:08:45Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "jessecarterMOOSE"
                          },
                          "bodyText": "Makes sense. Thanks!",
                          "url": "https://github.com/idaholab/moose/discussions/16766#discussioncomment-309435",
                          "updatedAt": "2022-07-18T22:44:25Z",
                          "publishedAt": "2021-01-25T18:11:58Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "Conservative Advection with coupled variable - upwind scheme",
          "author": {
            "login": "ngrilli"
          },
          "bodyText": "Dear MOOSE Users,\n\nI would like to solve this equation where \\rho is the variable and q and p are coupled variables.\nv is a velocity that I can import in the kernel as a MaterialProperty.\nI would like a kernel for the terms on the right hand-side that has the upwind scheme.\nI mean, I want the integral over the whole volume of the terms on the right side to be zero (in case of Neumann BC = zero flux).\nThe same as ConservativeAdvection in the framework, but with a coupled variable instead.\nIs there anything ready for this in the moose modules?\nIf not, I would like to create my own kernel starting from ConservativeAdvection\nand I will need to access the nodal values of the coupled variable to make the upwind scheme.\nIn the ConservativeAdvection kernel, this is done by:\n_u_nodal(_var.dofValues()),\nHow do I do the same for a coupled variable? Is there anything similar in moose?\nThank you very much in advance for your help.\nBest Regards,\nNicol\u00f2 Grilli\nNational University of Singapore",
          "url": "https://github.com/idaholab/moose/discussions/16675",
          "updatedAt": "2022-06-20T10:19:08Z",
          "publishedAt": "2021-01-13T11:47:40Z",
          "category": {
            "name": "Q&A General"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "aeslaughter"
                  },
                  "bodyText": "@lindsayad Do we have an example of this sort of upwind scheme?",
                  "url": "https://github.com/idaholab/moose/discussions/16675#discussioncomment-279411",
                  "updatedAt": "2022-06-20T10:19:09Z",
                  "publishedAt": "2021-01-13T15:28:24Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "lindsayad"
                          },
                          "bodyText": "Not with coupled variables. @ngrilli you could do:\n_q_nodal(getVar(\"q\", 0)->dofValues()),\n_p_nodal(getVar(\"p\", 0)->dofValues())\n\ngetVar is a method inherited from the Coupleable interface. The arguments to getVar are the name of the coupled variable (whatever the name is in your params.addCoupledVar(\"name\", \"doc_string\")) and then the variable component, which is usually 0. But we do allow users to pass a vector of variables to a single coupled var parameter (this is not well advertised or known).",
                          "url": "https://github.com/idaholab/moose/discussions/16675#discussioncomment-279772",
                          "updatedAt": "2022-06-20T10:19:28Z",
                          "publishedAt": "2021-01-13T17:45:28Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "ngrilli"
                          },
                          "bodyText": "Dear @aeslaughter and @lindsayad\nThank you very much, this is very helpful.\nI will develop my own kernel and will made it available in my github.\nBest Regards,\nNicol\u00f2 Grilli\nNational University of Singapore",
                          "url": "https://github.com/idaholab/moose/discussions/16675#discussioncomment-281218",
                          "updatedAt": "2022-06-20T10:19:27Z",
                          "publishedAt": "2021-01-14T07:56:29Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              },
              {
                "node": {
                  "author": {
                    "login": "ngrilli"
                  },
                  "bodyText": "Dear MOOSE Users,\nI have developed the following kernel for the conservative advection of a coupled variable:\nhttps://github.com/ngrilli/c_pfor_am/blob/main/src/kernels/ConservativeAdvectionCoupled.C\nIt seems to work when I use the full upwind scheme for my simulations.\nHowever, I am not sure if the out of diagonal Jacobian is correct in the case of full upwind scheme.\nSpecifically, in:\nConservativeAdvectionCoupled::fullUpwind(JacRes res_or_jac)\nI have used the nodal values of the coupled variable instead of the nodal value of the variable used in ConservativeAdvection\nHowever, I am not sure if the following lines are storing the out of diagonal Jacobian properly\n(and I have the same doubt for the residual):\nif (res_or_jac == JacRes::CALCULATE_JACOBIAN)\n{\naccumulateTaggedLocalMatrix();\nif (_has_diag_save_in)\n{\n  unsigned int rows = _local_ke.m();\n  DenseVector<Number> diag(rows);\n  for (unsigned int i = 0; i < rows; i++)\n    diag(i) = _local_ke(i, i);\n\n  Threads::spin_mutex::scoped_lock lock(Threads::spin_mtx);\n  for (const auto & var : _diag_save_in)\n    var->sys().solution().add_vector(diag, var->dofIndices());\n}\n\n}\nBest Regards,\nNicol\u00f2 Grilli\nNational University of Singapore",
                  "url": "https://github.com/idaholab/moose/discussions/16675#discussioncomment-304841",
                  "updatedAt": "2022-06-20T10:19:33Z",
                  "publishedAt": "2021-01-23T16:29:20Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "lindsayad"
                          },
                          "bodyText": "The pasted lines of code, whether right or wrong, will not actually have any impact on the accuracy of your matrix being fed to PETSc. These lines are usually only for visualization purposes; perhaps you already knew that?\nYou can test the accuracy of your Jacobian using the command line options: -snes_test_jacobian -snes_test_jacobian_view. I would only run this test for smallish problems, e.g. 1000 dofs or less, ideally 30 dofs or less in order to truly understand the output from -snes_test_jacobian_view.\nAre you worried about the speed of your simulation? If you do not care about a factor of 1.5 or so, I would highly recommend doing this with automatic differentiation, and then you will have no concern about the accuracy of your Jacobian.",
                          "url": "https://github.com/idaholab/moose/discussions/16675#discussioncomment-309143",
                          "updatedAt": "2022-06-23T13:13:02Z",
                          "publishedAt": "2021-01-25T16:54:59Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "Alpha in capillaryPressureVG as a function of temperature",
          "author": {
            "login": "mcacace"
          },
          "bodyText": "This post is on the porous flow module.\nI am trying to help a colleague of mine to implement a VG retention curve where the alpha coefficient is not considered as constant but varies with the background temperature condition. Looking at the respective uo, it does seem to me (first glance though) that the basic virtual functions can retrieve this information via the corresponding qp during their call. This said, being my first attempt with the module was wondering what would be the best way to implement such functional behaviour.\nThanks for helping,\nMauro",
          "url": "https://github.com/idaholab/moose/discussions/16735",
          "updatedAt": "2022-06-16T10:35:07Z",
          "publishedAt": "2021-01-18T23:26:46Z",
          "category": {
            "name": "Q&A Modules: General"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "cpgr"
                  },
                  "bodyText": "Hi Mauro,\nWithout thinking about it too much, one way might be to change the param alpha to a coupled variable, and then use an auxvariable to compute the temperature-dependent value of alpha. Like you said, you could then pass _alpha[_qp] into the various methods in this class.\nLet me know if you need a hand,\nChris",
                  "url": "https://github.com/idaholab/moose/discussions/16735#discussioncomment-292281",
                  "updatedAt": "2022-06-16T10:35:09Z",
                  "publishedAt": "2021-01-19T03:22:10Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "mcacace"
                          },
                          "bodyText": "Dear Chris,\nthanks for the prompt reply. Was thinking the same, but wanted to be sure I was heading the right direction. Will get at it and let you know if I have any problem.",
                          "url": "https://github.com/idaholab/moose/discussions/16735#discussioncomment-292568",
                          "updatedAt": "2022-06-16T10:35:29Z",
                          "publishedAt": "2021-01-19T07:50:54Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              },
              {
                "node": {
                  "author": {
                    "login": "fparisio-zz"
                  },
                  "bodyText": "Dear Chris,\nI am working with Mauro and together we are trying to explore the role of capillary forces in water-vapor systems. I have built a first simple example employing PorousFlowFluidStateSingleComponent where primary variables are pliq and h (files attached). The model is a single element and I am fixing enthalpy and pressure in order to follow an evaporation isotherm (here, 200 \u00b0C). Once the whole fluid has evaporated and liquid saturation is null, a full gas phase forms at a gas pressure which is controlled by the retention curve properties. Because the upper limit of pressure in the water EOS is 100 MPa, the maximum pressure has to be fixed accordingly, to avoid that the gas pressure increases to values that are above such limits (for our cases, approx. pc_max=70 MPa). Now, we observe that once the water has fully evaporated and the gas saturation is 1, the pressure to compute EOS properties is suddenly taken as the gas pressure (pliq is meaningless with fully gaseous phase) and this results in a jump in temperature up to approximately 550 \u00b0C. Now, this temperature is the result of the fixed value of enthalpy and pressure once the liquid phase disappears. Because of the shape and parametrization of the retention curve, this jump is more pronounced for a material that shows higher retention capabilities or, in other words, it is proportional to pc_max (see figure with different cases of pc_max). I understand this is how VG works (or any other retention model), but in reality, once the liquid phase has disappeared, the capillary pressure should be null and pgas=pliq at sgas=1. One way around could be achieved by a residual saturation that prevents a full evaporation (sgas<1 always), but that case implies higher values of capillary pressure and, as a consequence, gas pressure exceeds the threshold pgas>100 MPa and EOS cannot be computed.\nAt present, we are not sure what would be the best way out of this loop and we would like to ask you if you have any suggestion for us. In the examples provided in PorousFlow, the maximum capillary pressure is usually rather low (around 1 MPa) and the problem does not arise (or, the temperature jump is rather small). We could also discuss about the fact that perhaps retention properties of rocks are overestimated: the colored experimental retention curves (from Li and Horne, 2006) in figure d are experiments from reservoir rocks obtained with Mercury Porosimetry Intrusion, which might not be completely representative of water-vapor systems. Especially at high temperature, the lower surface tension would cause a decrease of retention capabilities of a porous medium and a lower pc_max (hence, our idea of a temperature-dependent alpha in the VG curve). Nonetheless, even with reduced retention capabilities (tens of MPa of pc_max), the current formulation falls short (although we understand it is an intrinsic problem of the retention theory).\nThank you very much for your help,\nFrancesco\nRef.:\nLi, K. and Horne, R.N., 2006. Fractal modeling of capillary pressure curves for The Geysers rocks. Geothermics, 35(2), pp.198-207.\n\nmoose_input.tar.gz",
                  "url": "https://github.com/idaholab/moose/discussions/16735#discussioncomment-296755",
                  "updatedAt": "2022-06-16T10:35:29Z",
                  "publishedAt": "2021-01-20T17:22:41Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "fparisio-zz"
                          },
                          "bodyText": "PS: we can also discuss this matter off-line if it requires longer replies and if you are interested in discussing more about the details.",
                          "url": "https://github.com/idaholab/moose/discussions/16735#discussioncomment-296762",
                          "updatedAt": "2022-06-16T10:35:42Z",
                          "publishedAt": "2021-01-20T17:24:28Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "WilkAndy"
                          },
                          "bodyText": "No, let's keep this online - it might be useful for someone in the future",
                          "url": "https://github.com/idaholab/moose/discussions/16735#discussioncomment-297246",
                          "updatedAt": "2022-06-16T10:35:42Z",
                          "publishedAt": "2021-01-20T20:42:36Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              },
              {
                "node": {
                  "author": {
                    "login": "WilkAndy"
                  },
                  "bodyText": "I can't make any better suggestions than what's already been said (all your suggestions are potentially good ones, i think), but just wanted to say how exciting it is to see PorousFlow being used in this way.  When we created it, we tried to make it flexible enough that it'd be able to handle cases such as this, and i'm so pleased it's working for you.\nMy uneducated opinion is that you're using VG in situations where it's incorrect.  I don't think i've seen experimental literature at such high temperatures and low liquid saturations.\nAlso, just for my interest, what's the problem with the behaviour at zero liquid saturation?  Are you trying to boil water and then do something with it afterwards?\na",
                  "url": "https://github.com/idaholab/moose/discussions/16735#discussioncomment-297245",
                  "updatedAt": "2022-06-16T10:35:43Z",
                  "publishedAt": "2021-01-20T20:42:15Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "fparisio-zz"
                          },
                          "bodyText": "@WilkAndy your opinion is actually very well educated! I agree that experimental evidence lacks at such low saturations and that it is not straight forward to extend retention curves to water-vapor systems. Perhaps the most informative study in this sense is by Li and Horne (2007).\nThe test simulated has no a particular significance other than exploring the capillary forces that develop during an evaporation isotherm. It will be functional to a more systematic study. Thank you for your input and we will post here whevener we find a proper way to handle the problem.\nFrancesco\nRef:\nLi, K. and Horne, R.N., 2007. Systematic study of steam\u2013water capillary pressure. Geothermics, 36(6), pp.558-574.",
                          "url": "https://github.com/idaholab/moose/discussions/16735#discussioncomment-308481",
                          "updatedAt": "2022-06-16T10:35:45Z",
                          "publishedAt": "2021-01-25T13:34:01Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              },
              {
                "node": {
                  "author": {
                    "login": "cpgr"
                  },
                  "bodyText": "Interesting work!\nI'm not sure what the best step is, but will think about it today. From memory, the temperature is calculated from pressure and enthalpy using the IAPWS97 equation, and it has something like this:\nswitch(phase):\n\ncase liquid:\n  T = T_from_p_h(liq_p, h)\n\ncase gas:\n  T = T_from_p_h(gas_p, h)\n\nwhich could cause the sudden jump in temperature that you observe.\nChris",
                  "url": "https://github.com/idaholab/moose/discussions/16735#discussioncomment-297494",
                  "updatedAt": "2022-06-16T10:36:05Z",
                  "publishedAt": "2021-01-20T22:47:40Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "fparisio-zz"
                          },
                          "bodyText": "So it seems, that a switch occurs whenever the liquid phase disappears. The effect of capillary pressure is to introduce a discontinuity in the pressure at full evaporation, which then translates into a temperature jump.",
                          "url": "https://github.com/idaholab/moose/discussions/16735#discussioncomment-308494",
                          "updatedAt": "2022-06-16T10:36:07Z",
                          "publishedAt": "2021-01-25T13:35:59Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "more cleavage plane in ACInterfaceCleavageFracture",
          "author": {
            "login": "wsfsz123"
          },
          "bodyText": "Hi, all,\nThe kernel modification of ACInterfaceCleavageFracture is used to simulate the anisotropic fracture with transverse isotropic (one cleavage plane), then if I want to use it to simulate the cubic symmetric with two cleavage plane or more, like three cleavage plane, refer to \"S. Teichtmeister, Phase field modeling of fracture in anisotropic brittle solids, 2017\". What should I do?\nThanks,\nShizhe",
          "url": "https://github.com/idaholab/moose/discussions/16249",
          "updatedAt": "2022-09-16T02:39:24Z",
          "publishedAt": "2020-11-19T08:56:11Z",
          "category": {
            "name": "Q&A Modules: Phase field"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "aeslaughter"
                  },
                  "bodyText": "@dschwen @laagesen @SudiptaBiswas Do you have an answer for this, it seems to have slipped through without a response.",
                  "url": "https://github.com/idaholab/moose/discussions/16249#discussioncomment-146870",
                  "updatedAt": "2022-09-16T02:39:26Z",
                  "publishedAt": "2020-12-04T02:13:33Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "author": {
                    "login": "jiangwen84"
                  },
                  "bodyText": "Sorry for the late reply. I think one way is to introduce additional phase field damage parameters to represent fractures on different cleavage planes, and enforce the sum of all damage parameters to be 1.",
                  "url": "https://github.com/idaholab/moose/discussions/16249#discussioncomment-147195",
                  "updatedAt": "2022-09-16T02:39:26Z",
                  "publishedAt": "2020-12-04T14:59:14Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "author": {
                    "login": "jiangwen84"
                  },
                  "bodyText": "If you want to implement Teichtmeister's approach, I think we should generalize ACInterfaceCleavageFracture to include more than one preferred planes in anisotropic metro A. We do not have that capability yet, but it should be straightforward to do. Let me know if you would like to contribute, and we can provide you some guidance.",
                  "url": "https://github.com/idaholab/moose/discussions/16249#discussioncomment-147208",
                  "updatedAt": "2022-09-16T02:39:27Z",
                  "publishedAt": "2020-12-04T15:11:32Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "author": {
                    "login": "wsfsz123"
                  },
                  "bodyText": "Thank you! I tried, but A is a second-order tensor, can only represent one cleavage plane, to introduce bi-cleavage plane, it should include Laplace (second-order) of c to the fracture density function,  then Allen-Cahn is not suitable anymore, does any evolution method works for it on MOOSE?",
                  "url": "https://github.com/idaholab/moose/discussions/16249#discussioncomment-147650",
                  "updatedAt": "2022-09-16T02:39:28Z",
                  "publishedAt": "2020-12-05T00:53:58Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "jiangwen84"
                          },
                          "bodyText": "Are you referring to the third term of equation (38) in  Teichtmeister's paper?",
                          "url": "https://github.com/idaholab/moose/discussions/16249#discussioncomment-149012",
                          "updatedAt": "2022-09-16T02:39:29Z",
                          "publishedAt": "2020-12-07T15:13:51Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "wsfsz123"
                          },
                          "bodyText": "Thank you, I quit this method, it seems not suitable for my problem. I am now trying to modify Gc(theta) directly (see attached figure, the reference to https://doi.org/10.1016/j.jmps.2020.104253), it is similar to ACInterfaceKobayashi kernels, but I have encountered the convergence problem even at the first step, attached is my input file. Besides, may I know how to choose the parameters or methods in executioners to improve the calculation efficiency on MOOSE?\nThanks,\nShizhe\n\n[crack_Kobayashi.txt](https://github.com/idaholab/moose/files/5693543/crack_Kobayashi.txt)",
                          "url": "https://github.com/idaholab/moose/discussions/16249#discussioncomment-207291",
                          "updatedAt": "2022-09-16T02:39:29Z",
                          "publishedAt": "2020-12-15T05:30:07Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "jiangwen84"
                          },
                          "bodyText": "Let us set use_current_history_variable = false first, and see if it improves the convergence. To further simplify the model, you can also set decomposition_type = none, to reduce nonlinearity.",
                          "url": "https://github.com/idaholab/moose/discussions/16249#discussioncomment-218014",
                          "updatedAt": "2022-09-16T02:39:29Z",
                          "publishedAt": "2020-12-17T04:37:54Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              },
              {
                "node": {
                  "author": {
                    "login": "wsfsz123"
                  },
                  "bodyText": "I tried and failed. since gc is constant before, now I need to use gc (grad(c)), do I need to modify the code in ComputeLinearElasticPFFractureStress.C, and how?",
                  "url": "https://github.com/idaholab/moose/discussions/16249#discussioncomment-220810",
                  "updatedAt": "2022-09-16T02:39:28Z",
                  "publishedAt": "2020-12-18T02:46:46Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "jiangwen84"
                          },
                          "bodyText": "Yes. If your Gc is a function of normal (gradient of c), you need to account for the derivative of G_c respect to c. Current implementation assumes Gc does not depend on c. To make the change, you have to make Gc as a derivative material, and add its derivative (g_d in eqn 23 in your referred paper) to the driving force term.",
                          "url": "https://github.com/idaholab/moose/discussions/16249#discussioncomment-234932",
                          "updatedAt": "2022-09-16T02:39:33Z",
                          "publishedAt": "2020-12-22T15:57:35Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              },
              {
                "node": {
                  "author": {
                    "login": "wsfsz123"
                  },
                  "bodyText": "The g_d is calculated in InterfaceOrientationMaterial (defined as _deps), so I think it could be used directly (ACInterfaceKobayashi is used for the gradient part of the fracture energy), my problem is: in the non-gradient term (f_elastic+Gc/2l*c^2), do I need to modify the calculation? I am thinking that Gc depends on the gradient of c, not c, so the partial gradient of c for this term shouldn't consider the gradient of Gc. But during my simulation, it has a convergence problem even when I only consider the non-gradient term (no ACinterface term).",
                  "url": "https://github.com/idaholab/moose/discussions/16249#discussioncomment-236057",
                  "updatedAt": "2022-09-16T02:39:35Z",
                  "publishedAt": "2020-12-23T01:50:56Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "jiangwen84"
                          },
                          "bodyText": "First, I think you should remove ACInterfaceKobayashi2. ACInterfaceKobayashi2 is the double-well potential term, and should not be considered in phase field fracture model.\nSecondly, you should definitely use chain rule to include the derivative of Gc respect to c through \\nabla c. See the second term on the right side of eqn 14 , and eon 16 in Shahed Rezaei's paper.\nLastly, you should make sure you use a consistent Mobility in your input file.  For phase field fracture model, the M = 1/(gc*visco). I saw you defined another M that was used in   ACInterfaceKobayashi1",
                          "url": "https://github.com/idaholab/moose/discussions/16249#discussioncomment-236210",
                          "updatedAt": "2022-09-16T02:39:36Z",
                          "publishedAt": "2020-12-23T05:21:55Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              },
              {
                "node": {
                  "author": {
                    "login": "wsfsz123"
                  },
                  "bodyText": "I have further questions about the parameter type in MOOSE.\nsuch as the following code in the material section, where c is the order parameter, then, my question is must gc_prop be a constant? if I have defined gc_prop to be a field that depends on the location (x,y), is it still works for this expression or should I put the gc_prop in \"args='? In the other words, the parameter in material_property_names should be constant or any type?\n[./local_fracture_energy]\ntype = DerivativeParsedMaterial\nf_name = local_fracture_energy\nargs = 'c'\nmaterial_property_names = 'gc_prop l'\nfunction = 'c^2 * gc_prop / 2 / l'\nderivative_order = 2\n[../]\nThanks,\nShizhe",
                  "url": "https://github.com/idaholab/moose/discussions/16249#discussioncomment-292547",
                  "updatedAt": "2022-09-16T02:39:37Z",
                  "publishedAt": "2021-01-19T07:26:30Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "jiangwen84"
                          },
                          "bodyText": "The gc_prop can be a function material that depends on (x,y,z,t). The args is the coupled variable name, and for your case it should not include gc_prop.",
                          "url": "https://github.com/idaholab/moose/discussions/16249#discussioncomment-294751",
                          "updatedAt": "2022-09-16T02:39:40Z",
                          "publishedAt": "2021-01-19T23:58:41Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "jiangwen84"
                          },
                          "bodyText": "Currently, gc_prop cannot be a function of damage parameter because we do not account for the derivative of gc_prop respect to the damage variable in our material class.\nIf that is something you need in the future, It should be straightforward to modify the codes to make gc_prop that depends on damage variable.",
                          "url": "https://github.com/idaholab/moose/discussions/16249#discussioncomment-294756",
                          "updatedAt": "2022-09-16T02:39:40Z",
                          "publishedAt": "2021-01-20T00:02:30Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              },
              {
                "node": {
                  "author": {
                    "login": "wsfsz123"
                  },
                  "bodyText": "Then, do I need to modify the definition of gc_prop in ComputePFFractureStressBase.C : _gc(getMaterialProperty(\"gc_prop\"))? Besides, I can't find any code of *.i  have use the gc_prop directly except the definition in ComputePFFractureStressBase.C.",
                  "url": "https://github.com/idaholab/moose/discussions/16249#discussioncomment-297800",
                  "updatedAt": "2022-09-16T02:39:40Z",
                  "publishedAt": "2021-01-21T00:51:16Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "jiangwen84"
                          },
                          "bodyText": "If you use a function material to define gc_prop, you do not need to change the source code.\nFor regression tests, we usually define gc_prop as GenericConstantMaterial\n[./pfbulkmat]\ntype = GenericConstantMaterial\nprop_names = 'gc_prop l visco'\nprop_values = '1e-3 0.04 1e-4'\n[../]",
                          "url": "https://github.com/idaholab/moose/discussions/16249#discussioncomment-302703",
                          "updatedAt": "2022-09-16T02:39:41Z",
                          "publishedAt": "2021-01-22T15:57:47Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              },
              {
                "node": {
                  "author": {
                    "login": "wsfsz123"
                  },
                  "bodyText": "Thank you! and how to solve the negative damage order parameter problem? could I restrict the range of the order parameter to be [0,1]?",
                  "url": "https://github.com/idaholab/moose/discussions/16249#discussioncomment-306110",
                  "updatedAt": "2022-09-16T02:39:42Z",
                  "publishedAt": "2021-01-24T12:17:22Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "jiangwen84"
                          },
                          "bodyText": "modules/combined/test/tests/phase_field_fracture/crack2d_vi_solver.i",
                          "url": "https://github.com/idaholab/moose/discussions/16249#discussioncomment-307345",
                          "updatedAt": "2022-09-16T02:39:42Z",
                          "publishedAt": "2021-01-25T02:08:58Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      }
    ]
  }
}