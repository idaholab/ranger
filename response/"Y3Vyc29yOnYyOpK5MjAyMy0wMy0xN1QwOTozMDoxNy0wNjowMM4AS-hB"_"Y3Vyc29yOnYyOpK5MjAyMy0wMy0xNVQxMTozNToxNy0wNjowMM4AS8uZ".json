{
  "discussions": {
    "pageInfo": {
      "hasNextPage": true,
      "endCursor": "Y3Vyc29yOnYyOpK5MjAyMy0wMy0xNVQxMTozNToxNy0wNjowMM4AS8uZ"
    },
    "edges": [
      {
        "node": {
          "title": "Postprocessing",
          "author": {
            "login": "alimostafavi24"
          },
          "bodyText": "Hello,\nI wanted to export animation for my results. When I use adaptive mesh multiple .e files are created. I can see the animation with peacock, but do not know how to export it. What is the best way to export movie file when adaptive mesh is used and multiple .e files are created?\nThanks,\nAli",
          "url": "https://github.com/idaholab/moose/discussions/23765",
          "updatedAt": "2023-04-29T03:43:24Z",
          "publishedAt": "2023-03-16T22:11:26Z",
          "category": {
            "name": "Q&A General"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "GiudGiud"
                  },
                  "bodyText": "Hello\nCan you load it all in paraview? Peacock is great for getting things to work but not really for postprocessing\nGuillaume",
                  "url": "https://github.com/idaholab/moose/discussions/23765#discussioncomment-5339361",
                  "updatedAt": "2023-03-16T22:18:46Z",
                  "publishedAt": "2023-03-16T22:18:45Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "author": {
                    "login": "alimostafavi24"
                  },
                  "bodyText": "Yes, ParaView works well. Thanks.",
                  "url": "https://github.com/idaholab/moose/discussions/23765#discussioncomment-5341289",
                  "updatedAt": "2023-03-17T04:09:49Z",
                  "publishedAt": "2023-03-17T04:09:48Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": []
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "How to handle grain merging for grains with same crystal orientation in `GrainTracker` \uff1f",
          "author": {
            "login": "PengWei97"
          },
          "bodyText": "Dear MOOSE experts,\nRecently, I wanted to perform grain merging based on GrainTracker, when two grains have the same crystallographic orientation, or their misorientation is below a very small value. But I'm not sure how such a merge operation should be performed in GrainTracker.\nSpecifically, when I was performing my EBSD microstructural grain growth simulation, I found that there was a twin that split the matrix grain into two grains, as shown in the image below.\n\nWhen I use the novel feature extraction and remapping algorithm developed by @permcody, due to the order parameter remapping operation, even if the twin disappears, there are still two grains left. Instead of merging into a complete grain under the same orientation as in the experiment. So I want to perform the operation of merging grains in GrainTracker based on the direct orientation relationship of the two grains.\nAny suggestions or recommendations to fix the problem would be greatly appreciated.\nThank you\nWei",
          "url": "https://github.com/idaholab/moose/discussions/22853",
          "updatedAt": "2023-03-17T01:32:57Z",
          "publishedAt": "2022-12-02T08:11:19Z",
          "category": {
            "name": "Q&A Modules: Phase field"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "GiudGiud"
                  },
                  "bodyText": "Hi\nThere s documentation on the grain tracker on this\nhttps://mooseframework.inl.gov/moose/source/postprocessors/GrainTracker.html\nwhich part in particular would you want more information on?\nAre you planning to modify the GrainTracker?\nGuillaume",
                  "url": "https://github.com/idaholab/moose/discussions/22853#discussioncomment-4293217",
                  "updatedAt": "2022-12-02T15:00:27Z",
                  "publishedAt": "2022-12-02T15:00:26Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "PengWei97"
                          },
                          "bodyText": "Oh, yeah. Thank you very much for your reply. I have read all the public information about GrainTracker, including web, cody's two papers and graduation thesis. Of course, please forgive me for still having a lot of confusion here.\n\nAre you planning to modify the GrainTracker?\n\nYes, in order to accomplish the purpose mentioned above, I plan to further build a class based on GrainTracker to determine whether the grain needs to be merged according to the orientation relationship of adjacent grains (from the input EBSD data).\nWei",
                          "url": "https://github.com/idaholab/moose/discussions/22853#discussioncomment-4298773",
                          "updatedAt": "2022-12-03T13:55:12Z",
                          "publishedAt": "2022-12-03T13:55:12Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              },
              {
                "node": {
                  "author": {
                    "login": "permcody"
                  },
                  "bodyText": "Hi Wei,\nReally happy to see this capability being exercised. It's not something I really had to work with much when I was working on this problem, but it did pop up in a few of our data sets. Briefly, there are two edge cases that have to be dealt with when working with \"twins\" (grains with the same crystallographic orientation). There's the merge case when they come together during evolution (is this even physical?) and the case where they are created due to the right combination of an odd grain shape and the right kinds of physics (again, I can't comment too much on how physical this is or not). I attempted to handle both in the snippet linked below. The way this is handled is by making sure the grains really are a twins (see the criteria starting on line 721). Ultimately, they should be represented by the same grain ID even though you have two (or more) physically disconnected features. Once two features are marked with the same ID, the GrainTracker should not attempt to remap either one of them if they get close enough to coalesce during a simulation. That's really all there is too of it from a logical point of view. I'm not sure I understand the rest of your inquiry about \"one disappearing\" but having \"two left\". It's true that the grain tracker never removes an inactive grain from the data structure, but anything that shrinks or joins together does get marked as \"INACTIVE\" and ignored by the GrainTracker for the remainder of the simulation.\n\n  \n    \n      moose/modules/phase_field/src/postprocessors/GrainTracker.C\n    \n    \n        Lines 663 to 738\n      in\n      6099fe5\n    \n  \n  \n    \n\n        \n          \n               /** \n        \n\n        \n          \n                * At this point we have should have only two cases left to handle: \n        \n\n        \n          \n                * Case 1: A grain in the new set who has an unset status (These are new grains, previously \n        \n\n        \n          \n                *         untracked) This case is easy to understand. Since we are matching up grains by \n        \n\n        \n          \n                *         looking at the old set and finding closest matches in the new set, any grain in \n        \n\n        \n          \n                *         the new set that isn't matched up is simply new since some other grain satisfied \n        \n\n        \n          \n                *         each and every request from the old set. \n        \n\n        \n          \n                * \n        \n\n        \n          \n                * Case 2: A grain in the old set who has an unset status (These are inactive grains that \n        \n\n        \n          \n                *         haven't been marked) We can only fall into this case when the very last grain on \n        \n\n        \n          \n                *         a given variable disappears during the current time step. In that case we never have \n        \n\n        \n          \n                *         a matching _var_index in the comparison loop above so that old grain never competes \n        \n\n        \n          \n                *         for any new grain which means it can't be marked inactive in the loop above. \n        \n\n        \n          \n                */ \n        \n\n        \n          \n               // Case 1 (new grains in _feature_sets): \n        \n\n        \n          \n               for (const auto grain_num : index_range(_feature_sets)) \n        \n\n        \n          \n               { \n        \n\n        \n          \n                 auto & grain = _feature_sets[grain_num]; \n        \n\n        \n          \n            \n        \n\n        \n          \n                 // New Grain \n        \n\n        \n          \n                 if (grain._status == Status::CLEAR) \n        \n\n        \n          \n                 { \n        \n\n        \n          \n                   /** \n        \n\n        \n          \n                    * Now we need to figure out what kind of \"new\" grain this is. Is it a nucleating grain that \n        \n\n        \n          \n                    * we're just barely seeing for the first time or is it a \"splitting\" grain. A grain that \n        \n\n        \n          \n                    * gets pinched into two or more pieces usually as it is being absorbed by other grains or \n        \n\n        \n          \n                    * possibly due to external forces. We have to handle splitting grains this way so as to \n        \n\n        \n          \n                    * no confuse them with regular grains that just happen to be in contact in this step. \n        \n\n        \n          \n                    * \n        \n\n        \n          \n                    * Splitting Grain: An grain that is unmatched by any old grain \n        \n\n        \n          \n                    *                  on the same order parameter with touching halos. \n        \n\n        \n          \n                    * \n        \n\n        \n          \n                    * Nucleating Grain: A completely new grain appearing somewhere in the domain \n        \n\n        \n          \n                    *                   not overlapping any other grain's halo. \n        \n\n        \n          \n                    * \n        \n\n        \n          \n                    * To figure out which case we are dealing with, we have to make another pass over all of \n        \n\n        \n          \n                    * the existing grains with matching variable indices to see if any of them have overlapping \n        \n\n        \n          \n                    * halos. \n        \n\n        \n          \n                    */ \n        \n\n        \n          \n            \n        \n\n        \n          \n                   // clang-format off \n        \n\n        \n          \n                   auto start_it = \n        \n\n        \n          \n                       std::lower_bound(_feature_sets.begin(), _feature_sets.end(), grain._var_index, \n        \n\n        \n          \n                                        [](const FeatureData & item, std::size_t var_index) \n        \n\n        \n          \n                                        { \n        \n\n        \n          \n                                          return item._var_index < var_index; \n        \n\n        \n          \n                                        }); \n        \n\n        \n          \n                   // clang-format on \n        \n\n        \n          \n            \n        \n\n        \n          \n                   // Loop over matching variable indices \n        \n\n        \n          \n                   for (MooseIndex(_feature_sets) \n        \n\n        \n          \n                            new_grain_index = std::distance(_feature_sets.begin(), start_it); \n        \n\n        \n          \n                        new_grain_index < _feature_sets.size() && \n        \n\n        \n          \n                        _feature_sets[new_grain_index]._var_index == grain._var_index; \n        \n\n        \n          \n                        ++new_grain_index) \n        \n\n        \n          \n                   { \n        \n\n        \n          \n                     auto & other_grain = _feature_sets[new_grain_index]; \n        \n\n        \n          \n            \n        \n\n        \n          \n                     // Splitting grain? \n        \n\n        \n          \n                     if (grain_num != new_grain_index && // Make sure indices aren't pointing at the same grain \n        \n\n        \n          \n                         other_grain._status == Status::MARKED && // and that the other grain is indeed marked \n        \n\n        \n          \n                         other_grain.boundingBoxesIntersect(grain) && // and the bboxes intersect \n        \n\n        \n          \n                         other_grain.halosIntersect(grain))           // and the halos also intersect \n        \n\n        \n          \n                     // TODO: Inspect combined volume and see if it's \"close\" to the expected value \n        \n\n        \n          \n                     { \n        \n\n        \n          \n                       grain._id = other_grain._id;    // Set the duplicate ID \n        \n\n        \n          \n                       grain._status = Status::MARKED; // Mark it \n        \n\n        \n          \n            \n        \n\n        \n          \n                       if (_verbosity_level > 0) \n        \n\n        \n          \n                         _console << COLOR_YELLOW << \"Split Grain Detected #\" << grain._id \n        \n\n        \n          \n                                  << \" (variable index: \" << grain._var_index << \")\\n\" \n        \n\n        \n          \n                                  << COLOR_DEFAULT; \n        \n\n        \n          \n                       if (_verbosity_level > 1) \n        \n\n        \n          \n                         _console << grain << other_grain; \n        \n\n        \n          \n                     } \n        \n\n        \n          \n                   } \n        \n    \n  \n\n\nThere is also a test you can look at here:\nhttps://github.com/idaholab/moose/blob/next/modules/phase_field/test/tests/grain_tracker_test/split_grain.i\nI'm not sure if I've answered your question, but take a look at the logic and the test and see if that's helpful. It's possible that this may not work exactly as you need it to, but we can discuss possible modifications to make it work for your needs.\nCody",
                  "url": "https://github.com/idaholab/moose/discussions/22853#discussioncomment-4294782",
                  "updatedAt": "2022-12-02T18:00:31Z",
                  "publishedAt": "2022-12-02T18:00:31Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "PengWei97"
                          },
                          "bodyText": "Hi Cody,\nI really appreciate your kind and detailed advice. Today I carefully read your suggestion, but I has some confusion about your reply, and I hope to get your further advice.\n\nThere's the merge case when they come together during evolution (is this even physical?)\n\nWe can find from the above figure that the merging of two substrate  grains is physical, when the intermediate twin disappears. I would like to ask whether  they come together here refers to the merger of twins or the merger of two substrate grains?\n\nthe case where they are created due to the right combination of an odd grain shape and the right kinds of physics (again, I can't comment too much on how physical this is or not).\n\nAlso what does they refer to here? And my current processing method is to directly import the initial EBSD structure into moose and use GrainTracker to track grains, in which the shape and type of twins are determined based on Euler angles.\n\nI'm not sure I understand the rest of your inquiry about \"one disappearing\" but having \"two left\".\n\nYes, your understanding is correct.\nHere's what I want to do based on your suggestion to accomplish grain merging\uff0cconsidering the difficulty of accurately identifying twins, I think the calculation of misorientation (based on the Euler angles of EBSD) can be performed for each grain and its adjacent grains. When their misorientation is lower than a very low value, the operation of grain._id = other_grain._id is executed to make the two grains merge. (Such merging also has physical meaning, because when the orientation difference between two grains is 0, they should be the same grain).\nThe above is my confusion about your enthusiastic suggestion and the operation I want to perform with reference to the code you gave, and I look forward to your next suggestion.\nWei",
                          "url": "https://github.com/idaholab/moose/discussions/22853#discussioncomment-4298685",
                          "updatedAt": "2022-12-03T13:30:48Z",
                          "publishedAt": "2022-12-03T13:30:47Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "PengWei97"
                          },
                          "bodyText": "Again, thank you very much for recommending such an important code block to me, considering that I need to add some new code on top of GrainTracker, so I feel that it is necessary to understand this code completely correctly, the following is my understanding of this code Understood, hope to get your affirmative answer or correction of misunderstanding,\nFor Case 1, traverse _feature_sets in the new set, and perform the following operations when grain._status == Status::CLEAR\n\n\nIf it is determined as Splitting grain, then set grain._id = other_grain._id. Among them, grain is the first part split from a mother grain in the old set, called grain A, and it does not match the new set; the other part of the split is called other_grain or grain B, and its state in the new set is set to Status::MARKED,  grain B is the same as the parent grain in the old set. Referring to the picture in your article, according to my understanding, I made the following annotations\uff0c\n\n\n\nIf (grain._var_index < _reserve_op_index),\n\nIf only one old_grain in _feature_sets_old matches the current grain, then grain._id = _feature_sets_old[old_grain_indices[0]]._id;\nIf there are more than one, Need more information to find correct candidate - contact a developer!\n\n\n\nIf the above conditions are met, then grain must be a nucleating grain.\n\n\nFor Case 2, I don\u2019t think there is much to explain. Its purpose is to make the state of Status::CLEAR in _feature_sets_old change to Status::INACTIVE in _feature_sets_old.\nThe above is my understanding of this code, looking forward to your guidance.\nHappy weekend.\nWei",
                          "url": "https://github.com/idaholab/moose/discussions/22853#discussioncomment-4298746",
                          "updatedAt": "2022-12-03T14:01:21Z",
                          "publishedAt": "2022-12-03T13:48:05Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "permcody"
                          },
                          "bodyText": "Hi Wei,\n\n\nThis is mostly correct. However, rather than discarding the \"mother grain\" and replacing it with two new grains (\"A\" and \"B\"), what happens with the algorithm as written is that both \"Grain A\" and \"Grain B\" will attempt to \"match up\" with the \"Mother Grain\" from the previous step. This is because at the point where they physically separate in a time step, they'll both have the same order parameter at the start of that time step, as as the middle picture of the figure indicates, they \"should\" have halos that touch. In that case, we'll allow one of the two grains to match up to the mother grain (doesn't really matter which one), and then the remaining grain will be \"detected as a split grain\" due to the criteria that I just explained. What's important though is that this isn't a case of merging twins, this is the opposite, this is a potential mechanism for creating twins (splitting)!\n\n\ni. This is exactly the case I just mentioned, the slow splitting of a grain into two child grains.\nii. This is a case where we have more than two child grains (with overlapping halos) in a single time step. This would be something like a 3-way split. I didn't think this was likely to happen so I just punted and decided to print out a message to contact the developer. I don't think you will hit this case.\n\n\nNucleation - you aren't dealing with that at all in your current sim. All of that logic only kicks in if you start using the \"reserve OP\" variables.\n\n\nSo back to your original question. Who to deal with twins merging?\nI was just reviewing the code again and realized that I specifically setup the GrainTracker to NOT treat twins in any special way (e.g. I made sure to remap one of them so that if they \"got too close\", one of them would be remapped to a new order parameter preventing them from re-merging. So you are correct, you (we) will need to adjust the grain tracker if you do indeed want to handle this case. So first order of business. I don't believe any of the logic in the \"trackGrains\" routine will need to change. Once we get the code to a place where twins re-merge, it'll be equivalent to a grain disappearing as it shrinks. Essentially in one time step, we'll have two child grains that move together to form one new grain, triggering the logic to handle the \"inactive\" grain case. Instead what needs to specifically change is how we handle twins in the remapping phase. Take a look at the logic here:\n\n  \n    \n      moose/modules/phase_field/src/postprocessors/GrainTracker.C\n    \n    \n        Lines 956 to 976\n      in\n      af38e9f\n    \n  \n  \n    \n\n        \n          \n                   // The first condition below is there to prevent symmetric checks (duplicate values) \n        \n\n        \n          \n                   if (i < j && grain1._id == grain2._id) \n        \n\n        \n          \n                   { \n        \n\n        \n          \n                     split_pairs.push_front(std::make_pair(i, j)); \n        \n\n        \n          \n                     if (grain1._var_index != grain2._var_index) \n        \n\n        \n          \n                     { \n        \n\n        \n          \n                       if (_verbosity_level > 0) \n        \n\n        \n          \n                         _console << COLOR_YELLOW << \"Split Grain (#\" << grain1._id \n        \n\n        \n          \n                                  << \") detected on unmatched OPs (\" << grain1._var_index << \", \" \n        \n\n        \n          \n                                  << grain2._var_index << \") attempting to remap to \" << grain1._var_index \n        \n\n        \n          \n                                  << \".\\n\" \n        \n\n        \n          \n                                  << COLOR_DEFAULT; \n        \n\n        \n          \n            \n        \n\n        \n          \n                       /** \n        \n\n        \n          \n                        * We're not going to try very hard to look for a suitable remapping. Just set it to \n        \n\n        \n          \n                        * what we want and hope it all works out. Make the GrainTracker great again! \n        \n\n        \n          \n                        */ \n        \n\n        \n          \n                       grain1._var_index = grain2._var_index; \n        \n\n        \n          \n                       grain1._status |= Status::DIRTY; \n        \n\n        \n          \n                     } \n        \n\n        \n          \n                   } \n        \n    \n  \n\n\nIn this logic, we are specifically dealing with twins (we know this because they share an id), but we are still remapping one of them to a new order parameter. I think the easiest thing to do would be to add a new Boolean to the GrainTracker (GrainTrackerInterface) that would prevent twins from getting remapped. Something likeremap_twins = false, then in the lines above, we simply don't remap one twin if the grain that's intersecting is the other twin.\nThe tricky bits: Implementing and testing out that new logic should be pretty easy if you have the right data set. The problem is that once you allow twins to not remap you open up several new edge cases. The first being that if you end up needing to remap a twin due to being close to an unrelated grain sharing the same order parameter, you'll need to remap the twin too and make sure there aren't any conflicts. You'll also have to add new logic to the \"trackGrains\" routine to essentially ignore messages that you may otherwise encounter from twins being close in subsequent time steps.\nMy suggestion is that you start with the Boolean and ignore the remap and see what happens. Even with the new edge cases this should be mostly working just with the new Boolean!",
                          "url": "https://github.com/idaholab/moose/discussions/22853#discussioncomment-4316943",
                          "updatedAt": "2022-12-05T20:35:29Z",
                          "publishedAt": "2022-12-05T20:35:28Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "permcody"
                          },
                          "bodyText": "Ok... Rereading that code block again for the third time... I'm still not getting this right. Look at the console message on line 963. It's explicitly trying to make sure the twins are on the same order parameter. This will allow them to merge if they get close enough. So, I'm again thinking that the merging case you are looking at really should be working already. I think I'll need to see a counter-example to provide better feedback.",
                          "url": "https://github.com/idaholab/moose/discussions/22853#discussioncomment-4317007",
                          "updatedAt": "2022-12-05T20:44:51Z",
                          "publishedAt": "2022-12-05T20:44:50Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "PengWei97"
                          },
                          "bodyText": "Hi Cody,\n\n... this is a potential mechanism for creating twins (splitting)!\n\n\nI totally agree with you. Case1 (for Splitting Grain) is the potential function with splitting twins.\n\n\nOnce we get the code to a place where twins re-merge, it'll be equivalent to a grain disappearing as it shrinks.\n\nYes, when it is determined that two grains (such as grain_i and grain_j) need to be merged, it is essentially to merge grain_j into grain_j (as you said one grain disappears), even if the order parameter indexes of the two grains are different.\n\nEssentially in one time step, we'll have two child grains that move together to form one new grain, triggering the logic to handle the \"inactive\" grain case.\n\nYeah, I think it is important to note that we are performing a merge operation and the new big grain has the same grain ID and _var_index as some child grain.\n\nThe problem is that once you allow twins to not remap you open up several new edge cases.\n\nYes, there may be some unexpected situations, such as merging grains to the same order parameter, this new large grain may have the same order parameter as the surrounding grains, this is what I think of the possible situation.\n\nOk, I tried to focus the Key problem on solving the merging of two grains, even though they have different order parameters. Specifically, when two grains (e.g. grain_i and grain_j) are identified and their order parameter indexes (e.g. gr1 and gr5) are different, how to realize the re-merger operation of these two grains?\nNext, based on your suggestion, the mergeGrainsMisorientation() function was created to do this in GrainTracker::trackGrains(), but it didn't meet our expectations, that is, Creating new unique grain in the next timestep. The core code in mergeGrainsMisorientation() is as follows,\nvoid \nGrainTracker::mergeGrainsMisorientation()\n{\n  // The simplest example: focus on specifying the merging of two grains to test how to re-merge grains\n  // For example, specifying to merge grain_i (_id == 0) and grain_j (_id == 2), and they have different order parameter indexs. Then, set `grain_j._id = grain_i._id` and `grain_j._id = grain_i._id`\n  for (const auto i : index_range(_feature_sets))\n  {\n    for (const auto j : index_range(_feature_sets))\n      if (_feature_sets[i]._id == 0 && _feature_sets[j]._id == 2)\n      {\n        // only make the Grain id of grain_j become the Grain id of grain_i,\n        // And the order parameter index modification operation is executed in remap algorithm;\n        std::cout << \"merging grain_i \" << _feature_sets[i]._id << \" and grain_j \" << _feature_sets[j]._id << std::endl;     \n        std::cout << \"merging grain_i._var_index \" << _feature_sets[i]._var_index << \" and grain_j._var_index \" << _feature_sets[j]._var_index << std::endl;   \n\n        _feature_sets[j]._id =  _feature_sets[i]._id;\n        _feature_sets[j]._var_index =  _feature_sets[i]._var_index;\n        std::cout << \"the grain_j._id \" << _feature_sets[j]._id << std::endl;\n        std::cout << \"the grain_j._var_index \" << _feature_sets[j]._var_index << std::endl;\n        break;\n\n        // grain_adj._status = Status::INACTIVE;     \n      }\n  }  \n}\nAnd the terminal outputs the following information, indicating that the merging of grains is not successful,\n...\nTime Step 0, time = 0\n...\n\nTime Step 1, time = 0\n...\nmerging grain_i 0 and grain_j 2\nmerging grain_i._var_index 1 and grain_j._var_index 5\nthe grain_j._id 0\nthe grain_j._var_index 1\nFinished inside of GrainTracker\n...\n\nTime Step 2, time = 10.5, dt = 5.5\n...\n\ufffd[32mMarking Grain 0 as INACTIVE (variable index: 1)\n\ufffd[39m\ufffd[33mNucleating Grain Detected  (variable index: 5)\n\ufffd[39m\ufffd[33m\n*****************************************************************************\nCouldn't find a matching grain while working on variable index: 5\nCreating new unique grain: 10\nGrain ID: 10\n...\n\nFinished Executing    \n\nSo, in general, I have tried to achieve the simplest grain merging function these days, without considering the remap algorithm. However, even though the merge operation was performed at Time Step 1, it was recognized as a new grain at Time Step 2, or because grain_j._var_index has not changed.  In addition, I also provide the complete code modification for GrainTrack and input file (vt_10.i) to prevent me from missing key information.\nFinally, my question is how to modify the operation of merging grains. And it seems that even if _feature_sets[j]._var_index =  _feature_sets[i]._var_index; is executed, _feature_sets[j]._var_index is still 5 at Time Step 2;\nThank you very much for your enthusiastic guidance and look forward to your next feedback.\nWei",
                          "url": "https://github.com/idaholab/moose/discussions/22853#discussioncomment-4323983",
                          "updatedAt": "2022-12-06T15:03:57Z",
                          "publishedAt": "2022-12-06T15:00:23Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "permcody"
                          },
                          "bodyText": "Wei,\nSorry it's taken me so long to get back to you. I still need to think about this a bit more, but I want to at least communicate the purpose and intent of a few of these function to suggest what you can look at to resolve this behavior.\nYou mention here at the bottom of your thread that the twin is recognized as a new grain in time step 2. That piece of information is critical because once the GrainTracker \"thinks\" it's a separate grain, it'll certainly make sure that it stays apart from every other grain so things will not re-merge as you've tried here. You can't force the re-merge outcome in the GrainTracker at all, it acts more like a Postprocessor than a \"Kernel\". Instead, the key to getting this to work properly is to setup the right conditions so that remerging will occur naturally during the solution phase. Essentially this will happen automatically if any two grains with the same order parameter get \"too close\".\nAgain, without looking at the code, what needs to happen is that information about twins is preserved so that we can force them to be on the same order parameter all the time. This means that any time any twin gets remapped to a different order parameter, we'll want to make the twin follow as well. In my opinion, this is all that needs to happen.\nI need to find some time to look at the code as I was pretty sure that I had already done this. It's possible the algorithm just has a bug, or perhaps I just didn't finish? I thought about these cases back when I implemented these algorithms, but I only had a single test case that I created. The same ones that I used to generate those images for the splitting and remerging cases.\nI'll let you know if I see anything that should be investigated further.\nBest Regards,\nCody",
                          "url": "https://github.com/idaholab/moose/discussions/22853#discussioncomment-4402396",
                          "updatedAt": "2022-12-14T17:12:36Z",
                          "publishedAt": "2022-12-14T17:12:35Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "PengWei97"
                          },
                          "bodyText": "Hi permcody,\nI believe that the grain merging problem has now been successfully resolved, with some modifications made to GrainTrack. Below is my approach and code for addressing the issue, although it may not be perfect. I would appreciate any feedback or comments you may have.\n\nYou can't force the re-merge outcome in the GrainTracker at all, it acts more like a Postprocessor than a \"Kernel\". Instead, the key to getting this to work properly is to setup the right conditions so that remerging will occur naturally during the solution phase.\n\nYes, I customized the GrainTrackerGG2 to handle grain merging operations only when certain conditions are met, such as when the misorientation angle is less than 1\u00b0.\nBelow are the three steps or stages involved in accomplishing the merging process:\n\nInitially, I created GrainTrackerGG by building upon GrainTracker. Then, I developed the createAdjacentIDVector() function to obtain the vector of each grain and its adjacent grain ID;\nAfterwards, I created GrainTrackerGG2, which inherits from GrainTrackerGG, and I overrode the trackGrains and remapGrains methods.\nFinally, I added the merging functionality to GrainTrackerGG2.\n\nThe following code is primarily responsible for handling the merging operation in GrainTrackerGG2:\nvoid\nGrainTrackerGG2::remapGrains()\n{\n  ...\n     // Case 2 (inactive grains in _feature_sets_old)\n    for (auto & grain : _feature_sets_old)\n    {\n       ...\n            /**\n             * We're not going to try very hard to look for a suitable remapping. Just set it to\n             * what we want and hope it all works out. Make the GrainTrackerGG great again!\n             */\n            grain1._var_index = grain2._var_index;\n            grain1._status |= Status::DIRTY;\n\n            if (_remerge_grains)  // by weipeng\n              grain_id_to_new_var.emplace_hint(\n                  grain_id_to_new_var.end(),\n                  std::pair<unsigned int, std::size_t>(grain1._id, grain1._var_index));\n       ...\n     }\n  ...\n}\n\nvoid \nGrainTrackerGG2::mergeGrainsBasedMisorientation()\n{\n  ...\n      if (misor_angle < threshold_merge)\n      {\n        _console << COLOR_YELLOW << \"Grain #\" << grain_i._id << \" and Grain #\" << grain_j._id\n                 << \" was merged (misor: \" << misor_angle << \").\\n\"\n                 << COLOR_DEFAULT;\n\n        grain_j._id = grain_i._id;\n      }\n  ...\n}\nThe result of the execution is as follows,\n\nFinally, I would like to express my sincere gratitude for your generous assistance, which helped me to successfully complete this task. I would greatly appreciate any feedback or suggestions you may have regarding this aspect. Additionally, I would be more than happy to merge this functionality into GrainTracker if it would be useful.\nBest Regards,\nWei",
                          "url": "https://github.com/idaholab/moose/discussions/22853#discussioncomment-5316856",
                          "updatedAt": "2023-03-15T03:53:25Z",
                          "publishedAt": "2023-03-15T03:53:22Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "@permcody",
                          "url": "https://github.com/idaholab/moose/discussions/22853#discussioncomment-5317222",
                          "updatedAt": "2023-03-15T05:09:26Z",
                          "publishedAt": "2023-03-15T05:09:25Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "permcody"
                          },
                          "bodyText": "Wei,\nThis is fantastic work! I'm very happy to see that you've managed to enhance the capabilities for your need. If you are interested, I would invite you to add your contributions to the MOOSE repository. I believe that the code above is reasonable to add to the existing GrainTracker class. Provided it be activated with appropriate input parameters, which it appears you have already done. I would also entertain adding a new inherited class provided we minimize copying from the existing class, even if that means we need to add additional hooks in the existing class to support your implementation. In either case, we are interested in this work.\nI would ask for the following:\n\nYour new and modified code changes\nOne or more regression tests that exercise your new logic\nDocumentation: Either added to the existing GrainTracker.md markdown, or a new Markdown file if you decide to contribute a new class.\n\nWe can assist you throughout the process!\nBest Regards,\nCody",
                          "url": "https://github.com/idaholab/moose/discussions/22853#discussioncomment-5326164",
                          "updatedAt": "2023-03-15T19:48:10Z",
                          "publishedAt": "2023-03-15T19:48:10Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "PengWei97"
                          },
                          "bodyText": "Permcody,\nIt is a great honor to receive your approval, and I am excited about merging my code into Moose. Thank you for the opportunity. I would also appreciate your guidance on the standard process of code development. As a Moose rookie, I am eager to learn and improve.\nNext, I will provide a detailed explanation of the additions and modifications I made to FeatureFloodCount and GrainTracker. And I also created PR #23757 to merge this part of the code.\nFirst, I added adjacent_id to the FeatureData class in FeatureFloodCount. This is used to store the grain ID of each adjacent grain for each feature or grain. It should be noted that the storage of the vector of adjacent grain IDs is done in GrainTracker. Additionally, I created three functions, getFeatureID, getAdjacentID, and getAdjacentGrainNum, to extract relevant information.\nBut here there are some warnings, and I don't know how to eliminate them,\n/home/pw-moose/projects/moose/modules/phase_field/build/header_symlinks/FeatureFloodCount.h:324:26: warning: 'FeatureFloodCount::FeatureData::_boundary_intersection' will be initialized after [-Wreorder]\n  324 |     BoundaryIntersection _boundary_intersection;\n      |                          ^~~~~~~~~~~~~~~~~~~~~~\n/home/pw-moose/projects/moose/modules/phase_field/build/header_symlinks/FeatureFloodCount.h:305:31: warning:   'std::vector<unsigned int> FeatureFloodCount::FeatureData::_adjacent_id' [-Wreorder]\n  305 |     std::vector<unsigned int> _adjacent_id;\n      |                               ^~~~~~~~~~~~\n/home/pw-moose/projects/moose/modules/phase_field/build/header_symlinks/FeatureFloodCount.h:171:5: warning:   when initialized here [-Wreorder]\n  171 |     FeatureData(std::size_t var_index,\nSecond, add createAdjacentIDVector() in GrainTracker.h to complete the purpose of creating adjacent grain vector;\nThird,  we need to add an interface for grain merging by creating a virtual function called \"mergeGrainsBasedMisorientation\" in the GrainTracker. I am planning to create a derived class, GrainTrackerMerge, which will be responsible for performing the detailed operations of grain merging based on the calculation of misorientation.\nFourth, add the function of grain merging to the derived class GrainTrackerMerge, based on the calculation of misorientation. But after the creation is complete, I run a test and it shows an error like this,\n===================================================================================\n= \u00a0 BAD TERMINATION OF ONE OF YOUR APPLICATION PROCESSES\n= \u00a0 PID 2945348 RUNNING AT pwmoose-PowerEdge-T640\n= \u00a0 EXIT CODE: 11\n= \u00a0 CLEANING UP REMAINING PROCESSES\n= \u00a0 YOU CAN IGNORE THE BELOW CLEANUP MESSAGES\n===================================================================================\nYOUR APPLICATION TERMINATED WITH THE EXIT STRING: Segmentation fault (signal 11)\nThis typically refers to a problem with your application.\nPlease see the FAQ page for debugging suggestions\nI suspect that the error may be related to creating the derived class GrainTrackerMerge based on GrainTracker. Although it may seem like a simple mistake, I would appreciate your guidance on this issue.\nFifthly, as I was unable to resolve the aforementioned bug, I added the function of grain merging directly to GrainTracker. Although I recognize that this may not be the wisest decision, I intend to move the last part of the code to the derived class GrainTrackerMerge once the bug is resolved\uff1b\nSixthly, I created a test to verify the newly modified GrainTracker, which I named \"test_GrainTrackerMerge.i\", and placed it in the directory \"./modules/phase_field/test/tests/GrainTrackerMerge\". However, when I attempted to run the test, I encountered the following error:\napplication called MPI_Abort(MPI_COMM_WORLD, 1) - process 21\n\n*** ERROR ***\nA 'EulerAngleFileReader' is not a registered object.\n\nIf you are trying to find this object in a dynamically linked library, make sure that\nthe library can be found either in your \"Problem/library_path\" parameter or in the\nMOOSE_LIBRARY_PATH environment variable.\nAfterwards, I copied the \"test_GrainTrackerMerge.i\" file to my own APP-yinglong directory and ran the test, which passed successfully. The results of the operation are shown below:\n\nOverall, I believe that I have successfully added the misorientation-based grain merging functionality to the grain tracker algorithm. I made some modifications and additions to the FeatureFloodCount and GrainTracker classes, and created a derived class, GrainTrackerMerge, for specific implementation. However, I hope to get your assistance in resolving the two bugs mentioned above.\nBest Regards,\nWei",
                          "url": "https://github.com/idaholab/moose/discussions/22853#discussioncomment-5333357",
                          "updatedAt": "2023-03-16T13:43:12Z",
                          "publishedAt": "2023-03-16T12:40:34Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "PETSc check error and libMesh compiling error",
          "author": {
            "login": "RWTHLHK"
          },
          "bodyText": "Hello guys, I need to install moose on a HPC cluster, but after compiling and check if PETSc works, I got the following error:\nRunning check examples to verify correct installation\nUsing PETSC_DIR=/home/../projects/moose/scripts/../petsc and PETSC_ARCH=arch-moose\nC/C++ example src/snes/tutorials/ex19 run successfully with 1 MPI process\nC/C++ example src/snes/tutorials/ex19 run successfully with 2 MPI processes\nC/C++ example src/snes/tutorials/ex19 run successfully with hypre\nC/C++ example src/snes/tutorials/ex19 run successfully with mumps\nC/C++ example src/snes/tutorials/ex19 run successfully with superlu_dist\n0a1,45\n> HDF5-DIAG: Error detected in HDF5 (1.12.1) MPI-process 0:\n>   #000: H5F.c line 532 in H5Fcreate(): unable to create file\n>     major: File accessibility\n>     minor: Unable to open file\n>   #001: H5VLcallback.c line 3282 in H5VL_file_create(): file create failed\n>     major: Virtual Object Layer\n>     minor: Unable to create file\n>   #002: H5VLcallback.c line 3248 in H5VL__file_create(): file create failed\n>     major: Virtual Object Layer\n>     minor: Unable to create file\n>   #003: H5VLnative_file.c line 63 in H5VL__native_file_create(): unable to create file\n>     major: File accessibility\n>     minor: Unable to open file\n>   #004: H5Fint.c line 1834 in H5F_open(): unable to open file: name = '/tmp/bq407628/login_19195/petsc.vJ5tzR.h5', tent_flags = 13\n>     major: File accessibility\n>     minor: Unable to open file\n>   #005: H5FD.c line 723 in H5FD_open(): open failed\n>     major: Virtual File Layer\n>     minor: Unable to initialize object\n>   #006: H5FDmpio.c line 850 in H5FD__mpio_open(): MPI_File_open failed: MPI error string is 'MPI_ERR_NO_SUCH_FILE: no such file or directory'\n>     major: Internal error (too specific to document in detail)\n>     minor: Some MPI function failed\n> [0]PETSC ERROR: --------------------- Error Message --------------------------------------------------------------\n> [0]PETSC ERROR: Error in external library\n> [0]PETSC ERROR: Error in HDF5 call H5Fcreate() Status -1\n> [0]PETSC ERROR: See https://petsc.org/release/faq/ for trouble shooting.\n> [0]PETSC ERROR: Petsc Release Version 3.16.6, unknown \n> [0]PETSC ERROR: /rwthfs/rz/cluster/home/bq407628/projects/moose/petsc/src/vec/vec/tests/ex47 on a arch-moose named nrm215.hpc.itc.rwth-aachen.de by bq407628 Fri Mar 17 00:39:18 2023\n> [0]PETSC ERROR: Configure options --download-hypre=1 --with-shared-libraries=1 --download-hdf5=1 --download-hdf5-fortran-bindings=0   --with-debugging=no --download-fblaslapack=1 --download-metis=1 --download-ptscotch=1 --download-parmetis=1 --download-superlu_dist=1 --download-mumps=1 --download-strumpack=1 --download-scalapack=1 --download-slepc=1 --with-mpi=1 --with-openmp=1 --with-cxx-dialect=C++11 --with-fortran-bindings=0 --with-sowing=0 --with-64-bit-indices \n> [0]PETSC ERROR: #1 PetscViewerFileSetName_HDF5() at /rwthfs/rz/cluster/home/bq407628/projects/moose/petsc/src/sys/classes/viewer/impls/hdf5/hdf5v.c:409\n> [0]PETSC ERROR: #2 PetscViewerFileSetName() at /rwthfs/rz/cluster/home/bq407628/projects/moose/petsc/src/sys/classes/viewer/impls/ascii/filev.c:649\n> [0]PETSC ERROR: #3 PetscViewerHDF5Open() at /rwthfs/rz/cluster/home/bq407628/projects/moose/petsc/src/sys/classes/viewer/impls/hdf5/hdf5v.c:534\n> [0]PETSC ERROR: #4 main() at ex47.c:25\n> [0]PETSC ERROR: PETSc Option Table entries:\n> [0]PETSC ERROR: -filename /tmp/bq407628/login_19195/petsc.vJ5tzR.h5\n> [0]PETSC ERROR: ----------------End of Error Message -------send entire error message to petsc-maint@mcs.anl.gov----------\n> --------------------------------------------------------------------------\n> MPI_ABORT was invoked on rank 0 in communicator MPI_COMM_WORLD\n> with errorcode 76.\n> \n> NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.\n> You may or may not see output from other processes, depending on\n> exactly when Open MPI kills them.\n> --------------------------------------------------------------------------\n> Failure executing command /opt/MPI/openmpi-3.1.3/linux/gcc_10.1.0/bin/mpiexec -x  MPI_NAME -x  OMP_NUM_THREADS -x  LD_LIBRARY_PATH -x  PATH --hostfile /tmp/bq407628/login_19195/hostfile-711970 -np 1 /rwthfs/rz/cluster/home/bq407628/projects/moose/petsc/src/vec/vec/tests/ex47 -filename /tmp/bq407628/login_19195/petsc.vJ5tzR.h5\n/home/bq407628/projects/moose/petsc/src/vec/vec/tests\nPossible problem with ex47 running with hdf5, diffs above\n\nAnd then when I compile libMesh, the following error occurs:\n<<< Found PETSc 3.16.6 installation in /home/../projects/moose/scripts/../petsc ... >>>\nchecking whether we can compile a trivial PETSc program... no\nchecking for TAO support via PETSc... no\nconfigure: error: *** PETSc was not found, but --enable-petsc-required was specified.",
          "url": "https://github.com/idaholab/moose/discussions/23767",
          "updatedAt": "2023-04-29T03:43:30Z",
          "publishedAt": "2023-03-16T23:47:27Z",
          "category": {
            "name": "Q&A General"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "GiudGiud"
                  },
                  "bodyText": "Hello\nSeems like HDF5 is broken.\nWhat does the diagnosiic script return in moose/scripts\nGuillaume",
                  "url": "https://github.com/idaholab/moose/discussions/23767#discussioncomment-5340001",
                  "updatedAt": "2023-03-17T00:22:57Z",
                  "publishedAt": "2023-03-17T00:22:56Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": []
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "Impact of CPU numbers",
          "author": {
            "login": "alimostafavi24"
          },
          "bodyText": "Hello,\nI faced a weird problem. When I run my simulation on my linux system and on hpc with 8 CPUs, my solution will converge.\nBut when I increase the number of CPUs to 28 and 94, my simulation will diverge.\nI wanted to know whether this is a common problem and how I can resolve the convergence problem with increasing number of CPUs.\nThank you,\nAli",
          "url": "https://github.com/idaholab/moose/discussions/23764",
          "updatedAt": "2023-04-29T03:44:03Z",
          "publishedAt": "2023-03-16T22:07:19Z",
          "category": {
            "name": "Q&A General"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "GiudGiud"
                  },
                  "bodyText": "Hello\nThe preconditioning is affected by the number of CPUs. You should look at designing preconditioning that is more resilient in parallel.\nWhat does your preconditioning block look right now?\nGuillaume",
                  "url": "https://github.com/idaholab/moose/discussions/23764#discussioncomment-5339299",
                  "updatedAt": "2023-03-16T22:10:55Z",
                  "publishedAt": "2023-03-16T22:10:55Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "author": {
                    "login": "alimostafavi24"
                  },
                  "bodyText": "[Preconditioning]\n  [./SMP_PJFNK]\n    type = SMP\n    full = true\n    solve_type = Newton\n  [../]\n[]\n\n[Executioner]\n  type = Transient\n  petsc_options_iname = '-pc_type -sub_pc_type -sub_pc_factor_levels'\n  petsc_options_value = 'bjacobi  ilu          4'\n\n  nl_rel_tol  = 1e-3\n  nl_abs_tol  = 1e-3\n  nl_max_its  = 70\n  l_tol       = 1e-3\n  l_max_its   = 70\n\n  #end_time    = 200\n\n # dt = 0.001\n end_time = 10\n\n\n#adaptive time stepping\n[./TimeStepper]\n   type = IterationAdaptiveDT\n\t    dt = 0.0005\n [../]\n[]",
                  "url": "https://github.com/idaholab/moose/discussions/23764#discussioncomment-5339314",
                  "updatedAt": "2023-03-16T22:13:06Z",
                  "publishedAt": "2023-03-16T22:13:05Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "I think the block in block jacobi depend on the partition of the problem.\nMaybe try to use the overlap parameters to sooth this?",
                          "url": "https://github.com/idaholab/moose/discussions/23764#discussioncomment-5339344",
                          "updatedAt": "2023-03-16T22:17:26Z",
                          "publishedAt": "2023-03-16T22:17:26Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "A negative test",
          "author": {
            "login": "doquang"
          },
          "bodyText": "Hi,\nIs there any way I can determine a negative test for the TestHarness? I mean, with a particular input file, the simulation will fail. And the test will say OK, if this simulation fails.\nThanks a lot,\n/ Minh",
          "url": "https://github.com/idaholab/moose/discussions/23759",
          "updatedAt": "2023-03-16T15:35:28Z",
          "publishedAt": "2023-03-16T15:30:11Z",
          "category": {
            "name": "Q&A Tools"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "GiudGiud"
                  },
                  "bodyText": "Yes it's the runexception test",
                  "url": "https://github.com/idaholab/moose/discussions/23759#discussioncomment-5335899",
                  "updatedAt": "2023-03-16T15:31:01Z",
                  "publishedAt": "2023-03-16T15:31:00Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "https://mooseframework.inl.gov/python/testers/RunException.html",
                          "url": "https://github.com/idaholab/moose/discussions/23759#discussioncomment-5335903",
                          "updatedAt": "2023-03-16T15:31:18Z",
                          "publishedAt": "2023-03-16T15:31:17Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "doquang"
                          },
                          "bodyText": "Thank you, @GiudGiud",
                          "url": "https://github.com/idaholab/moose/discussions/23759#discussioncomment-5335941",
                          "updatedAt": "2023-03-16T15:35:23Z",
                          "publishedAt": "2023-03-16T15:35:22Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "Exporting mesh generated by MOOSE",
          "author": {
            "login": "tannhorn"
          },
          "bodyText": "Hello, is it possible to export the mesh generated in MOOSE into e.g. the gmsh format? I have been looking through the documentation and the forum and haven't found anything, except for \"MOOSE supports reading and writing a large number of formats and could be extended to read more.\" in https://mooseframework.inl.gov/application_usage/mesh_block_type.html\nThanks!",
          "url": "https://github.com/idaholab/moose/discussions/23730",
          "updatedAt": "2023-03-16T08:06:05Z",
          "publishedAt": "2023-03-15T09:18:50Z",
          "category": {
            "name": "Q&A Meshing"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "GiudGiud"
                  },
                  "bodyText": "Hello\nNo we do not have this writing capability, though we would be interested in the contribution.\nBest,\nGuillaume",
                  "url": "https://github.com/idaholab/moose/discussions/23730#discussioncomment-5322111",
                  "updatedAt": "2023-03-15T13:55:35Z",
                  "publishedAt": "2023-03-15T13:55:34Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "cpgr"
                          },
                          "bodyText": "If the mesh isn't too complex I've had success using meshio, but it only does the mesh and not any associated variables etc.",
                          "url": "https://github.com/idaholab/moose/discussions/23730#discussioncomment-5326545",
                          "updatedAt": "2023-03-15T20:35:13Z",
                          "publishedAt": "2023-03-15T20:35:13Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "tannhorn"
                          },
                          "bodyText": "Thanks, I will check it out",
                          "url": "https://github.com/idaholab/moose/discussions/23730#discussioncomment-5330604",
                          "updatedAt": "2023-03-16T08:06:05Z",
                          "publishedAt": "2023-03-16T08:06:05Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "Time integration scheme",
          "author": {
            "login": "Richard-happy"
          },
          "bodyText": "Hello,I wonder know if there is any way to  solve PDEs with different Time integration schemes within a coupled problem.\nFor example, solving a heat conduction model with implicit-euler and  solving a linear elastic model with bdf2.",
          "url": "https://github.com/idaholab/moose/discussions/23732",
          "updatedAt": "2023-03-15T23:52:56Z",
          "publishedAt": "2023-03-15T14:23:58Z",
          "category": {
            "name": "Q&A General"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "GiudGiud"
                  },
                  "bodyText": "We dont support that within the same solve (eg coupling everything in the same matrix)\nbut you could use a multiapps for this\nhttps://mooseframework.inl.gov/moose/syntax/MultiApps/index.html",
                  "url": "https://github.com/idaholab/moose/discussions/23732#discussioncomment-5322620",
                  "updatedAt": "2023-03-15T14:38:01Z",
                  "publishedAt": "2023-03-15T14:38:00Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "Richard-happy"
                          },
                          "bodyText": "Thank you",
                          "url": "https://github.com/idaholab/moose/discussions/23732#discussioncomment-5327688",
                          "updatedAt": "2023-03-15T23:52:55Z",
                          "publishedAt": "2023-03-15T23:52:55Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "Installing MOOSE on windows with MSYS2",
          "author": {
            "login": "starkekr"
          },
          "bodyText": "I have been able to install libmesh and petsc with msys2 but run into trouble when trying to build MOOSE. Specifically, when linking with pcre I get the following error after running make in the test folder:\nLinking Executable /home/stark/projects/moose/test/moose_test-opt...\nC:/msys64/mingw64/bin/../lib/gcc/x86_64-w64-mingw32/12.2.0/../../../../x86_64-w64-mingw32/bin/ld.exe: C:/msys64/home/stark/projects/moose/framework/libmoose-opt.a(mesh_Unity.x86_64-w64-mingw32.opt.o):mesh_Unity.C:(.text+0xbd0d): undefined reference to `__imp__ZN7pcrecpp2RE4InitERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEPKNS_10RE_OptionsE'\nI realize that a native windows build is not fully supported in MOOSE (outside of WSL) but nevertheless I am trying. Any thoughts would be greatly appreciated.",
          "url": "https://github.com/idaholab/moose/discussions/23681",
          "updatedAt": "2023-04-29T03:44:19Z",
          "publishedAt": "2023-03-09T18:24:13Z",
          "category": {
            "name": "Q&A Getting Started"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "GiudGiud"
                  },
                  "bodyText": "I'm surprised you got this far.\n@dschwen do you know who can help",
                  "url": "https://github.com/idaholab/moose/discussions/23681#discussioncomment-5257870",
                  "updatedAt": "2023-03-09T18:32:53Z",
                  "publishedAt": "2023-03-09T18:32:52Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "So I talked to Daniel and while it s possible to get it to compile and to pass some of the test suite, the dynamic linking works differently so you wont be able to create an application from this MOOSE, which limits the usefulness quite a bit\nWe recommend you switch to WSL2 which has been satisfactory for many",
                          "url": "https://github.com/idaholab/moose/discussions/23681#discussioncomment-5310342",
                          "updatedAt": "2023-03-14T15:24:02Z",
                          "publishedAt": "2023-03-14T15:24:02Z",
                          "isAnswer": true
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "starkekr"
                          },
                          "bodyText": "Could I just put my code into one of the modules of MOOSE and build it locally rather than using stork to build an application? I think there would be no need to build my application dynamically in that case right?",
                          "url": "https://github.com/idaholab/moose/discussions/23681#discussioncomment-5326609",
                          "updatedAt": "2023-03-15T20:46:55Z",
                          "publishedAt": "2023-03-15T20:46:55Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "@permcody correct me if I m wrong but I think modules are linked dynamically too",
                          "url": "https://github.com/idaholab/moose/discussions/23681#discussioncomment-5326630",
                          "updatedAt": "2023-03-15T20:49:46Z",
                          "publishedAt": "2023-03-15T20:49:45Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "permcody"
                          },
                          "bodyText": "No, modules are compiled in, but yes, they each have their own library file.",
                          "url": "https://github.com/idaholab/moose/discussions/23681#discussioncomment-5327196",
                          "updatedAt": "2023-03-15T22:16:13Z",
                          "publishedAt": "2023-03-15T22:16:12Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "Non-zero exit after primary job finished",
          "author": {
            "login": "BoZeng1997"
          },
          "bodyText": "Hi,\nI am running a customized moose on HPC with PETSC individually compiled. I sometimes receive a non-zero exit after my computing is finished. It does not seem to interrupt the computing but it does appear repeatedly. So far I have not figure out which moose object is closely related to this issue. There are input decks that would return with non-zero signal with opt executable but returned just fine with dbg executable. I am not able to reproduce this issue on local ubuntu machine or HPC with conda environment. I do not think it is due to insufficient memory because it would appear on a simple problem with single cpu and 120G memory. Sometimes I received message about corrupted double-linked list sometimes  together with non-zero exit, sometimes I did not.  gdb on this cluster is not functioning well so I cannot provide backtrace info for now.\nFrom your experience, is this a bug need to be debugged?\nThe first kind of issue is exited on signal 11 (Segmentation fault):\nFinished Executing                                                                       [\ufffd[33m 12.56 s\ufffd[39m] [\ufffd[33m   66 MB\ufffd[39m]\n*** Error in `/qscratch/bzeng/projects/raccoon/raccoon-dbg': double free or corruption (out): 0x00002aaac06e5be0 ***\n*** Error in `/qscratch/bzeng/projects/raccoon/raccoon-dbg': corrupted double-linked list: 0x00000000014e1670 ***\n*** Error in `/qscratch/bzeng/projects/raccoon/raccoon-dbg': corrupted double-linked list: 0x0000000001a15b10 ***\n*** Error in `/qscratch/bzeng/projects/raccoon/raccoon-dbg': corrupted double-linked list: 0x000000000152b120 ***\n--------------------------------------------------------------------------\nPrimary job  terminated normally, but 1 process returned\na non-zero exit code. Per user-direction, the job has been aborted.\n--------------------------------------------------------------------------\n--------------------------------------------------------------------------\nmpiexec noticed that process rank 18 with PID 227203 on node solo1 exited on signal 11 (Segmentation fault).\n--------------------------------------------------------------------------\nEnd: Fri Mar 10 10:28:36 MST 2023\n\nAnd the second type is :\nFinished Executing                                                                       [\ufffd[33m201.75 s\ufffd[39m] [\ufffd[33m  164 MB\ufffd[39m]\n*** Error in `/qscratch/bzeng/projects/raccoon/raccoon-opt': corrupted double-linked list: 0x00000000037b4770 ***\n======= Backtrace: =========\n/lib64/libc.so.6(+0x80a4f)[0x2aaab8111a4f]\n/lib64/libc.so.6(+0x8120e)[0x2aaab811220e]\n/qscratch/bzeng/moose-compilers/petsc-3.16.5/lib/libpetsc.so.3.16(PetscFreeAlign+0xe)[0x2aaab2510269]\n/qscratch/bzeng/moose-compilers/petsc-3.16.5/lib/libpetsc.so.3.16(PetscEventRegLogDestroy+0xdb)[0x2aaab258d7d6]\n/qscratch/bzeng/moose-compilers/petsc-3.16.5/lib/libpetsc.so.3.16(PetscStageLogDestroy+0x31)[0x2aaab258c339]\n/qscratch/bzeng/moose-compilers/petsc-3.16.5/lib/libpetsc.so.3.16(+0x18c33e)[0x2aaab257433e]\n/qscratch/bzeng/moose-compilers/petsc-3.16.5/lib/libpetsc.so.3.16(PetscFinalize+0xd13)[0x2aaab24f5eac]\n/qscratch/bzeng/moose-compilers/petsc-3.16.5/lib/libslepc.so.3.16(SlepcFinalize+0xc8)[0x2aaab1e5f672]\n/qscratch/bzeng/projects/raccoon/moose/scripts/../libmesh/installed/lib/libmesh_opt.so.0(_ZN7libMesh11LibMeshInitD1Ev+0x477)[0x2aaab032a5b7]\n/qscratch/bzeng/projects/raccoon/raccoon-opt(main+0x9c)[0x4025dc]\n/lib64/libc.so.6(__libc_start_main+0xf5)[0x2aaab80b3555]\n/qscratch/bzeng/projects/raccoon/raccoon-opt[0x402813]\n======= Memory map: ========\n00400000-00404000 r-xp 00000000 552:aa07e 180144600483146984             /qscratch/bzeng/projects/raccoon/raccoon-opt\n00604000-00605000 r--p 00004000 552:aa07e 180144600483146984             /qscratch/bzeng/projects/raccoon/raccoon-opt\n00605000-00606000 rw-p 00005000 552:aa07e 180144600483146984             /qscratch/bzeng/projects/raccoon/raccoon-opt\n00606000-08f68000 rw-p 00000000 00:00 0                                  [heap]\n2aaaaaaab000-2aaaaaacd000 r-xp 00000000 00:13 198052684                  /usr/lib64/ld-2.17.so\n2aaaaaacd000-2aaaaaacf000 r-xp 00000000 00:00 0                          [vdso]\n2aaaaaacf000-2aaaaab15000 rw-p 00000000 00:00 0 \n2aaaaab15000-2aaaaab16000 rw-s 00000000 00:27 6516704                    /ram/tmp/ompi.solo289.137033/pid.218400/pmix_dstor_ds12_218400/dstore_sm.lock\n2aaaaab16000-2aaaaab17000 r--s 00000000 00:27 6516703                    /ram/tmp/ompi.solo289.137033/pid.218400/pmix_dstor_ds12_218400/initial-pmix_shared-segment-0\n2aaaaab17000-2aaaaab19000 rw-s 00000000 00:27 6516702                    /ram/tmp/ompi.solo289.137033/pid.218400/pmix_dstor_ds21_218400/smlockseg-14221313\n2aaaaab19000-2aaaaab65000 rw-p 00000000 00:00 0 \n2aaaaab65000-2aaaaab66000 r--s 00000000 00:27 6516701                    /ram/tmp/ompi.solo289.137033/pid.218400/pmix_dstor_ds21_218400/initial-pmix_shared-segment-0\n2aaaaab66000-2aaaaac91000 rw-p 00000000 00:00 0 \n2aaaaac91000-2aaaaac92000 r--s dabbad0003230000 00:05 45595              /dev/hfi1_0\n2aaaaac92000-2aaaaac98000 -w-s dabbad0002230000 00:05 45595              /dev/hfi1_0\n2aaaaac98000-2aaaaac9e000 -w-s dabbad0001230000 00:05 45595              /dev/hfi1_0\n2aaaaac9e000-2aaaaac9f000 r--s ffffa517b7cd9000 00:05 45595              /dev/hfi1_0\n2aaaaac9f000-2aaaaaca0000 rw-s dabbad0006230000 00:05 45595              /dev/hfi1_0\n2aaaaaca0000-2aaaaaca1000 r--s ffffa5178d29c000 00:05 45595              /dev/hfi1_0\n2aaaaaca1000-2aaaaaca2000 r--s dabbad0008230000 00:05 45595              /dev/hfi1_0\n2aaaaaca2000-2aaaaacc5000 rw-p 00000000 00:00 0 \n2aaaaaccc000-2aaaaaccd000 r--p 00021000 00:13 198052684                  /usr/lib64/ld-2.17.so\n2aaaaaccd000-2aaaaacce000 rw-p 00022000 00:13 198052684                  /usr/lib64/ld-2.17.so\n2aaaaacce000-2aaaaaccf000 rw-p 00000000 00:00 0 \n2aaaaaccf000-2aaaaacdc000 r-xp 00000000 552:aa07e 180144600483146979     /qscratch/bzeng/projects/raccoon/test/lib/libraccoon_test-opt.so.0.0.0\n2aaaaacdc000-2aaaaaedb000 ---p 0000d000 552:aa07e 180144600483146979     /qscratch/bzeng/projects/raccoon/test/lib/libraccoon_test-opt.so.0.0.0\n2aaaaaedb000-2aaaaaedc000 r--p 0000c000 552:aa07e 180144600483146979     /qscratch/bzeng/projects/raccoon/test/lib/libraccoon_test-opt.so.0.0.0\n2aaaaaedc000-2aaaaaedd000 rw-p 0000d000 552:aa07e 180144600483146979     /qscratch/bzeng/projects/raccoon/test/lib/libraccoon_test-opt.so.0.0.0\n2aaaaaedd000-2aaaab0a7000 r-xp 00000000 552:aa07e 180144600483146960     /qscratch/bzeng/projects/raccoon/lib/libraccoon-opt.so.0.0.0\n2aaaab0a7000-2aaaab2a6000 ---p 001ca000 552:aa07e 180144600483146960     /qscratch/bzeng/projects/raccoon/lib/libraccoon-opt.so.0.0.0\n2aaaab2a6000-2aaaab2c6000 r--p 001c9000 552:aa07e 180144600483146960     /qscratch/bzeng/projects/raccoon/lib/libraccoon-opt.so.0.0.0\n2aaaab2c6000-2aaaab2c8000 rw-p 001e9000 552:aa07e 180144600483146960     /qscratch/bzeng/projects/raccoon/lib/libraccoon-opt.so.0.0.0\n2aaaab2c8000-2aaaab2c9000 rw-p 00000000 00:00 0 \n2aaaab2c9000-2aaaab2d5000 r-xp 00000000 552:aa07e 180144600483146888     /qscratch/bzeng/projects/raccoon/moose/modules/module_loader/lib/libmodule_loader_with_ray_hc_tm_con_pf-opt.so.0.0.0\n2aaaab2d5000-2aaaab4d4000 ---p 0000c000 552:aa07e 180144600483146888     /qscratch/bzeng/projects/raccoon/moose/modules/module_loader/lib/libmodule_loader_with_ray_hc_tm_con_pf-opt.so.0.0.0\n2aaaab4d4000-2aaaab4d5000 r--p 0000b000 552:aa07e 180144600483146888     /qscratch/bzeng/projects/raccoon/moose/modules/module_loader/lib/libmodule_loader_with_ray_hc_tm_con_pf-opt.so.0.0.0\n2aaaab4d5000-2aaaab4d6000 rw-p 0000c000 552:aa07e 180144600483146888     /qscratch/bzeng/projects/raccoon/moose/modules/module_loader/lib/libmodule_loader_with_ray_hc_tm_con_pf-opt.so.0.0.0\n2aaaab4d6000-2aaaabb61000 r-xp 00000000 552:aa07e 180144600483146873     /qscratch/bzeng/projects/raccoon/moose/modules/phase_field/lib/libphase_field-opt.so.0.0.0\n2aaaabb61000-2aaaabd60000 ---p 0068b000 552:aa07e 180144600483146873     /qscratch/bzeng/projects/raccoon/moose/modules/phase_field/lib/libphase_field-opt.so.0.0.0\n2aaaabd60000-2aaaabdd9000 r--p 0068a000 552:aa07e 180144600483146873     /qscratch/bzeng/projects/raccoon/moose/modules/phase_field/lib/libphase_field-opt.so.0.0.0\n2aaaabdd9000-2aaaabdde000 rw-p 00703000 552:aa07e 180144600483146873     /qscratch/bzeng/projects/raccoon/moose/modules/phase_field/lib/libphase_field-opt.so.0.0.0\n2aaaabdde000-2aaaabddf000 rw-p 00000000 00:00 0 \n2aaaabddf000-2aaaabf54000 r-xp 00000000 552:aa07e 180144600483146800     /qscratch/bzeng/projects/raccoon/moose/modules/contact/lib/libcontact-opt.so.0.0.0\n2aaaabf54000-2aaaac154000 ---p 00175000 552:aa07e 180144600483146800     /qscratch/bzeng/projects/raccoon/moose/modules/contact/lib/libcontact-opt.so.0.0.0\n2aaaac154000-2aaaac164000 r--p 00175000 552:aa07e 180144600483146800     /qscratch/bzeng/projects/raccoon/moose/modules/contact/lib/libcontact-opt.so.0.0.0\n2aaaac164000-2aaaac166000 rw-p 00185000 552:aa07e 180144600483146800     /qscratch/bzeng/projects/raccoon/moose/modules/contact/lib/libcontact-opt.so.0.0.0\n2aaaac166000-2aaaac173000 rw-p 00000000 00:00 0 \n2aaaac173000-2aaaacc9e000 r-xp 00000000 552:aa07e 180144600483146743     /qscratch/bzeng/projects/raccoon/moose/modules/tensor_mechanics/lib/libtensor_mechanics-opt.so.0.0.0\n2aaaacc9e000-2aaaace9d000 ---p 00b2b000 552:aa07e 180144600483146743     /qscratch/bzeng/projects/raccoon/moose/modules/tensor_mechanics/lib/libtensor_mechanics-opt.so.0.0.0\n2aaaace9d000-2aaaacf52000 r--p 00b2a000 552:aa07e 180144600483146743     /qscratch/bzeng/projects/raccoon/moose/modules/tensor_mechanics/lib/libtensor_mechanics-opt.so.0.0.0\n2aaaacf52000-2aaaacf5b000 rw-p 00bdf000 552:aa07e 180144600483146743     /qscratch/bzeng/projects/raccoon/moose/modules/tensor_mechanics/lib/libtensor_mechanics-opt.so.0.0.0\n2aaaacf5b000-2aaaacf68000 rw-p 00000000 00:00 0 \n2aaaacf68000-2aaaad21b000 r-xp 00000000 552:aa07e 180144600483146616     /qscratch/bzeng/projects/raccoon/moose/modules/heat_conduction/lib/libheat_conduction-opt.so.0.0.0\n2aaaad21b000-2aaaad41a000 ---p 002b3000 552:aa07e 180144600483146616     /qscratch/bzeng/projects/raccoon/moose/modules/heat_conduction/lib/libheat_conduction-opt.so.0.0.0\n2aaaad41a000-2aaaad445000 r--p 002b2000 552:aa07e 180144600483146616     /qscratch/bzeng/projects/raccoon/moose/modules/heat_conduction/lib/libheat_conduction-opt.so.0.0.0\n2aaaad445000-2aaaad448000 rw-p 002dd000 552:aa07e 180144600483146616     /qscratch/bzeng/projects/raccoon/moose/modules/heat_conduction/lib/libheat_conduction-opt.so.0.0.0\n2aaaad448000-2aaaad44f000 rw-p 00000000 00:00 0 \n2aaaad44f000-2aaaad5d9000 r-xp 00000000 552:aa07e 180144600483146539     /qscratch/bzeng/projects/raccoon/moose/modules/ray_tracing/lib/libray_tracing-opt.so.0.0.0\n2aaaad5d9000-2aaaad7d8000 ---p 0018a000 552:aa07e 180144600483146539     /qscratch/bzeng/projects/raccoon/moose/modules/ray_tracing/lib/libray_tracing-opt.so.0.0.0\n2aaaad7d8000-2aaaad7e5000 r--p 00189000 552:aa07e 180144600483146539     /qscratch/bzeng/projects/raccoon/moose/modules/ray_tracing/lib/libray_tracing-opt.so.0.0.0\n2aaaad7e5000-2aaaad7e8000 rw-p 00196000 552:aa07e 180144600483146539     /qscratch/bzeng/projects/raccoon/moose/modules/ray_tracing/lib/libray_tracing-opt.so.0.0.0\n2aaaad7e8000-2aaaad7e9000 rw-p 00000000 00:00 0 \n2aaaad7e9000-2aaaaf463000 r-xp 00000000 552:aa07e 180144600483146421     /qscratch/bzeng/projects/raccoon/moose/framework/libmoose-opt.so.0.0.0\n2aaaaf463000-2aaaaf663000 ---p 01c7a000 552:aa07e 180144600483146421     /qscratch/bzeng/projects/raccoon/moose/framework/libmoose-opt.so.0.0.0\n2aaaaf663000-2aaaaf798000 r--p 01c7a000 552:aa07e 180144600483146421     /qscratch/bzeng/projects/raccoon/moose/framework/libmoose-opt.so.0.0.0\n2aaaaf798000-2aaaaf7b8000 rw-p 01daf000 552:aa07e 180144600483146421     /qscratch/bzeng/projects/raccoon/moose/framework/libmoose-opt.so.0.0.0\n2aaaaf7b8000-2aaaaf7d3000 rw-p 00000000 00:00 0 \n2aaaaf7d3000-2aaaaf7fc000 r-xp 00000000 00:13 198056658                  /usr/lib64/libpng15.so.15.13.0\n2aaaaf7fc000-2aaaaf9fc000 ---p 00029000 00:13 198056658                  /usr/lib64/libpng15.so.15.13.0\n2aaaaf9fc000-2aaaaf9fd000 r--p 00029000 00:13 198056658                  /usr/lib64/libpng15.so.15.13.0\n2aaaaf9fd000-2aaaaf9fe000 rw-p 0002a000 00:13 198056658                  /usr/lib64/libpng15.so.15.13.0\n2aaaaf9fe000-2aaaafa27000 r-xp 00000000 552:aa07e 180144600483146375     /qscratch/bzeng/projects/raccoon/moose/framework/contrib/pcre/libpcre-opt.so.0.0.0\n2aaaafa27000-2aaaafc26000 ---p 00029000 552:aa07e 180144600483146375     /qscratch/bzeng/projects/raccoon/moose/framework/contrib/pcre/libpcre-opt.so.0.0.0\n2aaaafc26000-2aaaafc27000 r--p 00028000 552:aa07e 180144600483146375     /qscratch/bzeng/projects/raccoon/moose/framework/contrib/pcre/libpcre-opt.so.0.0.0\n2aaaafc27000-2aaaafc28000 rw-p 00029000 552:aa07e 180144600483146375     /qscratch/bzeng/projects/raccoon/moose/framework/contrib/pcre/libpcre-opt.so.0.0.0\n2aaaafc28000-2aaaafc71000 r-xp 00000000 552:aa07e 180144600483146409     /qscratch/bzeng/projects/raccoon/moose/framework/contrib/hit/libhit-opt.so.0.0.0\n2aaaafc71000-2aaaafe71000 ---p 00049000 552:aa07e 180144600483146409     /qscratch/bzeng/projects/raccoon/moose/framework/contrib/hit/libhit-opt.so.0.0.0\n2aaaafe71000-2aaaafe72000 r--p 00049000 552:aa07e 180144600483146409     /qscratch/bzeng/projects/raccoon/moose/framework/contrib/hit/libhit-opt.so.0.0.0\n2aaaafe72000-2aaaafe73000 rw-p 0004a000 552:aa07e 180144600483146409     /qscratch/bzeng/projects/raccoon/moose/framework/contrib/hit/libhit-opt.so.0.0.0\n2aaaafe73000-2aaaafe74000 rw-p 00000000 00:00 0 \n2aaaafe74000-2aaab0fb9000 r-xp 00000000 552:aa07e 180144600533438388     /qscratch/bzeng/projects/raccoon/moose/libmesh/installed/lib/libmesh_opt.so.0.0.0\n2aaab0fb9000-2aaab11b9000 ---p 01145000 552:aa07e 180144600533438388     /qscratch/bzeng/projects/raccoon/moose/libmesh/installed/lib/libmesh_opt.so.0.0.0\n2aaab11b9000-2aaab11eb000 r--p 01145000 552:aa07e 180144600533438388     /qscratch/bzeng/projects/raccoon/moose/libmesh/installed/lib/libmesh_opt.so.0.0.0\n2aaab11eb000-2aaab11fe000 rw-p 01177000 552:aa07e 180144600533438388     /qscratch/bzeng/projects/raccoon/moose/libmesh/installed/lib/libmesh_opt.so.0.0.0\n2aaab11fe000-2aaab120b000 rw-p 00000000 00:00 0 \n2aaab120b000-2aaab12fc000 r-xp 00000000 552:aa07e 180144600533438209     /qscratch/bzeng/projects/raccoon/moose/libmesh/installed/lib/libnetcdf.so.13.1.1\n2aaab12fc000-2aaab14fc000 ---p 000f1000 552:aa07e 180144600533438209     /qscratch/bzeng/projects/raccoon/moose/libmesh/installed/lib/libnetcdf.so.13.1.1\n2aaab14fc000-2aaab14fd000 r--p 000f1000 552:aa07e 180144600533438209     /qscratch/bzeng/projects/raccoon/moose/libmesh/installed/lib/libnetcdf.so.13.1.1\n2aaab14fd000-2aaab1510000 rw-p 000f2000 552:aa07e 180144600533438209     /qscratch/bzeng/projects/raccoon/moose/libmesh/installed/lib/libnetcdf.so.13.1.1\n2aaab1510000-2aaab151a000 rw-p 00000000 00:00 0 \n2aaab151a000-2aaab151c000 r-xp 00000000 00:13 198055779                  /usr/lib64/libsz.so.2.0.1\n2aaab151c000-2aaab171b000 ---p 00002000 00:13 198055779                  /usr/lib64/libsz.so.2.0.1\n2aaab171b000-2aaab171c000 r--p 00001000 00:13 198055779                  /usr/lib64/libsz.so.2.0.1\n2aaab171c000-2aaab171d000 rw-p 00002000 00:13 198055779                  /usr/lib64/libsz.so.2.0.1\n2aaab171d000-2aaab1729000 r-xp 00000000 552:aa07e 180144600533438256     /qscratch/bzeng/projects/raccoon/moose/libmesh/installed/lib/libtimpi_opt.so.11.0.0\n2aaab1729000-2aaab1928000 ---p 0000c000 552:aa07e 180144600533438256     /qscratch/bzeng/projects/raccoon/moose/libmesh/installed/lib/libtimpi_opt.so.11.0.0\n2aaab1928000-2aaab1929000 r--p 0000b000 552:aa07e 180144600533438256     /qscratch/bzeng/projects/raccoon/moose/libmesh/installed/lib/libtimpi_opt.so.11.0.0\n2aaab1929000-2aaab192a000 rw-p 0000c000 552:aa07e 180144600533438256     /qscratch/bzeng/projects/raccoon/moose/libmesh/installed/lib/libtimpi_opt.so.11.0.0\n2aaab192a000-2aaab1a19000 r-xp 00000000 00:13 198055535                  /usr/lib64/libglpk.so.36.0.1\n2aaab1a19000-2aaab1c18000 ---p 000ef000 00:13 198055535                  /usr/lib64/libglpk.so.36.0.1\n2aaab1c18000-2aaab1c19000 r--p 000ee000 00:13 198055535                  /usr/lib64/libglpk.so.36.0.1\n2aaab1c19000-2aaab1c1a000 rw-p 000ef000 00:13 198055535                  /usr/lib64/libglpk.so.36.0.1\n2aaab1c1a000-2aaab1c2f000 r-xp 00000000 00:13 198057427                  /usr/lib64/libz.so.1.2.7\n2aaab1c2f000-2aaab1e2e000 ---p 00015000 00:13 198057427                  /usr/lib64/libz.so.1.2.7\n2aaab1e2e000-2aaab1e2f000 r--p 00014000 00:13 198057427                  /usr/lib64/libz.so.1.2.7\n2aaab1e2f000-2aaab1e30000 rw-p 00015000 00:13 198057427                  /usr/lib64/libz.so.1.2.7\n2aaab1e30000-2aaab21e2000 r-xp 00000000 552:aa07e 180144597832322793     /qscratch/bzeng/moose-compilers/petsc-3.16.5/lib/libslepc.so.3.16.2\n2aaab21e2000-2aaab23e1000 ---p 003b2000 552:aa07e 180144597832322793     /qscratch/bzeng/moose-compilers/petsc-3.16.5/lib/libslepc.so.3.16.2\n2aaab23e1000-2aaab23e3000 r--p 003b1000 552:aa07e 180144597832322793     /qscratch/bzeng/moose-compilers/petsc-3.16.5/lib/libslepc.so.3.16.2\n2aaab23e3000-2aaab23e7000 rw-p 003b3000 552:aa07e 180144597832322793     /qscratch/bzeng/moose-compilers/petsc-3.16.5/lib/libslepc.so.3.16.2\n2aaab23e7000-2aaab23e8000 rw-p 00000000 00:00 0 \n2aaab23e8000-2aaab393f000 r-xp 00000000 552:aa07e 180144597832314651     /qscratch/bzeng/moose-compilers/petsc-3.16.5/lib/libpetsc.so.3.16.5\n2aaab393f000-2aaab3b3e000 ---p 01557000 552:aa07e 180144597832314651     /qscratch/bzeng/moose-compilers/petsc-3.16.5/lib/libpetsc.so.3.16.5\n2aaab3b3e000-2aaab3b48000 r--p 01556000 552:aa07e 180144597832314651     /qscratch/bzeng/moose-compilers/petsc-3.16.5/lib/libpetsc.so.3.16.5\n2aaab3b48000-2aaab3b71000 rw-p 01560000 552:aa07e 180144597832314651     /qscratch/bzeng/moose-compilers/petsc-3.16.5/lib/libpetsc.so.3.16.5\n2aaab3b71000-2aaab3d76000 rw-p 00000000 00:00 0 \n2aaab3d76000-2aaab4147000 r-xp 00000000 552:aa07e 180144597832303491     /qscratch/bzeng/moose-compilers/petsc-3.16.5/lib/libHYPRE-2.23.0.so\n2aaab4147000-2aaab4347000 ---p 003d1000 552:aa07e 180144597832303491     /qscratch/bzeng/moose-compilers/petsc-3.16.5/lib/libHYPRE-2.23.0.so\n2aaab4347000-2aaab4348000 r--p 003d1000 552:aa07e 180144597832303491     /qscratch/bzeng/moose-compilers/petsc-3.16.5/lib/libHYPRE-2.23.0.so\n2aaab4348000-2aaab4350000 rw-p 003d2000 552:aa07e 180144597832303491     /qscratch/bzeng/moose-compilers/petsc-3.16.5/lib/libHYPRE-2.23.0.so\n2aaab4350000-2aaab436c000 rw-p 00000000 00:00 0 \n2aaab436c000-2aaab4465000 r-xp 00000000 552:aa07e 180144594460086150     /qscratch/bzeng/moose-compilers/petsc-3.16.5/lib/libsuperlu_dist.so.7.1.1\n2aaab4465000-2aaab4665000 ---p 000f9000 552:aa07e 180144594460086150     /qscratch/bzeng/moose-compilers/petsc-3.16.5/lib/libsuperlu_dist.so.7.1.1\n2aaab4665000-2aaab4666000 r--p 000f9000 552:aa07e 180144594460086150     /qscratch/bzeng/moose-compilers/petsc-3.16.5/lib/libsuperlu_dist.so.7.1.1\n2aaab4666000-2aaab4668000 rw-p 000fa000 552:aa07e 180144594460086150     /qscratch/bzeng/moose-compilers/petsc-3.16.5/lib/libsuperlu_dist.so.7.1.1\n2aaab4668000-2aaab4689000 r-xp 00000000 552:aa07e 180144597312321814     /qscratch/bzeng/moose-compilers/petsc-3.16.5/lib/libhdf5_hl.so.200.0.1\n2aaab4689000-2aaab4888000 ---p 00021000 552:aa07e 180144597312321814     /qscratch/bzeng/moose-compilers/petsc-3.16.5/lib/libhdf5_hl.so.200.0.1\n2aaab4888000-2aaab4889000 r--p 00020000 552:aa07e 180144597312321814     /qscratch/bzeng/moose-compilers/petsc-3.16.5/lib/libhdf5_hl.so.200.0.1\n2aaab4889000-2aaab488a000 rw-p 00021000 552:aa07e 180144597312321814     /qscratch/bzeng/moose-compilers/petsc-3.16.5/lib/libhdf5_hl.so.200.0.1\n2aaab488a000-2aaab488b000 rw-p 00000000 00:00 0 \n2aaab488b000-2aaab4ced000 r-xp 00000000 552:aa07e 180144597312321737     /qscratch/bzeng/moose-compilers/petsc-3.16.5/lib/libhdf5.so.200.1.0\n2aaab4ced000-2aaab4eec000 ---p 00462000 552:aa07e 180144597312321737     /qscratch/bzeng/moose-compilers/petsc-3.16.5/lib/libhdf5.so.200.1.0\n2aaab4eec000-2aaab4ef7000 r--p 00461000 552:aa07e 180144597312321737     /qscratch/bzeng/moose-compilers/petsc-3.16.5/lib/libhdf5.so.200.1.0\n2aaab4ef7000-2aaab4f01000 rw-p 0046c000 552:aa07e 180144597312321737     /qscratch/bzeng/moose-compilers/petsc-3.16.5/lib/libhdf5.so.200.1.0\n2aaab4f01000-2aaab4f03000 rw-p 00000000 00:00 0 \n2aaab4f03000-2aaab4f40000 r-xp 00000000 552:aa07e 180144597312313869     /qscratch/bzeng/moose-compilers/petsc-3.16.5/lib/libparmetis.so\n2aaab4f40000-2aaab513f000 ---p 0003d000 552:aa07e 180144597312313869     /qscratch/bzeng/moose-compilers/petsc-3.16.5/lib/libparmetis.so\n2aaab513f000-2aaab5140000 r--p 0003c000 552:aa07e 180144597312313869     /qscratch/bzeng/moose-compilers/petsc-3.16.5/lib/libparmetis.so\n2aaab5140000-2aaab5141000 rw-p 0003d000 552:aa07e 180144597312313869     /qscratch/bzeng/moose-compilers/petsc-3.16.5/lib/libparmetis.so\n2aaab5141000-2aaab519f000 r-xp 00000000 552:aa07e 180144597312313457     /qscratch/bzeng/moose-compilers/petsc-3.16.5/lib/libmetis.so\n2aaab519f000-2aaab539e000 ---p 0005e000 552:aa07e 180144597312313457     /qscratch/bzeng/moose-compilers/petsc-3.16.5/lib/libmetis.so\n2aaab539e000-2aaab539f000 r--p 0005d000 552:aa07e 180144597312313457     /qscratch/bzeng/moose-compilers/petsc-3.16.5/lib/libmetis.so\n2aaab539f000-2aaab53a0000 rw-p 0005e000 552:aa07e 180144597312313457     /qscratch/bzeng/moose-compilers/petsc-3.16.5/lib/libmetis.so\n2aaab53a0000-2aaab53a1000 rw-p 00000000 00:00 0 \n2aaab53a1000-2aaab54d9000 r-xp 00000000 00:13 198052602                  /usr/lib64/libX11.so.6.3.0\n2aaab54d9000-2aaab56d9000 ---p 00138000 00:13 198052602                  /usr/lib64/libX11.so.6.3.0\n2aaab56d9000-2aaab56da000 r--p 00138000 00:13 198052602                  /usr/lib64/libX11.so.6.3.0\n2aaab56da000-2aaab56df000 rw-p 00139000 00:13 198052602                  /usr/lib64/libX11.so.6.3.0\n2aaab56df000-2aaab56e1000 r-xp 00000000 00:13 200281872                  /opt/openmpi/4.1/gnu/lib/libmpi_usempi.so.40.30.0\n2aaab56e1000-2aaab58e0000 ---p 00002000 00:13 200281872                  /opt/openmpi/4.1/gnu/lib/libmpi_usempi.so.40.30.0\n2aaab58e0000-2aaab58e1000 r--p 00001000 00:13 200281872                  /opt/openmpi/4.1/gnu/lib/libmpi_usempi.so.40.30.0\n2aaab58e1000-2aaab58e2000 rw-p 00002000 00:13 200281872                  /opt/openmpi/4.1/gnu/lib/libmpi_usempi.so.40.30.0\n2aaab58e2000-2aaab593a000 r-xp 00000000 00:13 200281128                  /opt/openmpi/4.1/gnu/lib/libmpi_mpifh.so.40.30.0\n2aaab593a000-2aaab5b39000 ---p 00058000 00:13 200281128                  /opt/openmpi/4.1/gnu/lib/libmpi_mpifh.so.40.30.0\n2aaab5b39000-2aaab5b3a000 r--p 00057000 00:13 200281128                  /opt/openmpi/4.1/gnu/lib/libmpi_mpifh.so.40.30.0\n2aaab5b3a000-2aaab5b3b000 rw-p 00058000 00:13 200281128                  /opt/openmpi/4.1/gnu/lib/libmpi_mpifh.so.40.30.0\n2aaab5b3b000-2aaab5de0000 r-xp 00000000 00:2b 1496301181                 /projects/netpub/gnu/11.3.0-toss3/lib64/libgfortran.so.5.0.0\n2aaab5de0000-2aaab5fe0000 ---p 002a5000 00:2b 1496301181                 /projects/netpub/gnu/11.3.0-toss3/lib64/libgfortran.so.5.0.0\n2aaab5fe0000-2aaab5fe1000 r--p 002a5000 00:2b 1496301181                 /projects/netpub/gnu/11.3.0-toss3/lib64/libgfortran.so.5.0.0\n2aaab5fe1000-2aaab5fe3000 rw-p 002a6000 00:2b 1496301181                 /projects/netpub/gnu/11.3.0-toss3/lib64/libgfortran.so.5.0.0\n2aaab5fe3000-2aaab5ffa000 r-xp 00000000 00:2b 1496301132                 /projects/netpub/gnu/11.3.0-toss3/lib64/libgcc_s.so.1\n2aaab5ffa000-2aaab61f9000 ---p 00017000 00:2b 1496301132                 /projects/netpub/gnu/11.3.0-toss3/lib64/libgcc_s.so.1\n2aaab61f9000-2aaab61fa000 r--p 00016000 00:2b 1496301132                 /projects/netpub/gnu/11.3.0-toss3/lib64/libgcc_s.so.1\n2aaab61fa000-2aaab61fb000 rw-p 00017000 00:2b 1496301132                 /projects/netpub/gnu/11.3.0-toss3/lib64/libgcc_s.so.1\n2aaab61fb000-2aaab6212000 r-xp 00000000 00:13 198054755                  /usr/lib64/libpthread-2.17.so\n2aaab6212000-2aaab6411000 ---p 00017000 00:13 198054755                  /usr/lib64/libpthread-2.17.so\n2aaab6411000-2aaab6412000 r--p 00016000 00:13 198054755                  /usr/lib64/libpthread-2.17.so\n2aaab6412000-2aaab6413000 rw-p 00017000 00:13 198054755                  /usr/lib64/libpthread-2.17.so\n2aaab6413000-2aaab6417000 rw-p 00000000 00:00 0 \n2aaab6417000-2aaab645c000 r-xp 00000000 00:2b 1496301175                 /projects/netpub/gnu/11.3.0-toss3/lib64/libquadmath.so.0.0.0\n2aaab645c000-2aaab665c000 ---p 00045000 00:2b 1496301175                 /projects/netpub/gnu/11.3.0-toss3/lib64/libquadmath.so.0.0.0\n2aaab665c000-2aaab665d000 r--p 00045000 00:2b 1496301175                 /projects/netpub/gnu/11.3.0-toss3/lib64/libquadmath.so.0.0.0\n2aaab665d000-2aaab665e000 rw-p 00046000 00:2b 1496301175                 /projects/netpub/gnu/11.3.0-toss3/lib64/libquadmath.so.0.0.0\n2aaab665e000-2aaab6854000 r-xp 00000000 00:2b 1496301138                 /projects/netpub/gnu/11.3.0-toss3/lib64/libstdc++.so.6.0.29\n2aaab6854000-2aaab6a53000 ---p 001f6000 00:2b 1496301138                 /projects/netpub/gnu/11.3.0-toss3/lib64/libstdc++.so.6.0.29\n2aaab6a53000-2aaab6a5e000 r--p 001f5000 00:2b 1496301138                 /projects/netpub/gnu/11.3.0-toss3/lib64/libstdc++.so.6.0.29\n2aaab6a5e000-2aaab6a61000 rw-p 00200000 00:2b 1496301138                 /projects/netpub/gnu/11.3.0-toss3/lib64/libstdc++.so.6.0.29\n2aaab6a61000-2aaab6a64000 rw-p 00000000 00:00 0 \n2aaab6a64000-2aaab6b56000 r-xp 00000000 00:13 200280825                  /opt/openmpi/4.1/gnu/lib/libmpi.so.40.30.1\n2aaab6b56000-2aaab6d55000 ---p 000f2000 00:13 200280825                  /opt/openmpi/4.1/gnu/lib/libmpi.so.40.30.1\n2aaab6d55000-2aaab6d57000 r--p 000f1000 00:13 200280825                  /opt/openmpi/4.1/gnu/lib/libmpi.so.40.30.1\n2aaab6d57000-2aaab6d68000 rw-p 000f3000 00:13 200280825                  /opt/openmpi/4.1/gnu/lib/libmpi.so.40.30.1\n2aaab6d68000-2aaab6d7a000 rw-p 00000000 00:00 0 \n2aaab6d7a000-2aaab6e2a000 r-xp 00000000 00:13 200281892                  /opt/openmpi/4.1/gnu/lib/libopen-rte.so.40.30.1\n2aaab6e2a000-2aaab7029000 ---p 000b0000 00:13 200281892                  /opt/openmpi/4.1/gnu/lib/libopen-rte.so.40.30.1\n2aaab7029000-2aaab702b000 r--p 000af000 00:13 200281892                  /opt/openmpi/4.1/gnu/lib/libopen-rte.so.40.30.1\n2aaab702b000-2aaab702f000 rw-p 000b1000 00:13 200281892                  /opt/openmpi/4.1/gnu/lib/libopen-rte.so.40.30.1\n2aaab702f000-2aaab7031000 rw-p 00000000 00:00 0 \n2aaab7031000-2aaab7032000 r-xp 00000000 00:13 200281880                  /opt/openmpi/4.1/gnu/lib/libopen-orted-mpir.so\n2aaab7032000-2aaab7231000 ---p 00001000 00:13 200281880                  /opt/openmpi/4.1/gnu/lib/libopen-orted-mpir.so\n2aaab7231000-2aaab7232000 r--p 00000000 00:13 200281880                  /opt/openmpi/4.1/gnu/lib/libopen-orted-mpir.so\n2aaab7232000-2aaab7233000 rw-p 00001000 00:13 200281880                  /opt/openmpi/4.1/gnu/lib/libopen-orted-mpir.so\n2aaab7233000-2aaab732f000 r-xp 00000000 00:13 200281886                  /opt/openmpi/4.1/gnu/lib/libopen-pal.so.40.30.1\n2aaab732f000-2aaab752f000 ---p 000fc000 00:13 200281886                  /opt/openmpi/4.1/gnu/lib/libopen-pal.so.40.30.1\n2aaab752f000-2aaab7532000 r--p 000fc000 00:13 200281886                  /opt/openmpi/4.1/gnu/lib/libopen-pal.so.40.30.1\n2aaab7532000-2aaab7538000 rw-p 000ff000 00:13 200281886                  /opt/openmpi/4.1/gnu/lib/libopen-pal.so.40.30.1\n2aaab7538000-2aaab753f000 rw-p 00000000 00:00 0 \n2aaab753f000-2aaab7541000 r-xp 00000000 00:13 198052840                  /usr/lib64/libdl-2.17.so\n2aaab7541000-2aaab7741000 ---p 00002000 00:13 198052840                  /usr/lib64/libdl-2.17.so\n2aaab7741000-2aaab7742000 r--p 00002000 00:13 198052840                  /usr/lib64/libdl-2.17.so\n2aaab7742000-2aaab7743000 rw-p 00003000 00:13 198052840                  /usr/lib64/libdl-2.17.so\n2aaab7743000-2aaab774a000 r-xp 00000000 00:13 198055055                  /usr/lib64/librt-2.17.so\n2aaab774a000-2aaab7949000 ---p 00007000 00:13 198055055                  /usr/lib64/librt-2.17.so\n2aaab7949000-2aaab794a000 r--p 00006000 00:13 198055055                  /usr/lib64/librt-2.17.so\n2aaab794a000-2aaab794b000 rw-p 00007000 00:13 198055055                  /usr/lib64/librt-2.17.so\n2aaab794b000-2aaab794d000 r-xp 00000000 00:13 198055473                  /usr/lib64/libutil-2.17.so\n2aaab794d000-2aaab7b4c000 ---p 00002000 00:13 198055473                  /usr/lib64/libutil-2.17.so\n2aaab7b4c000-2aaab7b4d000 r--p 00001000 00:13 198055473                  /usr/lib64/libutil-2.17.so\n2aaab7b4d000-2aaab7b4e000 rw-p 00002000 00:13 198055473                  /usr/lib64/libutil-2.17.so\n2aaab7b4e000-2aaab7c4f000 r-xp 00000000 00:13 198053645                  /usr/lib64/libm-2.17.so\n2aaab7c4f000-2aaab7e4e000 ---p 00101000 00:13 198053645                  /usr/lib64/libm-2.17.so\n2aaab7e4e000-2aaab7e4f000 r--p 00100000 00:13 198053645                  /usr/lib64/libm-2.17.so\n2aaab7e4f000-2aaab7e50000 rw-p 00101000 00:13 198053645                  /usr/lib64/libm-2.17.so\n2aaab7e50000-2aaab7e90000 r-xp 00000000 00:2b 1496301187                 /projects/netpub/gnu/11.3.0-toss3/lib64/libgomp.so.1.0.0\n2aaab7e90000-2aaab808f000 ---p 00040000 00:2b 1496301187                 /projects/netpub/gnu/11.3.0-toss3/lib64/libgomp.so.1.0.0\n2aaab808f000-2aaab8090000 r--p 0003f000 00:2b 1496301187                 /projects/netpub/gnu/11.3.0-toss3/lib64/libgomp.so.1.0.0\n2aaab8090000-2aaab8091000 rw-p 00040000 00:2b 1496301187                 /projects/netpub/gnu/11.3.0-toss3/lib64/libgomp.so.1.0.0\n2aaab8091000-2aaab8255000 r-xp 00000000 00:13 198052785                  /usr/lib64/libc-2.17.so\n2aaab8255000-2aaab8454000 ---p 001c4000 00:13 198052785                  /usr/lib64/libc-2.17.so\n2aaab8454000-2aaab8458000 r--p 001c3000 00:13 198052785                  /usr/lib64/libc-2.17.so\n2aaab8458000-2aaab845a000 rw-p 001c7000 00:13 198052785                  /usr/lib64/libc-2.17.so\n2aaab845a000-2aaab845f000 rw-p 00000000 00:00 0 \n2aaab845f000-2aaab8466000 r-xp 00000000 00:13 198054841                  /usr/lib64/libaec.so.0.0.10\n2aaab8466000-2aaab8665000 ---p 00007000 00:13 198054841                  /usr/lib64/libaec.so.0.0.10\n2aaab8665000-2aaab8666000 r--p 00006000 00:13 198054841                  /usr/lib64/libaec.so.0.0.10\n2aaab8666000-2aaab8667000 rw-p 00007000 00:13 198054841                  /usr/lib64/libaec.so.0.0.10\n2aaab8667000-2aaab868e000 r-xp 00000000 00:13 198057829                  /usr/lib64/libxcb.so.1.1.0\n2aaab868e000-2aaab888d000 ---p 00027000 00:13 198057829                  /usr/lib64/libxcb.so.1.1.0\n2aaab888d000-2aaab888e000 r--p 00026000 00:13 198057829                  /usr/lib64/libxcb.so.1.1.0\n2aaab888e000-2aaab888f000 rw-p 00027000 00:13 198057829                  /usr/lib64/libxcb.so.1.1.0\n2aaab888f000-2aaab89ae000 r-xp 00000000 00:13 198053749                  /usr/lib64/libgfortran.so.3.0.0\n2aaab89ae000-2aaab8bae000 ---p 0011f000 00:13 198053749                  /usr/lib64/libgfortran.so.3.0.0\n2aaab8bae000-2aaab8baf000 r--p 0011f000 00:13 198053749                  /usr/lib64/libgfortran.so.3.0.0\n2aaab8baf000-2aaab8bb1000 rw-p 00120000 00:13 198053749                  /usr/lib64/libgfortran.so.3.0.0\n2aaab8bb1000-2aaab8bb3000 r-xp 00000000 00:13 198054239                  /usr/lib64/libXau.so.6.0.0\n2aaab8bb3000-2aaab8db3000 ---p 00002000 00:13 198054239                  /usr/lib64/libXau.so.6.0.0\n2aaab8db3000-2aaab8db4000 r--p 00002000 00:13 198054239                  /usr/lib64/libXau.so.6.0.0\n2aaab8db4000-2aaab8db5000 rw-p 00003000 00:13 198054239                  /usr/lib64/libXau.so.6.0.0\n2aaab8db5000-2aaab8db8000 r-xp 00000000 00:13 200350767                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_shmem_mmap.so\n2aaab8db8000-2aaab8fb7000 ---p 00003000 00:13 200350767                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_shmem_mmap.so\n2aaab8fb7000-2aaab8fb8000 r--p 00002000 00:13 200350767                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_shmem_mmap.so\n2aaab8fb8000-2aaab8fb9000 rw-p 00003000 00:13 200350767                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_shmem_mmap.so\n2aaab8fb9000-2aaab8fbb000 r-xp 00000000 00:13 200350721                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_reachable_weighted.so\n2aaab8fbb000-2aaab91ba000 ---p 00002000 00:13 200350721                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_reachable_weighted.so\n2aaab91ba000-2aaab91bb000 r--p 00001000 00:13 200350721                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_reachable_weighted.so\n2aaab91bb000-2aaab91bc000 rw-p 00002000 00:13 200350721                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_reachable_weighted.so\n2aaab91bc000-2aaab91be000 r-xp 00000000 00:13 200350759                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_schizo_slurm.so\n2aaab91be000-2aaab93bd000 ---p 00002000 00:13 200350759                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_schizo_slurm.so\n2aaab93bd000-2aaab93be000 r--p 00001000 00:13 200350759                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_schizo_slurm.so\n2aaab93be000-2aaab93bf000 rw-p 00002000 00:13 200350759                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_schizo_slurm.so\n2aaab93bf000-2aaab93c0000 r-xp 00000000 00:13 200350753                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_schizo_jsm.so\n2aaab93c0000-2aaab95c0000 ---p 00001000 00:13 200350753                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_schizo_jsm.so\n2aaab95c0000-2aaab95c1000 r--p 00001000 00:13 200350753                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_schizo_jsm.so\n2aaab95c1000-2aaab95c2000 rw-p 00002000 00:13 200350753                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_schizo_jsm.so\n2aaab95c2000-2aaab95c3000 r-xp 00000000 00:13 200350757                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_schizo_orte.so\n2aaab95c3000-2aaab97c3000 ---p 00001000 00:13 200350757                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_schizo_orte.so\n2aaab97c3000-2aaab97c4000 r--p 00001000 00:13 200350757                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_schizo_orte.so\n2aaab97c4000-2aaab97c5000 rw-p 00002000 00:13 200350757                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_schizo_orte.so\n2aaab97c5000-2aaab97c6000 r-xp 00000000 00:13 200350751                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_schizo_flux.so\n2aaab97c6000-2aaab99c6000 ---p 00001000 00:13 200350751                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_schizo_flux.so\n2aaab99c6000-2aaab99c7000 r--p 00001000 00:13 200350751                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_schizo_flux.so\n2aaab99c7000-2aaab99c8000 rw-p 00002000 00:13 200350751                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_schizo_flux.so\n2aaab99c8000-2aaab99d0000 r-xp 00000000 00:13 200350755                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_schizo_ompi.so\n2aaab99d0000-2aaab9bcf000 ---p 00008000 00:13 200350755                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_schizo_ompi.so\n2aaab9bcf000-2aaab9bd0000 r--p 00007000 00:13 200350755                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_schizo_ompi.so\n2aaab9bd0000-2aaab9bd2000 rw-p 00008000 00:13 200350755                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_schizo_ompi.so\n2aaab9bd2000-2aaab9bd7000 r-xp 00000000 00:13 200350625                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_ess_pmi.so\n2aaab9bd7000-2aaab9dd6000 ---p 00005000 00:13 200350625                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_ess_pmi.so\n2aaab9dd6000-2aaab9dd7000 r--p 00004000 00:13 200350625                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_ess_pmi.so\n2aaab9dd7000-2aaab9dd8000 rw-p 00005000 00:13 200350625                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_ess_pmi.so\n2aaab9dd8000-2aaab9dd9000 ---p 00000000 00:00 0 \n2aaab9dd9000-2aaab9fd9000 rw-p 00000000 00:00 0 \n2aaab9fd9000-2aaaba131000 r-xp 00000000 00:13 200350697                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_pmix_pmix3x.so\n2aaaba131000-2aaaba330000 ---p 00158000 00:13 200350697                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_pmix_pmix3x.so\n2aaaba330000-2aaaba331000 r--p 00157000 00:13 200350697                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_pmix_pmix3x.so\n2aaaba331000-2aaaba336000 rw-p 00158000 00:13 200350697                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_pmix_pmix3x.so\n2aaaba336000-2aaaba339000 rw-p 00000000 00:00 0 \n2aaaba339000-2aaaba33b000 r-xp 00000000 00:13 200752747                  /opt/openmpi/4.1/gnu/lib/pmix/mca_psquash_flex128.so\n2aaaba33b000-2aaaba53a000 ---p 00002000 00:13 200752747                  /opt/openmpi/4.1/gnu/lib/pmix/mca_psquash_flex128.so\n2aaaba53a000-2aaaba53b000 r--p 00001000 00:13 200752747                  /opt/openmpi/4.1/gnu/lib/pmix/mca_psquash_flex128.so\n2aaaba53b000-2aaaba53c000 rw-p 00002000 00:13 200752747                  /opt/openmpi/4.1/gnu/lib/pmix/mca_psquash_flex128.so\n2aaaba53c000-2aaaba53e000 r-xp 00000000 00:13 200752749                  /opt/openmpi/4.1/gnu/lib/pmix/mca_psquash_native.so\n2aaaba53e000-2aaaba73d000 ---p 00002000 00:13 200752749                  /opt/openmpi/4.1/gnu/lib/pmix/mca_psquash_native.so\n2aaaba73d000-2aaaba73e000 r--p 00001000 00:13 200752749                  /opt/openmpi/4.1/gnu/lib/pmix/mca_psquash_native.so\n2aaaba73e000-2aaaba73f000 rw-p 00002000 00:13 200752749                  /opt/openmpi/4.1/gnu/lib/pmix/mca_psquash_native.so\n2aaaba73f000-2aaaba746000 r-xp 00000000 00:13 200752717                  /opt/openmpi/4.1/gnu/lib/pmix/mca_bfrops_v21.so\n2aaaba746000-2aaaba946000 ---p 00007000 00:13 200752717                  /opt/openmpi/4.1/gnu/lib/pmix/mca_bfrops_v21.so\n2aaaba946000-2aaaba947000 r--p 00007000 00:13 200752717                  /opt/openmpi/4.1/gnu/lib/pmix/mca_bfrops_v21.so\n2aaaba947000-2aaaba948000 rw-p 00008000 00:13 200752717                  /opt/openmpi/4.1/gnu/lib/pmix/mca_bfrops_v21.so\n2aaaba948000-2aaaba963000 r-xp 00000000 00:13 200752715                  /opt/openmpi/4.1/gnu/lib/pmix/mca_bfrops_v20.so\n2aaaba963000-2aaabab63000 ---p 0001b000 00:13 200752715                  /opt/openmpi/4.1/gnu/lib/pmix/mca_bfrops_v20.so\n2aaabab63000-2aaabab64000 r--p 0001b000 00:13 200752715                  /opt/openmpi/4.1/gnu/lib/pmix/mca_bfrops_v20.so\n2aaabab64000-2aaabab65000 rw-p 0001c000 00:13 200752715                  /opt/openmpi/4.1/gnu/lib/pmix/mca_bfrops_v20.so\n2aaabab65000-2aaabab77000 r-xp 00000000 00:13 200752713                  /opt/openmpi/4.1/gnu/lib/pmix/mca_bfrops_v12.so\n2aaabab77000-2aaabad77000 ---p 00012000 00:13 200752713                  /opt/openmpi/4.1/gnu/lib/pmix/mca_bfrops_v12.so\n2aaabad77000-2aaabad78000 r--p 00012000 00:13 200752713                  /opt/openmpi/4.1/gnu/lib/pmix/mca_bfrops_v12.so\n2aaabad78000-2aaabad79000 rw-p 00013000 00:13 200752713                  /opt/openmpi/4.1/gnu/lib/pmix/mca_bfrops_v12.so\n2aaabad79000-2aaabad80000 r-xp 00000000 00:13 200752719                  /opt/openmpi/4.1/gnu/lib/pmix/mca_bfrops_v3.so\n2aaabad80000-2aaabaf80000 ---p 00007000 00:13 200752719                  /opt/openmpi/4.1/gnu/lib/pmix/mca_bfrops_v3.so\n2aaabaf80000-2aaabaf81000 r--p 00007000 00:13 200752719                  /opt/openmpi/4.1/gnu/lib/pmix/mca_bfrops_v3.so\n2aaabaf81000-2aaabaf82000 rw-p 00008000 00:13 200752719                  /opt/openmpi/4.1/gnu/lib/pmix/mca_bfrops_v3.so\n2aaabaf82000-2aaabaf95000 r-xp 00000000 00:13 200752751                  /opt/openmpi/4.1/gnu/lib/pmix/mca_ptl_tcp.so\n2aaabaf95000-2aaabb194000 ---p 00013000 00:13 200752751                  /opt/openmpi/4.1/gnu/lib/pmix/mca_ptl_tcp.so\n2aaabb194000-2aaabb195000 r--p 00012000 00:13 200752751                  /opt/openmpi/4.1/gnu/lib/pmix/mca_ptl_tcp.so\n2aaabb195000-2aaabb196000 rw-p 00013000 00:13 200752751                  /opt/openmpi/4.1/gnu/lib/pmix/mca_ptl_tcp.so\n2aaabb196000-2aaabb19e000 r-xp 00000000 00:13 200752753                  /opt/openmpi/4.1/gnu/lib/pmix/mca_ptl_usock.so\n2aaabb19e000-2aaabb39d000 ---p 00008000 00:13 200752753                  /opt/openmpi/4.1/gnu/lib/pmix/mca_ptl_usock.so\n2aaabb39d000-2aaabb39e000 r--p 00007000 00:13 200752753                  /opt/openmpi/4.1/gnu/lib/pmix/mca_ptl_usock.so\n2aaabb39e000-2aaabb39f000 rw-p 00008000 00:13 200752753                  /opt/openmpi/4.1/gnu/lib/pmix/mca_ptl_usock.so\n2aaabb39f000-2aaabb3a1000 r-xp 00000000 00:13 200752737                  /opt/openmpi/4.1/gnu/lib/pmix/mca_psec_native.so\n2aaabb3a1000-2aaabb5a0000 ---p 00002000 00:13 200752737                  /opt/openmpi/4.1/gnu/lib/pmix/mca_psec_native.so\n2aaabb5a0000-2aaabb5a1000 r--p 00001000 00:13 200752737                  /opt/openmpi/4.1/gnu/lib/pmix/mca_psec_native.so\n2aaabb5a1000-2aaabb5a2000 rw-p 00002000 00:13 200752737                  /opt/openmpi/4.1/gnu/lib/pmix/mca_psec_native.so\n2aaabb5a2000-2aaabb5a6000 r-xp 00000000 00:13 200752721                  /opt/openmpi/4.1/gnu/lib/pmix/mca_gds_ds12.so\n2aaabb5a6000-2aaabb7a5000 ---p 00004000 00:13 200752721                  /opt/openmpi/4.1/gnu/lib/pmix/mca_gds_ds12.so\n2aaabb7a5000-2aaabb7a6000 r--p 00003000 00:13 200752721                  /opt/openmpi/4.1/gnu/lib/pmix/mca_gds_ds12.so\n2aaabb7a6000-2aaabb7a7000 rw-p 00004000 00:13 200752721                  /opt/openmpi/4.1/gnu/lib/pmix/mca_gds_ds12.so\n2aaabb7a7000-2aaabb7b6000 r-xp 00000000 00:13 200280800                  /opt/openmpi/4.1/gnu/lib/libmca_common_dstore.so.1.0.2\n2aaabb7b6000-2aaabb9b6000 ---p 0000f000 00:13 200280800                  /opt/openmpi/4.1/gnu/lib/libmca_common_dstore.so.1.0.2\n2aaabb9b6000-2aaabb9b7000 r--p 0000f000 00:13 200280800                  /opt/openmpi/4.1/gnu/lib/libmca_common_dstore.so.1.0.2\n2aaabb9b7000-2aaabb9b8000 rw-p 00010000 00:13 200280800                  /opt/openmpi/4.1/gnu/lib/libmca_common_dstore.so.1.0.2\n2aaabb9b8000-2aaabb9cc000 r-xp 00000000 00:13 200752725                  /opt/openmpi/4.1/gnu/lib/pmix/mca_gds_hash.so\n2aaabb9cc000-2aaabbbcb000 ---p 00014000 00:13 200752725                  /opt/openmpi/4.1/gnu/lib/pmix/mca_gds_hash.so\n2aaabbbcb000-2aaabbbcc000 r--p 00013000 00:13 200752725                  /opt/openmpi/4.1/gnu/lib/pmix/mca_gds_hash.so\n2aaabbbcc000-2aaabbbcd000 rw-p 00014000 00:13 200752725                  /opt/openmpi/4.1/gnu/lib/pmix/mca_gds_hash.so\n2aaabbbcd000-2aaabbbd1000 r-xp 00000000 00:13 200752723                  /opt/openmpi/4.1/gnu/lib/pmix/mca_gds_ds21.so\n2aaabbbd1000-2aaabbdd0000 ---p 00004000 00:13 200752723                  /opt/openmpi/4.1/gnu/lib/pmix/mca_gds_ds21.so\n2aaabbdd0000-2aaabbdd1000 r--p 00003000 00:13 200752723                  /opt/openmpi/4.1/gnu/lib/pmix/mca_gds_ds21.so\n2aaabbdd1000-2aaabbdd2000 rw-p 00004000 00:13 200752723                  /opt/openmpi/4.1/gnu/lib/pmix/mca_gds_ds21.so\n2aaabbdd2000-2aaabbdd4000 r-xp 00000000 00:13 200752745                  /opt/openmpi/4.1/gnu/lib/pmix/mca_pshmem_mmap.so\n2aaabbdd4000-2aaabbfd3000 ---p 00002000 00:13 200752745                  /opt/openmpi/4.1/gnu/lib/pmix/mca_pshmem_mmap.so\n2aaabbfd3000-2aaabbfd4000 r--p 00001000 00:13 200752745                  /opt/openmpi/4.1/gnu/lib/pmix/mca_pshmem_mmap.so\n2aaabbfd4000-2aaabbfd5000 rw-p 00002000 00:13 200752745                  /opt/openmpi/4.1/gnu/lib/pmix/mca_pshmem_mmap.so\n2aaabbfd5000-2aaabc000000 rw-p 00000000 00:00 0 \n2aaabc000000-2aaabc021000 rw-p 00000000 00:00 0 \n2aaabc021000-2aaac0000000 ---p 00000000 00:00 0 \n2aaac0000000-2aaac0002000 r-xp 00000000 00:13 200752733                  /opt/openmpi/4.1/gnu/lib/pmix/mca_preg_compress.so\n2aaac0002000-2aaac0201000 ---p 00002000 00:13 200752733                  /opt/openmpi/4.1/gnu/lib/pmix/mca_preg_compress.so\n2aaac0201000-2aaac0202000 r--p 00001000 00:13 200752733                  /opt/openmpi/4.1/gnu/lib/pmix/mca_preg_compress.so\n2aaac0202000-2aaac0203000 rw-p 00002000 00:13 200752733                  /opt/openmpi/4.1/gnu/lib/pmix/mca_preg_compress.so\n2aaac0203000-2aaac0207000 r-xp 00000000 00:13 200752735                  /opt/openmpi/4.1/gnu/lib/pmix/mca_preg_native.so\n2aaac0207000-2aaac0406000 ---p 00004000 00:13 200752735                  /opt/openmpi/4.1/gnu/lib/pmix/mca_preg_native.so\n2aaac0406000-2aaac0407000 r--p 00003000 00:13 200752735                  /opt/openmpi/4.1/gnu/lib/pmix/mca_preg_native.so\n2aaac0407000-2aaac0408000 rw-p 00004000 00:13 200752735                  /opt/openmpi/4.1/gnu/lib/pmix/mca_preg_native.so\n2aaac0408000-2aaac040c000 r-xp 00000000 00:13 200752727                  /opt/openmpi/4.1/gnu/lib/pmix/mca_plog_default.so\n2aaac040c000-2aaac060b000 ---p 00004000 00:13 200752727                  /opt/openmpi/4.1/gnu/lib/pmix/mca_plog_default.so\n2aaac060b000-2aaac060c000 r--p 00003000 00:13 200752727                  /opt/openmpi/4.1/gnu/lib/pmix/mca_plog_default.so\n2aaac060c000-2aaac060d000 rw-p 00004000 00:13 200752727                  /opt/openmpi/4.1/gnu/lib/pmix/mca_plog_default.so\n2aaac060d000-2aaac060f000 r-xp 00000000 00:13 200752731                  /opt/openmpi/4.1/gnu/lib/pmix/mca_plog_syslog.so\n2aaac060f000-2aaac080e000 ---p 00002000 00:13 200752731                  /opt/openmpi/4.1/gnu/lib/pmix/mca_plog_syslog.so\n2aaac080e000-2aaac080f000 r--p 00001000 00:13 200752731                  /opt/openmpi/4.1/gnu/lib/pmix/mca_plog_syslog.so\n2aaac080f000-2aaac0810000 rw-p 00002000 00:13 200752731                  /opt/openmpi/4.1/gnu/lib/pmix/mca_plog_syslog.so\n2aaac0810000-2aaac0811000 r-xp 00000000 00:13 200752729                  /opt/openmpi/4.1/gnu/lib/pmix/mca_plog_stdfd.so\n2aaac0811000-2aaac0a11000 ---p 00001000 00:13 200752729                  /opt/openmpi/4.1/gnu/lib/pmix/mca_plog_stdfd.so\n2aaac0a11000-2aaac0a12000 r--p 00001000 00:13 200752729                  /opt/openmpi/4.1/gnu/lib/pmix/mca_plog_stdfd.so\n2aaac0a12000-2aaac0a13000 rw-p 00002000 00:13 200752729                  /opt/openmpi/4.1/gnu/lib/pmix/mca_plog_stdfd.so\n2aaac0a13000-2aaac0a14000 ---p 00000000 00:00 0 \n2aaac0a14000-2aaac0c14000 rw-p 00000000 00:00 0 \n2aaac0c14000-2aaac1014000 r--s 00000000 00:27 6575130                    /ram/tmp/ompi.solo289.137033/pid.218400/pmix_dstor_ds21_218400/smseg-14221313-0\n2aaac1014000-2aaac1414000 r--s 00000000 00:27 6575131                    /ram/tmp/ompi.solo289.137033/pid.218400/pmix_dstor_ds21_218400/smdataseg-14221313-0\n2aaac1414000-2aaac1430000 r-xp 00000000 00:13 200350675                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_op_avx.so\n2aaac1430000-2aaac162f000 ---p 0001c000 00:13 200350675                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_op_avx.so\n2aaac162f000-2aaac1630000 r--p 0001b000 00:13 200350675                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_op_avx.so\n2aaac1630000-2aaac1635000 rw-p 0001c000 00:13 200350675                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_op_avx.so\n2aaac1635000-2aaac1736000 rw-p 00000000 00:00 0 \n2aaac1736000-2aaac1776000 r--s dabbad0004230000 00:05 45595              /dev/hfi1_0\n2aaac1776000-2aaac1819000 rw-p 00000000 00:00 0 \n2aaac181d000-2aaac181f000 r-xp 00000000 00:13 200350773                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_state_app.so\n2aaac181f000-2aaac1a1e000 ---p 00002000 00:13 200350773                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_state_app.so\n2aaac1a1e000-2aaac1a1f000 r--p 00001000 00:13 200350773                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_state_app.so\n2aaac1a1f000-2aaac1a20000 rw-p 00002000 00:13 200350773                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_state_app.so\n2aaac1a20000-2aaac1a22000 r-xp 00000000 00:13 200350569                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_allocator_bucket.so\n2aaac1a22000-2aaac1c21000 ---p 00002000 00:13 200350569                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_allocator_bucket.so\n2aaac1c21000-2aaac1c22000 r--p 00001000 00:13 200350569                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_allocator_bucket.so\n2aaac1c22000-2aaac1c23000 rw-p 00002000 00:13 200350569                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_allocator_bucket.so\n2aaac1c25000-2aaac1c27000 r-xp 00000000 00:13 200350613                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_errmgr_default_app.so\n2aaac1c27000-2aaac1e27000 ---p 00002000 00:13 200350613                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_errmgr_default_app.so\n2aaac1e27000-2aaac1e28000 r--p 00002000 00:13 200350613                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_errmgr_default_app.so\n2aaac1e28000-2aaac1e29000 rw-p 00003000 00:13 200350613                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_errmgr_default_app.so\n2aaac1e29000-2aaac1e2b000 r-xp 00000000 00:13 200350567                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_allocator_basic.so\n2aaac1e2b000-2aaac202b000 ---p 00002000 00:13 200350567                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_allocator_basic.so\n2aaac202b000-2aaac202c000 r--p 00002000 00:13 200350567                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_allocator_basic.so\n2aaac202c000-2aaac202d000 rw-p 00003000 00:13 200350567                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_allocator_basic.so\n2aaac202d000-2aaac2031000 r-xp 00000000 00:13 200350719                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_rcache_rgpusm.so\n2aaac2031000-2aaac2230000 ---p 00004000 00:13 200350719                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_rcache_rgpusm.so\n2aaac2230000-2aaac2231000 r--p 00003000 00:13 200350719                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_rcache_rgpusm.so\n2aaac2231000-2aaac2232000 rw-p 00004000 00:13 200350719                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_rcache_rgpusm.so\n2aaac2232000-2aaac223a000 r-xp 00000000 00:13 200280796                  /opt/openmpi/4.1/gnu/lib/libmca_common_cuda.so.40.30.0\n2aaac223a000-2aaac2439000 ---p 00008000 00:13 200280796                  /opt/openmpi/4.1/gnu/lib/libmca_common_cuda.so.40.30.0\n2aaac2439000-2aaac243a000 r--p 00007000 00:13 200280796                  /opt/openmpi/4.1/gnu/lib/libmca_common_cuda.so.40.30.0\n2aaac243a000-2aaac243b000 rw-p 00008000 00:13 200280796                  /opt/openmpi/4.1/gnu/lib/libmca_common_cuda.so.40.30.0\n2aaac243b000-2aaac243f000 r-xp 00000000 00:13 200350717                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_rcache_grdma.so\n2aaac243f000-2aaac263e000 ---p 00004000 00:13 200350717                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_rcache_grdma.so\n2aaac263e000-2aaac263f000 r--p 00003000 00:13 200350717                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_rcache_grdma.so\n2aaac263f000-2aaac2640000 rw-p 00004000 00:13 200350717                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_rcache_grdma.so\n2aaac2640000-2aaac2642000 r-xp 00000000 00:13 200350715                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_rcache_gpusm.so\n2aaac2642000-2aaac2841000 ---p 00002000 00:13 200350715                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_rcache_gpusm.so\n2aaac2841000-2aaac2842000 r--p 00001000 00:13 200350715                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_rcache_gpusm.so\n2aaac2842000-2aaac2843000 rw-p 00002000 00:13 200350715                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_rcache_gpusm.so\n2aaac2843000-2aaac2846000 r-xp 00000000 00:13 200350663                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_mpool_hugepage.so\n2aaac2846000-2aaac2a46000 ---p 00003000 00:13 200350663                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_mpool_hugepage.so\n2aaac2a46000-2aaac2a47000 r--p 00003000 00:13 200350663                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_mpool_hugepage.so\n2aaac2a47000-2aaac2a48000 rw-p 00004000 00:13 200350663                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_mpool_hugepage.so\n2aaac2a48000-2aaac2a4c000 r-xp 00000000 00:13 200350571                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_bml_r2.so\n2aaac2a4c000-2aaac2c4b000 ---p 00004000 00:13 200350571                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_bml_r2.so\n2aaac2c4b000-2aaac2c4c000 r--p 00003000 00:13 200350571                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_bml_r2.so\n2aaac2c4c000-2aaac2c4d000 rw-p 00004000 00:13 200350571                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_bml_r2.so\n2aaac2c4d000-2aaac2c56000 r-xp 00000000 00:13 200350579                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_btl_smcuda.so\n2aaac2c56000-2aaac2e56000 ---p 00009000 00:13 200350579                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_btl_smcuda.so\n2aaac2e56000-2aaac2e57000 r--p 00009000 00:13 200350579                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_btl_smcuda.so\n2aaac2e57000-2aaac2e58000 rw-p 0000a000 00:13 200350579                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_btl_smcuda.so\n2aaac2e58000-2aaac2e5a000 r-xp 00000000 00:13 200280816                  /opt/openmpi/4.1/gnu/lib/libmca_common_sm.so.40.30.0\n2aaac2e5a000-2aaac3059000 ---p 00002000 00:13 200280816                  /opt/openmpi/4.1/gnu/lib/libmca_common_sm.so.40.30.0\n2aaac3059000-2aaac305a000 r--p 00001000 00:13 200280816                  /opt/openmpi/4.1/gnu/lib/libmca_common_sm.so.40.30.0\n2aaac305a000-2aaac305b000 rw-p 00002000 00:13 200280816                  /opt/openmpi/4.1/gnu/lib/libmca_common_sm.so.40.30.0\n2aaac305b000-2aaac306b000 r-xp 00000000 00:13 200350581                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_btl_tcp.so\n2aaac306b000-2aaac326a000 ---p 00010000 00:13 200350581                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_btl_tcp.so\n2aaac326a000-2aaac326b000 r--p 0000f000 00:13 200350581                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_btl_tcp.so\n2aaac326b000-2aaac326d000 rw-p 00010000 00:13 200350581                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_btl_tcp.so\n2aaac326d000-2aaac326e000 r-xp 00000000 00:13 200350577                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_btl_sm.so\n2aaac326e000-2aaac346d000 ---p 00001000 00:13 200350577                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_btl_sm.so\n2aaac346d000-2aaac346e000 r--p 00000000 00:13 200350577                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_btl_sm.so\n2aaac346e000-2aaac346f000 rw-p 00001000 00:13 200350577                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_btl_sm.so\n2aaac346f000-2aaac3472000 r-xp 00000000 00:13 200350575                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_btl_self.so\n2aaac3472000-2aaac3671000 ---p 00003000 00:13 200350575                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_btl_self.so\n2aaac3671000-2aaac3672000 r--p 00002000 00:13 200350575                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_btl_self.so\n2aaac3672000-2aaac3673000 rw-p 00003000 00:13 200350575                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_btl_self.so\n2aaac3673000-2aaac367d000 r-xp 00000000 00:13 200350583                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_btl_vader.so\n2aaac367d000-2aaac387d000 ---p 0000a000 00:13 200350583                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_btl_vader.so\n2aaac387d000-2aaac387e000 r--p 0000a000 00:13 200350583                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_btl_vader.so\n2aaac387e000-2aaac3880000 rw-p 0000b000 00:13 200350583                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_btl_vader.so\n2aaac3880000-2aaac3c81000 rw-s 00000000 00:12 6416616                    /dev/shm/vader_segment.solo289.137033.d90001.6\n2aaac3c81000-2aaac3c8a000 r-xp 00000000 00:13 200350703                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_pml_cm.so\n2aaac3c8a000-2aaac3e89000 ---p 00009000 00:13 200350703                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_pml_cm.so\n2aaac3e89000-2aaac3e8a000 r--p 00008000 00:13 200350703                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_pml_cm.so\n2aaac3e8a000-2aaac3e8b000 rw-p 00009000 00:13 200350703                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_pml_cm.so\n2aaac3e8b000-2aaac3fed000 rw-p 00000000 00:00 0 \n2aaac4000000-2aaac4021000 rw-p 00000000 00:00 0 \n2aaac4021000-2aaac8000000 ---p 00000000 00:00 0 \n2aaac8000000-2aaac80d3000 r--p 00000000 00:13 198055280                  /usr/lib64/libcuda.so.515.48.07\n2aaac80d3000-2aaac8537000 r-xp 000d3000 00:13 198055280                  /usr/lib64/libcuda.so.515.48.07\n2aaac8537000-2aaac92e1000 r--p 00537000 00:13 198055280                  /usr/lib64/libcuda.so.515.48.07\n2aaac92e1000-2aaac92f6000 r--p 012e0000 00:13 198055280                  /usr/lib64/libcuda.so.515.48.07\n2aaac92f6000-2aaac93fc000 rw-p 012f5000 00:13 198055280                  /usr/lib64/libcuda.so.515.48.07\n2aaac93fc000-2aaac945b000 rw-p 00000000 00:00 0 \n2aaac945b000-2aaac9461000 r-xp 00000000 00:13 200350667                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_mtl_psm2.so\n2aaac9461000-2aaac9660000 ---p 00006000 00:13 200350667                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_mtl_psm2.so\n2aaac9660000-2aaac9661000 r--p 00005000 00:13 200350667                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_mtl_psm2.so\n2aaac9661000-2aaac9662000 rw-p 00006000 00:13 200350667                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_mtl_psm2.so\n2aaac9662000-2aaac96c7000 r-xp 00000000 00:13 198057841                  /usr/lib64/libpsm2.so.2.2\n2aaac96c7000-2aaac98c6000 ---p 00065000 00:13 198057841                  /usr/lib64/libpsm2.so.2.2\n2aaac98c6000-2aaac98c7000 r--p 00064000 00:13 198057841                  /usr/lib64/libpsm2.so.2.2\n2aaac98c7000-2aaac98c8000 rw-p 00065000 00:13 198057841                  /usr/lib64/libpsm2.so.2.2\n2aaac98c8000-2aaac98ca000 rw-p 00000000 00:00 0 \n2aaac98ca000-2aaac98d4000 r-xp 00000000 00:13 198053857                  /usr/lib64/libnuma.so.1.0.0\n2aaac98d4000-2aaac9ad4000 ---p 0000a000 00:13 198053857                  /usr/lib64/libnuma.so.1.0.0\n2aaac9ad4000-2aaac9ad5000 r--p 0000a000 00:13 198053857                  /usr/lib64/libnuma.so.1.0.0\n2aaac9ad5000-2aaac9ad6000 rw-p 0000b000 00:13 198053857                  /usr/lib64/libnuma.so.1.0.0\n2aaac9ad6000-2aaac9ad8000 r-xp 00000000 00:13 200350599                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_coll_self.so\n2aaac9ad8000-2aaac9cd8000 ---p 00002000 00:13 200350599                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_coll_self.so\n2aaac9cd8000-2aaac9cd9000 r--p 00002000 00:13 200350599                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_coll_self.so\n2aaac9cd9000-2aaac9cda000 rw-p 00003000 00:13 200350599                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_coll_self.so\n2aaac9cda000-2aaac9cde000 r-xp 00000000 00:13 200350593                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_coll_inter.so\n2aaac9cde000-2aaac9edd000 ---p 00004000 00:13 200350593                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_coll_inter.so\n2aaac9edd000-2aaac9ede000 r--p 00003000 00:13 200350593                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_coll_inter.so\n2aaac9ede000-2aaac9edf000 rw-p 00004000 00:13 200350593                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_coll_inter.so\n2aaac9f41000-2aaac9fad000 rw-p 00000000 00:00 0 \n2aaaca02c000-2aaaca034000 r-xp 00000000 552:aa07e 180144594611103750     /qscratch/bzeng/projects/mortar/.jitcache/ca4ea86d12991e15.so\n2aaaca034000-2aaaca234000 ---p 00008000 552:aa07e 180144594611103750     /qscratch/bzeng/projects/mortar/.jitcache/ca4ea86d12991e15.so\n2aaaca234000-2aaaca235000 r--p 00008000 552:aa07e 180144594611103750     /qscratch/bzeng/projects/mortar/.jitcache/ca4ea86d12991e15.so\n2aaaca235000-2aaaca236000 rw-p 00009000 552:aa07e 180144594611103750     /qscratch/bzeng/projects/mortar/.jitcache/ca4ea86d12991e15.so\n2aaaca2f6000-2aaaca2f9000 r-xp 00000000 00:13 200350603                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_coll_sync.so\n2aaaca2f9000-2aaaca4f9000 ---p 00003000 00:13 200350603                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_coll_sync.so\n2aaaca4f9000-2aaaca4fa000 r--p 00003000 00:13 200350603                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_coll_sync.so\n2aaaca4fa000-2aaaca4fb000 rw-p 00004000 00:13 200350603                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_coll_sync.so\n2aaaca4fb000-2aaaca507000 r-xp 00000000 00:13 200350585                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_coll_adapt.so\n2aaaca507000-2aaaca706000 ---p 0000c000 00:13 200350585                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_coll_adapt.so\n2aaaca706000-2aaaca707000 r--p 0000b000 00:13 200350585                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_coll_adapt.so\n2aaaca707000-2aaaca708000 rw-p 0000c000 00:13 200350585                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_coll_adapt.so\n2aaaca708000-2aaaca714000 r-xp 00000000 00:13 200350587                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_coll_basic.so\n2aaaca714000-2aaaca913000 ---p 0000c000 00:13 200350587                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_coll_basic.so\n2aaaca913000-2aaaca914000 r--p 0000b000 00:13 200350587                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_coll_basic.so\n2aaaca914000-2aaaca915000 rw-p 0000c000 00:13 200350587                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_coll_basic.so\n2aaaca915000-2aaaca934000 r-xp 00000000 00:13 200350595                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_coll_libnbc.so\n2aaaca934000-2aaacab33000 ---p 0001f000 00:13 200350595                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_coll_libnbc.so\n2aaacab33000-2aaacab34000 r--p 0001e000 00:13 200350595                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_coll_libnbc.so\n2aaacab34000-2aaacab35000 rw-p 0001f000 00:13 200350595                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_coll_libnbc.so\n2aaacab35000-2aaacab4e000 r-xp 00000000 00:13 200350591                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_coll_han.so\n2aaacab4e000-2aaacad4e000 ---p 00019000 00:13 200350591                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_coll_han.so\n2aaacad4e000-2aaacad4f000 r--p 00019000 00:13 200350591                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_coll_han.so\n2aaacad4f000-2aaacad50000 rw-p 0001a000 00:13 200350591                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_coll_han.so\n2aaacad50000-2aaacad61000 r-xp 00000000 00:13 200350605                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_coll_tuned.so\n2aaacad61000-2aaacaf61000 ---p 00011000 00:13 200350605                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_coll_tuned.so\n2aaacaf61000-2aaacaf62000 r--p 00011000 00:13 200350605                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_coll_tuned.so\n2aaacaf62000-2aaacaf63000 rw-p 00012000 00:13 200350605                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_coll_tuned.so\n2aaacaf63000-2aaacaf66000 r-xp 00000000 00:13 200350589                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_coll_cuda.so\n2aaacaf66000-2aaacb165000 ---p 00003000 00:13 200350589                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_coll_cuda.so\n2aaacb165000-2aaacb166000 r--p 00002000 00:13 200350589                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_coll_cuda.so\n2aaacb166000-2aaacb167000 rw-p 00003000 00:13 200350589                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_coll_cuda.so\n2aaacb167000-2aaacb16d000 r-xp 00000000 00:13 200350601                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_coll_sm.so\n2aaacb16d000-2aaacb36c000 ---p 00006000 00:13 200350601                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_coll_sm.so\n2aaacb36c000-2aaacb36d000 r--p 00005000 00:13 200350601                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_coll_sm.so\n2aaacb36d000-2aaacb36e000 rw-p 00006000 00:13 200350601                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_coll_sm.so\n2aaacb36e000-2aaacb3a1000 r-xp 00000000 00:13 200350681                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_osc_rdma.so\n2aaacb3a1000-2aaacb5a1000 ---p 00033000 00:13 200350681                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_osc_rdma.so\n2aaacb5a1000-2aaacb5a2000 r--p 00033000 00:13 200350681                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_osc_rdma.so\n2aaacb5a2000-2aaacb5a3000 rw-p 00034000 00:13 200350681                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_osc_rdma.so\n2aaacb5a3000-2aaacb5c1000 r-xp 00000000 00:13 200350679                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_osc_pt2pt.so\n2aaacb5c1000-2aaacb7c1000 ---p 0001e000 00:13 200350679                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_osc_pt2pt.so\n2aaacb7c1000-2aaacb7c2000 r--p 0001e000 00:13 200350679                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_osc_pt2pt.so\n2aaacb7c2000-2aaacb7c3000 rw-p 0001f000 00:13 200350679                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_osc_pt2pt.so\n2aaacb7c3000-2aaacb7c8000 r-xp 00000000 552:aa07e 180144594325879671     /qscratch/bzeng/projects/mortar/.jitcache/3e56f11d1d848516.so\n2aaacb7c8000-2aaacb9c7000 ---p 00005000 552:aa07e 180144594325879671     /qscratch/bzeng/projects/mortar/.jitcache/3e56f11d1d848516.so\n2aaacb9c7000-2aaacb9c8000 r--p 00004000 552:aa07e 180144594325879671     /qscratch/bzeng/projects/mortar/.jitcache/3e56f11d1d848516.so\n2aaacb9c8000-2aaacb9c9000 rw-p 00005000 552:aa07e 180144594325879671     /qscratch/bzeng/projects/mortar/.jitcache/3e56f11d1d848516.so\n2aaacb9cf000-2aaacb9d5000 r-xp 00000000 00:13 200350683                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_osc_sm.so\n2aaacb9d5000-2aaacbbd4000 ---p 00006000 00:13 200350683                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_osc_sm.so\n2aaacbbd4000-2aaacbbd5000 r--p 00005000 00:13 200350683                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_osc_sm.so\n2aaacbbd5000-2aaacbbd7000 rw-p 00006000 00:13 200350683                  /opt/openmpi/4.1/gnu/lib/openmpi/mca_osc_sm.so\n2aaacbbd7000-2aaacc3d7000 r--s dabbad0005230000 00:05 45595              /dev/hfi1_0\n2aaacc3d7000-2aaacd97d000 rw-p 00000000 00:00 0 \n2aaacd97d000-2aaacd97e000 ---p 00000000 00:00 0 \n2aaacd97e000-2aaacdb7e000 rw-p 00000000 00:00 0 \n2aaacdb7e000-2aaacdfa1000 rw-s 00000000 00:12 6506212                    /dev/shm/psm2_shm.1370330000000000a223020\n2aaacdfa1000-2aaace3c4000 rw-s 00000000 00:12 6568081                    /dev/shm/psm2_shm.1370330000000000a21f020\n2aaace3c4000-2aaace7e7000 rw-s 00000000 00:12 6440895                    /dev/shm/psm2_shm.1370330000000000a20a020\n2aaace7e7000-2aaacec0a000 rw-s 00000000 00:12 6575142                    /dev/shm/psm2_shm.1370330000000000a20b020\n2aaacec0a000-2aaacf02d000 rw-s 00000000 00:12 6537876                    /dev/shm/psm2_shm.1370330000000000a208020\n2aaacf02d000-2aaacf450000 rw-s 00000000 00:12 6573757                    /dev/shm/psm2_shm.1370330000000000a218020\n2aaacf450000-2aaacf873000 rw-s 00000000 00:12 6559287                    /dev/shm/psm2_shm.1370330000000000a206020\n2aaacf873000-2aaacfc96000 rw-s 00000000 00:12 6445864                    /dev/shm/psm2_shm.1370330000000000a204020\n2aaacfc96000-2aaad00b9000 rw-s 00000000 00:12 6576240                    /dev/shm/psm2_shm.1370330000000000a205020\n2aaad00b9000-2aaad04dc000 rw-s 00000000 00:12 6444938                    /dev/shm/psm2_shm.1370330000000000a207020\n2aaad04dc000-2aaad08ff000 rw-s 00000000 00:12 6427583                    /dev/shm/psm2_shm.1370330000000000a209020\n2aaad08ff000-2aaad0d22000 rw-s 00000000 00:12 5733880                    /dev/shm/psm2_shm.1370330000000000a203020\n2aaad0d22000-2aaad1145000 rw-s 00000000 00:12 6137672                    /dev/shm/psm2_shm.1370330000000000a21e020\n2aaad1145000-2aaad1568000 rw-s 00000000 00:12 6441814                    /dev/shm/psm2_shm.1370330000000000a214020\n2aaad1568000-2aaad198b000 rw-s 00000000 00:12 6560087                    /dev/shm/psm2_shm.1370330000000000a210020\n2aaad198b000-2aaad1dae000 rw-s 00000000 00:12 6493744                    /dev/shm/psm2_shm.1370330000000000a217020\n2aaad1dae000-2aaad21d1000 rw-s 00000000 00:12 6531603                    /dev/shm/psm2_shm.1370330000000000a216020\n2aaad21d1000-2aaad25f4000 rw-s 00000000 00:12 6525380                    /dev/shm/psm2_shm.1370330000000000a226020\n2aaad25f4000-2aaad2a17000 rw-s 00000000 00:12 6552273                    /dev/shm/psm2_shm.1370330000000000a21c020\n2aaad2a17000-2aaad2e3a000 rw-s 00000000 00:12 6577249                    /dev/shm/psm2_shm.1370330000000000a20d020\n2aaad2e3a000-2aaad325d000 rw-s 00000000 00:12 6571056                    /dev/shm/psm2_shm.1370330000000000a212020\n2aaad325d000-2aaad3680000 rw-s 00000000 00:12 6557284                    /dev/shm/psm2_shm.1370330000000000a215020\n2aaad3680000-2aaad3aa3000 rw-s 00000000 00:12 6513580                    /dev/shm/psm2_shm.1370330000000000a225020\n2aaad3aa3000-2aaad3ec6000 rw-s 00000000 00:12 6561049                    /dev/shm/psm2_shm.1370330000000000a220020\n2aaad3ec6000-2aaad42e9000 rw-s 00000000 00:12 6437712                    /dev/shm/psm2_shm.1370330000000000a224020\n2aaad42e9000-2aaad470c000 rw-s 00000000 00:12 6578189                    /dev/shm/psm2_shm.1370330000000000a222020\n2aaad470c000-2aaad4b2f000 rw-s 00000000 00:12 6431664                    /dev/shm/psm2_shm.1370330000000000a20e020\n2aaad4b2f000-2aaad4f52000 rw-s 00000000 00:12 6561940                    /dev/shm/psm2_shm.1370330000000000a20c020\n2aaad4f52000-2aaad5375000 rw-s 00000000 00:12 6552869                    /dev/shm/psm2_shm.1370330000000000a21b020\n2aaad5375000-2aaad5798000 rw-s 00000000 00:12 6435742                    /dev/shm/psm2_shm.1370330000000000a21a020\n2aaad5798000-2aaad5bbb000 rw-s 00000000 00:12 6430606                    /dev/shm/psm2_shm.1370330000000000a221020\n2aaad5bbb000-2aaad5fde000 rw-s 00000000 00:12 6549823                    /dev/shm/psm2_shm.1370330000000000a219020\n2aaad5fde000-2aaad6401000 rw-s 00000000 00:12 6543668                    /dev/shm/psm2_shm.1370330000000000a20f020\n2aaad6401000-2aaad6824000 rw-s 00000000 00:12 6476377                    /dev/shm/psm2_shm.1370330000000000a21d020\n2aaad6824000-2aaad6c47000 rw-s 00000000 00:12 6579226                    /dev/shm/psm2_shm.1370330000000000a211020\n2aaad6c47000-2aaad706a000 rw-s 00000000 00:12 6480361                    /dev/shm/psm2_shm.1370330000000000a213020\n2aaad706a000-2aaad7070000 r-xp 00000000 552:aa07e 180144594325879677     /qscratch/bzeng/projects/mortar/.jitcache/ff285111b5aa8455.so\n2aaad7070000-2aaad726f000 ---p 00006000 552:aa07e 180144594325879677     /qscratch/bzeng/projects/mortar/.jitcache/ff285111b5aa8455.so\n2aaad726f000-2aaad7270000 r--p 00005000 552:aa07e 180144594325879677     /qscratch/bzeng/projects/mortar/.jitcache/ff285111b5aa8455.so\n2aaad7270000-2aaad7271000 rw-p 00006000 552:aa07e 180144594325879677     /qscratch/bzeng/projects/mortar/.jitcache/ff285111b5aa8455.so\n2aaad7271000-2aaad7277000 r-xp 00000000 552:aa07e 180144594325879689     /qscratch/bzeng/projects/mortar/.jitcache/33f37eeebb55be13.so\n2aaad7277000-2aaad7476000 ---p 00006000 552:aa07e 180144594325879689     /qscratch/bzeng/projects/mortar/.jitcache/33f37eeebb55be13.so\n2aaad7476000-2aaad7477000 r--p 00005000 552:aa07e 180144594325879689     /qscratch/bzeng/projects/mortar/.jitcache/33f37eeebb55be13.so\n2aaad7477000-2aaad7478000 rw-p 00006000 552:aa07e 180144594325879689     /qscratch/bzeng/projects/mortar/.jitcache/33f37eeebb55be13.so\n2aaad7478000-2aaad747e000 r-xp 00000000 552:aa07e 180144594325879701     /qscratch/bzeng/projects/mortar/.jitcache/5444f7feb254efd1.so\n2aaad747e000-2aaad767d000 ---p 00006000 552:aa07e 180144594325879701     /qscratch/bzeng/projects/mortar/.jitcache/5444f7feb254efd1.so\n2aaad767d000-2aaad767e000 r--p 00005000 552:aa07e 180144594325879701     /qscratch/bzeng/projects/mortar/.jitcache/5444f7feb254efd1.so\n2aaad767e000-2aaad767f000 rw-p 00006000 552:aa07e 180144594325879701     /qscratch/bzeng/projects/mortar/.jitcache/5444f7feb254efd1.so\n2aaad767f000-2aaad7681000 r-xp 00000000 552:aa07e 180144594325879707     /qscratch/bzeng/projects/mortar/.jitcache/82c4a0dc15f809f1.so\n2aaad7681000-2aaad7880000 ---p 00002000 552:aa07e 180144594325879707     /qscratch/bzeng/projects/mortar/.jitcache/82c4a0dc15f809f1.so\n2aaad7880000-2aaad7881000 r--p 00001000 552:aa07e 180144594325879707     /qscratch/bzeng/projects/mortar/.jitcache/82c4a0dc15f809f1.so\n2aaad7881000-2aaad7882000 rw-p 00002000 552:aa07e 180144594325879707     /qscratch/bzeng/projects/mortar/.jitcache/82c4a0dc15f809f1.so\n2aaad7882000-2aaad7888000 r-xp 00000000 552:aa07e 180144594611103799     /qscratch/bzeng/projects/mortar/.jitcache/2543f07740746ce9.so\n2aaad7888000-2aaad7a87000 ---p 00006000 552:aa07e 180144594611103799     /qscratch/bzeng/projects/mortar/.jitcache/2543f07740746ce9.so\n2aaad7a87000-2aaad7a88000 r--p 00005000 552:aa07e 180144594611103799     /qscratch/bzeng/projects/mortar/.jitcache/2543f07740746ce9.so\n2aaad7a88000-2aaad7a89000 rw-p 00006000 552:aa07e 180144594611103799     /qscratch/bzeng/projects/mortar/.jitcache/2543f07740746ce9.so\n2aaad7a89000-2aaad7a90000 r-xp 00000000 552:aa07e 180144594325879725     /qscratch/bzeng/projects/mortar/.jitcache/f1ea8842e501fe2d.so\n2aaad7a90000-2aaad7c8f000 ---p 00007000 552:aa07e 180144594325879725     /qscratch/bzeng/projects/mortar/.jitcache/f1ea8842e501fe2d.so\n2aaad7c8f000-2aaad7c90000 r--p 00006000 552:aa07e 180144594325879725     /qscratch/bzeng/projects/mortar/.jitcache/f1ea8842e501fe2d.so\n2aaad7c90000-2aaad7c91000 rw-p 00007000 552:aa07e 180144594325879725     /qscratch/bzeng/projects/mortar/.jitcache/f1ea8842e501fe2d.so\n2aaad7c91000-2aaad7c98000 r-xp 00000000 552:aa07e 180144594325879731     /qscratch/bzeng/projects/mortar/.jitcache/ca37a5764475c54b.so\n2aaad7c98000-2aaad7e97000 ---p 00007000 552:aa07e 180144594325879731     /qscratch/bzeng/projects/mortar/.jitcache/ca37a5764475c54b.so\n2aaad7e97000-2aaad7e98000 r--p 00006000 552:aa07e 180144594325879731     /qscratch/bzeng/projects/mortar/.jitcache/ca37a5764475c54b.so\n2aaad7e98000-2aaad7e99000 rw-p 00007000 552:aa07e 180144594325879731     /qscratch/bzeng/projects/mortar/.jitcache/ca37a5764475c54b.so\n2aaad7e99000-2aaad7ea0000 r-xp 00000000 552:aa07e 180144594611103823     /qscratch/bzeng/projects/mortar/.jitcache/64ad98e829af9524.so\n2aaad7ea0000-2aaad809f000 ---p 00007000 552:aa07e 180144594611103823     /qscratch/bzeng/projects/mortar/.jitcache/64ad98e829af9524.so\n2aaad809f000-2aaad80a0000 r--p 00006000 552:aa07e 180144594611103823     /qscratch/bzeng/projects/mortar/.jitcache/64ad98e829af9524.so\n2aaad80a0000-2aaad80a1000 rw-p 00007000 552:aa07e 180144594611103823     /qscratch/bzeng/projects/mortar/.jitcache/64ad98e829af9524.so\n2aaad80a1000-2aaad80a2000 r-xp 00000000 552:aa07e 180144594325879745     /qscratch/bzeng/projects/mortar/.jitcache/047ba5733bb68500.so\n2aaad80a2000-2aaad82a1000 ---p 00001000 552:aa07e 180144594325879745     /qscratch/bzeng/projects/mortar/.jitcache/047ba5733bb68500.so\n2aaad82a1000-2aaad82a2000 r--p 00000000 552:aa07e 180144594325879745     /qscratch/bzeng/projects/mortar/.jitcache/047ba5733bb68500.so\n2aaad82a2000-2aaad82a3000 rw-p 00001000 552:aa07e 180144594325879745     /qscratch/bzeng/projects/mortar/.jitcache/047ba5733bb68500.so\n2aaadc000000-2aaadc021000 rw-p 00000000 00:00 0 \n2aaadc021000-2aaae0000000 ---p 00000000 00:00 0 \n2aaae0000000-2aaae0021000 rw-p 00000000 00:00 0 \n2aaae0021000-2aaae4000000 ---p 00000000 00:00 0 \n7ffffff60000-7ffffffff000 rw-p 00000000 00:00 0                          [stack]\nffffffffff600000-ffffffffff601000 r-xp 00000000 00:00 0                  [vsyscall]\n[solo289:218419] *** Process received signal ***\n[solo289:218419] Signal: Aborted (6)\n[solo289:218419] Signal code: User function (kill, sigsend, abort, etc.) (0)\n[solo289:218419] [ 0] /lib64/libc.so.6(+0x36400)[0x2aaab80c7400]\n[solo289:218419] [ 1] /lib64/libc.so.6(gsignal+0x37)[0x2aaab80c7387]\n[solo289:218419] [ 2] /lib64/libc.so.6(abort+0x148)[0x2aaab80c8a78]\n[solo289:218419] [ 3] /lib64/libc.so.6(+0x78f67)[0x2aaab8109f67]\n[solo289:218419] [ 4] /lib64/libc.so.6(+0x80a4f)[0x2aaab8111a4f]\n[solo289:218419] [ 5] /lib64/libc.so.6(+0x8120e)[0x2aaab811220e]\n[solo289:218419] [ 6] /qscratch/bzeng/moose-compilers/petsc-3.16.5/lib/libpetsc.so.3.16(PetscFreeAlign+0xe)[0x2aaab2510269]\n[solo289:218419] [ 7] /qscratch/bzeng/moose-compilers/petsc-3.16.5/lib/libpetsc.so.3.16(PetscEventRegLogDestroy+0xdb)[0x2aaab258d7d6]\n[solo289:218419] [ 8] /qscratch/bzeng/moose-compilers/petsc-3.16.5/lib/libpetsc.so.3.16(PetscStageLogDestroy+0x31)[0x2aaab258c339]\n[solo289:218419] [ 9] /qscratch/bzeng/moose-compilers/petsc-3.16.5/lib/libpetsc.so.3.16(+0x18c33e)[0x2aaab257433e]\n[solo289:218419] [10] /qscratch/bzeng/moose-compilers/petsc-3.16.5/lib/libpetsc.so.3.16(PetscFinalize+0xd13)[0x2aaab24f5eac]\n[solo289:218419] [11] /qscratch/bzeng/moose-compilers/petsc-3.16.5/lib/libslepc.so.3.16(SlepcFinalize+0xc8)[0x2aaab1e5f672]\n[solo289:218419] [12] /qscratch/bzeng/projects/raccoon/moose/scripts/../libmesh/installed/lib/libmesh_opt.so.0(_ZN7libMesh11LibMeshInitD1Ev+0x477)[0x2aaab032a5b7]\n[solo289:218419] [13] /qscratch/bzeng/projects/raccoon/raccoon-opt(main+0x9c)[0x4025dc]\n[solo289:218419] [14] /lib64/libc.so.6(__libc_start_main+0xf5)[0x2aaab80b3555]\n[solo289:218419] [15] /qscratch/bzeng/projects/raccoon/raccoon-opt[0x402813]\n[solo289:218419] *** End of error message ***\n--------------------------------------------------------------------------\nPrimary job  terminated normally, but 1 process returned\na non-zero exit code. Per user-direction, the job has been aborted.\n--------------------------------------------------------------------------\n--------------------------------------------------------------------------\nmpiexec noticed that process rank 6 with PID 0 on node solo289 exited on signal 6 (Aborted).\n--------------------------------------------------------------------------\nEnd: Wed Mar  8 16:54:51 MST 2023",
          "url": "https://github.com/idaholab/moose/discussions/23722",
          "updatedAt": "2023-04-29T03:09:36Z",
          "publishedAt": "2023-03-14T19:00:36Z",
          "category": {
            "name": "Q&A General"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "GiudGiud"
                  },
                  "bodyText": "Hello\nThis seems like using valgrind on your code would help find the memory error\nYou can use it manually\nor can try using it on the whole app test suite, see below\nhttps://mooseframework.inl.gov/python/TestHarness.html\nGuillaume",
                  "url": "https://github.com/idaholab/moose/discussions/23722#discussioncomment-5313686",
                  "updatedAt": "2023-03-14T19:09:32Z",
                  "publishedAt": "2023-03-14T19:09:31Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "BoZeng1997"
                          },
                          "bodyText": "Before I can use valgrind, I think there is a setting I need to change at configure for moose or a package to update to solve this issue. I could not find where did we set DWARF5 in the configuration, or how I can have DWARF5 supported on the hpc.\n--83014-- WARNING: Serious error when reading debug info\n--83014-- When reading debug info from /projects/netpub/gnu/11.3.0-toss3/lib64/libgcc_s.so.1:\n--83014-- parse_CU_Header: is neither DWARF2 nor DWARF3 nor DWARF4\n==83020== Warning: invalid file descriptor 65524 in syscall close()\n==83020== Warning: invalid file descriptor 65525 in syscall close()\n==83020== Warning: invalid file descriptor 65526 in syscall close()\n==83020== Warning: invalid file descriptor 65527 in syscall close()\n==83020==    Use --log-fd=<number> to select an alternative log fd.\n==83020== Warning: invalid file descriptor 65528 in syscall close()\n==83020== Warning: invalid file descriptor 65529 in syscall close()\n==83021== Warning: invalid file descriptor 65524 in syscall close()\n==83021== Warning: invalid file descriptor 65525 in syscall close()\n==83021== Warning: invalid file descriptor 65526 in syscall close()\n==83021== Warning: invalid file descriptor 65527 in syscall close()\n==83021==    Use --log-fd=<number> to select an alternative log fd.\n==83021== Warning: invalid file descriptor 65528 in syscall close()\n==83021== Warning: invalid file descriptor 65529 in syscall close()\n\nI also have the DWARF version issue on local ubuntu machine with conda env. I am not sure if this is crucial to debugging the issue of non-zero exit.",
                          "url": "https://github.com/idaholab/moose/discussions/23722#discussioncomment-5314616",
                          "updatedAt": "2023-03-14T21:38:17Z",
                          "publishedAt": "2023-03-14T20:52:52Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "Can you run valgrind on the local ubuntu machine?\nmemory errors are typically not machine related but code-related",
                          "url": "https://github.com/idaholab/moose/discussions/23722#discussioncomment-5315507",
                          "updatedAt": "2023-03-14T23:19:57Z",
                          "publishedAt": "2023-03-14T23:19:56Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "BoZeng1997"
                          },
                          "bodyText": "This issue only occurred on this cluster. From the discussion people have about nonzero exit after primary job is finished, it looks more like a mpi issue rather than moose code issue. In some discussion, the issue resulted from a mismatch of openmpi version between compilation and execution. Although the script I used to compile PETSC and moose record the same openmpi module as for execution, recompile everything could be a last resort, especially when the gdb or valgrind is not functioning properly on my cluster.\nI am currently working on debugging another issue. I will come back to this one and report the result of reinstall everything. Before that, any advice is welcome since re-installation is also painful.",
                          "url": "https://github.com/idaholab/moose/discussions/23722#discussioncomment-5325851",
                          "updatedAt": "2023-03-15T19:07:32Z",
                          "publishedAt": "2023-03-15T19:07:31Z",
                          "isAnswer": true
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "Reporter System Vector of Tuples",
          "author": {
            "login": "maxnezdyur"
          },
          "bodyText": "I want to be able to send a vector of line segments from one multi-app to another. Is it possible to send a vector of tuples that hold the 6 coordinate values with the reporter system? I know I can send 6 reporters of each coord individually but I want to make the code cleaner and easier to read.  Let me know what would need to be done or if there was an easier way to send over a vector of line segments.",
          "url": "https://github.com/idaholab/moose/discussions/23734",
          "updatedAt": "2023-04-29T03:09:52Z",
          "publishedAt": "2023-03-15T16:08:51Z",
          "category": {
            "name": "Q&A General"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "GiudGiud"
                  },
                  "bodyText": "The reporter is the right data type to look at. I m not sure which one of vector of tuple or vector of vector is supported natively\n@loganharbour or @zachmprince may advise you further.",
                  "url": "https://github.com/idaholab/moose/discussions/23734#discussioncomment-5323816",
                  "updatedAt": "2023-03-15T16:12:28Z",
                  "publishedAt": "2023-03-15T16:12:27Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "author": {
                    "login": "loganharbour"
                  },
                  "bodyText": "Reporters just require a dataStore and dataLoad specialization for the object, plus a to_json specialization for converting to JSON.\nWe already have Point specialized for dataStore and dataLoad in DataIO.C. You will probably need to specialize to_json for Point in JsonIO.h. I think our library should work with the rest.\nI would just give it a try and to bother me with any compiler errors on Slack. Please put up a PR for whatever you need to get this working once it's all complete.",
                  "url": "https://github.com/idaholab/moose/discussions/23734#discussioncomment-5324232",
                  "updatedAt": "2023-03-15T16:30:34Z",
                  "publishedAt": "2023-03-15T16:29:25Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "loganharbour"
                          },
                          "bodyText": "Update... I think we'll also need to specialize a tuple",
                          "url": "https://github.com/idaholab/moose/discussions/23734#discussioncomment-5324251",
                          "updatedAt": "2023-03-15T16:30:44Z",
                          "publishedAt": "2023-03-15T16:30:44Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "maxnezdyur"
                          },
                          "bodyText": "It seems like if Point already has the dataStore and dataLoad specs, I could create two more for LineSegment that use the Point store/load and a to_json for both Point and LineSegement, then I would just have a vector of LineSegments.",
                          "url": "https://github.com/idaholab/moose/discussions/23734#discussioncomment-5324732",
                          "updatedAt": "2023-03-15T17:12:47Z",
                          "publishedAt": "2023-03-15T17:12:47Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "loganharbour"
                          },
                          "bodyText": "Yep - that should be plenty sufficient. Specialize all of the above in the location where LineSegment is declared and defined.",
                          "url": "https://github.com/idaholab/moose/discussions/23734#discussioncomment-5324846",
                          "updatedAt": "2023-03-15T17:22:34Z",
                          "publishedAt": "2023-03-15T17:22:33Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "maxnezdyur"
                          },
                          "bodyText": "For the dataStore and dataLoad for LineSegment should that be in DataIO?",
                          "url": "https://github.com/idaholab/moose/discussions/23734#discussioncomment-5324865",
                          "updatedAt": "2023-03-15T17:24:10Z",
                          "publishedAt": "2023-03-15T17:24:10Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "loganharbour"
                          },
                          "bodyText": "Nope - the convention should be that if it's not a class in MOOSE, it should be specialized there. Otherwise, it should be specialized where the object itself is declared and defined.\nFor example: std library things, libmesh objects, etc in DataIO. Everything else outside of DataIO",
                          "url": "https://github.com/idaholab/moose/discussions/23734#discussioncomment-5324988",
                          "updatedAt": "2023-03-15T17:35:18Z",
                          "publishedAt": "2023-03-15T17:35:17Z",
                          "isAnswer": true
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      }
    ]
  }
}