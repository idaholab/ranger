{
  "discussions": {
    "pageInfo": {
      "hasNextPage": true,
      "endCursor": "Y3Vyc29yOnYyOpK5MjAyMS0xMS0yNVQwNjozMTo0MC0wNzowMM4AOHks"
    },
    "edges": [
      {
        "node": {
          "title": "Simulation of solidification structure in additive manufacturing",
          "author": {
            "login": "wowodejiajia"
          },
          "bodyText": "Dear MOOSE developers,\nCan MOOSE simulate solidification structure simulation in additive manufacturing\uff1fIf it can, please give an example.",
          "url": "https://github.com/idaholab/moose/discussions/19385",
          "updatedAt": "2022-07-12T07:15:03Z",
          "publishedAt": "2021-11-15T02:50:08Z",
          "category": {
            "name": "Q&A General"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "jiangwen84"
                  },
                  "bodyText": "I guess you asked about the phase-field modeling of solidification. @SudiptaBiswas did you add any examples in MOOSE?",
                  "url": "https://github.com/idaholab/moose/discussions/19385#discussioncomment-1642274",
                  "updatedAt": "2022-07-12T07:15:03Z",
                  "publishedAt": "2021-11-15T04:13:44Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "SudiptaBiswas"
                          },
                          "bodyText": "We have some solidification examples here.",
                          "url": "https://github.com/idaholab/moose/discussions/19385#discussioncomment-1653153",
                          "updatedAt": "2022-07-12T07:15:03Z",
                          "publishedAt": "2021-11-16T17:46:10Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "wowodejiajia"
                          },
                          "bodyText": "Thank you.",
                          "url": "https://github.com/idaholab/moose/discussions/19385#discussioncomment-1655650",
                          "updatedAt": "2022-07-12T07:15:03Z",
                          "publishedAt": "2021-11-17T04:08:50Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              },
              {
                "node": {
                  "author": {
                    "login": "ngrilli"
                  },
                  "bodyText": "Dear @wowodejiajia\nWe have done this recent work:\nhttps://arxiv.org/abs/2105.13257\nwhich is now accepted in Computational Mechanics journal.\nIt is not based on phase field, but on elements moved from active to inactive subdomain and vice versa\nto model solidification.\nThe simulation used in the paper is here:\nhttps://github.com/ngrilli/c_pfor_am/tree/main/test/tests/Paper_ElementEliminationMethod\nNicol\u00f2",
                  "url": "https://github.com/idaholab/moose/discussions/19385#discussioncomment-1656952",
                  "updatedAt": "2022-07-12T07:15:06Z",
                  "publishedAt": "2021-11-17T10:06:51Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "wowodejiajia"
                          },
                          "bodyText": "Thank you very much.",
                          "url": "https://github.com/idaholab/moose/discussions/19385#discussioncomment-1719739",
                          "updatedAt": "2022-07-12T07:15:06Z",
                          "publishedAt": "2021-11-30T03:20:52Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "Peacock segmentation fault on MacOS",
          "author": {
            "login": "brandon-barclay"
          },
          "bodyText": "Hello,\nI have been running into a segmentation fault when trying to run peacock on mac. Have not had any issues running moose apps but I have been unable to visualize results with peacock. I did try paraview but I was also receiving an error there about the format of my output files being incorrect, which I haven't had when using peacock on ubuntu. I am currently on MacOS 12.0.1.\nThanks for your help.",
          "url": "https://github.com/idaholab/moose/discussions/19438",
          "updatedAt": "2022-07-04T08:30:08Z",
          "publishedAt": "2021-11-19T19:59:37Z",
          "category": {
            "name": "Q&A Tools"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "GiudGiud"
                  },
                  "bodyText": "Hello\nWhich version is your paraview?\nThe latest version complains about something we do with nodesets and sidesets (sharing the same name).\nDowngrading paraview could help. The alternative is to find the legacy exodus reader inside your new paraview. I've been told that's not easy\nOtherwise for peacock I dont know that we support Monterey yet. I ll try to find out\nGuillaume",
                  "url": "https://github.com/idaholab/moose/discussions/19438#discussioncomment-1678907",
                  "updatedAt": "2022-07-04T08:30:11Z",
                  "publishedAt": "2021-11-22T00:58:07Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "milljm"
                          },
                          "bodyText": "It's supposed to work yes... but I can reproduce this issue. More than likely an issue with one of dependency modules for VTK. I'll see if I can isolate it to PyQt, or Qt, etc...\n\u276f uname -r\n21.1.0\n\nInvoking with -i\n\u276f cd tests/kernels/simple_diffusion\n\u276f ../../../../python/peacock/peacock -i simple_diffusion.i\nFound executable: /Users/milljm/projects/moose/test/moose_test-opt\nzsh: bus error  ../../../../python/peacock/peacock -i simple_diffusion.i\n\nJust running peacock.\n\u276f ../../../../python/peacock/peacock\nFound executable: /Users/milljm/projects/moose/test/moose_test-opt\nzsh: segmentation fault  ../../../../python/peacock/peacock",
                          "url": "https://github.com/idaholab/moose/discussions/19438#discussioncomment-1681747",
                          "updatedAt": "2022-07-04T08:30:07Z",
                          "publishedAt": "2021-11-22T14:13:54Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "brandon-barclay"
                          },
                          "bodyText": "The issue I was having with paraview was the duplicate naming one, so thanks for letting me know. And as well the issue with peacock was producing the same output as above. Thanks for looking into it.",
                          "url": "https://github.com/idaholab/moose/discussions/19438#discussioncomment-1702044",
                          "updatedAt": "2022-07-04T08:30:11Z",
                          "publishedAt": "2021-11-25T18:19:42Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "milljm"
                          },
                          "bodyText": "I can isolate this to being a PyQt/Qt issue. Unfortunately we have a dependency issue preventing us from upgrading to a newer version. While this might not be the 100% fix, this is our dilemma:\n\u276f mamba create -n testing_environment clangxx_osx-64=12 pyqt python=3.9\n\n<trimmed>\n\nLooking for: ['clangxx_osx-64=12', 'pyqt', 'python=3.9']\n\nconda-forge/osx-64       Using cache\nconda-forge/noarch       Using cache\npublic/osx-64            [====================] (00m:00s) No change\npublic/noarch            [====================] (00m:00s) No change\nEncountered problems while solving:\n  - package clangxx_osx-64-12.0.1-h7e1b574_0 requires clang_osx-64 12.0.1 hb91bd55_0, but none of the providers can be installed\nWhile not very forthcoming with the actual dependency error; What the above is trying to tell us is that there exists no version of PyQt for any version of Python higher than 3.7 when also requiring Clang 12.\nThe gist of it is, we have moved on to Clang 12.x compilers, while PyQt has only been built with Clang 12.x for Python 3.7. I think the fix exists in later versions of Python/PyQt/Qt. I will attempt to see if that is the case. Will take some doing (use older version of MOOSE, since Peacock requires pyhit, which is a moose contrib).\nIndeed, throughout this whole process, I've managed to get Peacock to launch correctly 4 times (out of many attempts while using pdb), with no changes to any code (thread buggy?). Seems to be something with:\ndiff --git a/python/peacock/Execute/ExecuteOptionsPlugin.py b/python/peacock/Execute/ExecuteOptionsPlugin.py\nindex 480793cfca..6df59acf86 100755\n--- a/python/peacock/Execute/ExecuteOptionsPlugin.py\n+++ b/python/peacock/Execute/ExecuteOptionsPlugin.py\n@@ -168,12 +168,12 @@ class ExecuteOptionsPlugin(QWidget, Plugin):\n         self._loading_dialog.setInformativeText(app_path)\n         self._loading_dialog.show()\n         self._loading_dialog.raise_()\n-        QApplication.processEvents()\n+        QApplication.sendPostedEvents()\n\n         app_info = ExecutableInfo()\nThat is, something is dying in a PyQt thread process when asking it to perform background tasks (ref: https://doc.qt.io/qt-5/qcoreapplication.html#processEvents).",
                          "url": "https://github.com/idaholab/moose/discussions/19438#discussioncomment-1716902",
                          "updatedAt": "2022-07-04T08:30:11Z",
                          "publishedAt": "2021-11-29T16:10:25Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "milljm"
                          },
                          "bodyText": "Confirmed... while pinning a later Python (3.9), Peacock seems to launch. So far, this is what I am having to do:\n\u276f mamba init             # I am using Mambaforge, replace your commands with `conda` where applicable\n< restart terminal >\n\u276f mamba create -n peacock python=3.9 clangxx_osx-64 clang_osx-64 \\\n  gfortran_osx-64 mpich boa conda-build pyqt pandas matplotlib vtk\n\u276f mamba activate peacock\n< make changes to moose/conda/pyhit, see below diff >\n\u276f cd moose/conda/pyhit\n\u276f mamba mambabuild .     # or `conda build .`\n\u276f mamba install --use-local moose-pyhit\n\u276f mamba deactivate\n\u276f mamba activate peacock # reload environment\n\u276f cd moose/python\n\u276f mv pyhit not_pyhit     # Looks like Peacock prepends this path to syspath, making it impossible\n                         # to load our custom moose-pyhit package instead\n\u276f cd peacock\n\u276f ./peacock              # profit. So far so good. Peacock loads at least.\npyhit package diff (force build pyhit with Clang 11.x and Python 3.9):\ndiff --git a/conda/pyhit/meta.yaml b/conda/pyhit/meta.yaml\nindex 854b57f881..6f252f7792 100644\n--- a/conda/pyhit/meta.yaml\n+++ b/conda/pyhit/meta.yaml\n@@ -1,5 +1,5 @@\n {% set build = 0 %}\n-{% set version = \"2021.10.27\" %}\n+{% set version = \"2021.11.29\" %}\n \n package:\n   name: moose-pyhit\n@@ -14,18 +14,18 @@ build:\n \n requirements:\n   build:\n-    - {{ moose_cxx }}\n-    - {{ moose_python }}\n+    - clangxx_osx-64 11.1.0\n+    - python 3.9\n     - cython\n \n   host:\n-    - {{ moose_cxx }}\n-    - {{ moose_python }}\n+    - clangxx_osx-64 11.1.0\n+    - python 3.9\n     - cython\n \n   run:\n-    - {{ moose_cxx }}\n-    - python\n+    - clangxx_osx-64 11.1.0\n+    - python 3.9\n \n test:\n   imports:\nWith the above partially working, I think it might be possible to use a different environment solely for the purpose of launching Peacock. I'll continue to investigate. You may be thinking; Why not just use Clang 11? Well, Monterey's XCode version(s) do not gibe well with Clang-11. It forced us to move to Clang 12... MOOSE simply doesn't compile correctly under Monterey with Clang-11. @cticenhour is that correct?\n@brandon-barclay I am not exactly asking you to perform the above as a fix. I am just documenting my findings, as I find them. Although if you do wish to build the above, you will need to obtain the 10.9 MacSDK and install it to /opt. I use the conveniently available SDKs from here: https://github.com/phracker/MacOSX-SDKs/releases",
                          "url": "https://github.com/idaholab/moose/discussions/19438#discussioncomment-1717233",
                          "updatedAt": "2022-07-04T08:30:43Z",
                          "publishedAt": "2021-11-29T17:11:10Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "cticenhour"
                          },
                          "bodyText": "Monterey (or Big Sur with the most up-to-date Xcode version) just did not work with Clang 11, presumably due to the changes needed in order for Apple to have compatibility with their newer Apple Silicon platforms. The end result was that much of the MOOSE dependencies could be built successfully, but the final build of MOOSE would be riddled with library and linking errors resulting in a broken build. It's very possible Clang-11 could have worked with some heavy effort on Mac Intel systems, but our push for Apple Silicon support preempted any more work on it. Clang 12.0.0 or later holds partially optimized support for that architecture, with more full-featured support coming in Clang-13.",
                          "url": "https://github.com/idaholab/moose/discussions/19438#discussioncomment-1717422",
                          "updatedAt": "2022-07-04T08:30:49Z",
                          "publishedAt": "2021-11-29T17:38:25Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "milljm"
                          },
                          "bodyText": "Looks like using two environments may be the only path forward for now. Also, renaming that \"moose/python/pyhit\" directory is necessary. I'll have to bring all this up with my group, on how to proceed. I like the idea of no longer tying Peacock to moose/python/pyhit. As it seems to work just fine on my end:",
                          "url": "https://github.com/idaholab/moose/discussions/19438#discussioncomment-1717565",
                          "updatedAt": "2022-07-04T08:30:49Z",
                          "publishedAt": "2021-11-29T18:05:16Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "How to take grain size into consideration in uniaxial tension",
          "author": {
            "login": "xchengood"
          },
          "bodyText": "Dear Moose expert or users,\nCould anyone share your ideas or thoughts about how to take grain/particle size into consideration in power-law model (https://mooseframework.inl.gov/source/materials/crystal_plasticity/CrystalPlasticityKalidindiUpdate.html) for uniaxial tension simulation and look at how the effect of grain/particle size on the stress-strain curve? Thank you.",
          "url": "https://github.com/idaholab/moose/discussions/19199",
          "updatedAt": "2022-06-29T07:39:50Z",
          "publishedAt": "2021-10-25T19:29:57Z",
          "category": {
            "name": "Q&A Modules: Solid mechanics"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "sapitts"
                  },
                  "bodyText": "Hi @xchengood,\nYou may like to consider a Hall-Petch type term (for grain size influence) or an impenetrable barrier type model (for embedded particles) as additional hardening terms.\nIn a class that inherits from CrystalPlasticityKalidindiUpdate, I'd recommend either overwriting the method calculateStateVariableEvolutionRateComponent or adding a new constant hardening contribution term that is called in the stateful property initialization method. An example of this second approach is used in the initQpStatefulProperties method of CrystalPlasticityHCPDislocationSlipBeyerleinUpdate.\nHope this helps,\nStephanie",
                  "url": "https://github.com/idaholab/moose/discussions/19199#discussioncomment-1534645",
                  "updatedAt": "2022-06-29T07:39:50Z",
                  "publishedAt": "2021-10-25T19:48:28Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "xchengood"
                          },
                          "bodyText": "Hi @xchengood, You may like to consider a Hall-Petch type term (for grain size influence) or an impenetrable barrier type model (for embedded particles) as additional hardening terms.\nIn a class that inherits from CrystalPlasticityKalidindiUpdate, I'd recommend either overwriting the method calculateStateVariableEvolutionRateComponent or adding a new constant hardening contribution term that is called in the stateful property initialization method. An example of this second approach is used in the initQpStatefulProperties method of CrystalPlasticityHCPDislocationSlipBeyerleinUpdate.\nHope this helps, Stephanie\n\nHi @sapitts. Thank you for your information. It is helpful. I am wondering if the example model for HCP you mentioned can be used for FCC or BCC structure. If so, what can I make some modifications to this model (https://github.com/idaholab/moose/blob/next/modules/tensor_mechanics/test/tests/crystal_plasticity/hcp_single_crystal/update_method_hcp_aprismatic_capyramidal.i). Appreciate your help.",
                          "url": "https://github.com/idaholab/moose/discussions/19199#discussioncomment-1540612",
                          "updatedAt": "2022-06-29T07:39:50Z",
                          "publishedAt": "2021-10-26T18:45:52Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "sapitts"
                          },
                          "bodyText": "I'd strongly recommend against using the HCP class for a cubic crystal. As the name suggests, the class I linked to as an example applies assumptions unique to HCP crystal structures. The Kalidindi class that you linked to, source code here, is intended for FCC materials.\nYou will need to write some code to achieve your objective here. I'd advise creating a new class that inherits from CrystalPlasticityKalidindiUpdate and overwrite the initQpStatefulProperties method to add the new slip resistance contributions",
                          "url": "https://github.com/idaholab/moose/discussions/19199#discussioncomment-1541687",
                          "updatedAt": "2022-06-29T07:40:06Z",
                          "publishedAt": "2021-10-26T22:30:37Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "xchengood"
                          },
                          "bodyText": "I'd strongly recommend against using the HCP class for a cubic crystal. As the name suggests, the class I linked to as an example applies assumptions unique to HCP crystal structures. The Kalidindi class that you linked to, source code here, is intended for FCC materials.\nYou will need to write some code to achieve your objective here. I'd advise creating a new class that inherits from CrystalPlasticityKalidindiUpdate and overwrite the initQpStatefulProperties method to add the new slip resistance contributions\n\nHi @sapitts. Very appreciate your information.  The method of CrystalPlasticityHCPDislocationSlipBeyerleinUpdate you mentioned is developed based on the paper (https://www.sciencedirect.com/science/article/pii/S074964190700109X). My questions are below.\n\n\nDoes that method for HCP take the the VPSC model menthoned in the paper into consideration? If not, could you share any ideas about how to combine VPSC model to that method with me? So that I can apply the model to polycrystal.\n\n\nHow can I get and output pole figures presented in the paper in Moose?\n\n\nI see there are many variables referring to slip resistance and forest dislocation and substructure dislocation in the program (https://github.com/idaholab/moose/blob/next/modules/tensor_mechanics/test/tests/crystal_plasticity/hcp_single_crystal/update_method_hcp_aprismatic_active.i). Could you explain more about those variables in Postprocessors module? I also want to study the slip resistance, forest and substructure dislolcation change with time or temperature. But I am confused about the specific meaning of each variable.\n\n\nThanks a lot.",
                          "url": "https://github.com/idaholab/moose/discussions/19199#discussioncomment-1622909",
                          "updatedAt": "2022-06-29T07:40:07Z",
                          "publishedAt": "2021-11-10T23:36:03Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "ngrilli"
                          },
                          "bodyText": "Dear @xchengood\nI have implemented some time ago the Beyerlein, Tome model in MOOSE:\nhttps://github.com/ngrilli/c_pfor_am/blob/main/src/materials/FiniteStrainCrystalPlasticityUranium.C\nThis is based on forest and substructure dislocation densities as state variables.\nVPSC is not really a constitutive model but it is a type of solver, different from the finite element method in MOOSE.\nVPSC means that each grain is considered immersed into a uniform medium and treated as Eshelby inclusion to calculate the plastic deformation. It's different from CPFEM.\nConverting a pole figure from a paper into grain orientations is generally complicated,\nyou could parse the colours in the figure, convert into a distribution function, then use monte carlo methods\nto pick grain orientations.\nIt's better if you ask to the corresponding author if they can provide the original Euler angles data.\nBest Regards,\nNicol\u00f2",
                          "url": "https://github.com/idaholab/moose/discussions/19199#discussioncomment-1623062",
                          "updatedAt": "2022-06-29T07:40:58Z",
                          "publishedAt": "2021-11-11T00:32:37Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "sapitts"
                          },
                          "bodyText": "Hi @xchengood,\n\nAs @ngrilli describe, the crystal plasticity FEM implementation in MOOSE is different from the VPSC implementation described in Beyerlein and Tome, although both can use the same constitutive models. An overview of the crystal plasticity algorithm is given on the documentation page for ComputeMultipleCrystalPlasticityStress. There are many papers by Tome and collaborators to describe VPSC.\nWe do not currently have the capability to generate pole figures in MOOSE. We certainly do accept pull requests though!\nThe slip resistance, forest dislocations, and substructure density are explained in the documentation page for CrystalPlasticityHCPDislocationSlipBeyerleinUpdate as well as the papers cited on that documentation page. The numbers appended to the slip resistance and forest dislocations in the input file correspond to specific slip systems, in the order given in the text file hcp_aprismatic_capyramidal_slip_sys.txt.\n\nIf you'd like to discuss this HCP class and/or the forest dislocations and slip resistances further, please open a new discussion post specific to this new topic. In that way we will be best following the discussion board guidelines.  Thanks!",
                          "url": "https://github.com/idaholab/moose/discussions/19199#discussioncomment-1626509",
                          "updatedAt": "2022-06-29T07:41:01Z",
                          "publishedAt": "2021-11-11T15:20:38Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "sapitts"
                          },
                          "bodyText": "Hi @ngrilli,\nIt'd be great if you would be open to making a pull request to MOOSE for your crystal plasticity code, after generalizing the material and switching to the latest base class version. @dewenyushu has performed some bench-marking which shows that the ComputeMultipleCrystalPlasticityStress and CrystalPlasticityStressUpdateBase version is faster. We've also fixed some bugs from the older FiniteStrainCrystalPlasticity and UserObject versions. We'd be glad to assist you in navigating the documentation and testing requirements for a MOOSE pull request.\nIt would be nice to have contributed code from our community of crystal plasticity users in the MOOSE repository!\nBest Regards,\nStephanie",
                          "url": "https://github.com/idaholab/moose/discussions/19199#discussioncomment-1626558",
                          "updatedAt": "2022-06-29T07:41:01Z",
                          "publishedAt": "2021-11-11T15:31:28Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "ngrilli"
                          },
                          "bodyText": "Hi @sapitts\nI have only recently learned the User Object Crystal Plasticity code,\ntherefore my previous code is mainly done using the monolithic version.\nI think my code for the Beyerlein, Tom\u00e9 model is very similar to CrystalPlasticityHCPDislocationSlipBeyerleinUpdate\nI have other classes that may be interesting to the MOOSE CP community,\nI have recently coupled CP and phase field fracture:\nhttps://github.com/ngrilli/c_pfor_am/blob/main/src/materials/FiniteStrainUObasedCPDamageVol.C\nmy understanding is that there is no way to do that with existing classes.\nAnother interesting development is the implementation of continuum dislocation dynamics with transport equations,\nthe model by Thomas Hochrainer, Stefan Sandfeld, Michael Zaiser, Peter Gumbsch:\nhttps://www.sciencedirect.com/science/article/pii/S0022509613001877\ncoupled with the CP model using Orowan's law, but it's still using the monolithic code:\nhttps://github.com/ngrilli/c_pfor_am/blob/main/src/materials/FiniteStrainCrystalPlasticityDislo.C\nIt works but the code is poorly written and need to be improved.\nI did the pull request procedure once about 5 years ago and I may still remember how to do.\n@DaijunHU is working with me on this\nand we will be happy to contribute in the future.\nWe will let you know once we are ready.\nBest Regards,\nNicol\u00f2",
                          "url": "https://github.com/idaholab/moose/discussions/19199#discussioncomment-1640903",
                          "updatedAt": "2022-06-29T07:41:40Z",
                          "publishedAt": "2021-11-14T18:35:39Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "xchengood"
                          },
                          "bodyText": "Hi @sapitts @ngrilli . Thank you very much for your information. I really learned a lot. But I still have some confusion.\n\n\nAs you mentioned 'the VPSC is a kind of solver and it is a constitutive model', is there VPSC solver in Moose? If so, how to use it and are there any examples? If not, How can I apply the HCP model to polycrystal, not only for single crystal?\n\n\nI also want to study how the stress-strain curve change with temperature. I add the the following block to the [AuxKernels]\n[temperature]\ntype = FunctionAux\nvariable = temperature\nfunction = '300+400*t' # temperature increases at a constant rate\nexecute_on = timestep_begin\n[]\nIs my method correct? Basically, I got stress-strain curve at 300K and 1600K. The yield strength shows significant decrease, but the Young's modulus does not show any change. Two curves have the same slope. This does not make sense. If my method is not correct, could you share any ideas with me? Basically, the Young's modulus should decrease with the increase of temperature.\n\n\nThank you. Best wishes!",
                          "url": "https://github.com/idaholab/moose/discussions/19199#discussioncomment-1652754",
                          "updatedAt": "2022-06-29T07:42:02Z",
                          "publishedAt": "2021-11-16T16:39:47Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "sapitts"
                          },
                          "bodyText": "Hi @xchengood,\nPlease make a new discussion post to discuss these new issues. A new discussion post, with a title to capture these questions about including temperature effects and multiple crystals , will help other users find our discussion in the future.\nThanks,\nStephanie",
                          "url": "https://github.com/idaholab/moose/discussions/19199#discussioncomment-1652843",
                          "updatedAt": "2022-06-29T07:42:24Z",
                          "publishedAt": "2021-11-16T16:53:07Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "xchengood"
                          },
                          "bodyText": "Hi @xchengood, Please make a new discussion post to discuss these new issues. A new discussion post, with a title to capture these questions about including temperature effects and multiple crystals , will help other users find our discussion in the future.\nThanks, Stephanie\n\nHi @sapitts Thank you. I will make a new discussion post.",
                          "url": "https://github.com/idaholab/moose/discussions/19199#discussioncomment-1653695",
                          "updatedAt": "2022-06-29T07:42:25Z",
                          "publishedAt": "2021-11-16T19:32:12Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              },
              {
                "node": {
                  "author": {
                    "login": "dewenyushu"
                  },
                  "bodyText": "How can I get and output pole figures presented in the paper in Moose?\n\nWe had some issues calculating the updated Euler angles. I am working on a PR (#19494) to fix this issue and enable the capability to output updated Euler angles.\nTo visualize the texture, you will need to output the updated Euler angles in .csv files via appropriate postprocessors, and then use additional tools, e.g., MTEX, to plot the pole figures.",
                  "url": "https://github.com/idaholab/moose/discussions/19199#discussioncomment-1717192",
                  "updatedAt": "2022-06-29T07:40:10Z",
                  "publishedAt": "2021-11-29T17:04:19Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": []
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "SUPG tau stabilization parameter for temperature",
          "author": {
            "login": "smpark7"
          },
          "bodyText": "I've been using the INSAD kernels with SUPG and PSPG to model molten salt flow and temperature advection-diffusion in a lid-driven cavity with a volumetric heat source (fission) and sink. The tau parameter for temperature advection-diffusion in INSADStabilized3Eqn.C has an additional term in transient simulations that depends on the timestep size (4/dt**2).\nFor non-large timesteps in advection-dominated flow, this timestep term effectively eliminates the artificial diffusion from SUPG on \"non-physical\" boundary points like the top left corner of the lid-driven cavity where the velocity value is zero. This causes the temperature value on the corner to plunge and creates spurious oscillations in the temperature along the boundary when using natural BCs.\nI looked through the MOOSE INS Overview paper and tried looking at other resources but I couldn't find any references for the derivation of this term. Is this term in tau necessary for transient simulations?",
          "url": "https://github.com/idaholab/moose/discussions/17185",
          "updatedAt": "2022-06-05T03:56:33Z",
          "publishedAt": "2021-03-02T19:09:47Z",
          "category": {
            "name": "Q&A Modules: Navier-Stokes"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "GiudGiud"
                  },
                  "bodyText": "Tagging @pbalest and @snschune  as they will know more on what reference was followed for this implementation.\nIs stabilization required for your use case?",
                  "url": "https://github.com/idaholab/moose/discussions/17185#discussioncomment-491173",
                  "updatedAt": "2022-06-05T03:56:35Z",
                  "publishedAt": "2021-03-16T22:20:18Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "smpark7"
                          },
                          "bodyText": "Yes the prandtl number of the lid-driven cavity with molten salt is ~300k so it produces worse numerical oscillations in the temperature without stabilization.\nI also tried removing the timestep-dependent term in the tau parameter before running with SUPG stabilization. At steady state, the temperature values along the vertical and horizontal lines passing through the middle of the cavity are close to literature-reported values. The \"non-physical\" temperature value observed on the top-left corner is steady and does not induce oscillations in other parts of the domain like what I described in my initial post above.",
                          "url": "https://github.com/idaholab/moose/discussions/17185#discussioncomment-493280",
                          "updatedAt": "2022-06-05T03:56:35Z",
                          "publishedAt": "2021-03-17T11:51:56Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "Thanks for the additional information.\nWould you consider using our new finite volume capabilities? It should be able to remove unphysical corner values which can be simply caused by difficulties in applying boundary conditions there.\nThere are examples of lid-driven cavities in modules/navier_stokes/test/tests/finite_volume/ins/lid-driven",
                          "url": "https://github.com/idaholab/moose/discussions/17185#discussioncomment-494087",
                          "updatedAt": "2022-06-05T03:56:35Z",
                          "publishedAt": "2021-03-17T14:42:04Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "smpark7"
                          },
                          "bodyText": "Yes I'll definitely look into INSFV for future work!",
                          "url": "https://github.com/idaholab/moose/discussions/17185#discussioncomment-512610",
                          "updatedAt": "2022-06-05T03:56:37Z",
                          "publishedAt": "2021-03-22T11:15:40Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "lindsayad"
                          },
                          "bodyText": "@jwpeterson I believe I added that transient contribution to the tau parameter based off information in one of your fluids textbooks which I liked to steal and unfortunately can no longer steal \ud83d\ude06 I don't suppose you know the reference?",
                          "url": "https://github.com/idaholab/moose/discussions/17185#discussioncomment-1689654",
                          "updatedAt": "2022-08-26T19:40:59Z",
                          "publishedAt": "2021-11-23T19:09:55Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "lindsayad"
                          },
                          "bodyText": "We want to emphasize our FV capability but I still want to ensure that our FE capabilities are as good as they can be",
                          "url": "https://github.com/idaholab/moose/discussions/17185#discussioncomment-1689656",
                          "updatedAt": "2022-08-26T19:40:59Z",
                          "publishedAt": "2021-11-23T19:10:39Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "smpark7"
                          },
                          "bodyText": "Thanks for checking in on this thread. May I ask what's the current status on coupling and other supporting features in the NS FV system? I've seen the conference papers on Griffin & Pronghorn which showcased tight coupling through the multiapp system (please correct me if I'm wrong). Is direct coupling to FE variables a work-in-progress?",
                          "url": "https://github.com/idaholab/moose/discussions/17185#discussioncomment-1689918",
                          "updatedAt": "2022-08-26T19:40:59Z",
                          "publishedAt": "2021-11-23T19:55:50Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "lindsayad"
                          },
                          "bodyText": "We have coupled FV variables to FE physics, but not the other way around yet. @csdechant was working on FE variables to FV physics in #18394 but we seem to have stalled a little.\nI have been focused on the fluid flow physics development for FV, but others like @GiudGiud have applied it in more multiphysics contexts, with neutronics for instance. For neutronics coupling I believe that has been done with multiapps. But energy transport and passive scalar transport can certainly be solved in a single monolithic system (using FV variables for all)",
                          "url": "https://github.com/idaholab/moose/discussions/17185#discussioncomment-1690292",
                          "updatedAt": "2022-08-26T19:40:59Z",
                          "publishedAt": "2021-11-23T21:15:26Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              },
              {
                "node": {
                  "author": {
                    "login": "jwpeterson"
                  },
                  "bodyText": "I don't suppose you know the reference?\n\nI'm not sure what the original reference is, but my understanding is that this \"sum of reciprocals\" formula became a pseudo-standard approach in the early literature. See for example Eq. (18) and the discussion leading up to it in Tezduyar & Osawa, CMAME 190 (2000), p. 411-430 (attached).\nThe main idea is that in the limit as dt -> 0, tau -> dt/2, which I think relates back to the (even older) Taylor-Galerkin  stabilization method. On the other hand if dt is not small and |u|~0, then tau -> C * h^2 / nu, i.e. the classical diffusive limit for SUPG.\n\nYes the prandtl number of the lid-driven cavity with molten salt is ~300k\n\nThe Prandtl number for molten salt is .003 according to Wikipedia?\nTezduyar_CMAME_2000.pdf",
                  "url": "https://github.com/idaholab/moose/discussions/17185#discussioncomment-1689889",
                  "updatedAt": "2022-06-05T03:56:37Z",
                  "publishedAt": "2021-11-23T19:50:35Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "smpark7"
                          },
                          "bodyText": "Thank you for the references. I've also since found one other publication by the same author providing that tau formulation (link), but without as much derivation.\n\nThe Prandtl number for molten salt is .003 according to Wikipedia?\n\nThat appears to be the Prandtl number for molten potassium metal, rather than molten salt.",
                          "url": "https://github.com/idaholab/moose/discussions/17185#discussioncomment-1690014",
                          "updatedAt": "2022-06-06T08:48:59Z",
                          "publishedAt": "2021-11-23T20:18:46Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "jwpeterson"
                          },
                          "bodyText": "OK, well, a Prandtl number that large would mean that the thermal boundary layer is much, much, much thinner than the momentum boundary layer, so the mesh that you would need to capture the thermal boundary layer accurately would be much finer than that needed for capturing the velocity boundary layer. You might have better luck with a decoupled approach, as I would also expect thermal changes and momentum changes to happen on very different time scales, i.e. the two things would be almost decoupled from one another physically.",
                          "url": "https://github.com/idaholab/moose/discussions/17185#discussioncomment-1690028",
                          "updatedAt": "2022-06-06T08:48:59Z",
                          "publishedAt": "2021-11-23T20:20:59Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "smpark7"
                          },
                          "bodyText": "I see. Thank you for the insights!",
                          "url": "https://github.com/idaholab/moose/discussions/17185#discussioncomment-1690621",
                          "updatedAt": "2022-06-06T08:48:59Z",
                          "publishedAt": "2021-11-23T22:41:38Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "doquang"
                          },
                          "bodyText": "@jwpeterson - Do you mean the decoupled approach is the MultiApp in Moose?",
                          "url": "https://github.com/idaholab/moose/discussions/17185#discussioncomment-1708642",
                          "updatedAt": "2022-08-26T19:40:59Z",
                          "publishedAt": "2021-11-27T08:55:42Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "jwpeterson"
                          },
                          "bodyText": "@doquang Yes, MultiApps would be one way to implement a decoupled approach in MOOSE. This would allow you to e.g. use different time steps and different meshes for the momentum and thermal equations. I don't know much about the details of what you are doing, though, so decoupling the equations is just my initial instinct upon hearing about the high Prandtl number. Keeping the equations coupled would make sense if the Pr was up to O(10) or so.",
                          "url": "https://github.com/idaholab/moose/discussions/17185#discussioncomment-1713719",
                          "updatedAt": "2022-08-30T19:15:55Z",
                          "publishedAt": "2021-11-29T05:14:46Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "Visualization in MOOSE [DoFs]",
          "author": {
            "login": "jinca"
          },
          "bodyText": "Hello all,\nMay I ask how many DoFs the MOOSE application and peacock can handle?\nDoes it have a maximum number? what about more than 121 millions of DoFs?\nThanks in advance!\nJulita",
          "url": "https://github.com/idaholab/moose/discussions/19433",
          "updatedAt": "2022-10-30T07:25:23Z",
          "publishedAt": "2021-11-19T15:29:40Z",
          "category": {
            "name": "Q&A Meshing"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "ykvishal"
                  },
                  "bodyText": "It is better to limit peacock for small  simulations only. You can always run simulation via terminal and visualize output with Paraview. I ran few simulations with 3.5e9 DOFs, but you will need huge computational resources to run such large simulations.",
                  "url": "https://github.com/idaholab/moose/discussions/19433#discussioncomment-1672956",
                  "updatedAt": "2022-10-30T07:25:32Z",
                  "publishedAt": "2021-11-19T21:53:51Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "author": {
                    "login": "jinca"
                  },
                  "bodyText": "Thank you for the answer. Could you please let me know if you used a supercomputer? My DoF is 10 to 8 instead of your test of 10 to 9.\nAppreciate again your help, Julita",
                  "url": "https://github.com/idaholab/moose/discussions/19433#discussioncomment-1678250",
                  "updatedAt": "2022-10-30T07:25:44Z",
                  "publishedAt": "2021-11-21T19:26:44Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "ykvishal"
                          },
                          "bodyText": "Yes, I always use HPC for running MOOSE  simulations and visualization of data.",
                          "url": "https://github.com/idaholab/moose/discussions/19433#discussioncomment-1678282",
                          "updatedAt": "2022-10-30T07:25:45Z",
                          "publishedAt": "2021-11-21T19:36:51Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              },
              {
                "node": {
                  "author": {
                    "login": "jinca"
                  },
                  "bodyText": "Thanks again @ykvishal, could you please let me know the configuration of the modules you used to do the visualization? Cheers!",
                  "url": "https://github.com/idaholab/moose/discussions/19433#discussioncomment-1705669",
                  "updatedAt": "2022-10-30T07:25:45Z",
                  "publishedAt": "2021-11-26T12:56:54Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "ykvishal"
                          },
                          "bodyText": "This part is tricky, and it is not related to MOOSE. You may have to work with your HPC support team. I had shared my following requirements to my HPC support team:\n\nUse of desktop OnDemand (DOD)\nParaview is installed in DOD\nDOD works on whole node (ie I can use all cores of a given node)\nDOD also has a GPU\nParaview works in auto parallel mode in DOD (not using master/slave option. MS option is very slow)\n\nAfter a lot of problems, my HPC support team managed to make it work for me. Now, I can easily process 4TB data.  Also, for a couple of GB data, normal paraview works fine.\nI hope that it will work out for you. All the best.",
                          "url": "https://github.com/idaholab/moose/discussions/19433#discussioncomment-1713295",
                          "updatedAt": "2022-11-08T07:48:36Z",
                          "publishedAt": "2021-11-29T01:50:20Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "Recovering from a split mesh calc",
          "author": {
            "login": "makeclean"
          },
          "bodyText": "I've got a problem that I split into 36 bits using split-mesh, I turned recovery on, since I knew this calc was going to run longer than my HPC's queue time. It split fine, and ran fine with the following command:\nmpirun -np 36 --npernode 6 <exec> -i <input_file> --use-split\n\nI included a recovery option in the input,\n[Outputs]\n  [checkpoints]\n      type = Checkpoint\n      num_files = 2\n      interval = 40\n  []\n[]\n\nHowever, when trying to restart I get consisent failures; using the command\nmpirun -np 36 --npernode 6 <exec> -i <input_file> --use-split --recover\n\nI get the error,\n** ERROR ***\nERROR: Neither one of the following files can be located:\n\t'_mesh.cpr/36/header.cpr' nor\n\t'_mesh.cpr'\nIf you are running a parallel job, double check that you've created a split for 36 ranks.\nNote: One of paths above may refer to a valid directory on your system, however we are attempting to read a valid header file.\n\nEven setting the split mesh filename --split-file tpipe.cpr makes no difference to the error. In the checkpoint directory for the filename, which happens to be tpipe-cfl-water-temp-correct-pc-6-36_checkpoints_cp/1920_mesh.cpr.\nIs there a better way/right way to restart properly?",
          "url": "https://github.com/idaholab/moose/discussions/19429",
          "updatedAt": "2022-06-14T02:42:52Z",
          "publishedAt": "2021-11-19T10:53:04Z",
          "category": {
            "name": "Q&A General"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "GiudGiud"
                  },
                  "bodyText": "I think that s the way but maybe someone will correct me\nCan you get this to run by renaming the folder to the name it s expecting? _mesh.cpr it seems",
                  "url": "https://github.com/idaholab/moose/discussions/19429#discussioncomment-1685695",
                  "updatedAt": "2022-06-14T02:43:36Z",
                  "publishedAt": "2021-11-23T06:52:21Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "makeclean"
                          },
                          "bodyText": ":sad face: afraid not,\n*** Info ***\nUsing  for recovery.\nSetting Up\n  Setting Mesh...                                                                        [\n 27.30 s] [ 1270 MB]\nFinished Setting Up                                                                      [\n 29.15 s] [ 1339 MB]\n\n*** ERROR ***\nUnable to open file \".rd-47\". Check to make sure that it exists and that you have read per\nmission.\n\nI made a symbolic link from the timestep number/num splits folder to _mesh.cpr as suggested, its a hard no.",
                          "url": "https://github.com/idaholab/moose/discussions/19429#discussioncomment-1696743",
                          "updatedAt": "2022-06-14T02:43:37Z",
                          "publishedAt": "2021-11-24T21:45:35Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "ah it is looking for an empty filename now. There might be broken logic. I ll see if I can repoduce this",
                          "url": "https://github.com/idaholab/moose/discussions/19429#discussioncomment-1697763",
                          "updatedAt": "2022-06-14T02:43:43Z",
                          "publishedAt": "2021-11-25T03:58:06Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "Ok so I think the problem is that you did not specify the file name after --recover\nI m going to think about this more but maybe we want to error here when the file name is missing. Not sure why \" \" was an OK default",
                          "url": "https://github.com/idaholab/moose/discussions/19429#discussioncomment-1713112",
                          "updatedAt": "2022-06-14T02:43:43Z",
                          "publishedAt": "2021-11-29T00:33:04Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "Note that once the mesh is split, I think the recover use that directly, no need to add --use-split --split-file split-mesh-filename anymore, since\n--recover input_name_checkpoint_cp/00014 (which is akin to what you need to specify here) is already a distributed file.\nSplits are sort of a confusing additional distinction in general. It's really distributed vs replicated mesh that is the big deal. Using a split or not only makes a difference at initialization, on slow file systems. I think this question is more about a distributed recover than a split recover.",
                          "url": "https://github.com/idaholab/moose/discussions/19429#discussioncomment-1713125",
                          "updatedAt": "2022-06-14T02:43:54Z",
                          "publishedAt": "2021-11-29T00:40:12Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "\"Solve did not converge\"",
          "author": {
            "login": "abc-hy"
          },
          "bodyText": "I have some questions about \"Solve did not converge\".\nI want to set the mobility function as c dependent variable, which equals to M=abs(1-c^2), which is the absolute value of (1-c^2). However, my simulation always cannot converge, even though the time steps go downs to 10e(-14). When I do not set mobility as a function of c and just set M=1 or other constant, using the same parameters, it can work and can get results. I wonder what's the problem? Why can't it run when using c dependent mobility? Could you give me some advice about this?\nThank you very much.\nThe following is my input file.\n[Mesh]\n  type = GeneratedMesh\n  dim = 2\n  elem_type = QUAD4\n  nx = 60\n  ny = 24\n  nz = 0\n  xmin = 0\n  xmax = 6.0\n  ymin = 0\n  ymax = 2.4\n  zmin = 0\n  zmax = 0\n  uniform_refine = 3\n  nemesis = true\n  skip_partitioning = true\n[]\n\n[Variables]\n\n  [./c]\n    order = FIRST\n    family = LAGRANGE\n    [./InitialCondition]\n      type = IsolatedBoundingBoxIC\n      smaller_coordinate_corners = '0.0 0.3 0   0.0 1.5 0  4.0 0.3 0   4.0 1.5 0  2.0 0.0 0'\n      larger_coordinate_corners =  '2.0 0.9 0   2.0 2.1 0  6.0 0.9 0   6.0 2.1 0  4.0 2.4 0'\n      inside = '1.0 1.0 1.0 1.0 0.0'\n      outside = -1.0\n      int_width = 0\n    [../]\n  [../]\n\n  [./w]\n    order = FIRST\n    family = LAGRANGE\n  [../]\n\n[]\n\n\n[BCs]\n  [./Periodic]\n    [./cx]\n      variable = c\n      auto_direction = 'x,y'\n    [../]\n    [./wx]\n      variable = w\n      auto_direction = 'x,y'\n    [../]\n  [../]\n\n[]\n\n\n[Kernels]\n  [./c_res]\n    type = SplitCHParsed\n    variable = c\n    f_name = F\n    kappa_name = kappa_c\n    w = w\n  [../]\n  [./w_res]\n    type = SplitCHWRes\n    variable = w\n    mob_name = M\n  [../]\n  [./time]\n    type = CoupledTimeDerivative\n    variable = w\n    v = c\n  [../]\n[]\n\n\n[Materials]\n  [./mobility]\n    type = DerivativeParsedMaterial\n    f_name = M\n    args = 'c'\n    function = abs(1-c^2)\n    derivative_order = 1\n  [../]\n\n  [./kappa_c]\n    type = GenericConstantMaterial\n    prop_names  = 'kappa_c'\n    prop_values = '8.0e-4'\n  [../]\n\n  [./free_energy]\n    # equivalent to `MathFreeEnergy`\n    type = DerivativeParsedMaterial\n    f_name = F\n    args = 'c'\n    function = (27/8)*c^2*(2-4*c^2+2*c^4)\n  [../]\n[]\n\n[Postprocessors]\n  [./step_size]             # Size of the time step\n    type = TimestepSize\n  [../]\n  [./iterations]            # Number of iterations needed to converge timestep\n    type = NumNonlinearIterations\n  [../]\n  [./nodes]                 # Number of nodes in mesh\n    type = NumNodes\n  [../]\n  [./evaluations]           # Cumulative residual calculations for simulation\n    type = NumResidualEvaluations\n  [../]\n  [./active_time]           # Time computer spent on simulation\n    type = PerfGraphData\n    section_name = \"Root\"\n    data_type = total\n  [../]\n  [./c]            # output concentration file\n    type = ElementAverageValue\n    variable = 'c'\n  [../]\n\n[]\n\n[VectorPostprocessors]\n  [./x_direc]\n   type =  LineValueSampler\n    start_point = '0 1.2 0'\n    end_point = '6 1.2 0'\n    variable = 'c'\n    num_points = 600\n    sort_by =  id\n  [../]\n[]\n\n\n\n[Preconditioning]\n  # active = ' '\n  [./SMP]\n    type = SMP\n    full = true\n  [../]\n[]\n\n[Executioner]\n  type = Transient\n  scheme = 'BDF2'\n  #petsc_options = '-snes_mf'\n\n  #Preconditioned JFNK (default)\n  solve_type = 'NEWTON'\n\n  petsc_options_iname = '-pc_type -ksp_grmres_restart -sub_ksp_type -sub_pc_type -pc_asm_overlap'\n  petsc_options_value = 'asm      31                  preonly       lu           1'\n  #petsc_options_iname = '-pc_type'\n  #petsc_options_value = 'lu'\n\n  l_max_its = 30 # maximum linear iterations\n  l_tol = 1.0e-6 # 0.001 Linear Tolerance\n\n  nl_max_its = 50 # maximum number of nonlinear iterations. exceed will cut dt.\n  nl_rel_tol = 1.0e-9 # -8 nonlinear relative tolerance\n  #num_steps = 2\n\n  [./TimeStepper]\n    type = IterationAdaptiveDT\n    dt = 1e-6\n    cutback_factor = 0.67\n    growth_factor = 1.5   # 1.6\n    optimal_iterations = 10\n    iteration_window = 2\n  [../]\n\n  [./Adaptivity]\n    coarsen_fraction = 0.1\n    refine_fraction = 0.7\n    max_h_level = 3\n    interval = 1\n  [../]\n[]\n\n[Debug]\n  show_var_residual_norms = true\n[]\n\n[Outputs]\n  exodus = true\n  console = true\n  csv = true\n  interval = 2\n  checkpoint = true\n  [./console]\n    type = Console\n    max_rows = 10\n  [../]\n[]",
          "url": "https://github.com/idaholab/moose/discussions/19427",
          "updatedAt": "2022-07-18T19:22:40Z",
          "publishedAt": "2021-11-19T04:45:54Z",
          "category": {
            "name": "Q&A Modules: Phase field"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "jiangwen84"
                  },
                  "bodyText": "Add line_search = 'none'  in [Executioner] block.",
                  "url": "https://github.com/idaholab/moose/discussions/19427#discussioncomment-1672069",
                  "updatedAt": "2022-07-18T19:22:46Z",
                  "publishedAt": "2021-11-19T17:58:57Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "abc-hy"
                          },
                          "bodyText": "I added, but it still cannot converge...",
                          "url": "https://github.com/idaholab/moose/discussions/19427#discussioncomment-1672851",
                          "updatedAt": "2022-07-18T19:22:43Z",
                          "publishedAt": "2021-11-19T21:24:14Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "jiangwen84"
                          },
                          "bodyText": "What is your output? Here are the outputs on my machine for the first two steps\nTime Step 0, time = 0\n\nPostprocessor Values:\n+----------------+----------------+----------------+----------------+----------------+----------------+----------------+\n| time           | active_time    | c              | evaluations    | iterations     | nodes          | step_size      |\n+----------------+----------------+----------------+----------------+----------------+----------------+----------------+\n|   0.000000e+00 |   0.000000e+00 |   0.000000e+00 |   0.000000e+00 |   0.000000e+00 |   0.000000e+00 |   0.000000e+00 |\n+----------------+----------------+----------------+----------------+----------------+----------------+----------------+\n\n\nTime Step 1, time = 1e-06, dt = 1e-06\n 0 Nonlinear |R| = 8.285239e-02\n    |residual|_2 of individual variables:\n                          c: 0.0828524\n                          w: 0\n      0 Linear |R| = 8.285239e-02\n      1 Linear |R| = 8.285200e-02\n      2 Linear |R| = 8.150147e-02\n      3 Linear |R| = 4.260034e-03\n      4 Linear |R| = 5.015487e-05\n      5 Linear |R| = 1.157116e-06\n      6 Linear |R| = 2.224111e-08\n 1 Nonlinear |R| = 1.815031e+02\n    |residual|_2 of individual variables:\n                          c: 0.0113577\n                          w: 181.503\n      0 Linear |R| = 1.815031e+02\n      1 Linear |R| = 5.486170e+00\n      2 Linear |R| = 7.953554e-02\n      3 Linear |R| = 8.190110e-04\n      4 Linear |R| = 1.888074e-05\n 2 Nonlinear |R| = 4.182435e+01\n    |residual|_2 of individual variables:\n                          c: 0.000538839\n                          w: 41.8243\n      0 Linear |R| = 4.182435e+01\n      1 Linear |R| = 8.875130e-01\n      2 Linear |R| = 1.523437e-02\n      3 Linear |R| = 1.150581e-04\n      4 Linear |R| = 3.098059e-06\n 3 Nonlinear |R| = 4.621102e+00\n    |residual|_2 of individual variables:\n                          c: 7.24766e-06\n                          w: 4.6211\n      0 Linear |R| = 4.621102e+00\n      1 Linear |R| = 8.304308e-02\n      2 Linear |R| = 1.760706e-03\n      3 Linear |R| = 1.010337e-05\n      4 Linear |R| = 3.136062e-07\n 4 Nonlinear |R| = 4.457247e-01\n    |residual|_2 of individual variables:\n                          c: 6.77449e-08\n                          w: 0.445725\n      0 Linear |R| = 4.457247e-01\n      1 Linear |R| = 7.753800e-03\n      2 Linear |R| = 1.641713e-04\n      3 Linear |R| = 9.331427e-07\n      4 Linear |R| = 2.891046e-08\n 5 Nonlinear |R| = 4.246875e-02\n    |residual|_2 of individual variables:\n                          c: 6.02473e-10\n                          w: 0.0424687\n      0 Linear |R| = 4.246875e-02\n      1 Linear |R| = 7.411905e-04\n      2 Linear |R| = 1.571718e-05\n      3 Linear |R| = 8.825800e-08\n      4 Linear |R| = 2.726539e-09\n 6 Nonlinear |R| = 4.041104e-03\n    |residual|_2 of individual variables:\n                          c: 5.45484e-12\n                          w: 0.0040411\n      0 Linear |R| = 4.041104e-03\n      1 Linear |R| = 7.078257e-05\n      2 Linear |R| = 1.503071e-06\n      3 Linear |R| = 8.375145e-09\n      4 Linear |R| = 2.598920e-10\n 7 Nonlinear |R| = 3.843661e-04\n    |residual|_2 of individual variables:\n                          c: 7.64895e-14\n                          w: 0.000384366\n      0 Linear |R| = 3.843661e-04\n      1 Linear |R| = 6.727144e-06\n      2 Linear |R| = 1.428448e-07\n      3 Linear |R| = 7.919418e-10\n      4 Linear |R| = 2.472098e-11\n 8 Nonlinear |R| = 3.655650e-05\n    |residual|_2 of individual variables:\n                          c: 5.48361e-15\n                          w: 3.65565e-05\n      0 Linear |R| = 3.655650e-05\n      1 Linear |R| = 6.387932e-07\n      2 Linear |R| = 1.355982e-08\n      3 Linear |R| = 7.488306e-11\n      4 Linear |R| = 2.346971e-12\n 9 Nonlinear |R| = 3.477132e-06\n    |residual|_2 of individual variables:\n                          c: 5.27632e-16\n                          w: 3.47713e-06\n      0 Linear |R| = 3.477132e-06\n      1 Linear |R| = 6.070457e-08\n      2 Linear |R| = 1.288444e-09\n      3 Linear |R| = 7.092992e-12\n      4 Linear |R| = 2.228944e-13\n10 Nonlinear |R| = 3.307543e-07\n    |residual|_2 of individual variables:\n                          c: 1.3744e-16\n                          w: 3.30754e-07\n      0 Linear |R| = 3.307543e-07\n      1 Linear |R| = 5.771057e-09\n      2 Linear |R| = 1.224883e-10\n      3 Linear |R| = 6.726408e-13\n      4 Linear |R| = 2.118326e-14\n11 Nonlinear |R| = 3.146314e-08\n    |residual|_2 of individual variables:\n                          c: 1.19667e-16\n                          w: 3.14631e-08\n      0 Linear |R| = 3.146314e-08\n      1 Linear |R| = 5.486476e-10\n      2 Linear |R| = 1.164456e-11\n      3 Linear |R| = 6.382546e-14\n      4 Linear |R| = 2.013889e-15\n12 Nonlinear |R| = 2.993009e-09\n    |residual|_2 of individual variables:\n                          c: 1.07805e-16\n                          w: 2.99301e-09\n      0 Linear |R| = 2.993009e-09\n      1 Linear |R| = 5.216475e-11\n      2 Linear |R| = 1.107121e-12\n      3 Linear |R| = 6.060069e-15\n      4 Linear |R| = 1.915544e-16\n13 Nonlinear |R| = 2.847066e-10\n    |residual|_2 of individual variables:\n                          c: 9.72036e-17\n                          w: 2.84707e-10\n      0 Linear |R| = 2.847066e-10\n      1 Linear |R| = 4.958110e-12\n      2 Linear |R| = 1.052049e-13\n      3 Linear |R| = 5.723158e-16\n      4 Linear |R| = 1.812027e-17\n14 Nonlinear |R| = 2.712280e-11\n    |residual|_2 of individual variables:\n                          c: 9.22088e-17\n                          w: 2.71228e-11\n Solve Converged!\n  Finished Solving                                                                       [  5.04 s] [   71 MB]\n\nPostprocessor Values:\n+----------------+----------------+----------------+----------------+----------------+----------------+----------------+\n| time           | active_time    | c              | evaluations    | iterations     | nodes          | step_size      |\n+----------------+----------------+----------------+----------------+----------------+----------------+----------------+\n|   0.000000e+00 |   0.000000e+00 |   0.000000e+00 |   0.000000e+00 |   0.000000e+00 |   0.000000e+00 |   0.000000e+00 |\n|   1.000000e-06 |   1.093813e+01 |   1.384549e-02 |   1.600000e+01 |   1.400000e+01 |   9.283300e+04 |   1.000000e-06 |\n+----------------+----------------+----------------+----------------+----------------+----------------+----------------+\n\n\nTime Step 2, time = 1.67e-06, dt = 6.7e-07\n 0 Nonlinear |R| = 1.229267e+03\n    |residual|_2 of individual variables:\n                          c: 0.00252969\n                          w: 1229.27\n      0 Linear |R| = 1.229267e+03\n      1 Linear |R| = 7.734829e+00\n      2 Linear |R| = 1.327525e-01\n      3 Linear |R| = 1.205157e-03\n 1 Nonlinear |R| = 3.064926e+01\n    |residual|_2 of individual variables:\n                          c: 0.0013772\n                          w: 30.6493\n      0 Linear |R| = 3.064926e+01\n      1 Linear |R| = 9.227145e-01\n      2 Linear |R| = 1.189050e-02\n      3 Linear |R| = 1.772888e-04\n      4 Linear |R| = 3.157499e-06\n 2 Nonlinear |R| = 1.260911e+00\n    |residual|_2 of individual variables:\n                          c: 2.65882e-06\n                          w: 1.26091\n      0 Linear |R| = 1.260911e+00\n      1 Linear |R| = 4.084877e-03\n      2 Linear |R| = 2.466497e-04\n      3 Linear |R| = 2.018710e-06\n      4 Linear |R| = 5.770113e-08\n 3 Nonlinear |R| = 2.801769e-02\n    |residual|_2 of individual variables:\n                          c: 2.24828e-09\n                          w: 0.0280177\n      0 Linear |R| = 2.801769e-02\n      1 Linear |R| = 1.622836e-04\n      2 Linear |R| = 3.441862e-06\n      3 Linear |R| = 3.355155e-08\n      4 Linear |R| = 1.510242e-09\n 4 Nonlinear |R| = 5.889715e-04\n    |residual|_2 of individual variables:\n                          c: 9.66277e-13\n                          w: 0.000588971\n      0 Linear |R| = 5.889715e-04\n      1 Linear |R| = 5.029289e-06\n      2 Linear |R| = 1.174423e-07\n      3 Linear |R| = 1.119917e-09\n      4 Linear |R| = 4.734060e-11\n 5 Nonlinear |R| = 1.244730e-05\n    |residual|_2 of individual variables:\n                          c: 2.99929e-14\n                          w: 1.24473e-05\n      0 Linear |R| = 1.244730e-05\n      1 Linear |R| = 4.605462e-08\n      2 Linear |R| = 2.306548e-09\n      3 Linear |R| = 1.713258e-11\n      4 Linear |R| = 6.023799e-13\n 6 Nonlinear |R| = 3.065976e-07\n    |residual|_2 of individual variables:\n                          c: 3.8171e-15\n                          w: 3.06598e-07\n Solve Converged!",
                          "url": "https://github.com/idaholab/moose/discussions/19427#discussioncomment-1672898",
                          "updatedAt": "2022-07-18T19:22:43Z",
                          "publishedAt": "2021-11-19T21:35:53Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "abc-hy"
                          },
                          "bodyText": "",
                          "url": "https://github.com/idaholab/moose/discussions/19427#discussioncomment-1672947",
                          "updatedAt": "2022-07-18T19:22:54Z",
                          "publishedAt": "2021-11-19T21:48:49Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "abc-hy"
                          },
                          "bodyText": "Your simulation can converge??? I cannot converge....Why is this?",
                          "url": "https://github.com/idaholab/moose/discussions/19427#discussioncomment-1672952",
                          "updatedAt": "2022-07-20T15:39:21Z",
                          "publishedAt": "2021-11-19T21:49:35Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "abc-hy"
                          },
                          "bodyText": "Is there any problem in the settings of my MOOSE software that makes the simulation cannot converge?",
                          "url": "https://github.com/idaholab/moose/discussions/19427#discussioncomment-1672954",
                          "updatedAt": "2022-07-20T15:39:20Z",
                          "publishedAt": "2021-11-19T21:50:41Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "jiangwen84"
                          },
                          "bodyText": "Show me your Executioner block. Did you add line_search=none?",
                          "url": "https://github.com/idaholab/moose/discussions/19427#discussioncomment-1672963",
                          "updatedAt": "2022-07-20T15:39:20Z",
                          "publishedAt": "2021-11-19T21:57:11Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "abc-hy"
                          },
                          "bodyText": "I added it.",
                          "url": "https://github.com/idaholab/moose/discussions/19427#discussioncomment-1673017",
                          "updatedAt": "2022-07-20T15:39:21Z",
                          "publishedAt": "2021-11-19T22:18:56Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "jiangwen84"
                          },
                          "bodyText": "It is interesting. I used a Mac. Both 1 and 10 MPI processes were running fine.\nAdd '-snes_converged_reason' in your command line and let us know what is the reason for not converging.",
                          "url": "https://github.com/idaholab/moose/discussions/19427#discussioncomment-1673288",
                          "updatedAt": "2022-07-20T15:39:20Z",
                          "publishedAt": "2021-11-19T23:54:32Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "abc-hy"
                          },
                          "bodyText": "Do you mean, typing '-snes_converged_reason' in the command line when I am running the simulation?\nI am using windows subsystem of linux.",
                          "url": "https://github.com/idaholab/moose/discussions/19427#discussioncomment-1673417",
                          "updatedAt": "2022-07-20T15:39:20Z",
                          "publishedAt": "2021-11-20T01:05:22Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "abc-hy"
                          },
                          "bodyText": "Do you mean, add '-snes_converged_reason' in the input file? And let it run?",
                          "url": "https://github.com/idaholab/moose/discussions/19427#discussioncomment-1673426",
                          "updatedAt": "2022-07-20T15:39:20Z",
                          "publishedAt": "2021-11-20T01:09:40Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "defining the BC regarding the defromation gradient",
          "author": {
            "login": "mFathidoost"
          },
          "bodyText": "HI,\nI have a given gradient defromatin matrix. I need to define the BC of a 2D RVE in order to deform corresponding to the given gradient deformation. Do you know if MOOSE is possible to do that for me automatically? It mean that instead of BC I just enter the deformation gradient matrix. If yes via which module?\nthank you very much",
          "url": "https://github.com/idaholab/moose/discussions/19487",
          "updatedAt": "2023-02-16T11:33:34Z",
          "publishedAt": "2021-11-25T13:43:52Z",
          "category": {
            "name": "Q&A Modules: Solid mechanics"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "hugary1995"
                  },
                  "bodyText": "I suppose by deformation gradient you are implying large deformation. You can use the global strain system in the tensor mechanics module to do that.\nThe global strain system isn't strictly equivalent to a standard KUBC. There's a new PR #17475 to address that.",
                  "url": "https://github.com/idaholab/moose/discussions/19487#discussioncomment-1702981",
                  "updatedAt": "2023-02-16T11:33:34Z",
                  "publishedAt": "2021-11-26T00:18:32Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": []
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "How to calculate the off-diagonal terms of the Jacobian in CoupledVarNeumannBC",
          "author": {
            "login": "aaelmeli"
          },
          "bodyText": "Hi\nI recently encountered a problem where I have two Linear Systems that are coupled only on the boundaries.  The CoupledVarNeumannBC  object was used to achieve the coupling. The issue is, CoupledVarNeumannBC does not have a method that provides the Jacobian. This means that, whenever a direct linear solver is used, it will not show any coupling because the contribution of the CoupledVarNeumannBC  to the off-diagonal terms in the Jacobian is zero. This enforces using a nonlinear solver where the Jacobian can be approximated numerically using for example FD. This issue was under discussion in #19365 where @GiudGiud had fruitful thoughts. The issue is, for some coupled PDEs, like the one in #19365, this would result in slow convergence or even divergence.\nSo, I am re-posting the following question here to have better visibility in case anyone encountered a similar problem.\nThe question is, Is it possible to implement a function that calculates the Jacobian terms of the CoupledVarNeumannBC object? Any thoughts on the implementation?",
          "url": "https://github.com/idaholab/moose/discussions/19465",
          "updatedAt": "2022-09-01T17:13:32Z",
          "publishedAt": "2021-11-23T20:21:05Z",
          "category": {
            "name": "Q&A General"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "lindsayad"
                  },
                  "bodyText": "This class was added in #13503 for use with aux variables. We should update this class in order to provide Jacobian calculations if the coupled variable is a \"nonlinear\" variable.",
                  "url": "https://github.com/idaholab/moose/discussions/19465#discussioncomment-1690332",
                  "updatedAt": "2022-09-01T17:13:32Z",
                  "publishedAt": "2021-11-23T21:23:25Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "lindsayad"
                          },
                          "bodyText": "I've created #19468 to address this",
                          "url": "https://github.com/idaholab/moose/discussions/19465#discussioncomment-1690347",
                          "updatedAt": "2022-09-01T17:13:33Z",
                          "publishedAt": "2021-11-23T21:27:30Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "aaelmeli"
                          },
                          "bodyText": "I've created #19468 to address this\n\nThank you.",
                          "url": "https://github.com/idaholab/moose/discussions/19465#discussioncomment-1690414",
                          "updatedAt": "2022-09-01T17:13:33Z",
                          "publishedAt": "2021-11-23T21:47:17Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "@aaelmeli Alex made a PR and it is merged in the framework. Can you please try again now?",
                          "url": "https://github.com/idaholab/moose/discussions/19465#discussioncomment-1697772",
                          "updatedAt": "2022-09-01T17:13:33Z",
                          "publishedAt": "2021-11-25T04:00:45Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "aaelmeli"
                          },
                          "bodyText": "@aaelmeli Alex made a PR and it is merged in the framework. Can you please try again now?\n\nI have tested it, it works just fine. Thank you, @lindsayad and @GiudGiud",
                          "url": "https://github.com/idaholab/moose/discussions/19465#discussioncomment-1702075",
                          "updatedAt": "2022-09-01T17:13:35Z",
                          "publishedAt": "2021-11-25T18:27:39Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "N-S module calculation error, EXIT CODE: 9",
          "author": {
            "login": "ScouperLH"
          },
          "bodyText": "Hello everyone,\nAccept my warm greetings.\nI used to calculate the flow and heat transfer in an \"S\"-shaped pipe.\nThe error is reported as follows.\n\nMy files as follows:\n\nmu = 0.1\nrho = 1\nk = .01\ncp = 1\nvel = 'velocity'\nvelocity_interp_method = 'rc'\nadvected_interp_method = 'average'\n\n[Mesh]\n  type = FileMesh #Read in mesh from file\n  file = channel.e\n[]\n\n[Problem]\n  fv_bcs_integrity_check = true\n[]\n\n[Variables]\n  [u]\n    type = INSFVVelocityVariable\n    initial_condition = 1\n  []\n  [v]\n    type = INSFVVelocityVariable\n    initial_condition = 1\n  []\n  [w]\n    type = INSFVVelocityVariable\n    initial_condition = 1\n  []\n  [T]\n    type = INSFVEnergyVariable\n  []\n  [pressure]\n    type = INSFVPressureVariable\n  []\n  [lambda]\n    family = SCALAR\n    order = FIRST\n  []\n[]\n\n[ICs]\n  [T]\n    type = ConstantIC\n    variable = T\n    value = 300\n  []\n[]\n\n[AuxVariables]\n  [U]\n    order = CONSTANT\n    family = MONOMIAL\n    fv = true\n  []\n[]\n\n[AuxKernels]\n  [mag]\n    type = VectorMagnitudeAux\n    variable = U\n    x = u\n    y = v\n    z= w\n  []\n[]\n\n\n[FVKernels]\n  [mass]\n    type = INSFVMassAdvection\n    variable = pressure\n    advected_interp_method = ${advected_interp_method}\n    velocity_interp_method = ${velocity_interp_method}\n    vel = 'velocity'\n    pressure = pressure\n    u = u\n    v = v\n    w= w\n    mu = ${mu}\n    rho = ${rho}\n  []\n  [mean_zero_pressure]\n    type = FVScalarLagrangeMultiplier\n    variable = pressure\n    lambda = lambda\n  []\n\n  [u_time]\n    type = INSFVMomentumTimeDerivative\n    variable = 'u'\n    rho = ${rho}\n []\n  [u_advection]\n    type = INSFVMomentumAdvection\n    variable = u\n    advected_quantity = 'rhou'\n    vel = 'velocity'\n    advected_interp_method = ${advected_interp_method}\n    velocity_interp_method = ${velocity_interp_method}\n    pressure = pressure\n    u = u\n    v = v\n    w=w\n    mu = ${mu}\n    rho = ${rho}\n  []\n  [u_viscosity]\n    type = FVDiffusion\n    variable = u\n    coeff = ${mu}\n  []\n  [u_pressure]\n    type = INSFVMomentumPressure\n    variable = u\n    momentum_component = 'x'\n    pressure = pressure\n  []\n\n  [v_time]\n    type = INSFVMomentumTimeDerivative\n    variable = v\n    rho = ${rho}\n  []\n  [v_advection]\n    type = INSFVMomentumAdvection\n    variable = v\n    advected_quantity = 'rhov'\n    vel = 'velocity'\n    advected_interp_method = ${advected_interp_method}\n    velocity_interp_method = ${velocity_interp_method}\n    pressure = pressure\n    u = u\n    v = v\n    w=w\n    mu = ${mu}\n    rho = ${rho}\n  []\n  [v_viscosity]\n    type = FVDiffusion\n    variable = v\n    coeff = ${mu}\n  []\n  [v_pressure]\n    type = INSFVMomentumPressure\n    variable = v\n    momentum_component = 'y'\n    pressure = pressure\n  []\n\n  [w_time]\n    type = INSFVMomentumTimeDerivative\n    variable = w\n    rho = ${rho}\n  []\n [w_advection]\n    type = INSFVMomentumAdvection\n    variable = w\n    advected_quantity = 'rhow'\n    vel = 'velocity'\n    advected_interp_method = ${advected_interp_method}\n    velocity_interp_method = ${velocity_interp_method}\n    pressure = pressure\n    u = u\n    v = v\n    w=w\n    mu = ${mu}\n    rho = ${rho}\n  []\n  [w_viscosity]\n    type = FVDiffusion\n    variable = w\n    coeff = ${mu}\n  []\n  [w_pressure]\n    type = INSFVMomentumPressure\n    variable = w\n    momentum_component = 'z'\n    pressure = pressure\n  []\n\n  [temp_time]\n    type = INSFVEnergyTimeDerivative\n    variable = T\n    rho = ${rho}\n    cp_name = 'cp'\n  []\n  [temp_conduction]\n    type = FVDiffusion\n    coeff = 'k'\n    variable = T\n  []\n  [temp_advection]\n    type = INSFVEnergyAdvection\n    variable = T\n    vel = ${vel}\n    velocity_interp_method = ${velocity_interp_method}\n    advected_interp_method = ${advected_interp_method}\n    pressure = pressure\n    u = u\n    v = v\n    w= w\n    mu = ${mu}\n    rho = ${rho}\n  []\n[]\n\n[FVBCs]\n  [inlet-u]\n    type = INSFVInletVelocityBC\n    boundary = 'inlet'\n    variable = u\n    function = '1'\n  []\n  [inlet-v]\n    type = INSFVInletVelocityBC\n    boundary = 'inlet'\n    variable = v\n    function = '0'\n  []\n [inlet-w]\n    type = INSFVInletVelocityBC\n    boundary = 'inlet'\n    variable = w\n    function = '0'\n  []\n\n  [walls-u]\n    type = INSFVNoSlipWallBC\n    boundary = 'walltop wallbtm wallin wallout'\n    variable = u\n    function = 0\n  []\n  [walls-v]\n    type = INSFVNoSlipWallBC\n    boundary = 'walltop wallbtm wallin wallout'\n    variable = v\n    function = 0\n  []\n  [walls-w]\n    type = INSFVNoSlipWallBC\n    boundary = 'walltop wallbtm wallin wallout'\n    variable = w\n    function = 0\n  []\n  [T_hot]\n    type = FVDirichletBC\n    variable = T\n    boundary = 'walltop'\n    value = 310\n  []\n\n  [T_cold]\n    type = FVDirichletBC\n    variable = T\n    boundary = 'wallbtm'\n    value = 300\n  []\n\n  [outlet_p]\n    type = INSFVOutletPressureBC\n    boundary = 'outlet'\n    variable = pressure\n    function = '0'\n  []\n[]\n\n[Materials]\n  [functor_constants]\n    type = ADGenericConstantFunctorMaterial\n    prop_names = 'cp k'\n    prop_values = '${cp} ${k}'\n  []\n  [ins_fv]\n    type = INSFVMaterial\n    u = 'u'\n    v = 'v'\n    w = 'w'\n    pressure = 'pressure'\n    temperature = 'T'\n    rho = ${rho}\n  []\n[]\n\n[Executioner]\n  type = Transient\n  solve_type = 'NEWTON'\n  num_steps = 20\n  dt = .5\n  dtmin = .5\n  petsc_options_iname = '-pc_type -ksp_gmres_restart -sub_pc_type -sub_pc_factor_shift_type'\n  petsc_options_value = 'asm      200                lu           NONZERO'\n  line_search = 'none'\n  nl_abs_tol = 1e-10\n  nl_max_its = 50\n  l_max_its = 200\n[]\n\n[Outputs]\n  exodus = true\n  csv = true\n  perf_graph = true # prints a performance report to the terminal\n[]\n\nI used the command \u201c mpiexec -n 4\u201d, but  it's also keep slowly.\nHow can I debug it?\nThanks for your reading.",
          "url": "https://github.com/idaholab/moose/discussions/19460",
          "updatedAt": "2022-07-02T17:54:59Z",
          "publishedAt": "2021-11-23T13:57:07Z",
          "category": {
            "name": "Q&A General"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "lindsayad"
                  },
                  "bodyText": "Hi, that error message typically indicates that you are out of memory. What is your MOOSE revision? This should be printed shortly above the top of the text that you pasted in here. Also, how much memory is on your machine?",
                  "url": "https://github.com/idaholab/moose/discussions/19460#discussioncomment-1688953",
                  "updatedAt": "2022-07-02T17:56:20Z",
                  "publishedAt": "2021-11-23T17:02:44Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "ScouperLH"
                          },
                          "bodyText": "HELLO, Thanks for your answer.\nMy MOOSE revision is git commit d4b8ea6 on 2021-11-22\n.\nI use a VMware to run the test, it has 33GB memory,16CPUs. I have tried again, used 16 CPUs\uff0cthe same error message appeared.",
                          "url": "https://github.com/idaholab/moose/discussions/19460#discussioncomment-1691281",
                          "updatedAt": "2022-07-02T17:56:21Z",
                          "publishedAt": "2021-11-24T03:01:49Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "I think the memory graph shows you are running out of memory",
                          "url": "https://github.com/idaholab/moose/discussions/19460#discussioncomment-1691295",
                          "updatedAt": "2022-07-02T17:56:55Z",
                          "publishedAt": "2021-11-24T03:04:30Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "ScouperLH"
                          },
                          "bodyText": "You are right, now I will try the following:\n\nIncrease the memory of the virtual machine;\nSimplify the pipeline;\nTry to use the PJFNK method of calculation.\nI will report my results later.",
                          "url": "https://github.com/idaholab/moose/discussions/19460#discussioncomment-1691331",
                          "updatedAt": "2022-07-02T17:56:56Z",
                          "publishedAt": "2021-11-24T03:18:48Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "These are all good ideas. Another two are to rework the mesh and to turn off cell_gradient_caching for each variable. That will slow down the code a bit but it ll cut the memory cost.\nhttps://mooseframework.inl.gov/source/variables/MooseVariableFV.html",
                          "url": "https://github.com/idaholab/moose/discussions/19460#discussioncomment-1691346",
                          "updatedAt": "2022-07-05T02:42:33Z",
                          "publishedAt": "2021-11-24T03:23:19Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "lindsayad"
                          },
                          "bodyText": "You may also try using a distributed mesh. I hate to say it but PJFNK will not save you any memory here. We use AD and fill out all the non-zero coupling entries in the preconditioning matrix.\nYou may consider memory profiling and seeing where the highest memory use is. Turning cell_gradient_caching = false in all your variable blocks would be a big memory save as @GiudGiud suggested. I'd definitely start there and with a distributed mesh (after increasing your virtual machine's memory)",
                          "url": "https://github.com/idaholab/moose/discussions/19460#discussioncomment-1691371",
                          "updatedAt": "2022-07-05T02:42:33Z",
                          "publishedAt": "2021-11-24T03:32:52Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "lindsayad"
                          },
                          "bodyText": "Oh I forgot to ask ... what is your -pc_type? That will play a significant role in memory usage",
                          "url": "https://github.com/idaholab/moose/discussions/19460#discussioncomment-1691378",
                          "updatedAt": "2022-07-05T02:42:33Z",
                          "publishedAt": "2021-11-24T03:36:02Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "ScouperLH"
                          },
                          "bodyText": "Oh I forgot to ask ... what is your -pc_type? That will play a significant role in memory usage\n\nIt's '-pc_type -ksp_gmres_restart -sub_pc_type -sub_pc_factor_shift_type'.",
                          "url": "https://github.com/idaholab/moose/discussions/19460#discussioncomment-1691393",
                          "updatedAt": "2022-07-05T02:43:55Z",
                          "publishedAt": "2021-11-24T03:42:45Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "also I would remove this\n[AuxVariables]\n  [U]\n    order = CONSTANT\n    family = MONOMIAL\n    fv = true\n  []\n[]\n\n[AuxKernels]\n  [mag]\n    type = VectorMagnitudeAux\n    variable = U\n    x = u\n    y = v\n    z= w\n  []\n[]\n\nthis is for postprocessing and you can do that operation in paraview easily",
                          "url": "https://github.com/idaholab/moose/discussions/19460#discussioncomment-1691423",
                          "updatedAt": "2022-07-05T02:42:33Z",
                          "publishedAt": "2021-11-24T03:50:57Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "@ScouperLH we need the petsc_values as well not just the names\nnevermind it s in the input file\npetsc_options_iname = '-pc_type -ksp_gmres_restart -sub_pc_type -sub_pc_factor_shift_type'\npetsc_options_value = 'asm      200                lu           NONZERO'\nbuilding that Krylov base is for sure expensive. @lindsayad what do you recommend?",
                          "url": "https://github.com/idaholab/moose/discussions/19460#discussioncomment-1691425",
                          "updatedAt": "2022-07-05T02:45:19Z",
                          "publishedAt": "2021-11-24T03:51:49Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "lindsayad"
                          },
                          "bodyText": "IIRC PETSc does not allocate memory for all the GMRES vectors up front. I believe it allocates every 30 iterations or so as needed. @fdkong could comment on this. I think at this point we are kind of guessing what the big memory contributors are. A heap profile would settle this right away. It looks like these are all MOOSE objects. @ScouperLH how large is your mesh? If it's not too egregiously large, you can send it to alexlindsay239@gmail.com (or I suppose send me a google drive link), and I could profile this problem for you.",
                          "url": "https://github.com/idaholab/moose/discussions/19460#discussioncomment-1694750",
                          "updatedAt": "2022-07-05T02:45:26Z",
                          "publishedAt": "2021-11-24T15:39:17Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              },
              {
                "node": {
                  "author": {
                    "login": "ScouperLH"
                  },
                  "bodyText": "These are all good ideas. Another two are to rework the mesh and to turn off cell_gradient_caching for each variable. That will slow down the code a bit but it ll cut the memory cost. https://mooseframework.inl.gov/source/variables/MooseVariableFV.html\n\nThank you, I will try your suggestion.\nAnd as @lindsayad says, I use PJFNK to calculate, but it not save the memory. Also thanks for your answer!@lindsayad",
                  "url": "https://github.com/idaholab/moose/discussions/19460#discussioncomment-1691411",
                  "updatedAt": "2022-07-02T17:57:07Z",
                  "publishedAt": "2021-11-24T03:48:30Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "We've used AD in the finite volume for Navier Stokes. So we have a perfect numerical Jacobian and you might as well use it with Newton instead of PJFNK. Only reason to use PJFNK would be for memory imo, or if some other parts of the model didnt use AD",
                          "url": "https://github.com/idaholab/moose/discussions/19460#discussioncomment-1691479",
                          "updatedAt": "2022-07-02T17:57:10Z",
                          "publishedAt": "2021-11-24T04:11:40Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "lindsayad"
                          },
                          "bodyText": "@GiudGiud the issue is that with AD we fill the whole matrix (we don't respect users request for block diagonal or other custom sparsity pattern), so PJFNK and NEWTON will have the same memory requirements. So given that, indeed you should always use NEWTON when you are using AD as it will consume the same amount of memory and likely be way faster",
                          "url": "https://github.com/idaholab/moose/discussions/19460#discussioncomment-1694771",
                          "updatedAt": "2022-07-02T17:57:17Z",
                          "publishedAt": "2021-11-24T15:41:51Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              },
              {
                "node": {
                  "author": {
                    "login": "friedmud"
                  },
                  "bodyText": "You are using LU - sure... it's only on the parallel partitions with ASM... but LU will still take quite a lot of memory.  Try switching to something else like ILU with a small amount of fill to save even more RAM.",
                  "url": "https://github.com/idaholab/moose/discussions/19460#discussioncomment-1694867",
                  "updatedAt": "2022-07-02T17:57:50Z",
                  "publishedAt": "2021-11-24T15:54:47Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "fdkong"
                          },
                          "bodyText": "This is right. If we do not make any mistake, LU memory will dominate the whole simulation. It will be helpful if you could tell us, DoFs and Number of elements/nodes",
                          "url": "https://github.com/idaholab/moose/discussions/19460#discussioncomment-1695245",
                          "updatedAt": "2022-07-02T17:57:50Z",
                          "publishedAt": "2021-11-24T16:49:55Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "ScouperLH"
                          },
                          "bodyText": "Ok,it's the DoF, nodes and elements.",
                          "url": "https://github.com/idaholab/moose/discussions/19460#discussioncomment-1697463",
                          "updatedAt": "2022-07-02T17:58:04Z",
                          "publishedAt": "2021-11-25T01:56:03Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "fdkong"
                          },
                          "bodyText": "Thanks for information.  You have about half million DoFs, and you could run out of memory with ASM (LU) if the machine does not have enough memory.\nHow much memory you have on machine you were running? How much memory per core?",
                          "url": "https://github.com/idaholab/moose/discussions/19460#discussioncomment-1697489",
                          "updatedAt": "2022-07-02T17:58:26Z",
                          "publishedAt": "2021-11-25T02:05:33Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "ScouperLH"
                          },
                          "bodyText": "When I first calculated, my VMware is 33GB, 16cores, and per core has 2GB. Then I changed the memory to 50GB, but the memory is still not enough, which is unreasonable for a geometric model of this scale. I imported the grid into Fluent and set up a simple laminar flow model calculation to confirm that there is no problem with the grid. Finally, I simplified the geometric model, and I will report to you after the post-processing confirms that the result is correct.",
                          "url": "https://github.com/idaholab/moose/discussions/19460#discussioncomment-1697515",
                          "updatedAt": "2022-07-05T02:46:35Z",
                          "publishedAt": "2021-11-25T02:16:33Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "fdkong"
                          },
                          "bodyText": "Just for debugging. Could you change your input file to take this? As Derek mentioned earlier, to replace LU with ILU to save memory.\n  petsc_options_iname = '-pc_type -ksp_gmres_restart -sub_pc_type -sub_pc_factor_shift_type'\n  petsc_options_value = 'asm      200                ilu           NONZERO' \n\nIf this won't work, we might actually have some memory issue somewhere. In that case, it would be really helpful if you would share an example with us,  and we will try to nail down the issue",
                          "url": "https://github.com/idaholab/moose/discussions/19460#discussioncomment-1697551",
                          "updatedAt": "2022-07-05T02:46:35Z",
                          "publishedAt": "2021-11-25T02:26:54Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "ScouperLH"
                          },
                          "bodyText": "After modificated ILU it worked, I'm uploading my files to share you later.",
                          "url": "https://github.com/idaholab/moose/discussions/19460#discussioncomment-1697608",
                          "updatedAt": "2022-07-05T02:46:43Z",
                          "publishedAt": "2021-11-25T02:53:18Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "fdkong"
                          },
                          "bodyText": "That meant you should select a memory-efficient solver. If ILU works for you, you could keep using that. Linear solver/preconditioner and nonlinear solver are problem-dependent and sometimes tricky. This might improve in the future as the team is working on a dedicated CFD solver strategy.",
                          "url": "https://github.com/idaholab/moose/discussions/19460#discussioncomment-1697640",
                          "updatedAt": "2022-07-05T02:47:07Z",
                          "publishedAt": "2021-11-25T03:05:28Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              },
              {
                "node": {
                  "author": {
                    "login": "ScouperLH"
                  },
                  "bodyText": "Hello, moose experts, I have made the following modifications and tests:\n\n\nModify the variable cache and delete auxiliary variables.@GiudGiud  Run again and the same error message appears.\nAt the same time, the PJFNK method does not reduce memory consumption, which has been described in the previous comments.@lindsayad\n\n\nIncrease the memory to 64GB and redraw the geometric model and grid blend&channel/blend.e (in fact, new elems&nodes did not decrease, they increased, because I mistook the  grid number of the first model. The skewness of the new grid is better than that of the old grid.  They are in https://github.com/ScouperLH/bflow2.git )\n\n\nResults: the new grid run in the same inputfile (channel-3d2. i). It should be emphasized that the Lu command used by the solver uses 54gb of memory. Finally, the result is calculated. At present, I have no post-processing results, because I am still learning paraview, and may try to use Tecplot.\n\n\nFollowing suggestion of @friedmud @fdkong , I modified the solver command to ILU, which can successfully calculate the input files of blend model and channel model, and the memory usage is about 20GB.\n\n\nBUT, when I used ILU calculate channel-3d1st2.i  (with channel.e)\uff0cnew error appears:",
                  "url": "https://github.com/idaholab/moose/discussions/19460#discussioncomment-1698939",
                  "updatedAt": "2022-07-02T17:58:38Z",
                  "publishedAt": "2021-11-25T09:16:41Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "ScouperLH"
                          },
                          "bodyText": "I just recalculated this file, modified the parameters according to gambka 's comment\uff0c the error disappeared, and got the result.",
                          "url": "https://github.com/idaholab/moose/discussions/19460#discussioncomment-1699601",
                          "updatedAt": "2022-07-02T17:58:49Z",
                          "publishedAt": "2021-11-25T11:12:35Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "how big was the latest time step? I m going to fix that",
                          "url": "https://github.com/idaholab/moose/discussions/19460#discussioncomment-1700063",
                          "updatedAt": "2022-07-02T17:58:50Z",
                          "publishedAt": "2021-11-25T12:27:54Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "the one that failed that is",
                          "url": "https://github.com/idaholab/moose/discussions/19460#discussioncomment-1700075",
                          "updatedAt": "2022-07-02T17:58:50Z",
                          "publishedAt": "2021-11-25T12:29:53Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "ScouperLH"
                          },
                          "bodyText": "how big was the latest time step? I m going to fix that\n\nTime Step 20, time = 10, dt = 0.5\n\nWhen it calculate in Step 19, error occur. It was very close to the solution.",
                          "url": "https://github.com/idaholab/moose/discussions/19460#discussioncomment-1700189",
                          "updatedAt": "2022-07-05T02:47:56Z",
                          "publishedAt": "2021-11-25T12:50:32Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "Umm ok so what did you change?\nThe comment you linked is related to the time stepper just missing it s end time by a tiny fraction, and the solver dying when trying to solve for 1e-14 s .  I m looking for the magnitude of the tiny step it took in your case, if that was the problem",
                          "url": "https://github.com/idaholab/moose/discussions/19460#discussioncomment-1700274",
                          "updatedAt": "2022-07-05T02:47:56Z",
                          "publishedAt": "2021-11-25T13:05:49Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "ScouperLH"
                          },
                          "bodyText": "I change the nl_abs_tol=1.1-10",
                          "url": "https://github.com/idaholab/moose/discussions/19460#discussioncomment-1700287",
                          "updatedAt": "2022-07-05T02:47:56Z",
                          "publishedAt": "2021-11-25T13:07:56Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "oh ok that's not the same thing then.\nbtw it usually helps to scale your non-linear variables to reduce the residual / help convergence. You can do that manually for each variable or use automatic scaling. some docs:\nauto scaling: https://mooseframework.inl.gov/newsletter/2019_07.html\nmanual scaling: https://mooseframework.inl.gov/modules/porous_flow/convergence.html",
                          "url": "https://github.com/idaholab/moose/discussions/19460#discussioncomment-1700318",
                          "updatedAt": "2022-07-05T02:47:56Z",
                          "publishedAt": "2021-11-25T13:13:18Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "ScouperLH"
                          },
                          "bodyText": "Ok, I will read the files",
                          "url": "https://github.com/idaholab/moose/discussions/19460#discussioncomment-1700418",
                          "updatedAt": "2022-07-05T02:48:10Z",
                          "publishedAt": "2021-11-25T13:31:40Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      }
    ]
  }
}