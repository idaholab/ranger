{
  "discussions": {
    "pageInfo": {
      "hasNextPage": true,
      "endCursor": "Y3Vyc29yOnYyOpK5MjAyMS0wNS0wNlQxNjoyMjoyNi0wNjowMM4AMqqQ"
    },
    "edges": [
      {
        "node": {
          "title": "defineLegacyParams ()",
          "author": {
            "login": "styyokuda"
          },
          "bodyText": "MOOSE group,\nI am learning the MOOSE program. Please help me.\nI see in the header file:\ntemplate <>\nInputParameters validParams();\nThen, in the source file:\ndefineLegacyParams (DirichletBC);\nI don't see them for ADDirichletBC.\nPlease let me know why defineLegacyParams (ADDirichletBC) is not needed for the AD version.\nThomas",
          "url": "https://github.com/idaholab/moose/discussions/17798",
          "updatedAt": "2023-05-23T02:14:46Z",
          "publishedAt": "2021-05-11T15:06:14Z",
          "category": {
            "name": "Q&A General"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "GiudGiud"
                  },
                  "bodyText": "Hi Thomas\nThese is legacy code that is kept only in older object for compatibility with applications that would not have updated the way they use input parameters.\nAll new objects do not need this, and it's probably why the AD version, which came later, does not have it.\nGuillaume",
                  "url": "https://github.com/idaholab/moose/discussions/17798#discussioncomment-724535",
                  "updatedAt": "2023-05-23T02:14:58Z",
                  "publishedAt": "2021-05-11T15:43:44Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "styyokuda"
                          },
                          "bodyText": "Thank you very much Guillaume!\nThomas",
                          "url": "https://github.com/idaholab/moose/discussions/17798#discussioncomment-725336",
                          "updatedAt": "2023-05-23T02:15:10Z",
                          "publishedAt": "2021-05-11T18:24:11Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "AD material properties vs regular material properties",
          "author": {
            "login": "rh201"
          },
          "bodyText": "Hi all, when I run the code which contains block [[Modules/TensorMechanics/Master] [all]], there is an error as follows, do you ever occur the same/similar error and how to correct it?  And what is the difference between AD material properties and regular material properties? Thank you.\n*** ERROR ***\nThe requested AD material property mechanical_strain is declared as a regular material property. Either retrieve it as a regular material property with getMaterialProperty or declare it as an AD property wtih declareADProperty",
          "url": "https://github.com/idaholab/moose/discussions/17786",
          "updatedAt": "2022-10-26T13:36:25Z",
          "publishedAt": "2021-05-10T11:25:48Z",
          "category": {
            "name": "Q&A Modules: Solid mechanics"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "vanwdani"
                  },
                  "bodyText": "I don't know exactly what your input file/code looks like, but I would guess you have enabled the AD system in some fashion.  More about the AD: https://mooseframework.inl.gov/bison/automatic_differentiation/index.html",
                  "url": "https://github.com/idaholab/moose/discussions/17786#discussioncomment-719125",
                  "updatedAt": "2022-10-26T13:36:25Z",
                  "publishedAt": "2021-05-10T15:30:57Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "rh201"
                          },
                          "bodyText": "Thank you.",
                          "url": "https://github.com/idaholab/moose/discussions/17786#discussioncomment-724209",
                          "updatedAt": "2022-10-26T13:36:38Z",
                          "publishedAt": "2021-05-11T14:44:23Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "Libmesh conda compatibility with old moose",
          "author": {
            "login": "louisBS"
          },
          "bodyText": "Hi all,\nI updated my libmesh ( using conda update -all) and now I cannot compile my old moose using the latest libmesh. It's a bit of a pain for me to rebase my moose by resolving all the conflicts, so I wonder if there's any way for me to downgrade my libmesh version using conda to what it was before ?\nThank you very much,\nLouis",
          "url": "https://github.com/idaholab/moose/discussions/17790",
          "updatedAt": "2022-08-10T11:44:09Z",
          "publishedAt": "2021-05-10T20:34:41Z",
          "category": {
            "name": "Q&A Getting Started"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "travismui"
                  },
                  "bodyText": "I believe you can use conda search -i moose-libmesh to find the available versions of libmesh for moose and then use conda install moose-libmesh=<ver> to install a specific version (i.e. moose-libmesh=2021.02.15 to roll back one version). This should also roll back any dependencies like moose-petsc to their correct versions as well, but there may be other packages that you may also need to roll back separately.",
                  "url": "https://github.com/idaholab/moose/discussions/17790#discussioncomment-723950",
                  "updatedAt": "2022-08-10T11:44:32Z",
                  "publishedAt": "2021-05-11T14:00:51Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": []
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "3D frictional contact does not converge.",
          "author": {
            "login": "dzheng26"
          },
          "bodyText": "New to Moose. I tried to have a 3D frictional contact simulation. It is a tire-like tube push against a rigid surface. The rigid surface is modeled as one element with specified movement at all nodes.\nWithout friction (mono04-cnt.i), the example works fine. However it does not converge with friction (mono04-frc.i). If I change the frictional coefficient to zero (mono04-frc0.i), it works like the frictionless case.\nCould someone help me on this example?\nThe test data is attached.\ntest_data.tar.gz",
          "url": "https://github.com/idaholab/moose/discussions/17387",
          "updatedAt": "2022-06-14T22:40:20Z",
          "publishedAt": "2021-03-19T15:12:41Z",
          "category": {
            "name": "Q&A Modules: Solid mechanics"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "dzheng26"
                  },
                  "bodyText": "Also in \"modules/contact/examples/3d_berkovich\", the file \"indenter.e\" used by the input file is missing.",
                  "url": "https://github.com/idaholab/moose/discussions/17387#discussioncomment-503689",
                  "updatedAt": "2022-06-14T22:40:22Z",
                  "publishedAt": "2021-03-19T15:22:50Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "jiangwen84"
                          },
                          "bodyText": "@recuero Could you add the missing file? Thanks.",
                          "url": "https://github.com/idaholab/moose/discussions/17387#discussioncomment-503928",
                          "updatedAt": "2022-06-14T22:40:27Z",
                          "publishedAt": "2021-03-19T16:12:37Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "recuero"
                          },
                          "bodyText": "There is a journal file in the repository that can be used to generate the exodus file. The mesh is quite large. I am attaching it here, remove the txt extension.\nindenter.e.txt",
                          "url": "https://github.com/idaholab/moose/discussions/17387#discussioncomment-504044",
                          "updatedAt": "2022-06-14T22:40:28Z",
                          "publishedAt": "2021-03-19T16:36:10Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "dzheng26"
                          },
                          "bodyText": "Thanks @recuero . A small README file in the folder can be helpful.",
                          "url": "https://github.com/idaholab/moose/discussions/17387#discussioncomment-504586",
                          "updatedAt": "2022-06-14T22:40:30Z",
                          "publishedAt": "2021-03-19T18:30:07Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "recuero"
                          },
                          "bodyText": "I am not sure if you are referring to the journal file conversion to Exodus. But, in case you haven't come across it: https://mooseframework.inl.gov/modules/contact/BerkovichIndenterNodeFace.html",
                          "url": "https://github.com/idaholab/moose/discussions/17387#discussioncomment-504893",
                          "updatedAt": "2022-06-14T22:42:34Z",
                          "publishedAt": "2021-03-19T20:04:24Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "dzheng26"
                          },
                          "bodyText": "Thanks for sending me the .e file. Sorry for not make a follow up of this early. I tested the example 3d_berkovich. I have to make a small changed of the input file since the \"boty111\" is not defined on the .e file and print_perf_log has to be replaced. The example converged but slowly (I did not ran it all the way to the end). There are many non-linear iterations for each time step.\nFollow the example, I also made my small example converged. However it also converged slowly. Much too slow in my opinion and to other code I tried.\nInput file changes\n`<   [./boty111]\n<     type = DirichletBC\n<     variable = disp_y\n<     boundary = 111\n<     value = 0.0\n<   [../]\n<   [./botx111]\n<     type = DirichletBC\n<     variable = disp_x\n<     boundary = 111\n<     value = 0.0\n<   [../]\n<\n219c206\n<   print_perf_log = true\n\nperf_graph = true\nConvergence exampleTime Step 90, time = 0.36, dt = 0.004\n0 Nonlinear |R| = 2.298919e-02\n1 Nonlinear |R| = 2.035932e-03\n2 Nonlinear |R| = 1.890794e-03\n3 Nonlinear |R| = 1.748625e-03\n4 Nonlinear |R| = 1.504827e-03\n5 Nonlinear |R| = 1.277548e-03\n6 Nonlinear |R| = 1.046155e-03\n7 Nonlinear |R| = 8.971936e-04\n8 Nonlinear |R| = 7.813298e-04\n9 Nonlinear |R| = 7.658471e-04\n10 Nonlinear |R| = 6.122786e-04\n11 Nonlinear |R| = 1.882083e-04\n12 Nonlinear |R| = 1.696259e-04\n13 Nonlinear |R| = 1.302233e-04\n14 Nonlinear |R| = 1.204901e-04\n15 Nonlinear |R| = 1.975728e-07\n`",
                          "url": "https://github.com/idaholab/moose/discussions/17387#discussioncomment-687149",
                          "updatedAt": "2022-06-14T22:42:34Z",
                          "publishedAt": "2021-05-03T09:34:58Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "recuero"
                          },
                          "bodyText": "Problems with friction tend to need a larger number of nonlinear iterations. In addition, if you are using the slip damper, it will probably be adding to the number of nonlinear iterations by controlling the slip state of the nodes in contact.\nI assume it's your small problem that you are comparing to other codes. To improve convergence in MOOSE, I'd recommend investigating or tuning input parameters, such as normal_smoothing_method, normal_smoothing_distance, and penalty.",
                          "url": "https://github.com/idaholab/moose/discussions/17387#discussioncomment-688566",
                          "updatedAt": "2022-06-14T22:43:50Z",
                          "publishedAt": "2021-05-03T15:03:01Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "dzheng26"
                          },
                          "bodyText": "@recuero , thanks for the hints. I will have another trial. BTW, which formulation is best for 3D frictional contact? I use \"penalty\" currently.",
                          "url": "https://github.com/idaholab/moose/discussions/17387#discussioncomment-693356",
                          "updatedAt": "2022-06-14T22:43:50Z",
                          "publishedAt": "2021-05-04T13:42:10Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "recuero"
                          },
                          "bodyText": "For frictional contact, tangential_penalty usually yields good results.",
                          "url": "https://github.com/idaholab/moose/discussions/17387#discussioncomment-694799",
                          "updatedAt": "2022-06-14T22:43:50Z",
                          "publishedAt": "2021-05-04T16:51:40Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "dzheng26"
                          },
                          "bodyText": "@recuero Following your help, I did more tests. Here is what I found.\nFirst normal_smoothing_method is not allowed in my compiled code although from peacock I found edge_based and nodal_normal_based two options. So I cannot test it. I tested the penalty and tangential_penalty formulations with penalty swap (0.01, 0.1, 1.0 and 10.0) and normal_smoothing_distance swap (0.01, 0.1, 1.0 and 10.0). The cases for penalty=10 did not converge. All the others converged. Here is the total number of Nonlinear iterations for each test cases.\nFor penalty method (P0_01SD0_1 means penalty=0.01 and normal_smoothing_distance=0.1)\nP0_01SD0_1.log:| 95\nP0_01SD1_0.log:| 102\nP0_01SD10_0.log:| 150\n\nP0_1SD0_01.log:| 333\nP0_1SD0_1.log:| 353\nP0_1SD1_0.log:| 359\nP0_1SD10_0.log:| 334\n\nP1_0SD0_01.log:| 3120\nP1_0SD0_1.log:| 2843\nP1_0SD1_0.log:| 2748\nP1_0SD10_0.log:| 6558\n\nFor tangential_penalty method\nTP0_01SD0_01.log:| 106\nTP0_01SD0_1.log:| 102\nTP0_01SD1_0.log:| 98\nTP0_01SD10_0.log:| 105\n\nTP0_1SD0_01.log:| 239\nTP0_1SD0_1.log:| 488\nTP0_1SD1_0.log:| 239\nTP0_1SD10_0.log:| 242\n\nTP1_0SD0_01.log:| 918\nTP1_0SD0_1.log:| 993\nTP1_0SD1_0.log:| 944\nTP1_0SD10_0.log:| 953\n\nThe tangential_penalty method convergences better.\nWhen checking the results, there are visually noticeable penetrations through the contact plane even with penalty=1.0 for penalty formulation. WIth tangential_penalty method, there is no (little) penetration by formulation. However, there are visually noticeable violation of the friction law for penalty=0.01 or 0.1. It is hard to see for penalty=1.0 cases.\nWith the best usable setting (tangential_penalty with penalty=1.0 and normal_smoothing_distance=1.0), the number of nonlinear iterations is quite high (944 for 21 load steps). IMO, there are rooms for improvement for the contact algorithms.",
                          "url": "https://github.com/idaholab/moose/discussions/17387#discussioncomment-719315",
                          "updatedAt": "2022-06-14T22:43:50Z",
                          "publishedAt": "2021-05-10T16:09:43Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "recuero"
                          },
                          "bodyText": "The convergence behavior and interpenetration values depend heavily on the selection of parameters. \"Penalties\" are usually chosen in relation to the stiffnesses of the bodies involved. The normal smoothing distance is given in parametric coordinates, so it should range from 0 to 0.5. But this parameter's effect depends on the problem surfaces.",
                          "url": "https://github.com/idaholab/moose/discussions/17387#discussioncomment-719535",
                          "updatedAt": "2022-06-14T22:43:58Z",
                          "publishedAt": "2021-05-10T16:54:08Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "Grain growth simulation stuck at Nonlinear |R| step",
          "author": {
            "login": "ykvishal"
          },
          "bodyText": "I am planning to use phase_filed module (grain growth) for my research. I was testing 3D_6000_gr.i. I made following changes\n\n\nadded  parallel_type = distributed to the mesh block.\n\n\nChanged grain_tracker block and added following to the [UserObjects] block\n[./grain_tracker]\ntype = GrainTracker\nthreshold = 0.2\nconnecting_threshold = 0.08\ncompute_halo_maps = true # Only necessary for displaying HALOS\ncompute_var_to_feature_map = true\npolycrystal_ic_uo = voronoi\n[../]\n\n\nAdded following block\n[VectorPostprocessors]\n[./grain_volumes]\ntype = FeatureVolumeVectorPostprocessor\nflood_counter = grain_tracker\nexecute_on = 'initial timestep_end'\n#output_centroids = true\n[../]\n[]\n\n\nThis simulation always get stuck at the nonlinear step for many hours and nothing happens. I changed number of cores but same thing happened again. A typical example is shown here\n\nComplete output is also attached.\n3DGrainGrowthOutput.txt\nI also converted this 3D input file to 2D and same thing happened again. I am not sure if I am doing anything stupid.",
          "url": "https://github.com/idaholab/moose/discussions/17422",
          "updatedAt": "2022-06-14T02:39:13Z",
          "publishedAt": "2021-03-23T22:35:58Z",
          "category": {
            "name": "Q&A Modules: Phase field"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "permcody"
                  },
                  "bodyText": "Oh wow! So you get 39 perfect time steps and then it just locks up. Is it always 40? Based on your queue, this doesn't appear to be running on an INL machine. My guess is that we are running into a nasty edge case that may be related to some of the periodic constraint code that was added within the last year to even enable this type of simulation. When I ran this for my work, I had to run it with replicated mesh, but we've been working to make it work with distributed mesh which I can tell is working since you are running this on only 5 nodes!\nIf we can't replicate this on a smaller problem, we do have a script that produces stack traces from all the ranks and compares them for divergence, then we can track down the bad code. I'll see if I can't have one of my resources take a look at the problem.\nAs a last ditch effort to try to get this running, we could attempt to use the \"recover\" capability to see if just killing and resuming execution will get you past this hanging condition, but even if that works it's just a temporary workaround. To try this out, turn on the checkpoint outputs in your [Outputs] section by adding checkpoint=true. Then you can simply kill the run when it hands. After that just run the exact same command as you used to launch it the first time, but append --recover to the command line. If all goes well, it'll attempt to \"recover\" the simulation at Timestep 40. It might just hang again, but perhaps, it'll get through? Again, this really is just a last ditch effort.\nHave you looked at the output of your first 40? Hopefully everything up to this point is working well for you.",
                  "url": "https://github.com/idaholab/moose/discussions/17422#discussioncomment-526307",
                  "updatedAt": "2022-06-14T02:39:34Z",
                  "publishedAt": "2021-03-24T18:35:36Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "permcody"
                          },
                          "bodyText": "There is an option B if you want to replicate my run using \"ReplicatedMesh\". Switch your mesh type back and only run with partial nodes. With PBS you typically request several chunks that each only use a subset of the available cores on a node, something like this: \"-l select=14:ncpus=10:mpiprocs=10:mem=127GB\". This would give you 14, 10 CPU chunks assuming you have 127GB available on each node. Clearly this wastes a lot of CPUs but each CPU gets access to a lot more memory, it may be an option while we find time to look into the issue. You may have to run with even fewer CPUs. When I ran, I typically would use \"top\" to watch the headnode to make sure that I wouldn't run out of memory. Rank 0 will use a lot more memory than all the others when using the GrainTracker. PBS can handle that though as you can request a special chunk just to handle the Rank 0 memory requirements while packing the other ranks a little tighter.",
                          "url": "https://github.com/idaholab/moose/discussions/17422#discussioncomment-526338",
                          "updatedAt": "2022-06-14T02:40:32Z",
                          "publishedAt": "2021-03-24T18:42:43Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "ykvishal"
                          },
                          "bodyText": "Thank you very much @permcody  for your detailed reply.\nI forgot to mention 2 minor changes -\n\nI changed op_num to 50 from 28 due to following error\nUnable to find any suitable order parameters for remapping while working with the following grain IDs:\n{1576, 4022}\n\nPossible Resolutions:\n- Add more order parameters to your simulation (8 for 2D, 28 for 3D)\n- Increase adaptivity or reduce your grain boundary widths\n- Make sure you are not starting with too many grains for the mesh size\n\ufffd[39m\n\nMPI_ABORT was invoked on rank 0 in communicator MPI_COMM_WORLD\nwith errorcode 1.\n\nI am using Neumann boundary condition as I wanted to study effect of temperature gradient on grain growth and compare it with normal grain growth. I am following this input file.\n\nIs it always 40? \nNo. I running 3 more simulations and all three are stuck at Nonlinear step but with different Time Steps.  For 3D isotropic grain growth - stuck at Time Step 41.  Complete output file is here\n3DGrainGrowthOutputTest2.txt\nFor Temperature gradient cases\n\nOne is stuck at Time Step 24\n3DGrainGrowthTempGradCase1.txt\nand another at Time Step 27\n3DGrainGrowthTempGradCase2.txt\n\n Based on your queue, this doesn't appear to be running on an INL machine.\nNo. I am currently in Belgium and I am running simulations at the  Flemish Supercomputer Center (Vlaams Supercomputer Centrum - VSC). I am using Tier 1 nodes.\nMy guess is that we are running into a nasty edge case that may be related to some of the periodic constraint code that was added within the last year to even enable this type of simulation. \nI hope that it has nothing to do with Neumann boundary condition. Also, periodic boundary condition with parallel_type = distributed gives segmentation fault.\nAs a last ditch effort to try to get this running, we could attempt to use the \"recover\" capability \nYes, I am doing that. My colleague suggested this solution. I checked with 2D and 3D cases and it worked most of the time.\nHave you looked at the output of your first 40? Hopefully everything up to this point is working well for you.\nYes, I checked the simulation results till Time Step 39. I feel that the interface is not smooth. A typical example is shown below (unique_grains)\n\nThe interface in 2D simulations were also not smooth. After making the mesh fine, the interface became smooth. However, I could not check it for 3D simulations due to memory problem.\nAlso, the grain size distribution plot suggests that simulation is still in the transient stage. Following plot also suggests that there are very few small size of grains.\n\nI noticed similar thing for 2D simulations. I am not sure if it is related to interface issue (which I mentioned earlier). MOOSE does not calculate number of sides (of individual grains) so I am not sure if distribution of number of sides of grains will also show similar trends.\nThere is an option B if you want to replicate my run using \"ReplicatedMesh\"...................  With PBS you typically request several chunks that each only use a subset of the available cores on a node, something like this: \"-l select=14:ncpus=10:mpiprocs=10:mem=127GB\".\nI will certainly try this. My colleague and I tried your suggestion related to PBS file but it did not work for us. We may have to use -l pmem=124GB (or 248GB) with  #PBS -l nodes=10:ppn=2:broadwell\nI have few more questions (problems) related to GrainTracker and Large memory/number of cores requirement for temperature gradient cases but I will soon start separate threads on these topic.",
                          "url": "https://github.com/idaholab/moose/discussions/17422#discussioncomment-530962",
                          "updatedAt": "2022-06-14T02:40:32Z",
                          "publishedAt": "2021-03-25T18:13:57Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "ykvishal"
                          },
                          "bodyText": "Outcome of simulation with replicated mesh:\nI ran one simulation with parallel_type=replicated and simulation was again stuck at non-linear step and time step was 37 The output is attached here\nReplicatedMesh.txt\nFor this simulation 1)  I used Neumann boundary condition with 50 OPs. These conditions were used in earlier simulations also. 2) I used nodes10:ppn=14 with pmem=15gb to run this simulation as a simulation with nodes=7:ppn=2 with pmem=124gb setting was 10 times slower. (Also, based on VectorMemoryUsage the simulation with  nodes=7:ppn=2 with pmem=124gb setting only need pmem=57gb.)",
                          "url": "https://github.com/idaholab/moose/discussions/17422#discussioncomment-545161",
                          "updatedAt": "2022-06-14T02:40:49Z",
                          "publishedAt": "2021-03-29T19:04:09Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "fdkong"
                          },
                          "bodyText": "Are you able to get a backtrace for us? It hard to tell what was happening without knowing where the code was hanging.\nI ran the same problem but with a smaller mesh and a smaller number of grains on a desktop in parallel. I did not see any issue.  I might be going to run the same problem on our HPC soon.\n\nNeumann boundary condition\n\nIf you use Neumann boundary conditions for all boundaries, the system might be singular.  Did you check your model is well defined mathematically?",
                          "url": "https://github.com/idaholab/moose/discussions/17422#discussioncomment-545772",
                          "updatedAt": "2022-09-13T07:46:37Z",
                          "publishedAt": "2021-03-29T21:46:26Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "ykvishal"
                          },
                          "bodyText": "Are you able to get a backtrace for us? \nI was not asked about this. Earlier, I did not use this option with MOOSE. I will try to figure it out.\nIf you use Neumann boundary conditions for all boundaries, the system might be singular. Did you check your model is well defined mathematically?\nIn the original input file 3D_6000_gr.i, the BCs block was commented and temperature_gradient.i file does not BCs block. In such cases, default boundary condition would be Neumann boundary condition. I will run one simulation with periodic BC and see what happens.",
                          "url": "https://github.com/idaholab/moose/discussions/17422#discussioncomment-545844",
                          "updatedAt": "2022-09-13T07:46:37Z",
                          "publishedAt": "2021-03-29T22:09:55Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "permcody"
                          },
                          "bodyText": "Getting back to your results: How are you calculating radii for these grains? I would agree that your results are not all that smooth, but I'm a bit surprised by the apparent oscillation in your plot above. This simulation is about as coarse as I could make it to achieve the results I was after (testing the grain tracker more than simulating physics). When performing many of the runs we used for our papers, we ran in 2D and used a fair amount of adaptivity to smooth out the grain boundaries. If you are interested, our most recent publication is below that describes the algorithms and data structures in more detail:\nhttps://www.tandfonline.com/doi/full/10.1080/00295450.2020.1843893\nAnother suggestion for you: When running with the GrainTracker, rank 0 uses about 5-10x more memory than any of the remaining ranks. When I ran these simulation, I took that into account. I was able to request more memory for just the first rank and pack all of the remaining ranks more densely. If we can get this running with DistributedMesh and you discover how to reserve more memory for just rank 0, you shouldn't have to waste much or maybe even no memory for all of the remaining ranks.\nFinally, I encourage you to reach out to me directly. We can discuss sponsoring you so that you may run on our systems. Since Fande was successful in getting these simulations running on our super computing systems, perhaps we can compare to see what differences you are running into that are causing your simulations to hang.",
                          "url": "https://github.com/idaholab/moose/discussions/17422#discussioncomment-548647",
                          "updatedAt": "2022-09-13T07:46:37Z",
                          "publishedAt": "2021-03-30T15:09:29Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "ykvishal"
                          },
                          "bodyText": "Thank you @permcody\nHow are you calculating radii for these grains?\nI am using FeatureVolumeVectorPostprocessor to get volume of individual grains and then calculating spherical equivalent radius of all active grains (ie neglected all grains with zero volume).\nThank you for sharing your recent paper. I also want implement similar model. My interpolation function and additional driving force are little different. But  both models are similar from implementation point of view.\nWhen running with the GrainTracker, rank 0 uses about 5-10x more memory than any of the remaining ranks\nI tried this but I was not successful. My colleague also checked with our HPC support staff and they were also not sure about exact solution. I will try again.\nThank you very much for your offer of help. Certainly, I will contact you soon.",
                          "url": "https://github.com/idaholab/moose/discussions/17422#discussioncomment-550040",
                          "updatedAt": "2022-09-13T07:46:37Z",
                          "publishedAt": "2021-03-30T20:12:25Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              },
              {
                "node": {
                  "author": {
                    "login": "fdkong"
                  },
                  "bodyText": "@ykvishal  Could you check whether or not the solution from the previous steps looks right for you?\nCould you please share the 2D input file with us? And we will look into it.  We could run the 3D input, but the 2D problem will be a lot easier.\nWe had many improvements for distributed meshes and periodicity boundary conditions and grain trackers a while ago. We did large-scale studies for other examples, and that went well.  There might be some corner cases we did not know in this input file.",
                  "url": "https://github.com/idaholab/moose/discussions/17422#discussioncomment-527182",
                  "updatedAt": "2022-06-14T02:40:50Z",
                  "publishedAt": "2021-03-24T22:45:47Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "ykvishal"
                          },
                          "bodyText": "Thank you @fdkong\n Could you check whether or not the solution from the previous steps looks right for you?\nI feel that the interface is not that smooth and the grain size distribution shows less number of grains with small grain size. I showed these data in my earlier reply.\nCould you please share the 2D input file with us? And we will look into it. \nI am attaching input file and the 2D output files.\n2D_6000_grTempFull.i.txt\n2DTempFullOutputStuckNonLinear.txt\n2DTempFullOutputStuckNonLinearRestart.txt\nI selected as big mesh as possible.\nWe had many improvements for distributed meshes and periodicity boundary conditions and grain trackers a while ago.\nI am using neumann boundary condition. I hope that this won't be an issue.",
                          "url": "https://github.com/idaholab/moose/discussions/17422#discussioncomment-531093",
                          "updatedAt": "2022-06-24T03:30:08Z",
                          "publishedAt": "2021-03-25T18:46:23Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "fdkong"
                          },
                          "bodyText": "The same code worked for me on the HPC. I could go much farer than you did.\nOutputting checkpoint \n..                                                                                         [  3.18 s]\n\nTime Step 123, time = 0.0126028, dt = 0.000108618\nComputing initial residual                                                                 [  1.20 s]\n 0 Nonlinear |R| = 2.797739e+05\n      0 Linear |R| = 2.797739e+05\n      1 Linear |R| = 8.957504e+04\n      2 Linear |R| = 2.510090e+04\n      3 Linear |R| = 9.367619e+03\n      4 Linear |R| = 3.485534e+03\n      5 Linear |R| = 1.176542e+03\n      6 Linear |R| = 3.775351e+02\n      7 Linear |R| = 1.190099e+02\n      8 Linear |R| = 3.571200e+01\n      9 Linear |R| = 1.090630e+01\n 1 Nonlinear |R| = 2.504514e+05\n      0 Linear |R| = 2.504514e+05\n      1 Linear |R| = 7.536308e+04\n      2 Linear |R| = 1.807657e+04\n      3 Linear |R| = 5.229556e+03\n      4 Linear |R| = 1.497901e+03\n      5 Linear |R| = 4.153234e+02\n      6 Linear |R| = 1.164641e+02\n      7 Linear |R| = 3.156797e+01\n      8 Linear |R| = 8.189440e+00\n 2 Nonlinear |R| = 1.907387e+05\n      0 Linear |R| = 1.907387e+05\n      1 Linear |R| = 5.641056e+04\n      2 Linear |R| = 1.442387e+04\n      3 Linear |R| = 5.345585e+03\n      4 Linear |R| = 1.981149e+03\n      5 Linear |R| = 6.476763e+02\n      6 Linear |R| = 2.126636e+02\n      7 Linear |R| = 6.844217e+01\n      8 Linear |R| = 2.034061e+01\n      9 Linear |R| = 6.110929e+00\n 3 Nonlinear |R| = 1.265340e+05\n      0 Linear |R| = 1.265340e+05\n      1 Linear |R| = 3.876502e+04\n      2 Linear |R| = 8.806081e+03\n      3 Linear |R| = 3.216685e+03\n      4 Linear |R| = 1.048045e+03\n      5 Linear |R| = 3.830322e+02\n      6 Linear |R| = 1.130757e+02\n      7 Linear |R| = 3.520596e+01\n      8 Linear |R| = 8.560899e+00\n 4 Nonlinear |R| = 7.386303e+04\n      0 Linear |R| = 7.386303e+04\n      1 Linear |R| = 2.121771e+04\n      2 Linear |R| = 4.103992e+03\n      3 Linear |R| = 1.020028e+03\n      4 Linear |R| = 2.505141e+02\n      5 Linear |R| = 6.672495e+01\n      6 Linear |R| = 1.639721e+01\n      7 Linear |R| = 3.753881e+00\n 5 Nonlinear |R| = 1.023706e+04\n      0 Linear |R| = 1.023706e+04\n      1 Linear |R| = 1.508874e+03\n      2 Linear |R| = 5.450907e+02\n      3 Linear |R| = 1.512235e+02\n      4 Linear |R| = 3.366981e+01\n      5 Linear |R| = 7.897978e+00\n      6 Linear |R| = 2.058139e+00\n      7 Linear |R| = 4.616156e-01\n 6 Nonlinear |R| = 5.505459e+02\n      0 Linear |R| = 5.505459e+02\n      1 Linear |R| = 2.236292e+02\n      2 Linear |R| = 1.239342e+02\n      3 Linear |R| = 2.328252e+01\n      4 Linear |R| = 4.262796e+00\n      5 Linear |R| = 9.203517e-01\n      6 Linear |R| = 2.574110e-01\n      7 Linear |R| = 5.557414e-02\n      8 Linear |R| = 1.421568e-02\n 7 Nonlinear |R| = 3.552555e+01\n      0 Linear |R| = 3.552555e+01\n      1 Linear |R| = 1.122254e+01\n      2 Linear |R| = 7.806079e+00\n      3 Linear |R| = 1.284897e+00\n      4 Linear |R| = 1.955493e-01\n      5 Linear |R| = 4.754663e-02\n      6 Linear |R| = 8.088230e-03\n      7 Linear |R| = 1.711389e-03\n 8 Nonlinear |R| = 1.097400e-01\n      0 Linear |R| = 1.097400e-01\n      1 Linear |R| = 3.756871e-02\n      2 Linear |R| = 2.570770e-02\n      3 Linear |R| = 3.966574e-03\n      4 Linear |R| = 5.979761e-04\n      5 Linear |R| = 1.401121e-04\n      6 Linear |R| = 2.266665e-05\n      7 Linear |R| = 4.654228e-06\n 9 Nonlinear |R| = 4.805599e-06\n\n\nSo I still do not know what issue your simulation might have. One possible reason was that the disk was occupied by many output files. You could turn off file outputs to verify that.  The machine might not respond at all because of that. If you can share code backtraces with us when the code is stuck, it might be helpful.\nBTW, I used a parallel mesh generator for simulation setup efficiency. You could use the same block if you would like to. It might not resolve your issue, but I used that to reduce the simulation setup time.\n[Mesh]\n  [gmg]\n    type = DistributedRectilinearMeshGenerator\n    dim = 2 #3\n    nx = 2500 #180\n    ny = 2500 #180\n    #nz = 180\n    xmin = 0\n    xmax = 2500 #180\n    ymin = 0\n    ymax = 2500 #180\n    #zmin = 0\n    #zmax = 180\n    elem_type = QUAD4  #HEX8\n  []\n[]",
                          "url": "https://github.com/idaholab/moose/discussions/17422#discussioncomment-548587",
                          "updatedAt": "2022-06-24T03:30:09Z",
                          "publishedAt": "2021-03-30T14:56:59Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "ykvishal"
                          },
                          "bodyText": "Thank you @fdkong .\nI will certainly run another simulation with no output of any kind and see what happens.  I will also try to share outcome with backtraces. At the moment, our HPC is very busy so I may to wait for a few days to get desirable number of computing nodes.\nDistributedRectilinearMeshGenerator option looks interesting. I will use it for future simulations.",
                          "url": "https://github.com/idaholab/moose/discussions/17422#discussioncomment-550115",
                          "updatedAt": "2022-06-24T03:30:15Z",
                          "publishedAt": "2021-03-30T20:38:54Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "ykvishal"
                          },
                          "bodyText": "One possible reason was that the disk was occupied by many output files. You could turn off file outputs to verify that. The machine might not respond at all because of that.  If you can share code backtraces with us when the code is stuck, it might be helpful.\nDue to some package conflict issues, I was unable to use GDB in parallel condition. I cannot run same program on a single core.\nHowever, I followed your suggestion about turning off outputs and run simulations. I selected only one csv file for output and turned off all other output options. Also, there were no other files. Then simulations were running smoothly over 24 hrs.\nToday, I ran one simulations where I wanted grain volume data and nemesis output at every time-step. I an analyzing the impact of adaptivity on simulation results. So  a lot files were generated after few hours. And, the simulation again hanged in similar fashion. Also, the system size and number of grains were not that big. So I am assuming that your apprehension was right about this issue.\nThank you !",
                          "url": "https://github.com/idaholab/moose/discussions/17422#discussioncomment-584971",
                          "updatedAt": "2022-09-13T07:46:34Z",
                          "publishedAt": "2021-04-08T13:41:39Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "ykvishal"
                          },
                          "bodyText": "I just want to add that I was trying to perform large 2D (2400X2400 mesh and 20K grains) and 3D (192X192X192, 10K grains) simulations. My goal was to analyze data (microstructure, individual grain volume and mean grain size)  after every 20 time-steps. This would have created a large number of files. So, I tried to write them in the different sub directory as shown in subdir_output.i\nBut, it did not help and simulations always get stuck at Nonlinear step. After every few minutes, I am restarting my simulations as I need to generate some data for analysis.\nThere is some issue with gdb on my HPC cluster.  I need following packages for MOOSE software\nfoss/2019b  Python/3.7.4-GCCcore-8.3.0 CMake/3.15.3-GCCcore-8.3.0 Bison/3.3.2-GCCcore-8.3.0  flex/2.6.4-GCCcore-8.3.0  CUDA/10.2.89-GCC-8.3.0\nWhen I try to load gdb, I get following error:\n\nGCCcore/4.9.3(13):ERROR:150: Module 'GCCcore/4.9.3' conflicts with the currently loaded module(s) 'GCCcore/8.3.0'\nGCCcore/4.9.3(13):ERROR:102: Tcl command execution failed: conflict GCCcore\nzlib/1.2.8-GCCcore-4.9.3(15):ERROR:150: Module 'zlib/1.2.8-GCCcore-4.9.3' conflicts with the currently loaded module(s) 'zlib/1.2.11-GCCcore-8.3.0'\nzlib/1.2.8-GCCcore-4.9.3(15):ERROR:102: Tcl command execution failed: conflict zlib\nlibreadline/6.3-GCCcore-4.9.3(17):ERROR:150: Module 'libreadline/6.3-GCCcore-4.9.3' conflicts with the currently loaded module(s) 'libreadline/8.0-GCCcore-8.3.0'\nlibreadline/6.3-GCCcore-4.9.3(17):ERROR:102: Tcl command execution failed: conflict libreadline\nncurses/6.0-GCCcore-4.9.3(15):ERROR:150: Module 'ncurses/6.0-GCCcore-4.9.3' conflicts with the currently loaded module(s) 'ncurses/6.1-GCCcore-8.3.0'\nncurses/6.0-GCCcore-4.9.3(15):ERROR:102: Tcl command execution failed: conflict ncurses\nGCCcore/4.9.3(13):ERROR:150: Module 'GCCcore/4.9.3' conflicts with the currently loaded module(s) 'GCCcore/8.3.0'\nGCCcore/4.9.3(13):ERROR:102: Tcl command execution failed: conflict GCCcore\n\nI have contacted my HPC system  administrator about this issue. I hope that they will find some solution for this and I can run back-traces to figure out the issue.",
                          "url": "https://github.com/idaholab/moose/discussions/17422#discussioncomment-597146",
                          "updatedAt": "2022-09-13T07:46:35Z",
                          "publishedAt": "2021-04-11T20:15:18Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              },
              {
                "node": {
                  "author": {
                    "login": "ykvishal"
                  },
                  "bodyText": "I tried to use gdb in parallel but I could not make it work. As mentioned earlier, it is difficult to run this program on single node. So I am just using --recover option.\nAlso about discrepancy with MOOSE simulation and published data:\nCody was right about coarse mesh. I felt that number of mesh element in the diffuse interface width were not sufficient. So I performed  one 2D study where evolution of a circular grain embedded in  another grain  is tracked and compared with analytical solution. I varied mesh elements for a given diffuse interface width wGB. I found that 6 mesh elements are needed to match with analytical solution. My result is presented here:\n\nBased on this study, I performed a large 2D simulations where mesh size was 2400X2400 with 20,000 grains. The microstructure at two different time-steps are show here:\n\nZooming of a portion of above figure is presented here:\n\nFinally, evolution of mean grain size  and grain size distribution are presented here:\n\nNow, I have a good match with the published 2D grain growth data. Also, small grains are not missing in the GSD plot. I am going to use 6 mesh elements for my future work.\nI could not simulate 3D grain growth yet. I want to study evolution of 20000 grains with 400^3 mesh size (+adaptivity) but the memory requirement per core is very high. I managed to start one simulation for this case but the simulation was still at projecting initial condition after 2 days. I am still trying to figure it out.",
                  "url": "https://github.com/idaholab/moose/discussions/17422#discussioncomment-622200",
                  "updatedAt": "2022-06-24T03:30:24Z",
                  "publishedAt": "2021-04-16T20:06:12Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "PengWei97"
                          },
                          "bodyText": "hi @ykvishal,\nI have some basic questions about the grain size distribution map you gave. As we all know, moose can output the volume of each crystal grain at each time step, calculate according to the area in the 2D simulation (A = 2*pi^2), get the radius of each crystal grain and calculate the average radius, as , the frequency is calculated between the partitions, but the grain size distribution map I calculated is very different from the 2D theoretical Hillert distribution.\nHow do you calculate the frequency?\nThe following is the grain size distribution map I output,\n\nThank you!\nwei",
                          "url": "https://github.com/idaholab/moose/discussions/17422#discussioncomment-625645",
                          "updatedAt": "2022-06-24T03:30:37Z",
                          "publishedAt": "2021-04-18T06:19:07Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "aeslaughter"
                          },
                          "bodyText": "I could not simulate 3D grain growth yet. I want to study evolution of 20000 grains with 400^3 mesh size (+adaptivity) but the memory requirement per core is very high. I managed to start one simulation for this case but the simulation was still at projecting initial condition after 2 days. I am still trying to figure it out.\n\n@permcody @dschwen How big have you gone in 3D? Could he use a pre-split, distributed mesh for something like this? (If that is not being done already)",
                          "url": "https://github.com/idaholab/moose/discussions/17422#discussioncomment-640447",
                          "updatedAt": "2022-06-24T03:30:41Z",
                          "publishedAt": "2021-04-21T14:45:20Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "fdkong"
                          },
                          "bodyText": "How big have you gone in 3D?\n\nWe could go really big. I tried the case with 6K grains but I did not try something with 20K grains yet.\n\nCould he use a pre-split, distributed mesh for something like\n\nHe should use DistributedRectilinearMeshGenerator that generates mesh in parallel. DistributedRectilinearMeshGenerator will of course select the distributed mesh. I did not try the mesh adaptivity with  the distributed mesh for the grain tracker for a large number of grains. I assume that the combination works  properly.\n\n(+adaptivity) but the memory requirement per core is very high\n\nI do not know where memory comes from. What I know is that grain tracker will do extra works on the first core, and the first core may use 3 or 4 times more memory than others. @permcody has suggested @ykvishal to reserve extra memory for the first core.  @ykvishal Did you follow @permcody's suggestions?\nWhen you are talking about the memory usage, you need to give us about problem size and how many cores are you using, how much memory you have for each core, etc.\n\nI managed to start one simulation for this case but the simulation was still at projecting initial condition after 2 days.\n\nWe should be able to fix this soon. Have not managed to fix that yet.",
                          "url": "https://github.com/idaholab/moose/discussions/17422#discussioncomment-640532",
                          "updatedAt": "2022-06-24T03:30:41Z",
                          "publishedAt": "2021-04-21T15:01:57Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "ykvishal"
                          },
                          "bodyText": "Thank you @aeslaughter and @fdkong\n\nCould he use a pre-split, distributed mesh for something like this? (If that is not being done already)\n\nI tried pre-split and distributed mesh but the issue is related to initialization. It takes a couple of days to initialize if the system size >= 400^3 and number of grains are >=20K. As per @fdkong 's feedback, current algorithm is slow and a new algorithm will fix this issue.\nAlso @permcody @fdkong @dschwen gave a lot of helpful suggestions directly or indirectly (through their old posts here and on google groups).\n\nI did not try the mesh adaptivity with the distributed mesh for the grain tracker for a large number of grains. I assume that the combination works properly.\n\nYes, after your suggestion @fdkong, I started using DistributedRectilinearMeshGenerator for my 2D simulations and it works nicely. These 2D results are generated using DistributedRectilinearMeshGenerator , mesh adaptivity, GrainTraker and time-stepper.\n@permcody has suggested @ykvishal to reserve extra memory for the first core. @ykvishal Did you follow @permcody's suggestions?\nYes, I tried to implement this suggestion. Unfortunately, our HPC support staff informed me that we use different job scheduler and we can only assign memory per core using pmem option.  So, I cannot implement @permcody 's suggestion.  Also, after increasing memory per fore and number of OPs, I didnot have any problem related to GrainTracker step ie from Flooding Features ......  to Finished inside of GrainTracker\nBut, I feel that memory issue related something else. I observed that there is sudden jump in memory requirements for a couple of steps. For example, 1) Initializing equation system .........  - just after building/refining mesh step,  2) Time Step 1,  just around first non-linear calculation step.\nDuring early days, my simulations mostly got terminated at these steps. Now, I use more memory per core.\n\nWhen you are talking about the memory usage, you need to give us about problem size and how many cores are you using, how much memory you have for each core, etc.\n\nHere is one example for 3D study #17433. Here, I did not use mesh adaptivity but I used parallel_type = distributed in the mesh block.\nSimilarly for 2D simulations - I need to use 560 cores (nodes=20:ppn=28,pmem=6gb).\nI could complete initialization step with 280 cores (nodes=10:ppn=28,pmem=6gb) but it failed at time-step =1. I also tried with  280 cores (nodes=20:ppn=14,pmem=13gb) but it crashed after Time-step 1.  The VectorMemoryUsage analysis this case show unusual numbers for page_faults. The physical_mem per core also increased slightly.  For 560 cores case, the page_faults was either 0 or 1 for all cores.\nFor 400^3 and 20K grains case - I needed 560 cores (nodes=40:ppn=14,pmem=17gb) to start simulations. But, It was stuck in Projecting initial condition step for more than 2 days. So, I don't know whether it will fail at Time-step 1 or not.\nOur HPC gives nodes for 3 days max. Also, getting more than 20 nodes for 3 days is a challenge as there are less nodes for the 72 hrs queue compared to nodes for the 24 hrs queue.  I have put one request for 560 cores (nodes=40:ppn=14,pmem=17gb) 3 days ago and I am still waiting for it.\nPS: We have 28 cores per node and pmem can be 4gb, 6gb, 8gb (or mem can be 120+8gb,184 +8gb,248+8gb - 8gb per node is reserved for OS).",
                          "url": "https://github.com/idaholab/moose/discussions/17422#discussioncomment-641947",
                          "updatedAt": "2022-07-05T08:31:02Z",
                          "publishedAt": "2021-04-21T20:32:11Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "fdkong"
                          },
                          "bodyText": "For example, 1) Initializing equation system ......... - just after building/refining mesh step,\n\nYes, I would expect some jump here because libmesh is trying to create Jacobian matrix and vectors and many other things at this stage.\n\n\nTime Step 1, just around first non-linear calculation step.\n\n\nPETSc is trying to setup a preconditioner, and that will use memory for sure. How much memory is going to use totally depends on how do you select preconditioner options.  Could you please share the executioner block and the preconditioning block right here?",
                          "url": "https://github.com/idaholab/moose/discussions/17422#discussioncomment-642102",
                          "updatedAt": "2022-07-05T08:31:05Z",
                          "publishedAt": "2021-04-21T21:05:11Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "ykvishal"
                          },
                          "bodyText": "Could you please share the executioner block and the preconditioning block right here?\n\nBoth blocks here\n\n[Executioner]\n  type = Transient # Type of executioner, here it is transient with an adaptive time step\n  scheme = bdf2 # Type of time integration (2nd order backward euler), defaults to 1st order backward euler\n\n  #Preconditioned JFNK (default)\n  solve_type = 'PJFNK'\n\n  # Uses newton iteration to solve the problem.\n  #petsc_options_iname = '-pc_type -pc_hypre_type -ksp_gmres_restart -mat_mffd_type'\n  #petsc_options_value = 'hypre boomeramg 101 ds'\n\n  petsc_options_iname = '-pc_type -sub_pc_type'\n  petsc_options_value = 'asm ilu'\n  #petsc_options_value = 'asm lu'\n\n  l_max_its = 30 # Max number of linear iterations\n  l_tol = 1e-4 # Relative tolerance for linear solves\n  nl_max_its = 40 # Max number of nonlinear iterations\n  nl_rel_tol = 1e-10 # Absolute tolerance for nonlienar solves\n\n  start_time = 0.0\n  num_steps = 20000\n  dt = 0.000411335 \n\n  [./TimeStepper]\n    type = IterationAdaptiveDT\n    cutback_factor = 0.9 \n    dt = 0.00021 \n    growth_factor = 1.1 #\n    optimal_iterations = 8\n  [../]\n\n  [./Adaptivity]\n    initial_adaptivity = 4\n    refine_fraction = 0.9\n    coarsen_fraction = 0.05\n    max_h_level = 4\n  [../]\n[]\n\n\nThe current choice of petsc_options_iname and petsc_options_value  helps in delaying the hanging issue at the Nonlinear step (ie after every ~ 2 hrs 30mins) compared to the commented choice (which starts hanging issue after every ~1 hrs 20min) ie simulation can run for more time-steps.\n[Preconditioning]\n  [./SMP]\n    type = SMP\n    full = true\n  [../]\n[]",
                          "url": "https://github.com/idaholab/moose/discussions/17422#discussioncomment-642149",
                          "updatedAt": "2022-07-05T08:31:03Z",
                          "publishedAt": "2021-04-21T21:19:24Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "ykvishal"
                          },
                          "bodyText": "I  want to add one point  about initialization step- If I change boundary condition from Neumann to Periodic then Projecting Initial condition and Mesh adaptivity steps take 50 % more time.  ie it take more than 4-5 days for these two steps.",
                          "url": "https://github.com/idaholab/moose/discussions/17422#discussioncomment-642193",
                          "updatedAt": "2022-07-05T08:31:05Z",
                          "publishedAt": "2021-04-21T21:31:06Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "fdkong"
                          },
                          "bodyText": "The current choice of petsc_options_iname and petsc_options_value helps in delaying the hanging issue at the Nonlinear step (ie after every ~ 2 hrs 30mins)\n\nI do not understand how the petsc options are related to the hanging issue. If understand correctly, the hanging issue is related to the HPC file system you are using.\n\n[Preconditioning]\n[./SMP]\ntype = SMP\nfull = true\n[../]\n[]\n\nHmmm, this will use a lot of memory. Could you try \"full = false\"? Or at least customize  coupling elements.",
                          "url": "https://github.com/idaholab/moose/discussions/17422#discussioncomment-642253",
                          "updatedAt": "2022-07-05T08:31:05Z",
                          "publishedAt": "2021-04-21T21:44:23Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "ykvishal"
                          },
                          "bodyText": "If understand correctly, the hanging issue is related to the HPC file system you are using.\nYes, that is true. When commented all output options then this problem was not there.  My colleague is using Elasticity module of MOOSE for his research. He was having similar issue (but not identical) and he solved it by changing petsc_options_iname and petsc_options_value. I tried some of the options used by him and for some reason hanging problem is coming little later. I don't have much experience with Executioner block so I cannot explain it.\nCould you try \"full = false\"? Or at least customize coupling elements.\nYes, I will check this and compare it with previous case to see the difference.",
                          "url": "https://github.com/idaholab/moose/discussions/17422#discussioncomment-642305",
                          "updatedAt": "2022-07-05T08:31:05Z",
                          "publishedAt": "2021-04-21T22:02:25Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "ykvishal"
                          },
                          "bodyText": "Just quick update @fdkong\nI was testing one simulation on interactive nodes (560 cores - nodes=20:ppn=28,pmem=6gb) for mixed boundary condition (Neumann+Periodic. I commented full=true line in the SMP preconditioning block and the physical_mem per core is almost ~ 3-4 times smaller compared to earlier. Also simulations are ~ 4 times faster !!!\nNow, I will run these simulations with small number of cores and see what happens.\nThank you very much for this suggestion.",
                          "url": "https://github.com/idaholab/moose/discussions/17422#discussioncomment-642467",
                          "updatedAt": "2022-07-05T08:31:05Z",
                          "publishedAt": "2021-04-21T22:59:18Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              },
              {
                "node": {
                  "author": {
                    "login": "fdkong"
                  },
                  "bodyText": "@ykvishal Do you want to try this PR #17733 to check if the efficiency of the initial condition setup is improved?\nIIRC, you had an example that took two days to setup an initial condition. PR #17733 should significantly reduce the initial condition setup time.\nNoted that the hanging issue can not really resolved at our side. You have to talk to your HPC admins or you can use our HPC",
                  "url": "https://github.com/idaholab/moose/discussions/17422#discussioncomment-689091",
                  "updatedAt": "2022-06-24T03:30:42Z",
                  "publishedAt": "2021-05-03T16:00:44Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "ykvishal"
                          },
                          "bodyText": "Thank you very much @fdkong . Due to my prior travel plans, I could not respond immediately. My colleague @yucoutinho has updated our MOOSE with this PR #17733 . Now, I am in position to test it.\n\nIIRC, you had an example that took two days to setup an initial condition.\n\nYes, if I select mesh size 400^3, 50 OPs, 30K grains and int_width = 6 in my PolycrystalVoronoi block\n  [./voronoi]\n    type = PolycrystalVoronoi\n    grain_num = 30000 # Number of grains\n    rand_seed = 8675 # 301\n    coloring_algorithm = jp\n    #coloring_algorithm = bt\n    int_width = 6\n  [../]\n\nThen, Projecting initial condition runs for more than 2 days. If I comment the int_width =6 then it takes almost 24 hrs. The output file for this case is attached here\noutput30K400.txt\nAlso, if I add periodic boundary condition then the Projecting initial condition takes 50% more time.\nNow, I am waiting for required number of nodes (40) to run that simulation again. It may take few days to get these many number of nodes. I will keep you updated. Thank you again.",
                          "url": "https://github.com/idaholab/moose/discussions/17422#discussioncomment-704849",
                          "updatedAt": "2022-06-24T03:30:43Z",
                          "publishedAt": "2021-05-06T15:46:01Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "ykvishal"
                          },
                          "bodyText": "I also found the log file where the simulation was at Projecting initial condition  step after 2 days.\noutput400.txt\nHere Finalizing Polycrystal Initial Condition step also took 5 hrs.",
                          "url": "https://github.com/idaholab/moose/discussions/17422#discussioncomment-705656",
                          "updatedAt": "2022-06-24T03:31:16Z",
                          "publishedAt": "2021-05-06T17:52:23Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "fdkong"
                          },
                          "bodyText": "Then, Projecting initial condition runs for more than 2 days. If I comment the int_width =6 then it takes almost 24 hrs. The output file for this case is attached here\noutput30K400.txt\n\n\nAlso, if I add periodic boundary condition then the Projecting initial condition takes 50% more time.\n\nOh, thanks. I think we need to address one more spot..",
                          "url": "https://github.com/idaholab/moose/discussions/17422#discussioncomment-706863",
                          "updatedAt": "2022-06-24T03:31:24Z",
                          "publishedAt": "2021-05-06T23:47:25Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "ykvishal"
                          },
                          "bodyText": "I managed to test the new algorithm and results are as follows:\nCase1 - Mesh - 400^3, OPs=50, Num Grains =30K, int_width=0, Boundary condition - Neumann\n\nResult:\nCompared to earlier simulation, the new algorithm is almost ~1250 times faster!!!!!! Here is the log file\noutput30K400OPs50bt.txt\nCase2 - Mesh - 400^3, OPs=50, Num Grains =30K, int_width=6, Boundary condition - Neumann\nHere, I changed the int_width in the PolycrystalVoronoi  block and everything else is same as Case 1\n\nResult:\nThe initialization slows down again. This behavior is similar to earlier one. Here is the log file\noutput30K400OPs50btIntWidth6.txt\nCase3 - Mesh - 400^3, OPs=50, Num Grains =30K, int_width=0, Boundary condition - Periodic\nHere, I changed the boundary condition and everything else is same as Case 1.\n\nResult: Same as Case 2. New algorithm slows down again. Here is the log file\noutput30K400OPs50btPBC.txt\nCase4 - Mesh - 400^3, OPs=50, Num Grains =30K, int_width=6, Boundary condition - Periodic\nHere, I changed the int_width in the PolycrystalVoronoi  block and the boundary condition and everything else is same as Case 1.\n\nResult: Same as Case 2. New algorithm slows down again. Here is the log file\noutput30K400OPs50btIntWidth6PBC.txt\nSummary: New algorithm works nicely for Case 1. Thank you for this. It would be helpful if this algorithm also works for other cases.",
                          "url": "https://github.com/idaholab/moose/discussions/17422#discussioncomment-711633",
                          "updatedAt": "2022-07-05T08:31:13Z",
                          "publishedAt": "2021-05-07T20:57:24Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "fdkong"
                          },
                          "bodyText": "Thanks for these info. I will check the code again, and see if we can improve for other cases",
                          "url": "https://github.com/idaholab/moose/discussions/17422#discussioncomment-719212",
                          "updatedAt": "2022-07-05T08:31:15Z",
                          "publishedAt": "2021-05-10T15:47:42Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "A problem on PETSc installation",
          "author": {
            "login": "xuxiaobei1995"
          },
          "bodyText": "Hi all,\nI'm installing the latest version of MOOSE in an offline way. I downloaded corresponding PETSc with required external packages and executed the update_and_rebuild_petsc.sh but to encounter a problem when PETsc installed STRUMPACK:\n\nIs it necessary for MOOSE to install PETSc with STRUMPACK? If necessary, does anyone know the way to solve this problem? Any suggestion is appreciated.\nXiaobei",
          "url": "https://github.com/idaholab/moose/discussions/17784",
          "updatedAt": "2022-08-10T11:44:45Z",
          "publishedAt": "2021-05-10T09:41:22Z",
          "category": {
            "name": "Q&A Getting Started"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "milljm"
                  },
                  "bodyText": "Strumpack is not necessary. I ran into a similar issue recently, and was told what I am telling you...",
                  "url": "https://github.com/idaholab/moose/discussions/17784#discussioncomment-718512",
                  "updatedAt": "2022-08-10T11:44:53Z",
                  "publishedAt": "2021-05-10T13:33:14Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "xuxiaobei1995"
                          },
                          "bodyText": "Thank you Jason! That's really a good news to me.",
                          "url": "https://github.com/idaholab/moose/discussions/17784#discussioncomment-718906",
                          "updatedAt": "2022-08-10T11:44:53Z",
                          "publishedAt": "2021-05-10T14:48:37Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "Perform  3D_6000_gr.i unable to initialize the system",
          "author": {
            "login": "Pengwei007"
          },
          "bodyText": "Hello MOOSE users,\nAccept my warm greetings. I used the input file 3D_6000_gr.i that already existed in the grain growth, but an error was displayed when the input file was executed. I hope someone can solve my problem. The commands I run and the information displayed in the terminal are as follows,\nmpirun -np 15 ~/projects/panda/panda-opt -i 3D_6000_gr.i\nBuilding mesh ............................................................................\n.....................................                                                      [114.32 s]\nCaching mesh information ......................                                            [ 23.97 s]\nInitializing equation system ..................................\n===================================================================================\n=   BAD TERMINATION OF ONE OF YOUR APPLICATION PROCESSES\n=   PID 2514893 RUNNING AT haochenmd-PowerEdge-T640\n=   EXIT CODE: 9\n=   CLEANING UP REMAINING PROCESSES\n=   YOU CAN IGNORE THE BELOW CLEANUP MESSAGES\n===================================================================================\nYOUR APPLICATION TERMINATED WITH THE EXIT STRING: Killed (signal 9)\nThis typically refers to a problem with your application.\nPlease see the FAQ page for debugging suggestions\n\nBest Regards,\nWordsworth",
          "url": "https://github.com/idaholab/moose/discussions/17198",
          "updatedAt": "2022-09-08T18:37:46Z",
          "publishedAt": "2021-03-03T08:27:57Z",
          "category": {
            "name": "Q&A Modules: Phase field"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "permcody"
                  },
                  "bodyText": "You are out of memory. This input file is rather old and it used \"ReplicatedMesh\" rather than the newer \"DistributedMesh\" capability. As a result you have to have on the order of 8-10GB per MPI rank, which almost no clusters have. I ran this by using only a few ranks per node on the cluster at the time (again about a quarter of what was available).\nThe movie from that run is in the MOOSE gallery (MOOSE Gallery - 3D Grain Tracking). If you need to run it as is, you'll have to reduce the number of CPUs per node. An alternative would be to try using distributed mesh but you may have more work to get it fully adapted. Are you trying to expand on this capability or just trying things out?",
                  "url": "https://github.com/idaholab/moose/discussions/17198#discussioncomment-426348",
                  "updatedAt": "2022-09-08T18:37:47Z",
                  "publishedAt": "2021-03-03T16:49:26Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "Pengwei007"
                          },
                          "bodyText": "Thank you so much for your suggestion. The purpose of this example is to take a look at the three-dimensional ideal grain growth. Later, I may simulate the three-dimensional grain growth based on this model.\nAccording to your suggestion, there are two ways to modify it.\nFirst, instead of using 15 Processors to compute it in parallel, it may need to be reduced to 5 or less, right?\nSecond, we can change the grid type from replicated grid to distributed grid to reduce memory overflow. Is my understanding correct?\nAnd when I add parallel_type = distributed # in [mesh] block included in the input file, and then run the command line in the terminalmpirun -np 5 ~/projects/panda/panda-opt -i 3D_6000_gr.i\nBut it still showing a similar error above. So if I using distributed mesh, What do I need to consider?",
                          "url": "https://github.com/idaholab/moose/discussions/17198#discussioncomment-427778",
                          "updatedAt": "2021-03-04T06:37:17Z",
                          "publishedAt": "2021-03-04T01:08:39Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "Hi\nYou may still be running out of memory.\nCan you monitor your memory, using top or htop and see if that's the problem?\nGuillaume",
                          "url": "https://github.com/idaholab/moose/discussions/17198#discussioncomment-495180",
                          "updatedAt": "2021-03-17T18:44:09Z",
                          "publishedAt": "2021-03-17T18:44:09Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "Pengwei007"
                          },
                          "bodyText": "Dear @GiudGiud,\nThis is the running status of the computer after I run 3D_6000_gr.i. It shows that the memory is not exceeded. This time I used 30 cores for calculation.\n\nIn addition, the information output to the terminal outputs the following information. I don't know which parameter in the input should be modified to solve this problem. Would you have any good suggestions?\n\nGrain #151 intersects Grain #179 (variable index: 0)\n\nDepth 0: Remapping grain #151 from variable index 0 to 18 which currently contains zero grains.\n\nGrain #155 intersects Grain #180 (variable index: 0)\n\nDepth 0: Remapping grain #155 from variable index 0 to 17 which currently contains zero grains.\n\nGrain #157 intersects Grain #186 (variable index: 0)\n\nDepth 0: Remapping grain #157 from variable index 0 to 16 which currently contains zero grains.\n\nGrain #164 intersects Grain #165 (variable index: 0)\n\nDepth 0: Remapping grain #164 from variable index 0 to 24 whose closest grain (#107) is at a distance of 75.1332\n\nGrain #191 intersects Grain #289 (variable index: 0)\n\nDepth 0: Remapping grain #191 from variable index 0 to 25 whose closest grain (#80) is at a distance of 98.4886\n\nGrain #193 intersects Grain #451 (variable index: 0)\n\nDepth 0: Remapping grain #193 from variable index 0 to 20 whose closest grain (#54) is at a distance of 83.9226\n\n\nThe detailed output information is in the 3D_6000_gr.log file.\nHao",
                          "url": "https://github.com/idaholab/moose/discussions/17198#discussioncomment-597661",
                          "updatedAt": "2022-09-13T07:43:53Z",
                          "publishedAt": "2021-04-12T01:39:16Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "Is this top screenshot captured right before the crash?\n@permcody will know what these warnings mean\nYour simulation got a lot further than initially it seems, with more processors, so the distributed mesh helped. Cody if you want to elaborate on what you meant by what's needed to get it fully adapted.\nGuillaume",
                          "url": "https://github.com/idaholab/moose/discussions/17198#discussioncomment-598004",
                          "updatedAt": "2022-09-13T07:44:25Z",
                          "publishedAt": "2021-04-12T04:57:34Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "Pengwei007"
                          },
                          "bodyText": "hi @GiudGiud, thank you so much for your feedback.\n\nIs this top screenshot captured right before the crash?\n\nThe above detection using htop is the computer usage in the Projecting initial condition of this calculation.\nWe found that the memory is not overflowing. According to your question, I ran this simulation again, and traced the memory in the \"Time Step 1, time = 0.0002, dt = 0.0002\" stage. The memory usage accounted for 99.06% of the total memory. It did have a memory overflow.\nHow should I modify the input file to prevent memory overflow during the Time Step phase of the calculation phase?\nThe following are the specific details of this simulation and the input terminal file,\n\nmpirun -np 30 ~/projects/panda/panda-opt -i 3D_6000_gr.i > 3D_6000_gr_02.log\n\n\nGrain #5899 intersects Grain #5911 (variable index: 13)\n\nDepth 0: Remapping grain #5899 from variable index 13 to 22 whose closest grain (#487) is at a distance of 27\n\nFinished inside of GrainTracker\nOutputting nemesis ...                                                                     [  4.63 s]\nTime Step 0, time = 0\nPostprocessor Values:\n+----------------+----------------+----------------+----------------+----------------+----------------+\n| time           | DOFs           | dt             | grain_tracker  | n_elements     | n_nodes        |\n+----------------+----------------+----------------+----------------+----------------+----------------+\n|   0.000000e+00 |   0.000000e+00 |   0.000000e+00 |   6.000000e+03 |   0.000000e+00 |   0.000000e+00 |\n+----------------+----------------+----------------+----------------+----------------+----------------+\nOutputting checkpoint\n...............                                                                            [ 16.64 s]\nTime Step 1, time = 0.0002, dt = 0.0002\nComputing initial residual ...........................................                     [ 44.71 s]\n0 Nonlinear |R| = 1.958070e+07\n=   BAD TERMINATION OF ONE OF YOUR APPLICATION PROCESSES\n=   PID 2174924 RUNNING AT pwmoose-PowerEdge-T640\n=   EXIT CODE: 9\n=   CLEANING UP REMAINING PROCESSES\n=   YOU CAN IGNORE THE BELOW CLEANUP MESSAGES\nYOUR APPLICATION TERMINATED WITH THE EXIT STRING: Killed (signal 9)\nThis typically refers to a problem with your application.\nPlease see the FAQ page for debugging suggestions\n\nBest Regards,\nhao",
                          "url": "https://github.com/idaholab/moose/discussions/17198#discussioncomment-610476",
                          "updatedAt": "2022-09-13T07:44:33Z",
                          "publishedAt": "2021-04-14T14:49:05Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "Hello\nYou could try using a different time stepping scheme, bdf2 requires storing 3 statepoints, some first order schemes will only store 2.\nOtherwise you could;\n\nprofile the code and try to optimize it for memory. This might be more involved than you want\nrun a smaller case. Maybe 5000 grains could run?\nuse a computing cluster. Most nodes these days have at least 128 GB of memory, so you could have more than your current machine in just 3 nodes.\n\nGuillaume",
                          "url": "https://github.com/idaholab/moose/discussions/17198#discussioncomment-610547",
                          "updatedAt": "2022-09-13T07:44:51Z",
                          "publishedAt": "2021-04-14T14:59:10Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "Pengwei007"
                          },
                          "bodyText": "Thank you @GiudGiud  very much for your careful guidance. I reduced the number of grains to 100. When the simulation reached the second step, there was still a memory overflow.\nThis is the result of the input file I used and output to the terminal,\n3D_6000_gr_07.i\n3D_6000_gr_07.log\nSimilarly, I also performed a simulation of 500 grains, and the memory overflowed without finishing the first step. I don't know if I have done stupid things, always making this three-dimensional simulation out of memory.\nhao",
                          "url": "https://github.com/idaholab/moose/discussions/17198#discussioncomment-626651",
                          "updatedAt": "2022-09-13T07:44:52Z",
                          "publishedAt": "2021-04-18T14:21:41Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              },
              {
                "node": {
                  "author": {
                    "login": "Traiwit"
                  },
                  "bodyText": "interesting, just wonder if changing the PETSc solving options would help to reduce memory usage? I also have the same problem with my simulation (4m elements) on 256gb system, I only can run with mpi up to 7 cores (out of 32 cores) before it's out of memory. @permcody @GiudGiud\ntype = Transient\n solve_type = 'NEWTON'\n start_time = 0.0\n end_time = 11\n nl_abs_tol = 1e-2\n nl_rel_tol = 1e-2\n # l_max_its = 30\n # nl_max_its = 1000\n  petsc_options_iname = '-pc_type -pc_hypre_type'\n  petsc_options_value = 'hypre    boomeramg'",
                  "url": "https://github.com/idaholab/moose/discussions/17198#discussioncomment-627920",
                  "updatedAt": "2022-09-13T07:44:54Z",
                  "publishedAt": "2021-04-19T00:19:37Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "@fdkong will know more about memory consumption of each petsc solver",
                          "url": "https://github.com/idaholab/moose/discussions/17198#discussioncomment-705589",
                          "updatedAt": "2022-09-13T07:45:09Z",
                          "publishedAt": "2021-05-06T17:36:29Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              },
              {
                "node": {
                  "author": {
                    "login": "fdkong"
                  },
                  "bodyText": "Please see the discussion at #17422 (reply in thread)",
                  "url": "https://github.com/idaholab/moose/discussions/17198#discussioncomment-705659",
                  "updatedAt": "2022-09-13T07:45:19Z",
                  "publishedAt": "2021-05-06T17:52:32Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "Pengwei007"
                          },
                          "bodyText": "Thank you very much for your reply, @fdkong.\nI read what you quoted by ykvishal, but the  ykvishal\u2018s calculation example  has not reached the Time Step stage, and is still in the Projecting initial condition stage. When I run on my server, the memory overflow occurred during the Time Step stage. Even if the number of grains was reduced to 100, it was detected that the memory overflowed temporarily at this stage.\nWhen I ran a two-dimensional simulation with me, this problem did not occur even with 25600 grains. The input file used was named poly_grain_growth_2D_eldrforce_25600_fcc_copper.i\nFinally, I will read #17422  carefully, looking forward to finding the answer here.\nhao",
                          "url": "https://github.com/idaholab/moose/discussions/17198#discussioncomment-709220",
                          "updatedAt": "2022-09-13T07:45:19Z",
                          "publishedAt": "2021-05-07T13:09:53Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "Stress definition in coupled HM analyses of unsaturated soil",
          "author": {
            "login": "nlosacco"
          },
          "bodyText": "Hi all,\nI am willing to start using MOOSE for my research in geotechnical engineering (mainly for slope stability and tunnelling problems) which involve coupled hydro-mechanical analyses in partly-saturated soils.\nI looked at the documentation but I wasn't able to understand which (effective) stress definition is used for the mechanical part of unsaturated porous materials.\nThe porous flow documentation:\nhttps://mooseframework.inl.gov/modules/porous_flow/governing_equations.html\nstates that, for the solid mechanics bit:\n\"[...]\u00a0for multi-phase situations P_f = [weighed sum of pore pressures for each phase] is also used. Yet, other expressions involve Bishop's parameter\".\nThe sentence above is a bit cryptic: is Bishop's stress used (i.e. sigma_tot - P_gas * delta + chi * (P_gas - P_water)*delta\nwith chi the Bishop's parameter)? Can the two independent stress variables approach be used (e.g. sigma_tot - P_water and P_gas - P_water)?\nWhere can I find some more detailed explanation about how MOOSE can deal with this? Can you point me to any examples on the topic?\nThank you in advance for any help,\nN",
          "url": "https://github.com/idaholab/moose/discussions/17609",
          "updatedAt": "2022-07-05T09:51:18Z",
          "publishedAt": "2021-04-14T17:42:53Z",
          "category": {
            "name": "Q&A Modules: General"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "GiudGiud"
                  },
                  "bodyText": "@WilkAndy",
                  "url": "https://github.com/idaholab/moose/discussions/17609#discussioncomment-705553",
                  "updatedAt": "2022-07-05T09:51:18Z",
                  "publishedAt": "2021-05-06T17:28:47Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "author": {
                    "login": "WilkAndy"
                  },
                  "bodyText": "The documentation is poorly worded, my apologies.  I will fix it to read something like \"[...] for multi-phase situations P_f = [weighed sum of pore pressures for each phase] is also used. These forms are coded into the PorousFlowEffectiveFluidPressure Material.  Other expressions, such as one involving Bishop's parameter, could be included into PorousFlow if users request.\"\nI'll fix the documentation in the coming days.",
                  "url": "https://github.com/idaholab/moose/discussions/17609#discussioncomment-706404",
                  "updatedAt": "2022-07-05T07:22:31Z",
                  "publishedAt": "2021-05-06T20:53:39Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "nlosacco"
                          },
                          "bodyText": "@WilkAndy Thank you very much for your clarification. I think the possibility to use Bishop's stress would be a valuable addition to the program for those interested in solving partly saturated soil mechanics problems like, e.g. , applications involving stability of slopes.\nBest,\nN",
                          "url": "https://github.com/idaholab/moose/discussions/17609#discussioncomment-708977",
                          "updatedAt": "2022-07-05T07:22:31Z",
                          "publishedAt": "2021-05-07T12:02:53Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "WilkAndy"
                          },
                          "bodyText": "You can submit an \"feature enhancement\" issue if you like, specifying exactly what you need (eg, is Bishop's param an AuxVariable, should this work for N phases, what about M components, etc).\na",
                          "url": "https://github.com/idaholab/moose/discussions/17609#discussioncomment-708999",
                          "updatedAt": "2022-07-05T07:22:31Z",
                          "publishedAt": "2021-05-07T12:11:37Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "MPI, threads and Minimum Clang",
          "author": {
            "login": "WilkAndy"
          },
          "bodyText": "Hi everyone,\nI'm hoping someone might have thoughts on how to fix a bug.  A recent PR of mine, #15698 , is not passing the \"Minimum Clang Version\".  All other recipes pass.  The problem is in a test that has\n    min_threads = 2\n    min_parallel = 2\n\nThe same test passes on Minimum Clang with just min_threads = 2 and with just min_parallel = 2, but not both threads and MPI active.  Also, this test has 2 timesteps, each producing a file from a LineValueSampler.  The file from the first timestep passes, but the single node that is on the postprocessor boundary yields the incorrect result on the second timestep.   I'm not 100% sure, but i believe that the cause is that NodalUserObject::execute() is not being run for this node at the second timestep.\nSo, two questions:\n\n\nany thoughts about what's going wrong?  I know this is difficult to answer without diving into my code, which you do NOT want to do!\n\n\nany thoughts about how to debug this?  I can't reproduce the error on any of my systems, and obviously CIVET can only produce the error on Minimum Clang.",
          "url": "https://github.com/idaholab/moose/discussions/16098",
          "updatedAt": "2022-12-29T04:53:54Z",
          "publishedAt": "2020-11-06T03:14:43Z",
          "category": {
            "name": "Q&A General"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "lindsayad"
                  },
                  "bodyText": "Does this happen every time on CIVET or only sometimes? It would be a blessing if it\u2019s every time; then the issue is less likely to be a dreaded race condition. I typically debug race conditions with helgrind but that\u2019s kind of difficult to get setup...you have to ensure your threads are entirely pthreads based",
                  "url": "https://github.com/idaholab/moose/discussions/16098#discussioncomment-123772",
                  "updatedAt": "2022-12-29T04:54:05Z",
                  "publishedAt": "2020-11-07T16:05:53Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "author": {
                    "login": "WilkAndy"
                  },
                  "bodyText": "I think it occurs every time.  What do you mean about pthreads?  I thought we couldn't control that sort of thing with MOOSE?  I just use NodalUserObject::threadJoin without thinking about behind-the-scenes stuff.",
                  "url": "https://github.com/idaholab/moose/discussions/16098#discussioncomment-123887",
                  "updatedAt": "2022-12-29T04:54:05Z",
                  "publishedAt": "2020-11-08T00:28:45Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "lindsayad"
                          },
                          "bodyText": "What thread library is used behind the scenes is controlled with libmesh configure options",
                          "url": "https://github.com/idaholab/moose/discussions/16098#discussioncomment-123891",
                          "updatedAt": "2024-03-18T04:48:15Z",
                          "publishedAt": "2020-11-08T00:43:03Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "WilkAndy"
                          },
                          "bodyText": "Oh, OK.  Just to eliminate this possibility: do you know whether the Minimum Clang recipe uses a different thread library to the other recipes?   My uneducated opinion is that the problem is unlikely to be the thread library since the test only fails when both MPI and threads are active, but passes otherwise (only MPI, and only threads, and neither)",
                          "url": "https://github.com/idaholab/moose/discussions/16098#discussioncomment-124400",
                          "updatedAt": "2022-12-29T04:54:07Z",
                          "publishedAt": "2020-11-08T22:03:16Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "permcody"
                          },
                          "bodyText": "Minimum Clang definitely did use a different thread implementation because of missing support, not because of an explicit selection of configuration flags. This may not be the case anymore as we've recently bumped the minimum version of things. Can you give us a little more information on what's going on in that test or which post process appears to be failing? I wouldn't expect any of the thread libraries to cause a specific failure like this if your postprocessor is implemented correctly.",
                          "url": "https://github.com/idaholab/moose/discussions/16098#discussioncomment-125236",
                          "updatedAt": "2022-12-29T04:54:07Z",
                          "publishedAt": "2020-11-09T18:59:52Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "lindsayad"
                          },
                          "bodyText": "GitHub discussions don't appear to show mentions from issues/PRs \ud83d\ude26 Now we can have trifurcated conversations. Conversation also over here: #15698 (comment) We do explicitly request --with-thread-model=pthread in that recipe, but we don't explicitly --disable-openmp. However, @permcody is right: that box doesn't appear to support openmp, so if you look at the configuration summary, there is no -fopenmp in CXXFLAGS. On my desktop, if I pass --with-thread-model=pthread, I still get -fopenmp.",
                          "url": "https://github.com/idaholab/moose/discussions/16098#discussioncomment-125254",
                          "updatedAt": "2022-12-29T04:54:07Z",
                          "publishedAt": "2020-11-09T19:38:35Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "lindsayad"
                          },
                          "bodyText": "Mmm also mentions of issues/PRs from discussions doesn't trigger an event on the referenced issue/PR either. I don't like that",
                          "url": "https://github.com/idaholab/moose/discussions/16098#discussioncomment-125256",
                          "updatedAt": "2022-12-29T04:54:08Z",
                          "publishedAt": "2020-11-09T19:39:44Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "permcody"
                          },
                          "bodyText": "Another relevant issue: libMesh/libmesh#2070",
                          "url": "https://github.com/idaholab/moose/discussions/16098#discussioncomment-125262",
                          "updatedAt": "2022-12-29T04:54:08Z",
                          "publishedAt": "2020-11-09T19:48:51Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              },
              {
                "node": {
                  "author": {
                    "login": "WilkAndy"
                  },
                  "bodyText": "Another note to this Discussion.  We have discovered that the test fails irrespective of whether MPI is used or not - ie spatial_4_threads and spatial_4_threads_MPI BOTH fail.  It probably makes debugging easier to know that MPI is not involved, and it could point to a race condition as the spatial_4_threads always (luckily) passed until now.\nThey are being skipped at #16122",
                  "url": "https://github.com/idaholab/moose/discussions/16098#discussioncomment-125303",
                  "updatedAt": "2022-12-29T04:54:10Z",
                  "publishedAt": "2020-11-09T20:53:29Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "author": {
                    "login": "WilkAndy"
                  },
                  "bodyText": "@lindsayad , thanks for your offer of help.  I want to have a look a bit first.  But could you please tell me why many modules tests have threads != pthreads ?  I've seen that so many times, and can't remember why it's there.  Perhaps pthreads are known to be crappy with MOOSE?",
                  "url": "https://github.com/idaholab/moose/discussions/16098#discussioncomment-125313",
                  "updatedAt": "2022-12-29T04:54:15Z",
                  "publishedAt": "2020-11-09T21:02:39Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "lindsayad"
                          },
                          "bodyText": "Hey look at this guy: #11977 (comment). You heard of him? \ud83d\ude09 So from later on in that thread, you have an explanation from @andrsd. I myself would like to know quantitatively what \"tonnes of threads\" means. Also we should definitely be erroring out if we are attempting to run pthreads on code that is not safe for pthreads.",
                          "url": "https://github.com/idaholab/moose/discussions/16098#discussioncomment-125339",
                          "updatedAt": "2023-01-10T21:24:14Z",
                          "publishedAt": "2020-11-09T21:26:58Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "WilkAndy"
                          },
                          "bodyText": "Thanks for the info about pthreads and GeneralUserObjects.\nThis current problem happens for a NodalUserObject, so i believe it's not relevant.",
                          "url": "https://github.com/idaholab/moose/discussions/16098#discussioncomment-125345",
                          "updatedAt": "2023-01-10T21:24:13Z",
                          "publishedAt": "2020-11-09T21:40:50Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "lindsayad"
                          },
                          "bodyText": "Correct, not relevant to your thread problem. But that is why there are so many instances of threading != pthreads in modules",
                          "url": "https://github.com/idaholab/moose/discussions/16098#discussioncomment-125356",
                          "updatedAt": "2023-01-10T21:24:13Z",
                          "publishedAt": "2020-11-09T21:53:42Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              },
              {
                "node": {
                  "author": {
                    "login": "WilkAndy"
                  },
                  "bodyText": "Hey everyone, just another small question - i've just opened #16128 to attempt to explore this problem.  I actually only want to run \"Minimum Clang\" and no other recipe.  Is that somehow possible?",
                  "url": "https://github.com/idaholab/moose/discussions/16098#discussioncomment-125367",
                  "updatedAt": "2023-01-10T21:24:14Z",
                  "publishedAt": "2020-11-09T22:07:24Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "permcody"
                          },
                          "bodyText": "Short answer is that we don't have a direct way but there is a solution that at least administrators can exercise:\n\nCancel all jobs\nInvalidate just the one job you are interested in seeing.",
                          "url": "https://github.com/idaholab/moose/discussions/16098#discussioncomment-125413",
                          "updatedAt": "2023-01-10T21:24:13Z",
                          "publishedAt": "2020-11-09T23:52:11Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "permcody"
                          },
                          "bodyText": "Seems like a good feature request. Hopefully my new technician (starting next month) may have time to start looking at expanding capabilities a bit here and there.",
                          "url": "https://github.com/idaholab/moose/discussions/16098#discussioncomment-125414",
                          "updatedAt": "2023-01-10T21:24:13Z",
                          "publishedAt": "2020-11-09T23:54:32Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              },
              {
                "node": {
                  "author": {
                    "login": "WilkAndy"
                  },
                  "bodyText": "I think i've got to the bottom of this, but don't have an adequate fix.  Thanks for your help @lindsayad and @permcody - perhaps you have suggestions on how to modify my code, or the tests or the framework.\nI believe it occurs because the threads do not stay attached to nodes between timesteps.  Let me try to explain.\nI have a NodalUserObject that computes a GeochemistrySpatialReactor egs_at_node at each node.  egs_at_node is different at each node and each timestep.  At each timestep, i copy the values of egs_at_node from the \"child threads\" to the \"main thread\" using threadJoin, at \n  \n    \n      moose/modules/geochemistry/src/userobjects/GeochemistrySpatialReactor.C\n    \n    \n        Lines 422 to 428\n      in\n      3032917\n    \n  \n  \n    \n\n        \n          \n           GeochemistrySpatialReactor::threadJoin(const UserObject & uo) \n        \n\n        \n          \n           { \n        \n\n        \n          \n             const GeochemistrySpatialReactor & gsr = static_cast<const GeochemistrySpatialReactor &>(uo); \n        \n\n        \n          \n             for (unsigned i = 0; i < _num_my_nodes; ++i) \n        \n\n        \n          \n               if (!_execute_done[i] && gsr._execute_done[i]) \n        \n\n        \n          \n                 _egs_at_node[i] = gsr._egs_at_node[i]; \n        \n\n        \n          \n           } \n        \n    \n  \n\n .   (\"child threads\" and \"main thread\" are my names - i hope i've interpreted threadJoin correctly.)\nDuring initialization of the simulation, egs_at_node gets initialized in all threads.  Now consider the case where a main thread looks after node=0 for the first N timesteps.  Then threadJoin doesn't do anything for egs_at_node[0] (ie, at node=0) at these timesteps, which is as desired.  Now suppose that a child thread looks after node=0 at timestep N+1.  The problem is that its copy of egs_at_node[0] is still in the initialized state: it hasn't ever been touched by execute().  So threadJoin copies this egs_at_node[0] to the main thread, which overwrites it with incorrect values.\nHopefully this makes sense.\nI don't know for 100% sure that this is happening, but my mucking around at line 436 of \n  \n    \n      moose/modules/geochemistry/src/userobjects/GeochemistrySpatialReactor.C\n    \n    \n        Lines 422 to 443\n      in\n      2371699\n    \n  \n  \n    \n\n        \n          \n           GeochemistrySpatialReactor::threadJoin(const UserObject & uo) \n        \n\n        \n          \n           { \n        \n\n        \n          \n             GeochemistrySpatialReactor & gsr = \n        \n\n        \n          \n                 static_cast<GeochemistrySpatialReactor &>(const_cast<UserObject &>(uo)); \n        \n\n        \n          \n             for (unsigned i = 0; i < _num_my_nodes; ++i) \n        \n\n        \n          \n             { \n        \n\n        \n          \n               if (!_execute_done[i] && gsr._execute_done[i]) \n        \n\n        \n          \n               { \n        \n\n        \n          \n                 _console << \"execute_done by exactly one other thread, good, \" << i << '\\n' << std::endl; \n        \n\n        \n          \n                 _egs_at_node[i] = gsr._egs_at_node[i]; \n        \n\n        \n          \n               } \n        \n\n        \n          \n               if (_execute_done[i] && !gsr._execute_done[i]) \n        \n\n        \n          \n               { \n        \n\n        \n          \n                 _console << \"execute_done by only main thread, good, \" << i << '\\n' << std::endl; \n        \n\n        \n          \n                 gsr._egs_at_node[i] = _egs_at_node[i]; \n        \n\n        \n          \n               } \n        \n\n        \n          \n               if (!_execute_done[i] && !gsr._execute_done[i]) \n        \n\n        \n          \n                 mooseError(\"Execute not done by either thread for node \", i); \n        \n\n        \n          \n               if (_execute_done[i] && gsr._execute_done[i]) \n        \n\n        \n          \n                 mooseError(\"Execute done by both threads for node \", i); \n        \n\n        \n          \n             } \n        \n\n        \n          \n           } \n        \n    \n  \n\n suggests that it's true (the mucking around only works for 2 threads).\nSo, where to go from here?",
                  "url": "https://github.com/idaholab/moose/discussions/16098#discussioncomment-125509",
                  "updatedAt": "2023-01-10T21:24:14Z",
                  "publishedAt": "2020-11-10T06:23:42Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "permcody"
                          },
                          "bodyText": "Correct Andy. Threads are not guaranteed to have any sort of affinity so this is indeed likely the case. You should treat threads as independent processing tasks that are somewhat disconnected to the underlying memory layout. In the general case the OS can select any thread that's available and assign it to a task. As you've noticed this isn't always the case. With some models we do have thread affinity, but other we do not.\nOption 1: You can create a map instead of an ordered vector to handle your contributions back into your main data structure. That way no matter which thread handles a particular request, you'll be assured it ends up in the right spot during the join.\nOption 2: You can create a global data structure (static) and sum directly into it. Note that you do have to be careful about this kind of approach. Is your data structure thread safe meaning it can handle concurrent writes, or do you have to implement some sort of locking mechanism. In MOOSE we have a little of both. Depending on your needs we do have a thread-safe \"hash map\" available and there are also lock abstractions you can use to write to the master data structure.",
                          "url": "https://github.com/idaholab/moose/discussions/16098#discussioncomment-125751",
                          "updatedAt": "2024-03-18T04:46:57Z",
                          "publishedAt": "2020-11-10T15:16:19Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "WilkAndy"
                          },
                          "bodyText": "Thanks for those options, @permcody.   I don't really understand how each of them work.  Sorry for being so ignorant.  At the moment i have things like \n  \n    \n      moose/modules/geochemistry/include/userobjects/GeochemistrySpatialReactor.h\n    \n    \n        Lines 51 to 52\n      in\n      b908c63\n    \n  \n  \n    \n\n        \n          \n           /// ModelGeochemicalDatabase at each node \n        \n\n        \n          \n           std::vector<GeochemicalSystem> _egs_at_node; \n        \n    \n  \n\n\nOption 1: Are you saying this should somehow be a std::map with keys being node numbers and values being GeochemicalSystem ?   I don't understand how this is going to help.  Won't all the threads have their own copy of this map?\nOption 2:  Are you saying i should just write static in front of this line?    I think std::vectors are thread safe.   Then I don't have to do anything in threadJoin?",
                          "url": "https://github.com/idaholab/moose/discussions/16098#discussioncomment-126008",
                          "updatedAt": "2024-03-18T04:46:58Z",
                          "publishedAt": "2020-11-10T20:32:08Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "WilkAndy"
                          },
                          "bodyText": "Don't forget to reply at some stage :-)",
                          "url": "https://github.com/idaholab/moose/discussions/16098#discussioncomment-127218",
                          "updatedAt": "2024-03-18T06:57:47Z",
                          "publishedAt": "2020-11-11T20:18:58Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "He forgot ^^. @permcody\nstatic only provides thread safety at initialization. You'd still need a lock to modify it. If threads are just reading from it, then no worries.\nIt's also quite common in moose to have everything duplicated for each threads, to avoid locks.\n@WilkAndy can this be closed?",
                          "url": "https://github.com/idaholab/moose/discussions/16098#discussioncomment-704587",
                          "updatedAt": "2024-03-18T06:57:48Z",
                          "publishedAt": "2021-05-06T14:53:56Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              },
              {
                "node": {
                  "author": {
                    "login": "WilkAndy"
                  },
                  "bodyText": "Thanks @GiudGiud , this may be closed because of #16133 .   In summary: main thread gets info from the other threads during GeochemistrySpatialReactor::threadJoin, so main thread has all correct info after threadJoin.  Then, by #16133 , during the main-thread call of GeochemistrySpatialReactor::finalize(), the other-thread info is set equal to the main-thread info.  Hence, after finalize(), all threads have correct info.",
                  "url": "https://github.com/idaholab/moose/discussions/16098#discussioncomment-706668",
                  "updatedAt": "2024-03-18T06:57:54Z",
                  "publishedAt": "2021-05-06T22:23:32Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": []
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "Boussinesq for compressible fluid in NS module   ---------  Moving from Google User Group",
          "author": {
            "login": "ChrocheMisawa"
          },
          "bodyText": "Hello all,\nI would like to ask if current moose objects are able to solve a 3D transient natural convection problems for gas, such as the cooling of a hot storage cask by its surrounding air.\nThe input files under NS module folder only showed examples for incompressible material.\nDigging through the old threads, I see that Finite Volume methods was under development last, but it looks like it is still only valid for incompressible fluid at the current stage?\nMy end goal is to model the air cooling on an cylindrical cask, and later modeling a hex cooling channel. (Combined with HeatConduction Kernel)\nI have created a simple shell cylinder geometry that injects air from bottom to the top. But I was not able to use the InnerSurface as the heat surface to trigger the convection process.\nThe mesh file I used can be downloaded from here:\nhttps://drive.google.com/file/d/1-gvpLc3RptmA_OiLdVZnioWOq-bksUeT/view?usp=sharing\nhttps://drive.google.com/file/d/1PWP--BQMNr8AsrbJJa1VJIGj2wL6o9cl/view?usp=sharing\nCan anybody suggest some suitable objects that I can use (modify) to simulate an natural convection for this problem?\nThank you,\nZeyu Chen",
          "url": "https://github.com/idaholab/moose/discussions/17600",
          "updatedAt": "2022-06-10T12:59:47Z",
          "publishedAt": "2021-04-14T09:16:55Z",
          "category": {
            "name": "Q&A Modules: Navier-Stokes"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "GiudGiud"
                  },
                  "bodyText": "Hello\nWe indeed only have incompressible fluid in finite volume right now. If the temperature delta is not too high you could consider using the Boussinesq approximation. There is a PR up for FV compressible flow though, so that capability will be added soon.\nAll the kernels for modeling a cask with FE are already in MOOSE and its modules.\nYou'll need an interface kernel for convection at the surface. I am working on one now for finite volume.\nFor FE, you can have a look at ConjugateHeatTransfer\nBest,\nGuillaume",
                  "url": "https://github.com/idaholab/moose/discussions/17600#discussioncomment-610576",
                  "updatedAt": "2022-06-10T12:59:42Z",
                  "publishedAt": "2021-04-14T15:06:55Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "ChrocheMisawa"
                          },
                          "bodyText": "Hello,\nThanks for you reply!\nI looked at the ConjugateHeatTransfer example, it does not look like that it can handle the movement of the fluid phase. Or should I couple some other objects to my fluid block?\nFor a cylindrical geometry that has heat source in it and cooled by surrounding air, I am trying to get some results that looks like the right contour in the picture below.\nI have managed to produce the left contour by using a ConvectiveFluxFunction BC. I assume the ConjugateHeatTransfer is also only capable to reproduce the left picture?",
                          "url": "https://github.com/idaholab/moose/discussions/17600#discussioncomment-610899",
                          "updatedAt": "2022-06-10T12:59:43Z",
                          "publishedAt": "2021-04-14T16:13:28Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "Hi\nTo have the movement of the fluid phase you need to look at advection kernels. The convective heat transfer interface kernel (the boundary condition should also work) just gets heat from the solid to the fluid, it does not move the fluid.\nMOOSE can do laminar flow, once you have fluid advection kernels you should be able to reproduce the figure on the right.\nGuillaume",
                          "url": "https://github.com/idaholab/moose/discussions/17600#discussioncomment-612537",
                          "updatedAt": "2022-06-10T12:59:47Z",
                          "publishedAt": "2021-04-14T22:18:09Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "ChrocheMisawa"
                          },
                          "bodyText": "Thank you!\nI looked at the advection kernels for NS, it looks like they are all for incomprehensible fluids using finite volume method (IFV).\nShould I use the \"ConservativeAdvection\" kernel instead?",
                          "url": "https://github.com/idaholab/moose/discussions/17600#discussioncomment-612968",
                          "updatedAt": "2022-06-10T12:59:43Z",
                          "publishedAt": "2021-04-15T01:22:34Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "ChrocheMisawa"
                          },
                          "bodyText": "To follow up my previous comment, my question is what kernel and material objects should I use for my fluid block?\nIt seems that the material objects for NS module are mostly for incompressible flow. I tried to use \"Air\" with the [CompressibleNavierStokes] module but that did give a converged result.\nThe \"ConservativeAdvection\" normally should stabilize the solution for me, if I am correct. But it seems that the variables used in the \"module\" cannot be coupled with the variable requested by \"ConservativeAdvection\" directly.\nIs there any example input files for compressible fluid advection that I may refer? Most of the example files only uses INS or IFV materials which I believe is not valid for my case.\nThank you,\nZeyu Chen",
                          "url": "https://github.com/idaholab/moose/discussions/17600#discussioncomment-614000",
                          "updatedAt": "2022-10-17T18:08:43Z",
                          "publishedAt": "2021-04-15T07:44:15Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "If you want to use compressible flow, your best bet is to use the finite volume implementation the #17538 PR\nI am not familiar with the finite element version. Most work on this is in the Pronghorn MOOSE application, for which you will have to request access.More info at https://mooseframework.inl.gov/help/inl/index.html\nGuillaume",
                          "url": "https://github.com/idaholab/moose/discussions/17600#discussioncomment-617986",
                          "updatedAt": "2022-10-17T18:08:45Z",
                          "publishedAt": "2021-04-15T22:25:03Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "ChrocheMisawa"
                          },
                          "bodyText": "Finite volume method also sounds interesting to me. Is #17538 open to public? It looks like it is still under development.",
                          "url": "https://github.com/idaholab/moose/discussions/17600#discussioncomment-618692",
                          "updatedAt": "2022-10-17T18:08:46Z",
                          "publishedAt": "2021-04-16T04:42:05Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "As soon as the PR is up, it's technically open.\nIt is indeed still in development. if you encounter issues it would help to report them to @lindsayad.\n@lindsayad  do you mind the early user? Or could we share the FE HLLC branch?",
                          "url": "https://github.com/idaholab/moose/discussions/17600#discussioncomment-618711",
                          "updatedAt": "2022-10-17T18:08:46Z",
                          "publishedAt": "2021-04-16T04:52:23Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "lindsayad"
                          },
                          "bodyText": "Anyone can do whatever they want with it \ud83d\ude04 Yea just know that since that branch is under development things are liable to change",
                          "url": "https://github.com/idaholab/moose/discussions/17600#discussioncomment-618758",
                          "updatedAt": "2022-10-17T18:08:46Z",
                          "publishedAt": "2021-04-16T05:14:11Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "ChrocheMisawa"
                          },
                          "bodyText": "Anyone can do whatever they want with it \ud83d\ude04 Yea just know that since that branch is under development things are liable to change\n\nGood to know!\nMay I ask how should I utilize that branch?\nWould there be any example input files, since the current examples I have are all for IFV objects.",
                          "url": "https://github.com/idaholab/moose/discussions/17600#discussioncomment-618775",
                          "updatedAt": "2022-10-17T18:08:46Z",
                          "publishedAt": "2021-04-16T05:24:08Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "lindsayad"
                          },
                          "bodyText": "The best place to look for examples is in moose/modules/navier_stokes/test/tests/finite_volume/cns",
                          "url": "https://github.com/idaholab/moose/discussions/17600#discussioncomment-618800",
                          "updatedAt": "2022-10-17T18:08:31Z",
                          "publishedAt": "2021-04-16T05:38:53Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              },
              {
                "node": {
                  "author": {
                    "login": "lindsayad"
                  },
                  "bodyText": "Not really. You can open the \u2018tests\u2019 file which should exist in most directories. In that file there should be \u2018requirements\u2019 that outline what is being tested.\n\u2026\n On Apr 16, 2021, at 2:06 AM, ChrocheMisawa ***@***.***> wrote:\n\n \ufeff\n Thank you!\n\n I have switched to this branch and have seen these example files.\n Is there any description for those test examples? It's Ok if not, I can interpret the by myself.\n\n Best,\n Zeyu Chen\n\n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub, or unsubscribe.",
                  "url": "https://github.com/idaholab/moose/discussions/17600#discussioncomment-620724",
                  "updatedAt": "2022-06-10T12:59:47Z",
                  "publishedAt": "2021-04-16T14:23:59Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "ChrocheMisawa"
                          },
                          "bodyText": "Which \"test\" are you referring to?\nFor example, I am running the \"hllc_sod_shocktube_2D.i\" case located in:\nmoose/modules/navier_stokes/test/tests/finite_volume/cns/shock_tube_2D_cavity/\nbut the \"tests\" file in the same folder only shows:",
                          "url": "https://github.com/idaholab/moose/discussions/17600#discussioncomment-620957",
                          "updatedAt": "2022-06-10T12:59:44Z",
                          "publishedAt": "2021-04-16T15:07:46Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              },
              {
                "node": {
                  "author": {
                    "login": "lindsayad"
                  },
                  "bodyText": "Mmm yea looks like some of the earlier tests don\u2019t have the requirements yet\n\u2026\n On Apr 16, 2021, at 8:08 AM, ChrocheMisawa ***@***.***> wrote:\n\n \ufeff\n Which \"test\" are you referring to?\n\n For example, I am running the \"hllc_sod_shocktube_2D.i\" case located in:\n moose/modules/navier_stokes/test/tests/finite_volume/cns/shock_tube_2D_cavity/\n\n but the \"tests\" file in the same folder only shows:\n\n\n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub, or unsubscribe.",
                  "url": "https://github.com/idaholab/moose/discussions/17600#discussioncomment-621074",
                  "updatedAt": "2022-06-10T12:59:44Z",
                  "publishedAt": "2021-04-16T15:34:54Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "ChrocheMisawa"
                          },
                          "bodyText": "That's Ok, It's good to know that some tests will have outlines for us \ud83d\udc4d",
                          "url": "https://github.com/idaholab/moose/discussions/17600#discussioncomment-621099",
                          "updatedAt": "2022-06-10T12:59:44Z",
                          "publishedAt": "2021-04-16T15:40:09Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "ChrocheMisawa"
                          },
                          "bodyText": "Hello\uff0c\nI was trying to create a test natural convection case using air, by modifying the input file located at\nmoose/modules/navier_stokes/test/tests/ins/boussinesq/boussinesq_square.i\nBut it looks like the buoyancy kernel and material objects are not yet included for Compressible NSFV?\nOr do they have different names?\nWould you please provide a simple 2D box example case if it is achievable in the current version of moose?\nFor example, cold surface on left and hot surface on right.\nThank you,\nZeyu Chen",
                          "url": "https://github.com/idaholab/moose/discussions/17600#discussioncomment-645022",
                          "updatedAt": "2022-06-10T12:59:46Z",
                          "publishedAt": "2021-04-22T13:04:23Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "lindsayad"
                          },
                          "bodyText": "Note that there are four tests in upstream MOOSE in modules/navier_stokes/test/tests/finite_volume/ins/boussinesq/tests for Rayleigh numbers ranging from 1e3-1e6 that reproduce the results shown in #16023. I have also just pushed to my cnsfv branch (#17538) a couple of test cases that solve Rayleigh numbers of ~1e4 and ~1e5 using a purely compressible formulation, e.g. the tests do not use Boussinesq approximation kernels. These tests are in modules/navier_stokes/test/tests/finite_volume/cns/natural_convection/tests. Note that these use steady solves which are necessary for the convection discretization scheme used in the average-boussinesq.i input file (simple second-order central differencing). If you try to convert that input to do a transient solve you will likely see oscillations. Our current first order scheme (based on Kurganov-Tadmor without higher-order interpolation to faces) is too dissipative to yield physical results. However, I will be adding slope limiting soon such that we can bump the spatial accuracy to second order in smooth regions such that we will hopefully be able to run both steady and transient natural convection problems with a pure compressible formulation soon.\nHere are the FV compressible results for the velocity magnitude for the two different Rayleigh numbers I've tested:\nRa = 1.7e4\n\nRa = 1.4e5",
                          "url": "https://github.com/idaholab/moose/discussions/17600#discussioncomment-668023",
                          "updatedAt": "2022-06-10T12:59:44Z",
                          "publishedAt": "2021-04-28T08:00:02Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "ChrocheMisawa"
                          },
                          "bodyText": "Thank you!\nMay I ask when the slope limiting will be added?(roughly)\nI also found that many of the interface kernels test failed in your branch.\nAnd I was trying to test the ConjugateHeatTransfer module, so that I may apply a heat source in solid and import heat to the liquid, but is getting:\n\"ERROR: no MaterialPropertyName parameter named \"prop_getter_suffix\" found.\"\nI believe it work for the original Moose branch, is this just something with your branch specifically?",
                          "url": "https://github.com/idaholab/moose/discussions/17600#discussioncomment-677530",
                          "updatedAt": "2024-03-18T00:45:57Z",
                          "publishedAt": "2021-04-30T02:41:27Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "ChrocheMisawa"
                          },
                          "bodyText": "To follow my question, could you please show me how you calculated the Ra number?\nI was having trouble to find the numbers for some coefficients.\nThank you,\nZeyu Chen",
                          "url": "https://github.com/idaholab/moose/discussions/17600#discussioncomment-680142",
                          "updatedAt": "2024-03-18T00:45:57Z",
                          "publishedAt": "2021-04-30T15:47:40Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "lindsayad"
                          },
                          "bodyText": "May I ask when the slope limiting will be added?(roughly)\n\nI might attempt to do this within the next week\n\nI also found that many of the interface kernels test failed in your branch.\nAnd I was trying to test the ConjugateHeatTransfer module, so that I may apply a heat source in solid and import heat to the liquid, but is getting:\n\"ERROR: no MaterialPropertyName parameter named \"prop_getter_suffix\" found.\"\nI believe it work for the original Moose branch, is this just something with your branch specifically?\n\nprop_getter_suffix is added in my branch so yes it is definitely an issue with my branch specifically. I can't say when I'll get to fixing that but obviously it will have be fixed before my PR is merged\n\nTo follow my question, could you please show me how you calculated the Ra number?\n\nThis script shows my computation of the Rayleigh numbers:\ndef eta(mu, rho):\n    return mu / rho\ndef alpha(k, rho, cp):\n    return k / (rho * cp)\ndef beta(T):\n    return 1. / T\ndef Tavg(Th,Tc):\n    return (Th + Tc) / 2.\ndef dT(Th,Tc):\n    return Th - Tc\ndef Ra(rho, beta, dT, l, g, eta, alpha):\n    return rho * beta * dT * l**3 * g / (eta * alpha)\n\nrho = 1.29\ng = 9.81\ngamma = 1.4\nR = 8.3145\nweight = 29e-3 # air\ncp = gamma * (R /weight) / (gamma - 1)\nTh = 400\nTc = 273.15\nmu = 18.23e-6\nk = 25.68e-3\n\nl = 1e-2\nprint(Ra(rho, beta(Tavg(Th, Tc)), dT(Th, Tc), l, g, eta(mu, rho), alpha(k, rho, cp)))\nl = 2e-2\nprint(Ra(rho, beta(Tavg(Th, Tc)), dT(Th, Tc), l, g, eta(mu, rho), alpha(k, rho, cp)))",
                          "url": "https://github.com/idaholab/moose/discussions/17600#discussioncomment-680788",
                          "updatedAt": "2024-03-18T00:45:58Z",
                          "publishedAt": "2021-04-30T18:51:52Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "ChrocheMisawa"
                          },
                          "bodyText": "Related to the ConjugateHeatTransfer kernel, does that mean currently the heat transfer feature at the interface between solid and fluid is not yet available? Or maybe I can try using a multi-app?\nThank you,\nZeyu Chen",
                          "url": "https://github.com/idaholab/moose/discussions/17600#discussioncomment-689790",
                          "updatedAt": "2024-03-18T00:46:02Z",
                          "publishedAt": "2021-05-03T18:19:22Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "For finite volume it's currently not available. I'm adding diffusion and convection in this PR #17640 though it's not quite ready yet.\nYou can do this with a multiapp approach, in which case you'll have to use Neumann (function) boundary conditions based on the differences between the fluid and solid temperature at the interface.  You'll have to use average values or try to sample points on the boundaries. I have not done the latter before.\nBest,\nGuillaume",
                          "url": "https://github.com/idaholab/moose/discussions/17600#discussioncomment-689821",
                          "updatedAt": "2024-03-18T00:46:02Z",
                          "publishedAt": "2021-05-03T18:27:34Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "ChrocheMisawa"
                          },
                          "bodyText": "Got it, thank you!",
                          "url": "https://github.com/idaholab/moose/discussions/17600#discussioncomment-690029",
                          "updatedAt": "2024-03-18T00:46:02Z",
                          "publishedAt": "2021-05-03T19:25:11Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "ChrocheMisawa"
                          },
                          "bodyText": "Note that there are four tests in upstream MOOSE in modules/navier_stokes/test/tests/finite_volume/ins/boussinesq/tests for Rayleigh numbers ranging from 1e3-1e6 that reproduce the results shown in #16023. I have also just pushed to my cnsfv branch (#17538) a couple of test cases that solve Rayleigh numbers of ~1e4 and ~1e5 using a purely compressible formulation, e.g. the tests do not use Boussinesq approximation kernels. These tests are in modules/navier_stokes/test/tests/finite_volume/cns/natural_convection/tests. Note that these use steady solves which are necessary for the convection discretization scheme used in the average-boussinesq.i input file (simple second-order central differencing). If you try to convert that input to do a transient solve you will likely see oscillations. Our current first order scheme (based on Kurganov-Tadmor without higher-order interpolation to faces) is too dissipative to yield physical results. However, I will be adding slope limiting soon such that we can bump the spatial accuracy to second order in smooth regions such that we will hopefully be able to run both steady and transient natural convection problems with a pure compressible formulation soon.\nHere are the FV compressible results for the velocity magnitude for the two different Rayleigh numbers I've tested:\nRa = 1.7e4\n\nRa = 1.4e5\n\n\nHi Lindsay @lindsayad\nI'm no longer able to fetch your #17538 branch, could you please check what is wrong?\nThank you,\nZeyu Chen",
                          "url": "https://github.com/idaholab/moose/discussions/17600#discussioncomment-706565",
                          "updatedAt": "2022-10-17T18:08:52Z",
                          "publishedAt": "2021-05-06T21:46:13Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      }
    ]
  }
}