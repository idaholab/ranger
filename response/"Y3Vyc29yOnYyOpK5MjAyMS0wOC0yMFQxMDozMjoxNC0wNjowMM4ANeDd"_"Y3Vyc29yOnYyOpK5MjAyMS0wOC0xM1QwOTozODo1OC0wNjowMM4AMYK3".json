{
  "discussions": {
    "pageInfo": {
      "hasNextPage": true,
      "endCursor": "Y3Vyc29yOnYyOpK5MjAyMS0wOC0xM1QwOTozODo1OC0wNjowMM4AMYK3"
    },
    "edges": [
      {
        "node": {
          "title": "Sample problem .e files",
          "author": {
            "login": "TLWise"
          },
          "bodyText": "I would like to run the example contact sliding block problem. Where do I find the exodus (sliding_elastic_blocks_2d.e) files needed to perform the analysis?",
          "url": "https://github.com/idaholab/moose/discussions/18551",
          "updatedAt": "2021-08-20T15:23:10Z",
          "publishedAt": "2021-08-06T20:20:43Z",
          "category": {
            "name": "Q&A Getting Started"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "GiudGiud"
                  },
                  "bodyText": "You can find files with that name (which will contain the mesh) in the tests there:\n/modules/contact/test/tests/frictional/sliding_elastic_blocks_2d/gold/sliding_elastic_blocks_2d_out.e\n/modules/contact/test/tests/frictional/sliding_elastic_blocks_2d/sliding_elastic_blocks_2d.e\n/modules/contact/test/tests/sliding_block/sliding/sliding_elastic_blocks_2d.e\nLet me know if that s not the one you need",
                  "url": "https://github.com/idaholab/moose/discussions/18551#discussioncomment-1155420",
                  "updatedAt": "2021-08-10T18:30:37Z",
                  "publishedAt": "2021-08-10T18:30:26Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "TLWise"
                          },
                          "bodyText": "Got it. I was able to find the files and run the code. Thank you.",
                          "url": "https://github.com/idaholab/moose/discussions/18551#discussioncomment-1212300",
                          "updatedAt": "2021-08-20T15:23:00Z",
                          "publishedAt": "2021-08-20T15:23:00Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "Error running distributed mesh",
          "author": {
            "login": "bhollra"
          },
          "bodyText": "Hi and thanks for reading,\nI am attempting to run a simulation with a distributed mesh by following the information here. I am able split the mesh successfully with this command: sam-opt -i input.i --split-mesh 6 creating a folder ./mesh_file.cpr/6/ as I expected.\nHowever, when I attempt to run the simulation on the distributed mesh with mpiexec -n 6 ~/projects/SAM/sam-opt -i input.i --use-split I get the following error:\nERROR: Neither one of the following files can be located:\n        '/path/./mesh_file.cpr/1/header.cpr' nor\n        '/path/./mesh_file.cpr'\nIf you are running a parallel job, double check that you've created a split for 1 ranks.\nNote: One of paths above may refer to a valid directory on your system, however we are attempting to read a valid header file.\nIn the documentation it sounds like the code should automatically search for a mesh split by the number of cores specified in the mpiexec command, in this case 6. But this error message seems to indicate the code is looking for a mesh with 1 split.\nI am curious if anyone has any insight into the cause of this error? Is it possible this is a SAM specific issue?\nP.S. My framework information is:\nMOOSE Version:           git commit 48fe948cda on 2020-02-17\nLibMesh Version:         3b8296b3b7c2b526d0be242fa6208750c0ede69b\nPETSc Version:           3.11.4\nSLEPc Version:           3.11.0",
          "url": "https://github.com/idaholab/moose/discussions/18583",
          "updatedAt": "2022-06-21T14:44:06Z",
          "publishedAt": "2021-08-11T19:03:43Z",
          "category": {
            "name": "Q&A General"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "GiudGiud"
                  },
                  "bodyText": "Hello\nThe fact that it's looking for a 1-split makes me think something went terribly wrong with MPI. Like the code was compiled with a different MPI implementation than the mpirun you are using, and each process is identifying the number of ranks incorrectly.\nI'm not familiar with SAM. I dont think they would have modified this, even though their typical use case should not require split meshes.\n@travismui is there anything we should be aware of with regards to SAM and distributed runs?\nDo you really need distributed meshes with a pre-split? The impact on performance is usually negligible. It's only done to save some memory (and save some time on IO with slow file systems for the split). What is your application? SAM is more than reasonable with memory usage\nGuillaume",
                  "url": "https://github.com/idaholab/moose/discussions/18583#discussioncomment-1165097",
                  "updatedAt": "2022-06-21T14:52:21Z",
                  "publishedAt": "2021-08-12T18:35:14Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "bhollra"
                          },
                          "bodyText": "Hi Guillaume,\nThanks for your response. In this case, I am using SAM to model a large 3D solid heat conduction domain, so the memory demands are quite large. Without a distributed mesh I am currently limited to running on only one processor.\nMy SAM/MOOSE version was about a year and a half old. After updating to the newest version last night, the simulation is now able to load the '/path/./mesh_file.cpr/6/header.cpr' folder correctly. So it seems you were right and there likely was some incompatibility issue going on with MPI.\nHowever, I am now seeing a new error:\n*** ERROR ***\nThe following error occurred in the object \"MOOSE Problem\", of type \"FEProblem\".\nNeed Exodus reader to restart variables but the reader is not available\nUse either FileMesh with an Exodus mesh file or FileMeshGenerator with an Exodus mesh' 'file and with use_for_exodus_restart equal to true\nIncluded bedlow are my mesh blocks and variable blocks:\n[Mesh]\n\tfile = ${meshFileName}\n[]\n[Variables]\n\t[./T_solid]\n\t\torder = FIRST\n\t\tfamily = LAGRANGE\n\t\tblock = 'all blocks'\n\t\tscaling = 1.0E-2\n\t\tinitial_from_file_var = T_solid\n\t\tinitial_from_file_timestep = 2\n\t[../]\n[]\nIt appears to me that the error is cause by the initial_from_file_var parameter in the variable sub-block. When initial_from_file_var and initial_from_file_timestep are removed and replaced with test constant IC:\n[./InitialCondition]\ntype = ConstantIC\nvalue = 1000\n[../]\nThe simulation is able to run successfully.\nIt seems that variable data are not stored in the split mesh files. Is it possible to initialize a distributed simulation with a variable from an Exodus file that is not distributed via another method?\nSome background on my simulations: The simulation that is currently giving me an error is a transient simulation that needs to be initialized with a temperature distribution calculated by a steady state simulation. The steady state simulation uses multiapps to couple the 3D solid domain with several 1D fluid components. It is my understanding that is is not possible to use multiapps and a distributed mesh together, so I was forced to use one processor for the steady state simulation. Now, attempting the transient simulation, the model no longer includes the 1D fluid multiapps (it is a pure 3D solid conduction problem), so I am hoping to use to distributed mesh to decrease the simulation time.\nThank you,\nBrent\nP.S. I have created a very simplified version of my input and reproduced the same errors using the combined-opt moose module, so I feel confident this is not a SAM specific error.\nP.P.S. Updated framework information:\nMOOSE Version:           git commit 71aebe45e9 on 2021-08-11\nLibMesh Version:         \nPETSc Version:           3.15.1\nSLEPc Version:           3.15.1",
                          "url": "https://github.com/idaholab/moose/discussions/18583#discussioncomment-1169284",
                          "updatedAt": "2022-06-21T16:44:38Z",
                          "publishedAt": "2021-08-13T16:52:58Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              },
              {
                "node": {
                  "author": {
                    "login": "GiudGiud"
                  },
                  "bodyText": "Hello\n\nThe solution for your issue is to use a file mesh generator (in one word) and set the parameter \u2018use_for_exodus_restart = true\u2019.\n\nGuillaume\n\u2026\n Le 13 ao\u00fbt 2021 \u00e0 10:53, bhollra ***@***.***> a \u00e9crit :\n\n \ufeff\n Hi Guillaume,\n\n Thanks for your response. In this case, I am using SAM to model a large 3D solid heat conduction domain, so the memory demands are quite large. Without a distributed mesh I am currently limited to running on only one processor.\n\n My SAM/MOOSE version was about a year and a half old. After updating to the newest version last night, the simulation is now able to load the '/path/./mesh_file.cpr/6/header.cpr' folder correctly. So it seems you were right and there likely was some incompatibility issue going on with MPI.\n\n However, I am now seeing a new error:\n *** ERROR ***\n The following error occurred in the object \"MOOSE Problem\", of type \"FEProblem\".\n Need Exodus reader to restart variables but the reader is not available\n Use either FileMesh with an Exodus mesh file or FileMeshGenerator with an Exodus mesh' 'file and with use_for_exodus_restart equal to true\n\n Included bedlow are my mesh blocks and variable blocks:\n [Mesh]\n file = ${meshFileName}\n []\n\n [Variables]\n [./T_solid]\n order = FIRST\n family = LAGRANGE\n block = 'all blocks'\n scaling = 1.0E-2\n initial_from_file_var = T_solid\n initial_from_file_timestep = 2\n [../]\n []\n\n It appears to me that the error is cause by the initial_from_file_var parameter in the variable sub-block. When initial_from_file_var and initial_from_file_timestep are removed and replaced with test constant IC:\n [./InitialCondition]\n type = ConstantIC\n value = 1000\n [../]\n The simulation is able to run successfully.\n It seems that variable data are not stored in the split mesh files. Is it possible to initialize a distributed simulation with a variable from an Exodus file that is not distributed via another method?\n\n Some background on my simulations: The simulation that is currently giving me an error is a transient simulation that needs to be initialized with a temperature distribution calculated by a steady state simulation. The steady state simulation uses multiapps to couple the 3D solid domain with several 1D fluid components. It is my understanding that is is not possible to use multiapps and a distributed mesh together, so I was forced to use one processor for the steady state simulation. Now, attempting the transient simulation, the model no longer includes the 1D fluid multiapps (it is a pure 3D solid conduction problem), so I am hoping to use to distributed mesh to decrease the simulation time.\n\n Thank you,\n Brent\n\n P.S. I have created a very simplified version of my input and reproduced the same errors using the combined-opt moose module, so I feel confident this is not a SAM specific error.\n P.P.S. Updated framework information:\n MOOSE Version: git commit 71aebe4 on 2021-08-11\n LibMesh Version:\n PETSc Version: 3.15.1\n SLEPc Version: 3.15.1\n\n \u2014\n You are receiving this because you commented.\n Reply to this email directly, view it on GitHub, or unsubscribe.\n Triage notifications on the go with GitHub Mobile for iOS or Android.",
                  "url": "https://github.com/idaholab/moose/discussions/18583#discussioncomment-1169834",
                  "updatedAt": "2022-07-09T08:25:04Z",
                  "publishedAt": "2021-08-13T19:43:37Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "bhollra"
                          },
                          "bodyText": "Thanks Guillaume, but when I try this I get the same error message.\nTo test this I took the following steps:\n\n\nUpdate mesh block to the following:\n[Mesh]\n#       file = ${meshFileName}\n[./fmg]\n type = FileMeshGenerator\n file = mesh.e\n use_for_exodus_restart = true\n[../]\n[]\n\n\nCreate split mesh:\nmpiexec -n 6 ~/MOOSE_08_2021/moose/modules/combined/combined-opt -i simplified.i --split-mesh 6 --split-file mesh_fmg.cpr\n\n\nRun simulation:\nmpiexec -n 6 ~/MOOSE_08_2021/moose/modules/combined/combined-opt -i simplified.i --use-split --split-file mesh_fmg.cpr\n\n\nIf it is any help, you can find the full input file here:\nsimplified.txt",
                          "url": "https://github.com/idaholab/moose/discussions/18583#discussioncomment-1170209",
                          "updatedAt": "2022-07-09T08:25:05Z",
                          "publishedAt": "2021-08-13T20:59:41Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              },
              {
                "node": {
                  "author": {
                    "login": "GiudGiud"
                  },
                  "bodyText": "Hello\nI seem to have missed a few things in my previous reply, I ll try to be more exhaustive here.\n\nFor your use case, you do need to split the mesh. You can simply use the --distributed-mesh option, as it will distribute the mesh among each process and reduce the memory cost of the simulation accordingly. Splitting meshes is used on multi-node jobs to reduce I/O, so each node does not have to load the entire mesh but just the split it is in charge of.\n\nSplitting meshes is also useful if the mesh does not fit on the memory of a single node. This is not your case it seems. Could you please share with us the size of the problem, eg the number of elements and the number of dofs/element?\n\nSplitting the mesh, step 2, only creates the mesh split. It does not load the variables and initialize them. So essentially, it prevents you from using the exodus restart capability. The exodus file containing the initial variable values is never loaded, because the mesh split is used instead. I'll let others pitch in on this, but I think we will add a log to document this issue.\n\nYou could work with Checkpoint restart to create the initialization if you absolutely want to use split meshes. This will require using the same amount of nodes, and may fail if the Steady simulation system is not exactly the same as the Transient one. I would just recommend you avoid using split meshes and use the distributed option instead, which can work in conjunction with Exodus restart.\nBest\nGuillaume",
                  "url": "https://github.com/idaholab/moose/discussions/18583#discussioncomment-1187766",
                  "updatedAt": "2022-07-09T08:25:08Z",
                  "publishedAt": "2021-08-16T00:35:13Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "bhollra"
                          },
                          "bodyText": "Hi Guillaume,\nI really appreciate your continued help on this issue. I had somehow missed the availability of the \"--distributed-mesh\" command line option. It appears I was making this much more complicated than it needed to be. I am now able to run my simulation distributed across 5 cores.\nIf I attempt to use more cores the simulation is either unable to converge or terminates after computing the initial residual of time step one (potentially due to a temporary spike in RAM usage). I have not spent much time troubleshooting this, but running on 5 processors should be good enough for my simulation.\nP.S.\nFor some information on the size of the simulation I am attempting please see the following output. This simulation uses between 60-70% of the RAM on my 24GB desktop:\n\nMesh: \nParallel Type:           distributed\nMesh Dimension:          3\nSpatial Dimension:       3\nNodes:                   \nTotal:                 2805425\nLocal:                 466047\nMin/Max/Avg:           422088/496784/467570\nElems:                   \nTotal:                 4329440\nLocal:                 696246\nMin/Max/Avg:           663922/757444/721573\nNum Subdomains:          727\nNum Partitions:          6\nPartitioner:             parmetis\n\n\nNonlinear System:\nNum DOFs:                2805425\nNum Local DOFs:          466047\nVariables:               \"T_solid\" \nFinite Element Types:    \"LAGRANGE\" \nApproximation Orders:    \"FIRST\" \n\n\nAuxiliary System:\nNum DOFs:                886420\nNum Local DOFs:          152121\nVariables:               \"power_density\" \nFinite Element Types:    \"LAGRANGE\" \nApproximation Orders:    \"FIRST\" \n\n\nExecution Information:\nExecutioner:             Transient\nTimeStepper:             FunctionDT\nSolver Mode:             NEWTON\nPETSc Preconditioner:    gamg \nMOOSE Preconditioner:    SMP",
                          "url": "https://github.com/idaholab/moose/discussions/18583#discussioncomment-1192510",
                          "updatedAt": "2022-07-09T08:25:18Z",
                          "publishedAt": "2021-08-16T23:30:18Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "The inability to converge with more cores is usually just a matter of tuning the tolerances and the pre-conditioner settings. For example, the asm preconditioner will need to have an overlap parameter specified to perform better with more core. Less efficient pre-conditioning can mean that allowing for more linear iterations helps the solve.\nWith the Newton solve method, it's likely your memory issue is due to the need to store the system matrix. You could switch to the PJFNK solve method. This will not converge as well, but scales better in terms of memory.\nWe are 1-2 weeks away from merging new memory profiling utilities in MOOSE (see #16298) if you ever want to determine the cause of the memory spike for sure.",
                          "url": "https://github.com/idaholab/moose/discussions/18583#discussioncomment-1192613",
                          "updatedAt": "2022-07-09T08:25:21Z",
                          "publishedAt": "2021-08-17T00:26:06Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "bhollra"
                          },
                          "bodyText": "Hi Guillaume,\nAnother question just came up, this time regarding the compatibility of using --recover and --use-distributed together.\nMy desktop had an issue that cause the simulation to terminate early. When I attempted running mpiexec -n 5 ~/SAM_08_2021/SAM/sam-opt -i  square_full_core_SBO.i --recover --distributed-mesh I got the following error:\n*** ERROR ***\nERROR: Neither one of the following files can be located:\n        'square_full_core_SBO_out_cp/0270_mesh.cpr/1/header.cpr' nor\n        'square_full_core_SBO_out_cp/0270_mesh.cpr'\nIf you are running a parallel job, double check that you've created a split for 1 ranks.\nNote: One of paths above may refer to a valid directory on your system, however we are attempting to read a valid header file.\nI found this interesting because when I attempted to run the input with a restart block added:\n[Problem]\nrestart_file_base = square_full_core_SBO_out_cp/LATEST\n[]\nThe simulation has no issues initializing using the checkpoint. To confirm:\n*** Info ***                                                                                                        \nUsing /home/bhollra/spring_2021/summer_2021/square_full_core/SBO/square_full_core_SBO_out_cp/0270 for restart.      \nis output in the terminal.\nThere are workarounds I can use to reinitialize my simulation using the results from the last output time step of the terminated simulation, but I did find it interesting that using --recover did not work while using a restart from the same checkpoint did.",
                          "url": "https://github.com/idaholab/moose/discussions/18583#discussioncomment-1207515",
                          "updatedAt": "2022-07-09T08:25:21Z",
                          "publishedAt": "2021-08-19T16:07:11Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "Interesting. This might be a bug with the --recover option and splits. I ll try to reproduce that later and I ll raise an issue if needed.\nThanks for letting us know.\nI'm glad it works with the restart option though.",
                          "url": "https://github.com/idaholab/moose/discussions/18583#discussioncomment-1207714",
                          "updatedAt": "2022-07-09T08:25:38Z",
                          "publishedAt": "2021-08-19T16:31:52Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "Ok I confirmed recover+split worked on the simple diffusion case.\nI simply made that case a transient and added\n checkpoint = true\nThen I ran:\n../../../moose_test-opt -i simple_diffusion.i --split-mesh 4 --split-file mesh_split\nmpirun -n 4 ../../../moose_test-opt -i simple_diffusion.i --use-split 4 --split-file mesh_split --half-transient\nmpirun -n 4 ../../../moose_test-opt -i simple_diffusion.i --use-split 4 --split-file mesh_split --recover\n\nI would recommend you make it work on a small example like this before trying to see what is different with your case.",
                          "url": "https://github.com/idaholab/moose/discussions/18583#discussioncomment-1208421",
                          "updatedAt": "2022-07-09T08:25:38Z",
                          "publishedAt": "2021-08-19T19:10:17Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "You could also have a look at the recover/checkpoint tests in test/tests/mesh/checkpoint btw",
                          "url": "https://github.com/idaholab/moose/discussions/18583#discussioncomment-1208461",
                          "updatedAt": "2022-07-09T08:25:39Z",
                          "publishedAt": "2021-08-19T19:18:57Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "Boundary condition:NeumannBC did not working",
          "author": {
            "login": "emmelines"
          },
          "bodyText": "Hi\nI am using the phase-field model to simulate two phase-separated microstructure evolution. In my model, I set NeumannBC as the boundary condition. However, when I check the boundary flux using SideAverageValue, the result showed the value of flux is not zero. Is there any reason for the boundary condition cannot work properly?\nThank you.",
          "url": "https://github.com/idaholab/moose/discussions/18608",
          "updatedAt": "2022-06-10T13:57:22Z",
          "publishedAt": "2021-08-16T18:50:55Z",
          "category": {
            "name": "Q&A Modules: Phase field"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "GiudGiud"
                  },
                  "bodyText": "Hello\nSideAverageValue computes the average of a variable not really of a flux. Are you using the gradient as the variable?\nIf not you may be wanting to use SideDiffusiveFluxIntegral\nGuillaume",
                  "url": "https://github.com/idaholab/moose/discussions/18608#discussioncomment-1191711",
                  "updatedAt": "2022-06-10T13:57:23Z",
                  "publishedAt": "2021-08-16T19:03:55Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "emmelines"
                          },
                          "bodyText": "Hi\nI did use gradient variable, so the SideAverageValue should fit in my case. Is it?\nThanks.\nEmmeline",
                          "url": "https://github.com/idaholab/moose/discussions/18608#discussioncomment-1196857",
                          "updatedAt": "2022-06-10T13:57:39Z",
                          "publishedAt": "2021-08-17T18:41:08Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "But a SideAverageValue does not take gradient variables? Did you use the gradient component as the variable?\nI think pasting your variable block and the postprocessor block would help here",
                          "url": "https://github.com/idaholab/moose/discussions/18608#discussioncomment-1197311",
                          "updatedAt": "2022-06-10T13:57:40Z",
                          "publishedAt": "2021-08-17T20:49:39Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "emmelines"
                          },
                          "bodyText": "Hi\nThe following are my variable and postprocessor. Thank you for staying on this problem with me. I appreciate.\n[Variables]\n  [./c]\n  [../]\n  [./w]\n  [../]\n  [./eta_a1]\n  [../]\n  [./eta_b1]\n  [../]\n  [./eta_b2]\n  [../]\n  [./eta_b3]\n  [../]\n  [./eta_b4]\n  [../]\n[]\n\n[Postprocessors]\n  [./ElementInt_c]\n    type = ElementIntegralVariablePostprocessor\n    variable = c\n  [../]\n  [./precip_area] # since eta=1.0 inside the precipitate\n    type = ElementIntegralVariablePostprocessor\n    variable = 'eta_a1 eta_b1 eta_b2 eta_b3 eta_b4'\n  [../]\n  [./total_F]\n    type = ElementIntegralVariablePostprocessor\n    variable = total_F\n  [../]\n  [./F]\n    type = ElementIntegralVariablePostprocessor\n    variable = F\n  [../]\n  [./dwdx]\n    type = ElementIntegralVariablePostprocessor\n    variable = dwdx\n    execute_on = 'initial timestep_end'\n  [../]\n  [./dwdy]\n    type = ElementIntegralVariablePostprocessor\n    variable = dwdy\n    execute_on = 'initial timestep_end'\n  [../]\n#######\n  [./total_Fc]\n  type = ElementIntegralVariablePostprocessor\n  variable = total_Fc\n  [../]\n  [./total_Feta]\n  type = ElementIntegralVariablePostprocessor\n  variable = total_Feta\n  [../]\n  [./F_c]\n    type = ElementIntegralVariablePostprocessor\n    variable = F_c\n    execute_on = 'initial timestep_end'\n  [../]\n  [./F_eta]\n    type = ElementIntegralVariablePostprocessor\n    variable = F_eta\n    execute_on = 'initial timestep_end'\n  [../]\n  [./F_etaandc]\n    type = ElementIntegralVariablePostprocessor\n    variable = F_etaandc\n    execute_on = 'initial timestep_end'\n  [../]\n  [./right_jx]\n    type = SideAverageValue\n    variable = jx\n    boundary = right\n  [../]\n  [./right_jy]\n    type = SideAverageValue\n    variable = jy\n    boundary = right\n  [../]\n  [./left_jx]\n    type = SideAverageValue\n    variable = jx\n    boundary = left\n  [../]\n  [./left_jy]\n    type = SideAverageValue\n    variable = jy\n    boundary = left\n  [../]\n  [./right_j_tot]\n    type = SideAverageValue\n    variable = j_tot\n    boundary = right\n  [../]\n  [./left_j_tot]\n    type = SideAverageValue\n    variable = j_tot\n    boundary = left\n  [../]\n  [./top_jx]\n    type = SideAverageValue\n    variable = jx\n    boundary = top\n  [../]\n  [./top_jy]\n    type = SideAverageValue\n    variable = jy\n    boundary = top\n  [../]\n  [./bottom_jx]\n    type = SideAverageValue\n    variable = jx\n    boundary = bottom\n  [../]\n  [./bottom_jy]\n    type = SideAverageValue\n    variable = jy\n    boundary = bottom\n  [../]\n  [./top_j_tot]\n    type = SideAverageValue\n    variable = j_tot\n    boundary = top\n  [../]\n  [./bottom_j_tot]\n    type = SideAverageValue\n    variable = j_tot\n    boundary = bottom\n  [../]",
                          "url": "https://github.com/idaholab/moose/discussions/18608#discussioncomment-1197368",
                          "updatedAt": "2022-06-10T13:57:41Z",
                          "publishedAt": "2021-08-17T20:59:19Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "So jx and jy are AuxVariables? Did you define them in the input file ?\nTagging @laagesen in case there s something special about phase field here",
                          "url": "https://github.com/idaholab/moose/discussions/18608#discussioncomment-1197546",
                          "updatedAt": "2024-03-16T04:08:42Z",
                          "publishedAt": "2021-08-17T21:57:30Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "emmelines"
                          },
                          "bodyText": "I defined jx and jy in AuxKernels.\n[AuxKernels]\n[./dwdx]\n    type = VariableGradientComponent\n    variable = dwdx\n    gradient_variable = w\n    component = x\n  [../]\n  [./dwdy]\n    type = VariableGradientComponent\n    variable = dwdy\n    gradient_variable = w\n    component = y\n  [../]\n  [./jx]\n    type = ParsedAux\n    variable = jx\n    args = 'dwdx'\n    function = '-1.0*dwdx'\n  [../]\n  [./jy]\n    type = ParsedAux\n    variable = jy\n    args = 'dwdy'\n    function = '-1.0*dwdy'\n  [../]",
                          "url": "https://github.com/idaholab/moose/discussions/18608#discussioncomment-1197562",
                          "updatedAt": "2022-09-12T14:52:36Z",
                          "publishedAt": "2021-08-17T22:02:38Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "Not sure. While we wait for someone else to pitch in, you are dealing with a diffusive flux right?\nIf so, SideDiffusiveFluxIntegral will compute it from the variable definition. Does that work for you?",
                          "url": "https://github.com/idaholab/moose/discussions/18608#discussioncomment-1197592",
                          "updatedAt": "2022-09-12T14:52:57Z",
                          "publishedAt": "2021-08-17T22:14:30Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "emmelines"
                          },
                          "bodyText": "Hi\nI am trying the SideDiffusiveFluxIntegral, and it seems like my library has to update first. I will get back to you once I complete the computation. Thanks a lot!",
                          "url": "https://github.com/idaholab/moose/discussions/18608#discussioncomment-1201904",
                          "updatedAt": "2022-09-12T14:52:57Z",
                          "publishedAt": "2021-08-18T16:01:47Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "dschwen"
                          },
                          "bodyText": "[./dwdx]\n    type = ElementIntegralVariablePostprocessor\n    variable = dwdx\n    execute_on = 'initial timestep_end'\n  [../]\n  [./dwdy]\n    type = ElementIntegralVariablePostprocessor\n    variable = dwdy\n    execute_on = 'initial timestep_end'\n  [../]\n\nYou're integrating the gradient components over a volume rather than evaluating it on the side where you apply the BC.",
                          "url": "https://github.com/idaholab/moose/discussions/18608#discussioncomment-1203270",
                          "updatedAt": "2022-09-12T14:53:31Z",
                          "publishedAt": "2021-08-18T21:38:16Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "they are talking about these postprocessors I think\n    type = SideAverageValue\n    variable = jx\n    boundary = top\n  [../]\n  [./top_jy]\n    type = SideAverageValue\n    variable = jy\n    boundary = top\n  [../]\n  [./bottom_jx]\n    type = SideAverageValue\n    variable = jx\n    boundary = bottom\n  [../]\n  [./bottom_jy]\n    type = SideAverageValue\n    variable = jy\n    boundary = bottom\n  [../]",
                          "url": "https://github.com/idaholab/moose/discussions/18608#discussioncomment-1203293",
                          "updatedAt": "2022-09-12T14:53:30Z",
                          "publishedAt": "2021-08-18T21:43:56Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              },
              {
                "node": {
                  "author": {
                    "login": "jiangwen84"
                  },
                  "bodyText": "@emmelines In FEM, NeumannBC is weakly enforced. The flux won't be exactly zero. However, the flux will become more accurate as mesh is refined.\nFor your problem, you can take a look at the global concentration. Zero flux will result in conserved concentration.",
                  "url": "https://github.com/idaholab/moose/discussions/18608#discussioncomment-1204013",
                  "updatedAt": "2022-06-10T13:58:44Z",
                  "publishedAt": "2021-08-19T03:03:38Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "emmelines"
                          },
                          "bodyText": "@jiangwen84\nCould I ask what is the reason for NeumannBC has weak enforcement in FEM?\nThank you.",
                          "url": "https://github.com/idaholab/moose/discussions/18608#discussioncomment-1207676",
                          "updatedAt": "2022-06-10T13:58:42Z",
                          "publishedAt": "2021-08-19T16:25:00Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "jiangwen84"
                          },
                          "bodyText": "You can go to https://mooseframework.inl.gov/workshop/workshop/index.html#/2/7\nThe third term of the weak form is the Neumann BC. As you can see, that term is weighted by the test function \\phi_i. That means this term is weakly enforced. As you increase the test function space (use higher order and/or small mesh size), the flux k\\grad T n will become more accurate.",
                          "url": "https://github.com/idaholab/moose/discussions/18608#discussioncomment-1207895",
                          "updatedAt": "2022-06-10T13:58:42Z",
                          "publishedAt": "2021-08-19T17:09:50Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "Cannot calculate  TENSOR_MECHANICS correctly",
          "author": {
            "login": "ScouperLH"
          },
          "bodyText": "Hi, I am new to MOOSE. I followed the tutorial on youtube\uff08https://www.youtube.com/watch?v=L9plLYkAbvQ&list=TLPQMDcwNzIwMjEvnbj3LWAiyQ&index=6\uff09to do a FEM calculation of the piston, and used the correct files in the tutorial, no matter whether I updated the MOOSE and Conda in advance, my MOOSE results are as shown in the picture. Before the calculation, I have modified the Makefile, opened TENSOR_MECHANICS, and recompiled.\nI want to know how to calculate it correctly?\nThank you!",
          "url": "https://github.com/idaholab/moose/discussions/18531",
          "updatedAt": "2022-07-27T14:12:36Z",
          "publishedAt": "2021-08-05T08:38:55Z",
          "category": {
            "name": "Q&A Modules: General"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "ngrilli"
                  },
                  "bodyText": "@ScouperLH\nYou need to share the input file for help.\nIt looks like your simulation runs though.\nNicol\u00f2",
                  "url": "https://github.com/idaholab/moose/discussions/18531#discussioncomment-1133678",
                  "updatedAt": "2022-07-27T14:12:32Z",
                  "publishedAt": "2021-08-05T08:51:49Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "ScouperLH"
                          },
                          "bodyText": "thank you for your reply! My input file is as follows. I don't see the kernel file in the app after compiling. Is it because I am using the built-in TENSOR_MECH of MOOSE?\n[Mesh]\ndisplacements = 'disp_x disp_y disp_z' #Define displacements for deformed mesh\ntype = FileMesh #Read in mesh from file\nfile = piston_coarse.e\n[]\n[./Adaptivity]\nsteps = 1\n#initial_steps = 2\nmax_h_level = 3\ncycles_per_step = 1\ninitial_marker = uniform\nmarker = errorFraction\n[./Markers]\n[./uniform]\ntype = UniformMarker\nmark = refine\n[../]\n[./errorFraction]\n  type = ErrorFractionMarker\n  coarsen = 0.5\n  indicator = gradientJump\n  refine = 0.5\n[] \n\n[../]\n[./Indicators]\n[./gradientJump]\ntype = GradientJumpIndicator\nvariable = disp_y\n[]\n[]\n[../]\n[Variables]\n[./disp_x]\norder = FIRST\nfamily = LAGRANGE\n[../]\n[./disp_y]\norder = FIRST\nfamily = LAGRANGE\n[../]\n[./disp_z]\norder = FIRST\nfamily = LAGRANGE\n[../]\n[]\n[Kernels]\n[./TensorMechanics]\n#Stress divergence kernels\ndisplacements = 'disp_x disp_y disp_z'\n[../]\n[]\n[AuxVariables]\n[./von_mises]\n#Dependent variable used to visualize the Von Mises stress\norder = CONSTANT\nfamily = MONOMIAL\n[../]\n[]\n[AuxKernels]\n[./von_mises_kernel]\n#Calculates the von mises stress and assigns it to von_mises\ntype = RankTwoScalarAux\nvariable = von_mises\nrank_two_tensor = stress\nexecute_on = timestep_end\nscalar_type = VonMisesStress\n[../]\n[]\n[Functions]\n[./rampLinear]\ntype = ParsedFunction\nvalue = t*550e5\n[]\n[]\n[BCs]\n[./Pressure]\n[./load]\n#Applies the pressure\nboundary = load_surf\nfunction = rampLinear\ndisp_x = disp_x\ndisp_y = disp_y\ndisp_z = disp_z\n[../]\n[../]\n[./symmetry_x]\n#Applies symmetry on the xmin faces\ntype = DirichletBC\nvariable = disp_x\nboundary = 'xmin'\nvalue = 0.0\n[../]\n[./hold_y]\n#Anchors the bottom against deformation in the y-direction\ntype = DirichletBC\nvariable = disp_y\nboundary = 'ymin'\nvalue = 0.0\n[../]\n[./symmetry_z]\n#Applies symmetry on the zmin faces\ntype = DirichletBC\nvariable = disp_z\nboundary = 'zmin'\nvalue = 0.0\n[../]\n[]\n[Materials]\nactive = 'density_steel stress strain elasticity_tensor_steel'\n[./elasticity_tensor_steel]\n#Creates the elasticity tensor using steel parameters\nyoungs_modulus = 210e9 #Pa\npoissons_ratio = 0.3\ntype = ComputeIsotropicElasticityTensor\nblock = 1\n[../]\n[./strain]\n#Computes the strain, assuming small strains\ntype = ComputeFiniteStrain\nblock = 1\ndisplacements = 'disp_x disp_y disp_z'\n[../]\n[./stress]\n#Computes the stress, using linear elasticity\ntype = ComputeFiniteStrainElasticStress\nblock = 1\n[../]\n[./density_steel]\n#Defines the density of steel\ntype = GenericConstantMaterial\nblock = 1\nprop_names = density\nprop_values = 7850 # kg/m^3\n[../]\n[]\n[Preconditioning]\n[./SMP]\n#Creates the entire Jacobian, for the Newton solve\ntype = SMP\nfull = true\n[../]\n[]\n[Executioner]\n#We solve a steady state problem using Newton's iteration\ntype = Transient\nsolve_type = NEWTON\nnl_rel_tol = 1e-9\nl_max_its = 30\nl_tol = 1e-4\nnl_max_its = 10\npetsc_options_iname = '-pc_type -pc_hypre_type -ksp_gmres_restart'\npetsc_options_value = 'hypre boomeramg 31'\ndt = 0.1\nnum_steps = 10\n[]\n[Outputs]\nexodus = true\nperf_graph = true\n[]",
                          "url": "https://github.com/idaholab/moose/discussions/18531#discussioncomment-1133739",
                          "updatedAt": "2022-07-27T14:12:32Z",
                          "publishedAt": "2021-08-05T09:04:39Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              },
              {
                "node": {
                  "author": {
                    "login": "ajacquey"
                  },
                  "bodyText": "You should modify your pressure BC.\nLooking at the source code of the PressureAction, you should provide the displacements as a vector displacements = 'disp_x disp_y disp_z' instead of providing the three displacement variables separately.\nYour BC should look like that:\n[./Pressure]\n  [./load]\n    #Applies the pressure\n\tboundary = load_surf\n\tfunction = rampLinear\n\tdisplacements = 'disp_x disp_y disp_z'\n  [../]",
                  "url": "https://github.com/idaholab/moose/discussions/18531#discussioncomment-1134088",
                  "updatedAt": "2022-07-27T14:13:10Z",
                  "publishedAt": "2021-08-05T10:31:54Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "ScouperLH"
                          },
                          "bodyText": "Thank you! I modified it accordingly, and it works!",
                          "url": "https://github.com/idaholab/moose/discussions/18531#discussioncomment-1143744",
                          "updatedAt": "2022-07-27T14:13:11Z",
                          "publishedAt": "2021-08-08T05:33:36Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              },
              {
                "node": {
                  "author": {
                    "login": "hugary1995"
                  },
                  "bodyText": "@GregVernon this is a nice tutorial. I suggest to check it into the tensor mechanics module as an example, and enable at least syntax check so that it doesn't break in the future.",
                  "url": "https://github.com/idaholab/moose/discussions/18531#discussioncomment-1134320",
                  "updatedAt": "2022-07-27T14:13:16Z",
                  "publishedAt": "2021-08-05T11:46:52Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "GregVernon"
                          },
                          "bodyText": "Will do!",
                          "url": "https://github.com/idaholab/moose/discussions/18531#discussioncomment-1135225",
                          "updatedAt": "2022-07-27T14:13:16Z",
                          "publishedAt": "2021-08-05T15:16:14Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "hugary1995"
                          },
                          "bodyText": "Now that this is merged, I think it'd be great if you can somehow point viewers of that YouTube tutorial to the updated input file. I'm not a YouTube expert, but I think that's doable. Anyways, it's your call.",
                          "url": "https://github.com/idaholab/moose/discussions/18531#discussioncomment-1202516",
                          "updatedAt": "2022-07-27T14:13:16Z",
                          "publishedAt": "2021-08-18T18:21:47Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GregVernon"
                          },
                          "bodyText": "Yep - I'll do that today!",
                          "url": "https://github.com/idaholab/moose/discussions/18531#discussioncomment-1206693",
                          "updatedAt": "2022-07-27T14:13:17Z",
                          "publishedAt": "2021-08-19T14:06:30Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "symmertric9 fill method with in a 2D simulation",
          "author": {
            "login": "pharshaad"
          },
          "bodyText": "Hi all,\nI was wondering if I could use the symmetric9 fill method with a 2D mesh.\nThanks,\nLeon",
          "url": "https://github.com/idaholab/moose/discussions/18620",
          "updatedAt": "2022-06-13T08:29:21Z",
          "publishedAt": "2021-08-17T21:46:28Z",
          "category": {
            "name": "Q&A Modules: Solid mechanics"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "hugary1995"
                  },
                  "bodyText": "Yes",
                  "url": "https://github.com/idaholab/moose/discussions/18620#discussioncomment-1198181",
                  "updatedAt": "2022-06-13T08:29:21Z",
                  "publishedAt": "2021-08-18T03:03:10Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "dschwen"
                          },
                          "bodyText": "To eleborate, our tensors and vectors are always 3D, no matter the mesh.",
                          "url": "https://github.com/idaholab/moose/discussions/18620#discussioncomment-1203247",
                          "updatedAt": "2022-06-13T08:29:26Z",
                          "publishedAt": "2021-08-18T21:34:13Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "pharshaad"
                          },
                          "bodyText": "Got it, thanks, @hugary1995 and @dschwen.",
                          "url": "https://github.com/idaholab/moose/discussions/18620#discussioncomment-1203520",
                          "updatedAt": "2022-06-13T08:29:26Z",
                          "publishedAt": "2021-08-18T23:09:18Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "Question about ParsedMaterial v ParsedFunction",
          "author": {
            "login": "richmondodufisan"
          },
          "bodyText": "I want a \"material property\" that is a user defined function of time only. In my input file, under the materials block, I have the following:\n  [m_inf]\n    type = ADParsedMaterial\n    f_name = m_inf\n    function = 't + 3*t'\n    outputs = exodus\n  []\n\nHowever I get an error when I try to run this. From the documentation, my understanding is that ParsedMaterial is an \"extended\" form of ParsedFunction where you can also add variables you're solving for, (e.g displacement) into the function, is that correct? But ParsedFunction only recognizes x,y,z and t. Why then, is this not running?\nAlso, if I were to use ADParsedFunction, and created this under a \"Functions\" block, would I still be able to use it in my Material Interface?\nAlso, when retrieving this from the input file, in my material file, I have:\n_m_inf(getADMaterialPropertyByName<Real>(\"m_inf\")),\nI called it a \"Real\" since my function is real valued, is that correct? I didn't see anything in the documentation on how to consume ParsedFunction/ParsedMaterials.",
          "url": "https://github.com/idaholab/moose/discussions/18637",
          "updatedAt": "2021-08-18T22:04:44Z",
          "publishedAt": "2021-08-18T21:30:42Z",
          "category": {
            "name": "Q&A General"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "dschwen"
                  },
                  "bodyText": "ParsedMaterial is an \"extended\" form of ParsedFunction\n\nThe two systems are independent and other than the underlying function parser do not share any code. For example there is no ADParsedFunction. You cannot use the two interchangably. One is used like any other Function, one is used like any other Material.",
                  "url": "https://github.com/idaholab/moose/discussions/18637#discussioncomment-1203239",
                  "updatedAt": "2021-08-18T21:36:42Z",
                  "publishedAt": "2021-08-18T21:32:59Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "richmondodufisan"
                          },
                          "bodyText": "Okay, thanks. In my case I want a user-defined function of time only to be used in the Material Interface for computing a material property. Should I be using Parsed Function, then? And if no, what's the reason for the error in the block of code I pasted above? And if yes, how do I consume ParsedFunctions? Since they're not materials, would\n_m_inf(getADMaterialPropertyByName<Real>(\"m_inf\")), still be correct?",
                          "url": "https://github.com/idaholab/moose/discussions/18637#discussioncomment-1203261",
                          "updatedAt": "2021-08-18T21:42:49Z",
                          "publishedAt": "2021-08-18T21:36:26Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "You can use a ParsedFunction and a GenericFunctionMaterial\nOR a ParsedMaterial\nw/ the appropriate AD pre-fixes to the materials if you want to use AD, but AD does not matter for this material if you only have a time dependence.\nThe way you retrieve this material property seems fine (for AD)",
                          "url": "https://github.com/idaholab/moose/discussions/18637#discussioncomment-1203339",
                          "updatedAt": "2021-08-18T21:49:30Z",
                          "publishedAt": "2021-08-18T21:49:30Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "dschwen"
                          },
                          "bodyText": "or a TimeStepMaterial...",
                          "url": "https://github.com/idaholab/moose/discussions/18637#discussioncomment-1203391",
                          "updatedAt": "2021-08-18T22:04:34Z",
                          "publishedAt": "2021-08-18T22:04:34Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "Problem about linking external library",
          "author": {
            "login": "yuezhiying6"
          },
          "bodyText": "Dear all,\nI am now linking a external FORTRAN library ti my code. I add the \"ADDITIONAL_LIBS += -L/path/to/my/lib -lname \" to my Makefile. However, when I use \"make\" command to compile my code, there will be an error occurs:\n/home/yzy/miniconda3/envs/moose/bin/../lib/gcc/x86_64-conda-linux-gnu/9.3.0/../../../../x86_64-conda-linux-gnu/bin/ld: warning: libgfortran.so.3, needed by /home/yzy/projects/full_couple/lib/libcobra.so, not found (try using -rpath or -rpath-link)\n/home/yzy/miniconda3/envs/moose/bin/../lib/gcc/x86_64-conda-linux-gnu/9.3.0/../../../../x86_64-conda-linux-gnu/bin/ld: /home/yzy/projects/full_couple/lib/libcobra.so: undefined reference to _gfortran_st_open@GFORTRAN_1.0' /home/yzy/miniconda3/envs/moose/bin/../lib/gcc/x86_64-conda-linux-gnu/9.3.0/../../../../x86_64-conda-linux-gnu/bin/ld: /home/yzy/projects/full_couple/lib/libcobra.so: undefined reference to _gfortran_st_read@GFORTRAN_1.0'\n/home/yzy/miniconda3/envs/moose/bin/../lib/gcc/x86_64-conda-linux-gnu/9.3.0/../../../../x86_64-conda-linux-gnu/bin/ld: /home/yzy/projects/full_couple/lib/libcobra.so: undefined reference to _gfortran_transfer_real_write@GFORTRAN_1.4' /home/yzy/miniconda3/envs/moose/bin/../lib/gcc/x86_64-conda-linux-gnu/9.3.0/../../../../x86_64-conda-linux-gnu/bin/ld: /home/yzy/projects/full_couple/lib/libcobra.so: undefined reference to _gfortran_transfer_array@GFORTRAN_1.0'\n/home/yzy/miniconda3/envs/moose/bin/../lib/gcc/x86_64-conda-linux-gnu/9.3.0/../../../../x86_64-conda-linux-gnu/bin/ld: /home/yzy/projects/full_couple/lib/libcobra.so: undefined reference to _gfortran_cpu_time_8@GFORTRAN_1.0' /home/yzy/miniconda3/envs/moose/bin/../lib/gcc/x86_64-conda-linux-gnu/9.3.0/../../../../x86_64-conda-linux-gnu/bin/ld: /home/yzy/projects/full_couple/lib/libcobra.so: undefined reference to _gfortran_st_rewind@GFORTRAN_1.0'\n/home/yzy/miniconda3/envs/moose/bin/../lib/gcc/x86_64-conda-linux-gnu/9.3.0/../../../../x86_64-conda-linux-gnu/bin/ld: /home/yzy/projects/full_couple/lib/libcobra.so: undefined reference to _gfortran_st_write_done@GFORTRAN_1.0' /home/yzy/miniconda3/envs/moose/bin/../lib/gcc/x86_64-conda-linux-gnu/9.3.0/../../../../x86_64-conda-linux-gnu/bin/ld: /home/yzy/projects/full_couple/lib/libcobra.so: undefined reference to _gfortran_cpu_time_4@GFORTRAN_1.0'\n/home/yzy/miniconda3/envs/moose/bin/../lib/gcc/x86_64-conda-linux-gnu/9.3.0/../../../../x86_64-conda-linux-gnu/bin/ld: /home/yzy/projects/full_couple/lib/libcobra.so: undefined reference to _gfortran_transfer_array_write@GFORTRAN_1.4' /home/yzy/miniconda3/envs/moose/bin/../lib/gcc/x86_64-conda-linux-gnu/9.3.0/../../../../x86_64-conda-linux-gnu/bin/ld: /home/yzy/projects/full_couple/lib/libcobra.so: undefined reference to _gfortran_transfer_character_write@GFORTRAN_1.4'\n/home/yzy/miniconda3/envs/moose/bin/../lib/gcc/x86_64-conda-linux-gnu/9.3.0/../../../../x86_64-conda-linux-gnu/bin/ld: /home/yzy/projects/full_couple/lib/libcobra.so: undefined reference to _gfortran_stop_numeric_f08@GFORTRAN_1.4' /home/yzy/miniconda3/envs/moose/bin/../lib/gcc/x86_64-conda-linux-gnu/9.3.0/../../../../x86_64-conda-linux-gnu/bin/ld: /home/yzy/projects/full_couple/lib/libcobra.so: undefined reference to _gfortran_transfer_integer_write@GFORTRAN_1.4'\n/home/yzy/miniconda3/envs/moose/bin/../lib/gcc/x86_64-conda-linux-gnu/9.3.0/../../../../x86_64-conda-linux-gnu/bin/ld: /home/yzy/projects/full_couple/lib/libcobra.so: undefined reference to _gfortran_transfer_character@GFORTRAN_1.0' /home/yzy/miniconda3/envs/moose/bin/../lib/gcc/x86_64-conda-linux-gnu/9.3.0/../../../../x86_64-conda-linux-gnu/bin/ld: /home/yzy/projects/full_couple/lib/libcobra.so: undefined reference to _gfortran_stop_string@GFORTRAN_1.0'\n/home/yzy/miniconda3/envs/moose/bin/../lib/gcc/x86_64-conda-linux-gnu/9.3.0/../../../../x86_64-conda-linux-gnu/bin/ld: /home/yzy/projects/full_couple/lib/libcobra.so: undefined reference to memcpy@GLIBC_2.14' /home/yzy/miniconda3/envs/moose/bin/../lib/gcc/x86_64-conda-linux-gnu/9.3.0/../../../../x86_64-conda-linux-gnu/bin/ld: /home/yzy/projects/full_couple/lib/libcobra.so: undefined reference to _gfortran_transfer_real@GFORTRAN_1.0'\n/home/yzy/miniconda3/envs/moose/bin/../lib/gcc/x86_64-conda-linux-gnu/9.3.0/../../../../x86_64-conda-linux-gnu/bin/ld: /home/yzy/projects/full_couple/lib/libcobra.so: undefined reference to _gfortran_st_write@GFORTRAN_1.0' /home/yzy/miniconda3/envs/moose/bin/../lib/gcc/x86_64-conda-linux-gnu/9.3.0/../../../../x86_64-conda-linux-gnu/bin/ld: /home/yzy/projects/full_couple/lib/libcobra.so: undefined reference to _gfortran_transfer_integer@GFORTRAN_1.0'\n/home/yzy/miniconda3/envs/moose/bin/../lib/gcc/x86_64-conda-linux-gnu/9.3.0/../../../../x86_64-conda-linux-gnu/bin/ld: /home/yzy/projects/full_couple/lib/libcobra.so: undefined reference to `_gfortran_st_read_done@GFORTRAN_1.0'\ncollect2: error: ld returned 1 exit status\n/home/yzy/projects/moose/framework/app.mk:406: recipe for target '/home/yzy/projects/full_couple/full_couple-opt' failed\nmake: *** [/home/yzy/projects/full_couple/full_couple-opt] Error 1\nI install my MOOSE through conda. Because I am not familiar with the ubuntu system, I don't know how to link this library successfully.\nAny advice would be greatly appreciated!\nZhiying",
          "url": "https://github.com/idaholab/moose/discussions/18605",
          "updatedAt": "2022-06-14T20:39:26Z",
          "publishedAt": "2021-08-14T11:52:47Z",
          "category": {
            "name": "Q&A General"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "GiudGiud"
                  },
                  "bodyText": "Hello\nIt looks like your compiler is not finding libgfortran, needed to use compiled fortran code.\nLet's try to locate it first, either with\nwhereis libgfortran or ldconfig -p | grep libgfortran\nIf that does not work, you'll need to download it.\n@milljm does it come with the conda install?\nGuillaume",
                  "url": "https://github.com/idaholab/moose/discussions/18605#discussioncomment-1187738",
                  "updatedAt": "2022-06-14T20:39:30Z",
                  "publishedAt": "2021-08-15T23:52:18Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "milljm"
                          },
                          "bodyText": "Our latest environment installs libgortran 5:\n(moose) [CentOS-8][~]> conda list | grep libgfortran\nlibgfortran-ng            9.4.0                h69a702a_8    conda-forge\nlibgfortran5              9.4.0                h62347ff_8    conda-forge\n\nIf your already-built-app was built using an older Fortran compiler, it will be necessary to either:\n\nrebuild that app using the same Fortran compiler MOOSE requires (libgfortran.so.5)\nor\nremove the Conda MOOSE environment and install the necessary older Fortran compiler your app requires, and then build PETSc, libMesh, and MOOSE using this older Fortran compiler, so that everything matches.",
                          "url": "https://github.com/idaholab/moose/discussions/18605#discussioncomment-1190243",
                          "updatedAt": "2022-06-14T20:39:30Z",
                          "publishedAt": "2021-08-16T14:13:30Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "yuezhiying6"
                          },
                          "bodyText": "Thanks for your reply very much, @milljm  and @GiudGiud. Your advice is of great help to me in solving the problem. I will try to recompile my code with libgfortran-5.",
                          "url": "https://github.com/idaholab/moose/discussions/18605#discussioncomment-1190275",
                          "updatedAt": "2022-06-14T20:39:31Z",
                          "publishedAt": "2021-08-16T14:18:58Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "Error of being not a registered object and segmentation fault",
          "author": {
            "login": "xchengood"
          },
          "bodyText": "Hi Moose expert or user,\nI am studying and trying to implement a input file example called 3d.i located in the path projects/moose/modules/tensor_mechanics/test/tests/rom_stress_update.\nFirst, I try implementation in terminal and I got the following error.\n\nThen, I try it in the peacock. The following error comes and a window pops out.\n\nBefore implementation, I already update my conda and do something about compile using 'make -j4'.\nCould anyone help me with fixing this error? Thank you.",
          "url": "https://github.com/idaholab/moose/discussions/18602",
          "updatedAt": "2022-07-04T08:33:48Z",
          "publishedAt": "2021-08-13T15:26:21Z",
          "category": {
            "name": "Q&A Modules: Solid mechanics"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "dschwen"
                  },
                  "bodyText": "Run the executable with the --allow-test-objects option! The SS316 model is just a test for the ROM system.",
                  "url": "https://github.com/idaholab/moose/discussions/18602#discussioncomment-1168887",
                  "updatedAt": "2022-07-04T08:33:47Z",
                  "publishedAt": "2021-08-13T15:27:56Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "xchengood"
                          },
                          "bodyText": "--allow-test-objects\n\nThank you. It works in the terminal. But how can I implement it in peacock? It seems not right if I just put that at the end of the executable command line for peacock. I got 'unrecognized arguments'.",
                          "url": "https://github.com/idaholab/moose/discussions/18602#discussioncomment-1168909",
                          "updatedAt": "2022-07-04T08:34:11Z",
                          "publishedAt": "2021-08-13T15:33:49Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "dschwen"
                          },
                          "bodyText": "I suggest using an editor like Atom with a MOOSE syntax autocompletion plugin to edit input files, and run them from the terminal. It's a more powerful way to work with MOOSE. Unfortunately peacock is not working properly on the latest macOS for me, so I cannot reproduce your issue.",
                          "url": "https://github.com/idaholab/moose/discussions/18602#discussioncomment-1168962",
                          "updatedAt": "2022-07-04T08:34:12Z",
                          "publishedAt": "2021-08-13T15:46:49Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "xchengood"
                          },
                          "bodyText": "I suggest using an editor like Atom with a MOOSE syntax autocompletion plugin to edit input files, and run them from the terminal. It's a more powerful way to work with MOOSE. Unfortunately peacock is not working properly on the latest macOS for me, so I cannot reproduce your issue.\n\nThank you for your suggestion. I will do that.",
                          "url": "https://github.com/idaholab/moose/discussions/18602#discussioncomment-1168974",
                          "updatedAt": "2022-07-04T08:34:22Z",
                          "publishedAt": "2021-08-13T15:49:27Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "You can add command line options in other options with peacock. See this page\nhttps://mooseframework.inl.gov/application_usage/peacock.html",
                          "url": "https://github.com/idaholab/moose/discussions/18602#discussioncomment-1187782",
                          "updatedAt": "2022-07-04T08:34:22Z",
                          "publishedAt": "2021-08-16T00:47:48Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "EXIT CODE: 11",
          "author": {
            "login": "DomenicoCFD"
          },
          "bodyText": "Hi All,\nI am trying to resolve a 3D numerical problem on a cluster which does not differ from other for which I already got a converged solution in MOOSE. For some reasons I got the following error message:\nDoes anyone have an idea of what this could be related to?\nI look forward to hearing from you.\nRegards,\n===================================================================================\n=   BAD TERMINATION OF ONE OF YOUR APPLICATION PROCESSES\n=   PID 9079 RUNNING AT node-vvvvv5\n=   EXIT CODE: 11\n=   CLEANING UP REMAINING PROCESSES\n=   YOU CAN IGNORE THE BELOW CLEANUP MESSAGES",
          "url": "https://github.com/idaholab/moose/discussions/18588",
          "updatedAt": "2022-07-05T13:15:53Z",
          "publishedAt": "2021-08-12T10:29:06Z",
          "category": {
            "name": "Q&A General"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "GiudGiud"
                  },
                  "bodyText": "Hello\nThis could be for a variety of reasons, actual bug / running out of memory / MPI issues.\nCould you please compile in debug mode (METHOD=dbg make -j XX) and re-run this a debugger?\nA shorthand for it:\nmpirun -n XXX gdb --ex run --ex bt --args ./your_app-dbg -i your_input_file.i\nGuillaume",
                  "url": "https://github.com/idaholab/moose/discussions/18588#discussioncomment-1164310",
                  "updatedAt": "2022-07-05T13:14:50Z",
                  "publishedAt": "2021-08-12T15:36:43Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "author": {
                    "login": "DomenicoCFD"
                  },
                  "bodyText": "Hi Gulliaume,\n\nMany thanks for your email. As I am relatively new to MOOSE, could you\nplease give me a bit more directions with regards to what you mean with\nyour command line? In fact, referring to it (see below):\n\nmpirun -n XXX gdb --ex run --ex bt ./your_app-dbg -i your_input_file.i\n\n\n   - What does XXX stand for?\n   - How should I get the ./your_app-dbg? I tried to follow the\n   instructions reported in the following link:\n\nhttps://mooseframework.inl.gov/getting_started/examples_and_tutorials/examples/ex21_debugging.html\n\nTherefore I initially tried to execute the following command in the main\napplication folder:\n\nMETHOD=dbg make -j8\n\nbut then I got the following error message:\n\nMakefile:19: /gpfs/cfms/home/username/projects/moose/framework/build.mk: No\nsuch file or directory\nMakefile:20: /gpfs/cfms/home/username/projects/moose/framework/moose.mk: No\nsuch file or directory\nMakefile:48: /gpfs/cfms/home/username/projects/moose/modules/modules.mk: No\nsuch file or directory\nMakefile:56: /gpfs/cfms/home/username/projects/moose/framework/app.mk: No\nsuch file or directory\nmake: *** No rule to make target\n`/gpfs/cfms/home/username/projects/moose/framework/app.mk'.  Stop\n\nHence, could you please clarify more about the details on the command line\nyou shared?\n\nI look forward to hearing from you.\n\nYours Sincerely,\n\nDomenico di Cugno, Ph. D.\n\u2026\nOn Thu, 12 Aug 2021 at 16:36, Guillaume Giudicelli ***@***.***> wrote:\n Hello\n\n This could be for a variety of reasons, actual bug / running out of memory\n / MPI issues.\n Could you please compile in debug mode and re-run this a debugger?\n A shorthand for it:\n mpirun -n XXX gdb --ex run --ex bt ./your_app-dbg -i your_input_file.i\n\n Guillaume\n\n \u2014\n You are receiving this because you authored the thread.\n Reply to this email directly, view it on GitHub\n <#18588 (comment)>,\n or unsubscribe\n <https://github.com/notifications/unsubscribe-auth/AVFIBH67FRRUJXD6JMQHHKLT4PTBNANCNFSM5CA2NXMA>\n .\n Triage notifications on the go with GitHub Mobile for iOS\n <https://apps.apple.com/app/apple-store/id1477376905?ct=notification-email&mt=8&pt=524675>\n or Android\n <https://play.google.com/store/apps/details?id=com.github.android&utm_campaign=notification-email>\n .\n\n\n-- \n*Domenico di Cugno* // Systems Engineer\n\n*e: ***@***.***   *t*: 0117 906 1100   *w: *\nwww.cfms.org.uk\nCFMS Services Ltd // Bristol & Bath Science Park // Dirac Crescent // Emersons\nGreen // Bristol // BS16 7FR\n\n<https://cfms.org.uk/media/384108/email-footer-darren-swift.png?width=500&height=115&mode=crop>\n<https://cfms.org.uk/media/384108/email-footer-darren-swift.png?width=500&height=115&mode=crop>\n<https://cfms.org.uk/industry-themes/smart-infrastructure/?utm_source=email&utm_medium=gmail-footer&utm_campaign=infrastructure&utm_content=landing-page.>\n<https://cfms.org.uk/industry-themes/smart-infrastructure/?utm_source=email&utm_medium=gmail-footer&utm_campaign=infrastructure&utm_content=landing-page.>\n<https://cfms.org.uk/news-events-opinions/opinions/2021/may/make-the-most-of-automation-with-open-networking/?utm_source=email&utm_medium=gmail-footer&utm_campaign=opinions&utm_content=open-networking.>\n<https://cfms.org.uk/news-events-opinions/opinions/2021/may/make-the-most-of-automation-with-open-networking/?utm_source=email&utm_medium=gmail-footer&utm_campaign=opinions&utm_content=open-networking.>\n<https://cfms.org.uk/news-events-opinions/opinions/2021/may/make-the-most-of-automation-with-open-networking/?utm_source=email&utm_medium=gmail-footer&utm_campaign=opinions&utm_content=open-networking.>",
                  "url": "https://github.com/idaholab/moose/discussions/18588#discussioncomment-1165492",
                  "updatedAt": "2022-07-05T13:14:50Z",
                  "publishedAt": "2021-08-12T20:21:55Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "XX is the number of processes here.\nnote the --args I added to the command btw\nAre you getting the same errors with the regular make command ?\nWhich directory are you running this from? Are you using the conda installation, if so did you remember to activate the conda environment?\nHave you used gdb before? The page you linked is the right one to help you.",
                          "url": "https://github.com/idaholab/moose/discussions/18588#discussioncomment-1165528",
                          "updatedAt": "2022-07-05T13:15:03Z",
                          "publishedAt": "2021-08-12T20:35:09Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              },
              {
                "node": {
                  "author": {
                    "login": "DomenicoCFD"
                  },
                  "bodyText": "Hi,\n\nMany thanks for your email and your corrections/amendments on your previous\ninstructions.\n\nI assumed I should be considering the same number of processes as that I\nwant to make the regular run. And I also guess that XX appearing into\nMETHOD ... should match the XXX that you specified into the command line\nmpirun ....\n\nAre you getting the same errors with the regular make command ? Which\ndirectory are you running this from?\nShould I perform the regular make command as: make j XX I still get the\nsame error. However, I do not understand why is this happening as I am into\nthe main application directory where the *Makefile* file exists. Unless, it\nis the matter of generating another MOOSE application specifically for the\ndebugger only?\n\nAre you using the conda installation, if so did you remember to activate\nthe conda environment?\nFor some reason internal to the business that I work for I am not sure that\nthe conda activation command is needed for the cluster environment but I\nmight be wrong on this and I would need to double check on that. In any\ncases, by running the conda activate moose the output message is: *bash:\nconda: command not found*\n\nHave you used gdb before? The page you linked is the right one to help you.\nAs I said, I am relatively new to MOOSE and so far I have never used gdb\nbefore. But to be honest, by reading the webpage about debugger it is\nunclear to me about which MOOSE application to consider for the debugger.\n\nI look forward to hearing from you.\n\nKind Regards,\n\nDomenico\n\u2026\nOn Thu, 12 Aug 2021 at 21:35, Guillaume Giudicelli ***@***.***> wrote:\n XX is the number of processes here.\n\n note the --args I added to the command btw\n\n Are you getting the same errors with the regular make command ?\n Which directory are you running this from? Are you using the conda\n installation, if so did you remember to activate the conda environment?\n\n Have you used gdb before? The page you linked is the right one to help you.\n\n \u2014\n You are receiving this because you authored the thread.\n Reply to this email directly, view it on GitHub\n <#18588 (reply in thread)>,\n or unsubscribe\n <https://github.com/notifications/unsubscribe-auth/AVFIBHYY4B6PN3HKXACAERTT4QWARANCNFSM5CA2NXMA>\n .\n Triage notifications on the go with GitHub Mobile for iOS\n <https://apps.apple.com/app/apple-store/id1477376905?ct=notification-email&mt=8&pt=524675>\n or Android\n <https://play.google.com/store/apps/details?id=com.github.android&utm_campaign=notification-email>\n .\n\n\n-- \n*Domenico di Cugno* // Systems Engineer\n\n*e: ***@***.***   *t*: 0117 906 1100   *w: *\nwww.cfms.org.uk\nCFMS Services Ltd // Bristol & Bath Science Park // Dirac Crescent // Emersons\nGreen // Bristol // BS16 7FR\n\n<https://cfms.org.uk/media/384108/email-footer-darren-swift.png?width=500&height=115&mode=crop>\n<https://cfms.org.uk/media/384108/email-footer-darren-swift.png?width=500&height=115&mode=crop>\n<https://cfms.org.uk/industry-themes/smart-infrastructure/?utm_source=email&utm_medium=gmail-footer&utm_campaign=infrastructure&utm_content=landing-page.>\n<https://cfms.org.uk/industry-themes/smart-infrastructure/?utm_source=email&utm_medium=gmail-footer&utm_campaign=infrastructure&utm_content=landing-page.>\n<https://cfms.org.uk/news-events-opinions/opinions/2021/may/make-the-most-of-automation-with-open-networking/?utm_source=email&utm_medium=gmail-footer&utm_campaign=opinions&utm_content=open-networking.>\n<https://cfms.org.uk/news-events-opinions/opinions/2021/may/make-the-most-of-automation-with-open-networking/?utm_source=email&utm_medium=gmail-footer&utm_campaign=opinions&utm_content=open-networking.>\n<https://cfms.org.uk/news-events-opinions/opinions/2021/may/make-the-most-of-automation-with-open-networking/?utm_source=email&utm_medium=gmail-footer&utm_campaign=opinions&utm_content=open-networking.>",
                  "url": "https://github.com/idaholab/moose/discussions/18588#discussioncomment-1165746",
                  "updatedAt": "2022-07-05T13:17:01Z",
                  "publishedAt": "2021-08-12T21:48:02Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "Hey\nPlease use the quote reply feature (next to the checkmark button) if you want to quote. Will make it easier to read.\nThe XX for make and the XX for mpirun do not have to match. They will match if you want to use the same number of processes for the two separate tasks, and they tend to be both equal to the number of cores that your machine has, but they do not have to.\nOk so the error does not have to do with generating the debug executable. Since you are not using conda, and are using a computing cluster where I assume someone else installed moose for you, what you need to do is specify where the MOOSE directory is before building your application. What does echo $MOOSE_DIR return?\nOnce this is fixed, we are trying to build a new executable specifically for debugging. Not really a new application.\ngdb is not tied to moose. It's used in general for debugging. You can find a lot of help on using it just by searching online. You should be good just using the command I gave you though, once you have built the application.\nGuillaume",
                          "url": "https://github.com/idaholab/moose/discussions/18588#discussioncomment-1165797",
                          "updatedAt": "2022-07-05T13:17:40Z",
                          "publishedAt": "2021-08-12T22:08:31Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "DomenicoCFD"
                          },
                          "bodyText": "Hi,\nMany thanks for your clarifications. Here below are my thoughts:\n\nBy running the echo $MOOSE_DIR I do receive only an empty line as output. I guess this is because we compile a specific version of moose and so, at every job and within the bash file, we execute a module load command as follows:\n\nmodule load /path_to_module_files/moose-vxxx\nSo I guess this is what echo command should give.\n\nI can now see that it is not the case of generating a new application, but the question remain around the command I would need to generate the -gdb executable. Do I need to use the path to the moose somehow in any command line? as the METHOD= ... won't work.\n\nKind Regards,\nDomenico",
                          "url": "https://github.com/idaholab/moose/discussions/18588#discussioncomment-1165849",
                          "updatedAt": "2022-07-05T13:17:40Z",
                          "publishedAt": "2021-08-12T22:33:17Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "Ugh the formatting of the message is messed up again. I guess I ll just have to deal with it ^^\nOk if you are to recompile the executable in debug mode you need to have access to moose. So module load, then compile.\nWhen compiling, either MOOSE should be in the application/moose folder, as a submodule or MOOSE_DIR should be set.",
                          "url": "https://github.com/idaholab/moose/discussions/18588#discussioncomment-1165880",
                          "updatedAt": "2022-07-05T13:17:45Z",
                          "publishedAt": "2021-08-12T22:43:07Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "You can specify the path in the command line if you want to, so\nMOOSE_DIR=path_to_moose METHOD=dbg make -j XX",
                          "url": "https://github.com/idaholab/moose/discussions/18588#discussioncomment-1165882",
                          "updatedAt": "2022-07-05T13:20:34Z",
                          "publishedAt": "2021-08-12T22:43:36Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "DomenicoCFD"
                          },
                          "bodyText": "Hi,\nIt seems that something is now happening but still some errors as it cannot find few commands:\nhere below there is the output/error message.\n[username@hostname application]$ MOOSE_DIR=/path_to_moose/moose-210516/ METHOD=dbg make -j 24\nmake: mpicxx: Command not found\nmake: mpif90: Command not found\n/bin/sh: mpif90: command not found\nUsing HIT from /path_to_moose/framework/contrib/hit\nCompiling C++ (in dbg mode) /path_to_moose/framework/build/unity_src/src_Unity.C...\nCompiling C++ (in dbg mode) /path_to_moose/framework/build/unity_src/outputs_Unity.C...\nCompiling C++ (in dbg mode) /path_to_moose/framework/build/unity_src/outputs_png_Unity.C...\nCompiling C++ (in dbg mode) /path_to_moose/framework/build/unity_src/outputs_formatters_Unity.C...\nCompiling C++ (in dbg mode) /path_to_moose/framework/build/unity_src/controls_Unity.C...\nCompiling C++ (in dbg mode) /path_to_moose/framework/build/unity_src/reporters_Unity.C...\nCompiling C++ (in dbg mode) /path_to_moose/framework/build/unity_src/timeintegrators_Unity.C...\nCompiling C++ (in dbg mode) /path_to_moose/framework/build/unity_src/fvbcs_Unity.C...\nCompiling C++ (in dbg mode) /path_to_moose/framework/build/unity_src/meshgenerators_Unity.C...\nCompiling C++ (in dbg mode) /path_to_moose/framework/build/unity_src/relationshipmanagers_Unity.C...\nCompiling C++ (in dbg mode) /path_to_moose/framework/build/unity_src/vectorpostprocessors_Unity.C...\nCompiling C++ (in dbg mode) /path_to_moose/framework/build/unity_src/problems_Unity.C...\nCompiling C++ (in dbg mode) /path_to_moose/framework/build/unity_src/partitioner_Unity.C...\nCompiling C++ (in dbg mode) /path_to_moose/framework/build/unity_src/timesteppers_Unity.C...\nCompiling C++ (in dbg mode) /path_to_moose/framework/build/unity_src/auxkernels_Unity.C...\nCompiling C++ (in dbg mode) /path_to_moose/framework/build/unity_src/fviks_Unity.C...\nCompiling C++ (in dbg mode) /path_to_moose/framework/build/unity_src/predictors_Unity.C...\nCompiling C++ (in dbg mode) /path_to_moose/framework/build/unity_src/constraints_Unity.C...\nCompiling C++ (in dbg mode) /path_to_moose/framework/build/unity_src/transfers_Unity.C...\n/path_to_moose/libmesh/installed/contrib/bin/libtool: line 1763: mpicxx: command not found\nmake: *** [/path_to_moose/framework/build/unity_src/src_Unity.x86_64-pc-linux-gnu.dbg.lo] Error 1\nmake: *** Waiting for unfinished jobs....\n/path_to_moose/libmesh/installed/contrib/bin/libtool: line 1763: mpicxx: command not found\nmake: *** [/path_to_moose/framework/build/unity_src/outputs_Unity.x86_64-pc-linux-gnu.dbg.lo] Error 1\n/path_to_moose/libmesh/installed/contrib/bin/libtool: line 1763: mpicxx: command not found\nmake: *** [/path_to_moose/framework/build/unity_src/outputs_png_Unity.x86_64-pc-linux-gnu.dbg.lo] Error 1\n/path_to_moose/libmesh/installed/contrib/bin/libtool: line 1763: mpicxx: command not found\nmake: *** [/path_to_moose/framework/build/unity_src/outputs_formatters_Unity.x86_64-pc-linux-gnu.dbg.lo] Error 1\n/path_to_moose/libmesh/installed/contrib/bin/libtool: line 1763: mpicxx: command not found\nmake: *** [/path_to_moose/framework/build/unity_src/controls_Unity.x86_64-pc-linux-gnu.dbg.lo] Error 1\n/path_to_moose/libmesh/installed/contrib/bin/libtool: line 1763: mpicxx: command not found\nmake: *** [/path_to_moose/framework/build/unity_src/reporters_Unity.x86_64-pc-linux-gnu.dbg.lo] Error 1\n/path_to_moose/libmesh/installed/contrib/bin/libtool: line 1763: mpicxx: command not found\nmake: *** [/path_to_moose/framework/build/unity_src/timeintegrators_Unity.x86_64-pc-linux-gnu.dbg.lo] Error 1\n/path_to_moose/libmesh/installed/contrib/bin/libtool: line 1763: mpicxx: command not found\nmake: *** [/path_to_moose/framework/build/unity_src/fvbcs_Unity.x86_64-pc-linux-gnu.dbg.lo] Error 1\n/path_to_moose/libmesh/installed/contrib/bin/libtool: line 1763: mpicxx: command not found\nmake: *** [/path_to_moose/framework/build/unity_src/meshgenerators_Unity.x86_64-pc-linux-gnu.dbg.lo] Error 1\n/path_to_moose/libmesh/installed/contrib/bin/libtool: line 1763: mpicxx: command not found\nmake: *** [/path_to_moose/framework/build/unity_src/relationshipmanagers_Unity.x86_64-pc-linux-gnu.dbg.lo] Error 1\n/path_to_moose/libmesh/installed/contrib/bin/libtool: line 1763: mpicxx: command not found\nmake: *** [/path_to_moose/framework/build/unity_src/vectorpostprocessors_Unity.x86_64-pc-linux-gnu.dbg.lo] Error 1\n/path_to_moose/libmesh/installed/contrib/bin/libtool: line 1763: mpicxx: command not found\nmake: *** [/path_to_moose/framework/build/unity_src/problems_Unity.x86_64-pc-linux-gnu.dbg.lo] Error 1\n/path_to_moose/libmesh/installed/contrib/bin/libtool: line 1763: mpicxx: command not found\nmake: *** [/path_to_moose/framework/build/unity_src/partitioner_Unity.x86_64-pc-linux-gnu.dbg.lo] Error 1\n/path_to_moose/libmesh/installed/contrib/bin/libtool: line 1763: mpicxx: command not found\nmake: *** [/path_to_moose/framework/build/unity_src/timesteppers_Unity.x86_64-pc-linux-gnu.dbg.lo] Error 1\n/path_to_moose/libmesh/installed/contrib/bin/libtool: line 1763: mpicxx: command not found\nmake: *** [/path_to_moose/framework/build/unity_src/auxkernels_Unity.x86_64-pc-linux-gnu.dbg.lo] Error 1\n/path_to_moose/libmesh/installed/contrib/bin/libtool: line 1763: mpicxx: command not found\nmake: *** [/path_to_moose/framework/build/unity_src/fviks_Unity.x86_64-pc-linux-gnu.dbg.lo] Error 1\n/path_to_moose/libmesh/installed/contrib/bin/libtool: line 1763: mpicxx: command not found\nmake: *** [/path_to_moose/framework/build/unity_src/predictors_Unity.x86_64-pc-linux-gnu.dbg.lo] Error 1\n/path_to_moose/libmesh/installed/contrib/bin/libtool: line 1763: mpicxx: command not found\nmake: *** [/path_to_moose/framework/build/unity_src/constraints_Unity.x86_64-pc-linux-gnu.dbg.lo] Error 1\n/path_to_moose/libmesh/installed/contrib/bin/libtool: line 1763: mpicxx: command not found\nmake: *** [/path_to_moose/framework/build/unity_src/transfers_Unity.x86_64-pc-linux-gnu.dbg.lo] Error 1",
                          "url": "https://github.com/idaholab/moose/discussions/18588#discussioncomment-1165901",
                          "updatedAt": "2022-07-05T13:20:34Z",
                          "publishedAt": "2021-08-12T22:54:13Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "It's not finding the mpi wrapped compilers, which will compile your application with the MPI library that you are using.\nYou need to export the CC, CXX and FC environment variables to the location of your MPI-wrapped compilers.\nIf you don't know where they are, you'll need to talk to whoever installed MOOSE for you as you need to use the same compilers as those that were used to install MOOSE.",
                          "url": "https://github.com/idaholab/moose/discussions/18588#discussioncomment-1165910",
                          "updatedAt": "2022-07-05T13:20:38Z",
                          "publishedAt": "2021-08-12T22:58:43Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "DomenicoCFD"
                          },
                          "bodyText": "Hi,\nMany thanks for your direction! Really useful! I will speak tomorrow morning UTC time zone with whoever is/was involved into the MOOSE installation.\nI will keep you informed on how it goes eventually! But for now many thanks for your priceless support!\nKind Regards,\nDomenico",
                          "url": "https://github.com/idaholab/moose/discussions/18588#discussioncomment-1165915",
                          "updatedAt": "2022-07-05T13:20:37Z",
                          "publishedAt": "2021-08-12T23:01:56Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "UMAT as Plugin",
          "author": {
            "login": "12arya129"
          },
          "bodyText": "Hello,\nI want to learn more about using UMAT (Fortran) in moose, I tried searching it on Moose website but couldn't find much. Any help?",
          "url": "https://github.com/idaholab/moose/discussions/17165",
          "updatedAt": "2022-06-02T14:51:53Z",
          "publishedAt": "2021-03-01T10:35:54Z",
          "category": {
            "name": "Q&A Modules: General"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "lynnmunday"
                  },
                  "bodyText": "It was a part of the MOOSE solid mechanics module but the solid mechanics module was deprecated in favor of the tensor mechanics module and the umat code did not make it into tensor mechanics.  If you wanted to try reimplementing the umat code into tensor mechanics, you could start from this commit from 7/25/2012 which implemented umat in solid mechanics:  94051c7\nI think we might try to add a umat capability back into tensor mechanics this summer.",
                  "url": "https://github.com/idaholab/moose/discussions/17165#discussioncomment-419573",
                  "updatedAt": "2022-06-02T14:51:53Z",
                  "publishedAt": "2021-03-01T20:32:39Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "Traiwit"
                          },
                          "bodyText": "Hi @lynnmunday is there any update on UMAT?",
                          "url": "https://github.com/idaholab/moose/discussions/17165#discussioncomment-1166631",
                          "updatedAt": "2022-06-02T14:52:03Z",
                          "publishedAt": "2021-08-13T05:28:55Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "lynnmunday"
                          },
                          "bodyText": "@dschwen has done a lot of umat work recently.   In May he merged this:\n#17742\nThere are also some other issues he is working on.  I think it would be ready to try and there are examples in the above pr.",
                          "url": "https://github.com/idaholab/moose/discussions/17165#discussioncomment-1168827",
                          "updatedAt": "2022-06-02T14:51:58Z",
                          "publishedAt": "2021-08-13T15:14:58Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "dschwen"
                          },
                          "bodyText": "Stay tuned for further improvements in that area. And let us know if you have specific UMAT requirements. We're always interested in feedback on this capability!",
                          "url": "https://github.com/idaholab/moose/discussions/17165#discussioncomment-1168929",
                          "updatedAt": "2022-06-02T14:51:58Z",
                          "publishedAt": "2021-08-13T15:38:58Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      }
    ]
  }
}