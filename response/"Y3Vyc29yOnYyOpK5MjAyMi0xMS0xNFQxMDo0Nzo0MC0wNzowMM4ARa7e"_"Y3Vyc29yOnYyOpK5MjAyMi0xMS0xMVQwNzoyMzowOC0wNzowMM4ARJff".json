{
  "discussions": {
    "pageInfo": {
      "hasNextPage": true,
      "endCursor": "Y3Vyc29yOnYyOpK5MjAyMi0xMS0xMVQwNzoyMzowOC0wNzowMM4ARJff"
    },
    "edges": [
      {
        "node": {
          "title": "How to improve the convergence of CZM ?",
          "author": {
            "login": "echo1115"
          },
          "bodyText": "Hi all,\nWhen I simulating a thermal-mechanical case with CZM model, it became difficult to converge after softening onset (damage>0). According to https://mooseframework.inl.gov/source/materials/cohesive_zone_model/BiLinearMixedModeTraction.html#Camanho2002,\nIt seems the parameter viscosity  can help, but I don't know its value range and how to set it appropriate according to specific case.\nHere is my czm setting:\n  [czm]\n    type = BiLinearMixedModeTraction\n    boundary = 'Block5_matrix'\n    penalty_stiffness = 1.0e15 \n    GI_c = 25 \n    GII_c = 25 \n    normal_strength = 100e6\n    shear_strength = 240e6\n    eta = 1 \n    viscosity = 1 \n    mixed_mode_criterion = POWER_LAW #BK\n  []\n\nMaybe someone could give me suggestions. Thanks in advance.",
          "url": "https://github.com/idaholab/moose/discussions/22683",
          "updatedAt": "2022-11-14T14:14:09Z",
          "publishedAt": "2022-11-13T12:51:41Z",
          "category": {
            "name": "Q&A Modules: Solid mechanics"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "hugary1995"
                  },
                  "bodyText": "Yeah, the convergence issue is common to all softening models. Typical ways of dealing with this include\n\nalternating minimization.\nlagging the state variables.\nnonlinear preconditioner.\n\nYou can set up 1 using fixed point iterations.\nOption 2 is recommended for CZM, where you would set lag_mode_mixity = true and lag_displacement_jump = true.\nOption 3 is not yet available in MOOSE, but it is on the roadmap.",
                  "url": "https://github.com/idaholab/moose/discussions/22683#discussioncomment-4128630",
                  "updatedAt": "2022-11-13T14:57:57Z",
                  "publishedAt": "2022-11-13T14:57:56Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "echo1115"
                          },
                          "bodyText": "@hugary1995 Thanks for your useful suggestions!",
                          "url": "https://github.com/idaholab/moose/discussions/22683#discussioncomment-4137106",
                          "updatedAt": "2022-11-14T14:13:47Z",
                          "publishedAt": "2022-11-14T14:13:47Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "Question regarding interface kernels",
          "author": {
            "login": "souravmat-git"
          },
          "bodyText": "Hello,\nI have a question regarding interface kernels. I am trying to implement the interfacial conditions, Eqs. (3) and (4), in MOOSE (please refer to the following schematic):\n\nHere $\\phi^{\\theta}$, $\\sigma^{\\theta}$, and $i^{\\theta}$ refer to the electric potential, conductivity and current in the bulk domains $\\theta = \\alpha, \\beta$. Eq. (3) ensures the current continuity, and Eq. (4) gives the interfacial current.\nFurther, I think these conditions are similar to the ElectrostaticContactCondition, which is already in MOOSE. I found an example input file, contact_conductance_calculated.i, based on this kernel.\nHowever, my question is regarding the part of the code that ensures these conditions. Specifically,\nswitch (type)\n  {\n    case Moose::Element:\n      res = -contact_conductance * (_neighbor_value[_qp] - _u[_qp]) * _test[_i][_qp];\n      break;\n\n    case Moose::Neighbor:\n      res = _conductivity_primary[_qp] * _grad_u[_qp] * _normals[_qp] * _test_neighbor[_i][_qp];\n      break;\n  }\n\nI am unsure how this code ensures current continuity, i.e. Eq. (3).\nI found a similar GitHub discussion concerning this Interface kernel with coupled variable. In this case, however, the residuals are implemented differently despite having similar interfacial conditions.\nAre these implementations equivalent, or am I missing something?\nI welcome clarifications/suggestions regarding this.\nThanks,\nSourav",
          "url": "https://github.com/idaholab/moose/discussions/22680",
          "updatedAt": "2022-11-13T19:03:50Z",
          "publishedAt": "2022-11-11T22:43:24Z",
          "category": {
            "name": "Q&A General"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "hugary1995"
                  },
                  "bodyText": "Yes, this ensures current continuity weakly.",
                  "url": "https://github.com/idaholab/moose/discussions/22680#discussioncomment-4121414",
                  "updatedAt": "2022-11-12T00:37:48Z",
                  "publishedAt": "2022-11-12T00:37:47Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "souravmat-git"
                          },
                          "bodyText": "Thanks!",
                          "url": "https://github.com/idaholab/moose/discussions/22680#discussioncomment-4129714",
                          "updatedAt": "2022-11-13T19:03:50Z",
                          "publishedAt": "2022-11-13T19:03:49Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "Help with checking one modified cystal plasticity program",
          "author": {
            "login": "xchengood"
          },
          "bodyText": "Dear Moose experts or users,\nI am trying to achieve the constitute model mentioned in section 4 of the literature [1] and section 2 of the literature [2] in Moose. I did some modifications in CrystalPlasticityStressUpdateBase.h, CrystalPlasticityStressUpdateBase.c, CrystalPlasticityKalidindiUpdate.h and CrystalPlasticityKalidindiUpdate.c. Specific changes are described below. All codes are here https://github.com/xchengood/Nonschmid. Could anyone go to look through it and help me check that? The test file that I used is update_method_test.i. Thank you.\n(1) In CrystalPlasticityStressUpdateBase.h https://github.com/xchengood/Nonschmid/blob/main/CrystalPlasticityStressUpdateBase.h\nThe resolved shear stress in equation 3 in Literature [2] is calculated by taking the non-Schmid effect into consideration. So there are some modifications in line 93 and line 234.\n(2) In CrystalPlasticityStressUpdateBase.c https://github.com/xchengood/Nonschmid/blob/main/CrystalPlasticityStressUpdateBase.C\nModifications in line 107, line 126, line 130, line 371, line 413 - line 460, line 471, and line 483.\nline 413 - 460 is to achieve equation (4) in literature [2].\n(3) In CrystalPlasticityKalidindiUpdate.h https://github.com/xchengood/Nonschmid/blob/main/CrystalPlasticityKalidindiUpdate.h\nModifications in lines 101 - 106 express variables in equations (7) - (11) in literature [1].\n(4) In CrystalPlasticityKalidindiUpdate.c https://github.com/xchengood/Nonschmid/blob/main/CrystalPlasticityKalidindiUpdate.C\nModifications are in lines 28 - 33, line3 54 - 59, line 117, line 185 - line 198.\nline 117 is to achieve equation (10) in literature [1].\nline 185 - line 198 is to achieve dslip_dtau.\n[1]Yalcinkaya T, Brekelmans WA, Geers MG. BCC single crystal plasticity modeling and its experimental identification. Modelling and Simulation in Materials Science and Engineering. 2008 Oct 1;16(8):085007.\n[2]Lim H, Hale LM, Zimmerman JA, Battaile CC, Weinberger CR. A multi-scale model of dislocation plasticity in \u03b1-Fe: Incorporating temperature, strain rate and non-Schmid effects. International Journal of Plasticity. 2015 Oct 1;73:100-18.",
          "url": "https://github.com/idaholab/moose/discussions/22665",
          "updatedAt": "2023-01-03T23:10:25Z",
          "publishedAt": "2022-11-11T03:56:12Z",
          "category": {
            "name": "Q&A Modules: Solid mechanics"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "hugary1995"
                  },
                  "bodyText": "You can set up a single element test to probe the flow curve, and compare it with the curves reported in the papers. If there is any discrepancy, feel free to post your comparisons here and hopefully someone can help you diagnose that.",
                  "url": "https://github.com/idaholab/moose/discussions/22665#discussioncomment-4121453",
                  "updatedAt": "2022-11-12T00:51:37Z",
                  "publishedAt": "2022-11-12T00:51:36Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": []
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "Error about \"PETSC LAPACK syev routine returned error code 2\"",
          "author": {
            "login": "xchengood"
          },
          "bodyText": "Hi Moose experts or users,\nI got the following errors. Any ideas to solve that? Thank you",
          "url": "https://github.com/idaholab/moose/discussions/22641",
          "updatedAt": "2023-01-03T23:18:43Z",
          "publishedAt": "2022-11-09T17:50:57Z",
          "category": {
            "name": "Q&A Modules: Solid mechanics"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "GiudGiud"
                  },
                  "bodyText": "Hello\nCan you please attach the full simulation log?\nAlso do you know which tensor that was? If you could paste it here that could help\nGuillaume",
                  "url": "https://github.com/idaholab/moose/discussions/22641#discussioncomment-4099784",
                  "updatedAt": "2022-11-09T18:03:04Z",
                  "publishedAt": "2022-11-09T18:03:04Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "xchengood"
                          },
                          "bodyText": "Here is the error log. I have no any ideas about which tensor that was. Thank you.\nerror log.txt",
                          "url": "https://github.com/idaholab/moose/discussions/22641#discussioncomment-4101026",
                          "updatedAt": "2022-11-09T20:28:58Z",
                          "publishedAt": "2022-11-09T20:28:57Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "@sapitts  could you please help with this",
                          "url": "https://github.com/idaholab/moose/discussions/22641#discussioncomment-4101219",
                          "updatedAt": "2022-11-09T21:06:05Z",
                          "publishedAt": "2022-11-09T20:53:20Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "hugary1995"
                          },
                          "bodyText": "This error comes from eigvalue decomposition of the right cauchy green strain, for the RU decomposition. You can go to the corresponding frame in a debugger, then print the failing tensor. Although unlikely, if lapack fails to find eigenvalues and eigenvectors of a well-conditioned symmetric r2t, we can attempt to fix that.",
                          "url": "https://github.com/idaholab/moose/discussions/22641#discussioncomment-4121435",
                          "updatedAt": "2022-11-12T00:46:23Z",
                          "publishedAt": "2022-11-12T00:45:50Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "a question in 3D navier stokes",
          "author": {
            "login": "Oops-Qiao"
          },
          "bodyText": "Hello,\nI have a simple question when I look at your moose code regarding the velocity component.\nhttps://github.com/idaholab/moose/blob/next/modules/navier_stokes/src/kernels/NSMomentumInviscidFlux.C\nIn line 42 we have\n// For _component = k,\n// (rhou) * u_k = (rhou_k) * u <- we write it this way\nRealVectorValue vec(_u[_qp] * _u_vel[_qp],  // (U_k) * u_1\n_u[_qp] * _v_vel[_qp],  // (U_k) * u_2\n_u[_qp] * _w_vel[_qp]); // (U_k) * u_3\nand\nhttps://github.com/idaholab/moose/blob/next/modules/navier_stokes/src/kernels/NSEnergyInviscidFlux.C\nin line 40\n// velocity vector\nRealVectorValue vel(_u_vel[_qp], _v_vel[_qp], _w_vel[_qp]);\nI just wonder that in 3D geometry, should each component of velocity be defined as a vector? It looks to me that in the upper two examples in your code, the velocity component is just a real such that the vel(_u_vel[_qp], _v_vel[_qp], _w_vel[_qp]) is a vector.\nIt is a little bit confusing. Thank you for clarification.\nBest regards\nQia.",
          "url": "https://github.com/idaholab/moose/discussions/22650",
          "updatedAt": "2022-11-11T23:07:08Z",
          "publishedAt": "2022-11-10T17:34:33Z",
          "category": {
            "name": "Q&A General"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "Oops-Qiao"
                  },
                  "bodyText": "@GiudGiud\nHello, :) There seems to be an interesting question.",
                  "url": "https://github.com/idaholab/moose/discussions/22650#discussioncomment-4120975",
                  "updatedAt": "2022-11-11T23:00:40Z",
                  "publishedAt": "2022-11-11T23:00:39Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "no each component is not a vector.\nWhat you are seeing is a momentum flux so you have u * u terms",
                          "url": "https://github.com/idaholab/moose/discussions/22650#discussioncomment-4120990",
                          "updatedAt": "2022-11-11T23:03:43Z",
                          "publishedAt": "2022-11-11T23:03:42Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "Oops-Qiao"
                          },
                          "bodyText": "Thank you so much.",
                          "url": "https://github.com/idaholab/moose/discussions/22650#discussioncomment-4121005",
                          "updatedAt": "2022-11-11T23:07:09Z",
                          "publishedAt": "2022-11-11T23:07:08Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "Meaning of different execute_on parameters",
          "author": {
            "login": "js-jixu"
          },
          "bodyText": "Hi, experts.\nMany objects have the parameter execute_on, and execute_on also has many options. Some options have obvious meanings, such as TIMESTEP_END. But I also have doubts about some options.\n\n\nI guess LINEAR and NONLINEAR stand for executing the object on linear and non-linear iterations respectively. Is my guess right?\n\n\nDoes ALWAYS mean that object is always executed in the steady or transient simulation? That sounds unlikely.\n\n\nHow is CUSTOM used? It looks like CUSTOM needs some other parameters to help.",
          "url": "https://github.com/idaholab/moose/discussions/22667",
          "updatedAt": "2022-11-11T20:57:58Z",
          "publishedAt": "2022-11-11T14:50:02Z",
          "category": {
            "name": "Q&A General"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "hugary1995"
                  },
                  "bodyText": "Detailed information here: https://mooseframework.inl.gov/moose/source/interfaces/SetupInterface.html\nThe only ones not so intuitive are LINEAR and NONLINEAR, they actually mean RESIDUAL and JACOBIAN, resp.",
                  "url": "https://github.com/idaholab/moose/discussions/22667#discussioncomment-4118369",
                  "updatedAt": "2022-11-11T14:57:18Z",
                  "publishedAt": "2022-11-11T14:57:17Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "CUSTOM is on its way out because apps can now register additional execute_on flags\n#22124",
                          "url": "https://github.com/idaholab/moose/discussions/22667#discussioncomment-4118407",
                          "updatedAt": "2022-11-11T15:02:32Z",
                          "publishedAt": "2022-11-11T15:02:32Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "js-jixu"
                          },
                          "bodyText": "Thank you for replies! I'm reading those.",
                          "url": "https://github.com/idaholab/moose/discussions/22667#discussioncomment-4118459",
                          "updatedAt": "2022-11-11T15:07:52Z",
                          "publishedAt": "2022-11-11T15:07:52Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "maxnezdyur"
                          },
                          "bodyText": "Just to confirm. When using multiapp and TIMESTEP_BEGIN, an object will be called every fixed point iteration within a timestep if they have a TIMESTEP_BEGIN flag active?",
                          "url": "https://github.com/idaholab/moose/discussions/22667#discussioncomment-4120518",
                          "updatedAt": "2022-11-11T20:57:59Z",
                          "publishedAt": "2022-11-11T20:57:58Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "Can we build a static library of an App and easily used it in other computers with the same OS",
          "author": {
            "login": "zx1987"
          },
          "bodyText": "Dear Moose user group,\nI was hoping to compile a static library of an App, to use it on different computers with the same OS by just copying that compiled app. I was searching and found this discussion: #22326\nI was thinking maybe I can build libmesh and moose statically as described in the above post, and then compile our app after that. Will this give us a static library of the app, or there are additional steps I should consider? Thank you!\nBest,\nXiang",
          "url": "https://github.com/idaholab/moose/discussions/22653",
          "updatedAt": "2022-11-15T20:15:27Z",
          "publishedAt": "2022-11-10T19:46:39Z",
          "category": {
            "name": "Q&A General"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "GiudGiud"
                  },
                  "bodyText": "You'll have to follow the post you linked to, then add the static flags in the CXXFLAGS environment variable.\n@milljm",
                  "url": "https://github.com/idaholab/moose/discussions/22653#discussioncomment-4111016",
                  "updatedAt": "2022-11-10T20:03:17Z",
                  "publishedAt": "2022-11-10T20:03:17Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "milljm"
                          },
                          "bodyText": "I agree, the post you linked, is basically the gist of what needs to happen. MOOSE based apps only build according to how libMesh was built. But if you're after a total relocatable binary, you may need to build statically, starting with PETSc.",
                          "url": "https://github.com/idaholab/moose/discussions/22653#discussioncomment-4111187",
                          "updatedAt": "2022-11-10T20:24:23Z",
                          "publishedAt": "2022-11-10T20:24:23Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "zx1987"
                          },
                          "bodyText": "Thank you @milljm @GiudGiud for your confirmation. I will test this out and let you know. Thanks.",
                          "url": "https://github.com/idaholab/moose/discussions/22653#discussioncomment-4111305",
                          "updatedAt": "2022-11-10T20:40:21Z",
                          "publishedAt": "2022-11-10T20:40:20Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "zx1987"
                          },
                          "bodyText": "I tried to do the static build of petsc, but came across the error like \"/home/xzhang16/mambaforge3/envs/petsc/bin/../lib/gcc/x86_64-conda-linux-gnu/10.4.0/../../../../x86_64-conda-linux-gnu/bin/ld: cannot find -lhdf5_cpp: No such file or directory\"\nDo you have any idea what might be wrong? @milljm @GiudGiud  I have more detailed error message attached in case it could be helpful. Thank you!\nStaticLibmeshError.txt",
                          "url": "https://github.com/idaholab/moose/discussions/22653#discussioncomment-4118392",
                          "updatedAt": "2022-11-11T15:00:23Z",
                          "publishedAt": "2022-11-11T15:00:22Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "which HDF5 library are you trying to use? One provided by your local environment or by PETSc ?",
                          "url": "https://github.com/idaholab/moose/discussions/22653#discussioncomment-4118418",
                          "updatedAt": "2022-11-11T15:03:24Z",
                          "publishedAt": "2022-11-11T15:03:24Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "zx1987"
                          },
                          "bodyText": "I did not really specify which hdf5 to use and was assuming if I take the stand installation procedure, it should be using the one from PETSc.  So I just did this again, by resetting my $PATH so the system only have access to the mamabaforge3 folder hence libraries from PETSc. It turns out I had the same error.  I tried to search lhdf5 in the mambaforge3 and nothing was found.  Tere are the steps I took in this new attempt:\n`curl -L -O https://github.com/conda-forge/miniforge/releases/latest/download/Mambaforge-Linux-x86_64.sh`\n`bash Mambaforge-Linux-x86_64.sh -b -p ~/mambaforge3`\n`unset LD_LIBRARY_PATH`\n`PATH=$(getconf PATH)` \n`export PATH=$HOME/mambaforge3/bin:$PATH  # reset the PATH such that I will not mistakenly use things other than from the the mambaforge3 folder`\n`conda config --add channels https://conda.software.inl.gov/public`\n\nsteps taken from post  https://github.com/idaholab/moose/discussions/22326\n`mamba activate base    # get back to the original environment`\n`mamba create -n petsc moose-petsc moose-tools`\n`mamba activate petsc`  \n`cd ~/projects/moose`\n`git clean -xfd`\n`git submodule foreach --recursive git clean -xfd`\n\n`export MOOSE_JOBS=8   # replace this number with how many cores your machine has`\n`export METHODS=opt`\n`scripts/update_and_rebuild_libmesh.sh --enable-all-static --enable-static`",
                          "url": "https://github.com/idaholab/moose/discussions/22653#discussioncomment-4118597",
                          "updatedAt": "2022-11-11T16:36:52Z",
                          "publishedAt": "2022-11-11T15:28:49Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "milljm"
                          },
                          "bodyText": "If you're going to use Mamba, you might as well create and distribute a mamba package containing your binary instead (since if using Mamba, you'll need to have each of your users also install Mamba).\nHave a look at moose/conda/generate_recipe.sh. The gist of this tool's use is as follows:\ncd ~/projects\ngit clone https://github.com/idaholab/moose\ngit clone <your moose-based application>\nexport MOOSE_SKIP_DOCS=True\nmoose/conda/generate_recipe.sh /absolute/path/to/<your moose-based application> 12\n\n12 being the number of cores you can use on this machine\nMOOSE_SKIP_DOCS=True telling the make install process to ignore building documentation if you prefer\n\nThis will pre-install everything necessary (including Conda, boa, etc) into a temporary directory, and proceed to building your application as a relocatable package (A conda package). Much like; moose-libmesh, moose-tools, etc.\nOnce/If successful, your package can be installed by others, via:\nmamba install /path/to/created/conda-package.tar.gz",
                          "url": "https://github.com/idaholab/moose/discussions/22653#discussioncomment-4120445",
                          "updatedAt": "2022-11-11T20:50:34Z",
                          "publishedAt": "2022-11-11T20:44:26Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "Gradient of the hydrostatic stress \\sigma_H",
          "author": {
            "login": "saturn00000"
          },
          "bodyText": "Dear MOOSE Team\ncan we define the gradient of the hydrostatic stress, \\sigma_H, which is computed at the integration points from the nodal displacements in MOOSE?\nThe test input file looks like:\n...\n\n[AuxVariables]\n  [hydrostatic]\n    order = CONSTANT\n    family = MONOMIAL\n  []\n  [grad_u_x]\n    order = CONSTANT\n    family = MONOMIAL\n  []\n[]\n\n[AuxKernels]\n  [hydrostatic]\n    type = ADRankTwoScalarAux\n    rank_two_tensor = stress\n    variable = hydrostatic\n    scalar_type = Hydrostatic\n  []\n\n  [grad_u_x_aux]\n    type = VariableGradientComponent\n    variable = grad_u_x\n    component = x\n    gradient_variable = hydrostatic\n  []\n\n[]\n...\n\nThe results show that the value of the gradient of the hydrostatic stress in x direction (defined as grad_u_x) is 0...",
          "url": "https://github.com/idaholab/moose/discussions/22661",
          "updatedAt": "2022-11-16T07:03:15Z",
          "publishedAt": "2022-11-11T01:08:48Z",
          "category": {
            "name": "Q&A Getting Started"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "hugary1995"
                  },
                  "bodyText": "You can do a local L2 projection which preserves dual numbers. See e.g. https://github.com/hugary1995/eel/blob/main/src/materials/chemistry/ChemicalPotential.C",
                  "url": "https://github.com/idaholab/moose/discussions/22661#discussioncomment-4113067",
                  "updatedAt": "2022-11-11T01:55:45Z",
                  "publishedAt": "2022-11-11T01:55:44Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "saturn00000"
                          },
                          "bodyText": "can we just set order = second\ne.g.\n  [hydrostatic]\n    order = second \n    family = MONOMIAL\n  []",
                          "url": "https://github.com/idaholab/moose/discussions/22661#discussioncomment-4113184",
                          "updatedAt": "2022-11-11T02:20:17Z",
                          "publishedAt": "2022-11-11T02:20:16Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "hugary1995"
                          },
                          "bodyText": "Yes, actually you can get it to work using any monomial equal or above first order. Please be reminded that all derivatives in the ADReal will be lost by projecting it onto an AuxVariable. So if your model is somehow coupled to the gradient of the hydrostatic stress, the Jacobian will no longer be exact.",
                          "url": "https://github.com/idaholab/moose/discussions/22661#discussioncomment-4119774",
                          "updatedAt": "2022-11-11T18:26:32Z",
                          "publishedAt": "2022-11-11T18:26:31Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "moose-tools installation issues",
          "author": {
            "login": "MusannaGalib"
          },
          "bodyText": "Hello,\nI am trying to install MOOSE in HPC. After installing miniconda, I did -\nconda config --add channels https://conda.software.inl.gov/public\nconda create --name moose -q -y\n\nwhen I am trying to install moose-tools, the following problem occurs.\n(moose) [galibubc@cedar5 MOOSE]$ conda install moose-tools\nCollecting package metadata (current_repodata.json): done\nSolving environment: failed with initial frozen solve. Retrying with flexible solve.\nSolving environment: failed with repodata from current_repodata.json, will retry with next repodata source.\nCollecting package metadata (repodata.json): done\nSolving environment: failed with initial frozen solve. Retrying with flexible solve.\nSolving environment: \\ \nFound conflicts! Looking for incompatible packages.\nThis can take several minutes.  Press CTRL-C to abort.\nfailed                                                                          \n\nUnsatisfiableError:",
          "url": "https://github.com/idaholab/moose/discussions/22617",
          "updatedAt": "2022-11-15T20:09:52Z",
          "publishedAt": "2022-11-08T05:42:52Z",
          "category": {
            "name": "Q&A General"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "GiudGiud"
                  },
                  "bodyText": "so moose-tools is the only package you are trying to install in that environment right?\n@milljm",
                  "url": "https://github.com/idaholab/moose/discussions/22617#discussioncomment-4086629",
                  "updatedAt": "2022-11-08T13:12:56Z",
                  "publishedAt": "2022-11-08T13:12:55Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "MusannaGalib"
                          },
                          "bodyText": "yes. After installing the python 3.x development libraries I will install petsc and libmesh - if I am not wrong.",
                          "url": "https://github.com/idaholab/moose/discussions/22617#discussioncomment-4090854",
                          "updatedAt": "2022-11-08T21:03:03Z",
                          "publishedAt": "2022-11-08T21:03:02Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "milljm"
                          },
                          "bodyText": "It's possible the Python version built-in to your installed version of miniconda, is too far outdated to support Python >= 3.7.\nThe good news is, it sounds like you don't need our Conda stack. Normally in an HPC environment, that environment will supply a working stack better suited for the hardware that makes up your HPC environment. Conda is great for workstations. Not so great for HPC clusters.",
                          "url": "https://github.com/idaholab/moose/discussions/22617#discussioncomment-4096859",
                          "updatedAt": "2022-11-09T13:01:28Z",
                          "publishedAt": "2022-11-09T13:00:54Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "MusannaGalib"
                          },
                          "bodyText": "Hello @milljm\nThanks for the reply. I installed the latest version of miniconda. Are you saying I do not need to install moose-tools in our HPC?\nWithout installing the moose tools I installed petsc successfully.\nunset PETSC_DIR PETSC_ARCH\n./scripts/update_and_rebuild_petsc.sh\n\nHowever when I am trying to install libmesh, facing the following error:\n(moose) [galibubc@cedar1 moose]$ ./scripts/update_and_rebuild_libmesh.sh\nPETSc submodule will be used. PETSc submodule is our default solver.\nIMPORTANT: If you did not run the update_and_rebuild_petsc.sh script yet, please run it before building libMesh\n---------------------------------------------\n----------- Configuring libMesh -------------\n---------------------------------------------\nchecking build system type... x86_64-pc-linux-gnu\nchecking host system type... x86_64-pc-linux-gnu\nchecking target system type... x86_64-pc-linux-gnu\nchecking for a BSD-compatible install... /home/galibubc/projects/def-mponga/galibubc/MOOSE/projects/moose/scripts/../libmesh/build-aux/install-sh -C\nchecking whether build environment is sane... yes\nchecking for a thread-safe mkdir -p... /cvmfs/soft.computecanada.ca/gentoo/2020/bin/mkdir -p\nchecking for gawk... gawk\nchecking whether make sets $(MAKE)... yes\nchecking whether make supports nested variables... yes\nchecking whether UID '3115128' is supported by ustar format... no\nchecking whether GID '3115128' is supported by ustar format... no\nchecking how to create a ustar tar archive... none\nchecking whether make supports nested variables... (cached) yes\nchecking whether to enable maintainer-specific portions of Makefiles... no\nchecking for src/base/libmesh.C... no\n<<< Configuring build directory for VPATH build >>>\nchecking for perl... /cvmfs/soft.computecanada.ca/gentoo/2020/usr/bin/perl\nnote: MPI library path not given...\nnote: MPI library path not given...\nchecking whether make supports the include directive... yes (GNU style)\nchecking whether the C compiler works... yes\nchecking for C compiler default output file name... a.out\nchecking for suffix of executables... \nchecking whether we are cross compiling... no\nchecking for suffix of object files... o\nchecking whether we are using the GNU C compiler... yes\nchecking whether mpicc accepts -g... yes\nchecking for mpicc option to accept ISO C89... none needed\nchecking whether mpicc understands -c and -o together... yes\nchecking dependency style of mpicc... gcc3\nchecking whether we are using the GNU Fortran compiler... yes\nchecking whether mpif90 accepts -g... yes\nchecking whether we are using the GNU Fortran 77 compiler... yes\nchecking whether mpif77 accepts -g... yes\nchecking whether we are using the GNU C++ compiler... yes\nchecking whether mpicxx accepts -g... yes\nchecking dependency style of mpicxx... gcc3\n<<< C++ compiler is gcc-11.x >>>\nchecking for a sed that does not truncate output... /cvmfs/soft.computecanada.ca/gentoo/2020/bin/sed\nchecking for C++ compiler vendor... gnu\nconfigure: Seeking a C++ standard between \"2014\" and \"2017\"\nchecking whether mpicxx supports C++17 features by default... yes\nchecking for C++11 auto keyword support... yes\nchecking for C++11 range-based for loop support... yes\nchecking for C++11 initializer list support... yes\nchecking for C++11 std::unique_ptr support... yes\nchecking for C++11 std::make_unique workaround support... yes\nchecking for C++11 std::tuple support... yes\nchecking for C++11 lambda support... yes\nchecking for C++11 fixed type enumeration support... yes\nchecking for C++11 fixed type enumeration forward declaration support... yes\nchecking for C++11 override keyword support... yes\nchecking for C++11 move constructor support... yes\nchecking for C++11 deleted functions support... yes\nchecking for C++11 defaulted functions support... yes\nchecking for C++11 nullptr support... yes\nchecking for C++11 'final' keyword support... yes\nchecking for C++11 decltype support... yes\nchecking for C++11 std::begin/end support for arrays... yes\nchecking for C++11 std container erase() functions returning iterators... yes\nchecking for C++11 std container emplace() functions... yes\nchecking for C++11 std::iota algorithm... yes\nchecking for C++11 std::vector::data() API... yes\nchecking for C++11 std::shared_ptr support... yes\nchecking for C++11 rvalue references support... yes\nchecking for C++11 std::to_string() support... yes\nchecking for C++11 constexpr support... yes\nchecking for C++11 variadic template support... yes\nchecking for C++11 alias declarations support... yes\nchecking for C++11 std::array... yes\nchecking for C++11 std::isnan... yes\nchecking for C++11 std::isinf... yes\nchecking for C++17 std::*::merge... yes\nconfigure: Found C++17 standard support\nchecking whether mpicxx supports C++14 features by default... yes\nconfigure: Found C++14 standard support\nchecking whether mpicxx supports C++11 features by default... yes\nconfigure: Found C++11 standard support\nconfigure: Using support for C++17 standard\n<<< Configuring libMesh with methods \"opt oprof devel dbg\" >>>\n<<< Compiler warnings are just warnings >>>\n<<< Disabling extra paranoid compiler warnings >>>\nchecking for C++14 std::make_unique support... yes\nchecking for C++11 std::regex support... yes\nchecking for C++11 <thread> support... yes\nchecking for C++11 <condition_variable> support... yes\nchecking for C++11 <type_traits> support... yes\nchecking for C++11 std::asinh support in <cmath>... yes\nchecking for C++11 std::acosh support in <cmath>... yes\nchecking for C++11 std::atanh support in <cmath>... yes\nchecking for C++11 std::asinh(complex) support in <complex>... yes\nchecking for C++11 std::acosh(complex) support in <complex>... yes\nchecking for C++11 std::atanh(complex) support in <complex>... yes\nchecking for C++11 std::erf support in <cmath>... yes\nchecking for C++17 fallthrough attribute support... yes, but disabled.\nchecking for __attribute__ ((fallthrough)) support... yes\nchecking how to print strings... printf\nchecking for a sed that does not truncate output... (cached) /cvmfs/soft.computecanada.ca/gentoo/2020/bin/sed\nchecking for grep that handles long lines and -e... /cvmfs/soft.computecanada.ca/gentoo/2020/bin/grep\nchecking for egrep... /cvmfs/soft.computecanada.ca/gentoo/2020/bin/grep -E\nchecking for fgrep... /cvmfs/soft.computecanada.ca/gentoo/2020/bin/grep -F\nchecking for ld used by mpicc... /cvmfs/soft.computecanada.ca/gentoo/2020/usr/bin/ld\nchecking if the linker (/cvmfs/soft.computecanada.ca/gentoo/2020/usr/bin/ld) is GNU ld... yes\nchecking for BSD- or MS-compatible name lister (nm)... /cvmfs/soft.computecanada.ca/gentoo/2020/usr/bin/nm -B\nchecking the name lister (/cvmfs/soft.computecanada.ca/gentoo/2020/usr/bin/nm -B) interface... BSD nm\nchecking whether ln -s works... yes\nchecking the maximum length of command line arguments... 1572864\nchecking how to convert x86_64-pc-linux-gnu file names to x86_64-pc-linux-gnu format... func_convert_file_noop\nchecking how to convert x86_64-pc-linux-gnu file names to toolchain format... func_convert_file_noop\nchecking for /cvmfs/soft.computecanada.ca/gentoo/2020/usr/bin/ld option to reload object files... -r\nchecking for objdump... objdump\nchecking how to recognize dependent libraries... pass_all\nchecking for dlltool... no\nchecking how to associate runtime and link libraries... printf %s\\n\nchecking for ar... ar\nchecking for archiver @FILE support... @\nchecking for strip... strip\nchecking for ranlib... ranlib\nchecking command to parse /cvmfs/soft.computecanada.ca/gentoo/2020/usr/bin/nm -B output from mpicc object... ok\nchecking for sysroot... no\nchecking for a working dd... /cvmfs/soft.computecanada.ca/gentoo/2020/bin/dd\nchecking how to truncate binary pipes... /cvmfs/soft.computecanada.ca/gentoo/2020/bin/dd bs=4096 count=1\nchecking for mt... no\nchecking if : is a manifest tool... no\nchecking how to run the C preprocessor... mpicc -E\nchecking for ANSI C header files... yes\nchecking for sys/types.h... yes\nchecking for sys/stat.h... yes\nchecking for stdlib.h... yes\nchecking for string.h... yes\nchecking for memory.h... yes\nchecking for strings.h... yes\nchecking for inttypes.h... yes\nchecking for stdint.h... yes\nchecking for unistd.h... yes\nchecking for dlfcn.h... yes\nchecking for objdir... .libs\nchecking if mpicc supports -fno-rtti -fno-exceptions... no\nchecking for mpicc option to produce PIC... -fPIC -DPIC\nchecking if mpicc PIC flag -fPIC -DPIC works... yes\nchecking if mpicc static flag -static works... no\nchecking if mpicc supports -c -o file.o... yes\nchecking if mpicc supports -c -o file.o... (cached) yes\nchecking whether the mpicc linker (/cvmfs/soft.computecanada.ca/gentoo/2020/usr/bin/ld -m elf_x86_64) supports shared libraries... yes\nchecking whether -lc should be explicitly linked in... no\nchecking dynamic linker characteristics... GNU/Linux ld.so\nchecking how to hardcode library paths into programs... immediate\nchecking whether stripping libraries is possible... yes\nchecking if libtool supports shared libraries... yes\nchecking whether to build shared libraries... yes\nchecking whether to build static libraries... no\nchecking how to run the C++ preprocessor... mpicxx -E\nchecking for ld used by mpicxx... /cvmfs/soft.computecanada.ca/gentoo/2020/usr/bin/ld -m elf_x86_64\nchecking if the linker (/cvmfs/soft.computecanada.ca/gentoo/2020/usr/bin/ld -m elf_x86_64) is GNU ld... yes\nchecking whether the mpicxx linker (/cvmfs/soft.computecanada.ca/gentoo/2020/usr/bin/ld -m elf_x86_64) supports shared libraries... yes\nchecking for mpicxx option to produce PIC... -fPIC -DPIC\nchecking if mpicxx PIC flag -fPIC -DPIC works... yes\nchecking if mpicxx static flag -static works... no\nchecking if mpicxx supports -c -o file.o... yes\nchecking if mpicxx supports -c -o file.o... (cached) yes\nchecking whether the mpicxx linker (/cvmfs/soft.computecanada.ca/gentoo/2020/usr/bin/ld -m elf_x86_64) supports shared libraries... yes\nchecking dynamic linker characteristics... (cached) GNU/Linux ld.so\nchecking how to hardcode library paths into programs... immediate\nchecking if libtool supports shared libraries... yes\nchecking whether to build shared libraries... yes\nchecking whether to build static libraries... no\nchecking for mpif77 option to produce PIC... -fPIC\nchecking if mpif77 PIC flag -fPIC works... yes\nchecking if mpif77 static flag -static works... no\nchecking if mpif77 supports -c -o file.o... yes\nchecking if mpif77 supports -c -o file.o... (cached) yes\nchecking whether the mpif77 linker (/cvmfs/soft.computecanada.ca/gentoo/2020/usr/bin/ld -m elf_x86_64) supports shared libraries... yes\nchecking dynamic linker characteristics... (cached) GNU/Linux ld.so\nchecking how to hardcode library paths into programs... immediate\nchecking if libtool supports shared libraries... yes\nchecking whether to build shared libraries... yes\nchecking whether to build static libraries... no\nchecking for mpif90 option to produce PIC... -fPIC\nchecking if mpif90 PIC flag -fPIC works... yes\nchecking if mpif90 static flag -static works... no\nchecking if mpif90 supports -c -o file.o... yes\nchecking if mpif90 supports -c -o file.o... (cached) yes\nchecking whether the mpif90 linker (/cvmfs/soft.computecanada.ca/gentoo/2020/usr/bin/ld -m elf_x86_64) supports shared libraries... yes\nchecking dynamic linker characteristics... (cached) GNU/Linux ld.so\nchecking how to hardcode library paths into programs... immediate\nchecking Major version... 1\nchecking Minor version... 8\nchecking Point version... 0-pre\nchecking whether ln -s works... yes\nchecking for a sed that does not truncate output... (cached) /cvmfs/soft.computecanada.ca/gentoo/2020/bin/sed\nchecking for pkg-config... /cvmfs/soft.computecanada.ca/gentoo/2020/usr/bin/pkg-config\nchecking whether the compiler implements namespaces... yes\n---------------------------------------------\n------- Configuring compiler features -------\n---------------------------------------------\n<<< Default floating point is double precision (double) >>>\nchecking for C/C++ restrict keyword... __restrict\nchecking pwd.h usability... yes\nchecking pwd.h presence... yes\nchecking for pwd.h... yes\n<<< Configuring library with getpwuid >>>\n<<< Configuring library with exception throwing support >>>\n<<< Configuring library with compile timestamps >>>\nchecking size of short int... 2\nchecking size of int... 4\nchecking size of unsigned int... 4\nchecking size of size_t... 8\nchecking size of long int... 8\nchecking size of float... 4\nchecking size of double... 8\nchecking size of void *... 8\nchecking size of function_pointer... 8\nchecking whether the compiler supports Run-Time Type Identification... yes\nchecking getopt.h usability... yes\nchecking getopt.h presence... yes\nchecking for getopt.h... yes\nchecking sys/time.h usability... yes\nchecking sys/time.h presence... yes\nchecking for sys/time.h... yes\nchecking process.h usability... no\nchecking process.h presence... no\nchecking for process.h... no\nchecking csignal usability... yes\nchecking csignal presence... yes\nchecking for csignal... yes\nchecking sys/resource.h usability... yes\nchecking sys/resource.h presence... yes\nchecking for sys/resource.h... yes\nchecking whether the compiler has locale... yes\nchecking whether the compiler has stringstream... yes\nchecking fenv.h usability... yes\nchecking fenv.h presence... yes\nchecking for fenv.h... yes\nchecking xmmintrin.h usability... yes\nchecking xmmintrin.h presence... yes\nchecking for xmmintrin.h... yes\nchecking whether sigaction is declared... yes\nchecking for mkdir with two arguments... yes\nchecking direct.h usability... no\nchecking direct.h presence... no\nchecking for direct.h... no\nchecking whether _mkdir is declared... no\nchecking for mkstemp... yes\nchecking for gettimeofday... yes\nchecking sys/utsname.h usability... yes\nchecking sys/utsname.h presence... yes\nchecking for sys/utsname.h... yes\nchecking whether the compiler supports std::unordered_multimap... yes\nchecking whether the compiler supports std::unordered_map... yes\nchecking whether the compiler supports std::unordered_multiset... yes\nchecking whether the compiler supports std::unordered_set... yes\nchecking whether the compiler supports std::hash... yes\nchecking for library containing dlopen... -ldl\nchecking whether the c++ compiler supports dlopen/dlsym/dlclose... yes\nchecking whether the compiler supports GCC C++ ABI name demangling... yes\nchecking whether the c++ compiler supports glibc backtrace... yes\nchecking if errno.h can be wrapped in namespace... yes\n---------------------------------------------\n----- Done configuring compiler features ----\n---------------------------------------------\n---------------------------------------------\n----- Configuring core library features -----\n---------------------------------------------\nconfiguring gdb command... \"no\"\n>>> INFO: Disabling library warnings <<<\n>>> Configuring library without warnings <<<\n<<< Configuring library with deprecated code support >>>\n../configure: line 46713: irrelevant=yes: command not found\n<<< Configuring library to require ``include \"libmesh/etc.h\"'' style >>>\n<<< Configuring library to keep names in libMesh namespace >>>\nconfiguring size of boundary_id... 2\nconfiguring size of dof_id... 4\nconfiguring size of processor_id... 4\nconfiguring size of subdomain_id... 2\n<<< Configuring library with unique id support >>>\nconfiguring size of unique_id... 8\n<<< Configuring library with AMR support >>>\n<<< Configuring library with variational smoother support >>>\n<<< Configuring library with periodic BC support >>>\n<<< Configuring library with Dirichlet constraint support >>>\n<<< --enable-parmesh is deprecated; use --enable-distmesh >>>\nconfiguring size of mapvector chunks: 1\n<<< Configuring library to use ghosted local vectors >>>\n<<< Configuring library to store node valence >>>\n<<< Configuring library with higher order p-FEM shapes >>>\n<<< Configuring library with second derivatives >>>\n<<< Configuring library with real number support >>>\n<<< Configuring library with reference counting support >>>\n<<< Configuring library example suite support >>>\n---------------------------------------------\n-- Done configuring core library features ---\n---------------------------------------------\n---------------------------------------------\n----- Configuring for optional packages -----\n---------------------------------------------\nchecking for built-in XDR support... no\nchecking for XDR support in /usr/include/tirpc... no\nconfigure: error: *** XDR was not found, but --enable-xdr-required was specified.\nRunning make -j 1...\nmake: *** No targets specified and no makefile found.  Stop.\n(moose) [galibubc@cedar1 moose]$ \n\n\nI checked previous discussion threads on how to install xdr on HPC but couldn't understand it correctly. Can you suggest on this? Thanks.",
                          "url": "https://github.com/idaholab/moose/discussions/22617#discussioncomment-4119077",
                          "updatedAt": "2022-11-11T16:32:39Z",
                          "publishedAt": "2022-11-11T16:32:39Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "Hello\nYou're going to have to install libtirpc-devel.\nIt s likely easier to ask the cluster administrators to do it\nGuillaume",
                          "url": "https://github.com/idaholab/moose/discussions/22617#discussioncomment-4119101",
                          "updatedAt": "2022-11-11T16:36:29Z",
                          "publishedAt": "2022-11-11T16:36:29Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "MusannaGalib"
                          },
                          "bodyText": "Hello Guillaume,\nThanks. I will contact them then!",
                          "url": "https://github.com/idaholab/moose/discussions/22617#discussioncomment-4119150",
                          "updatedAt": "2022-11-11T16:43:27Z",
                          "publishedAt": "2022-11-11T16:43:26Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "hypre AMG does not converge in thermomechanical coupling problem",
          "author": {
            "login": "js-jixu"
          },
          "bodyText": "Hi, experts.\nI want to compute some large scale thermomechanical coupling problem, with about millions of degrees of freedom. Obviously, it is not suitable to use LU, because it requires too much computing resources. So I want to try other preconditioners. After reading about the Hypre/BoomerAMG on the MOOSE website, I figured it might be appropriate.\nThere is a thermomechanical coupling model that can be solved well with lu. This model is not large, with only 60,000 degrees of freedom. Here is its Executioner block:\n[Executioner]\n  type = Transient\n  dt = 1\n  end_time = 50\n  steady_state_detection = true\n\n  solve_type = 'PJFNK'\n  petsc_options = '-snes_converged_reason -ksp_converged_reason -snes_linesearch_monitor'\n  petsc_options_iname = '-pc_type -pc_factor_shift_type'\n  petsc_options_value = 'lu       NONZERO'\n  line_search = 'none'\n\n  nl_rel_tol = 1e-8\n  nl_abs_tol = 1e-8\n  nl_max_its = 30\n  l_max_its = 100\n  automatic_scaling = true\n  compute_scaling_once = false\n  off_diagonals_in_auto_scaling = true\n[]\n\nBut when I changed the preconditioner to hypre, it was difficult to converge;\n  petsc_options_iname = '-pc_type -pc_hypre_type -pc_hypre_boomeramg_strong_threshold -pc_hypre_boomeramg_agg_nl -pc_hypre_boomeramg_agg_num_paths -pc_hypre_boomeramg_max_levels -pc_hypre_boomeramg_coarsen_type -pc_hypre_boomeramg_interp_type -pc_hypre_boomeramg_P_max -pc_hypre_boomeramg_truncfactor'\n  petsc_options_value = 'hypre    boomeramg      0.7                                  4                          5                                  25                            HMIS                             ext+i                           2                         0.3                            '\n\nI want to know where should I improve it?\nBesides, I've found two simple spelling mistakes on the website.",
          "url": "https://github.com/idaholab/moose/discussions/22468",
          "updatedAt": "2022-12-06T14:25:10Z",
          "publishedAt": "2022-10-22T15:51:31Z",
          "category": {
            "name": "Q&A General"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "GiudGiud"
                  },
                  "bodyText": "Hello\nI d start with something with less options active and with less truncation, higher cutoff thresholds, try to get good (fewer iterations) but more expensive (each iteration takes long) convergence .\nThen work from there to reduce costs.\nIs this only thermo mechanics? No fluids?\nGuillaume",
                  "url": "https://github.com/idaholab/moose/discussions/22468#discussioncomment-3941125",
                  "updatedAt": "2022-10-22T18:52:56Z",
                  "publishedAt": "2022-10-22T18:52:55Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "js-jixu"
                          },
                          "bodyText": "My problem also has fluids. Does hypre perform well in the INS problem?",
                          "url": "https://github.com/idaholab/moose/discussions/22468#discussioncomment-3941827",
                          "updatedAt": "2022-10-22T23:20:55Z",
                          "publishedAt": "2022-10-22T23:20:55Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "js-jixu"
                          },
                          "bodyText": "I reduced the number of options and lowered -pc_hypre_boomeramg_strong_threshold and -pc_hypre_boomeramg_truncfactor as much as possible to get better convergence:\n  petsc_options_iname = '-pc_type -pc_hypre_type -pc_hypre_boomeramg_strong_threshold -pc_hypre_boomeramg_interp_type -pc_hypre_boomeramg_truncfactor'\n  petsc_options_value = 'hypre    boomeramg      0                                    ext+i                           0.1                            '\n\nBut it doesn't work. My problem is a thermal-mechanical-fluid coupling problem. There is a heating rod in the middle with fluid flowing around it. And the heating rod will expand as the temperature rises.\nI have two questions. The first is whether AMG is only suitable for solving solid mechanics problems, not for solving INS problems. Since I saw @friedmud and Jed Brown in the moose-users group saying that BoomerAMG was originally designed to solve the steady state scalar problem, convergence was difficult when I coupled the fluid flow.\nThe second is whether there is a combination of options with the strongest convergence in AMG's options. This combination does not consider the computational resources consumed, as long as it can converge. I even set the -pc_hypre_boomeramg_strong_threshold to 0, but it still doesn't converge:\nTime Step 1, time = 0.25, dt = 0.25\n\nPerforming automatic scaling calculation\n\n 0 Nonlinear |R| = 4.647580e+03\n    |residual|_2 of individual variables:\n                   velocity: 4647.58\n                   p:        9.10215e-06\n                   Tf:       4.78304e-13\n                   Ts:       0.327606\n                   disp_x:   5.46689e-19\n                   disp_y:   5.46689e-19\n                   disp_z:   2.5208e-20\n      0 Linear |R| = 4.647580e+03\n      1 Linear |R| = 4.647580e+03\n      2 Linear |R| = 4.647580e+03\n      3 Linear |R| = 4.647580e+03\n      4 Linear |R| = 4.647580e+03\n      5 Linear |R| = 4.647580e+03\n      6 Linear |R| = 4.647580e+03\n      7 Linear |R| = 4.647580e+03\n      8 Linear |R| = 4.647580e+03\n      9 Linear |R| = 4.647580e+03\n     10 Linear |R| = 4.647580e+03\n     11 Linear |R| = 4.647580e+03\n     12 Linear |R| = 4.647580e+03\n     13 Linear |R| = 4.647580e+03\n     14 Linear |R| = 4.647580e+03\n     15 Linear |R| = 4.647580e+03\n     16 Linear |R| = 4.647580e+03\n     17 Linear |R| = 4.647580e+03\n     18 Linear |R| = 4.647580e+03\n     19 Linear |R| = 4.647580e+03\n     20 Linear |R| = 4.647580e+03\n     21 Linear |R| = 4.647580e+03\n     22 Linear |R| = 4.647580e+03\n     23 Linear |R| = 4.647580e+03\n     24 Linear |R| = 4.647580e+03\n     25 Linear |R| = 4.647580e+03\n     26 Linear |R| = 4.647580e+03\n     27 Linear |R| = 4.647580e+03\n     28 Linear |R| = 4.647580e+03\n     29 Linear |R| = 4.647580e+03\n     30 Linear |R| = 4.647580e+03\n     31 Linear |R| = 4.647580e+03\n     32 Linear |R| = 4.647580e+03\n     33 Linear |R| = 4.647580e+03\n     34 Linear |R| = 4.647580e+03\n     35 Linear |R| = 4.647580e+03\n     36 Linear |R| = 4.647580e+03\n     37 Linear |R| = 4.647580e+03\n     38 Linear |R| = 4.647580e+03\n     39 Linear |R| = 4.647580e+03\n     40 Linear |R| = 4.647580e+03\n     41 Linear |R| = 4.647580e+03\n     42 Linear |R| = 4.647580e+03\n     43 Linear |R| = 4.647580e+03\n     44 Linear |R| = 4.647580e+03\n     45 Linear |R| = 4.647580e+03\n     46 Linear |R| = 4.647580e+03\n     47 Linear |R| = 4.647580e+03\n     48 Linear |R| = 4.647580e+03\n     49 Linear |R| = 4.647580e+03\n     50 Linear |R| = 4.647580e+03\n     51 Linear |R| = 4.647580e+03\n     52 Linear |R| = 4.647580e+03\n     53 Linear |R| = 4.647580e+03\n     54 Linear |R| = 4.647580e+03\n     55 Linear |R| = 4.647580e+03\n     56 Linear |R| = 4.647580e+03\n     57 Linear |R| = 4.647580e+03\n     58 Linear |R| = 4.647580e+03\n     59 Linear |R| = 4.647580e+03\n     60 Linear |R| = 4.647580e+03\n     61 Linear |R| = 4.647580e+03\n     62 Linear |R| = 4.647580e+03\n     63 Linear |R| = 4.647580e+03\n     64 Linear |R| = 4.647580e+03\n     65 Linear |R| = 4.647580e+03\n     66 Linear |R| = 4.647580e+03\n     67 Linear |R| = 4.647580e+03\n     68 Linear |R| = 4.647580e+03\n     69 Linear |R| = 4.647580e+03\n     70 Linear |R| = 4.647580e+03\n     71 Linear |R| = 4.647580e+03\n     72 Linear |R| = 4.647580e+03\n     73 Linear |R| = 4.647580e+03\n     74 Linear |R| = 4.647580e+03\n     75 Linear |R| = 4.647580e+03\n     76 Linear |R| = 4.647580e+03\n     77 Linear |R| = 4.647580e+03\n     78 Linear |R| = 4.647580e+03\n     79 Linear |R| = 4.647580e+03\n     80 Linear |R| = 4.647580e+03\n     81 Linear |R| = 4.647580e+03\n     82 Linear |R| = 4.647580e+03\n     83 Linear |R| = 4.647580e+03\n     84 Linear |R| = 4.647580e+03\n     85 Linear |R| = 4.647580e+03\n     86 Linear |R| = 4.647580e+03\n     87 Linear |R| = 4.647580e+03\n     88 Linear |R| = 4.647580e+03\n     89 Linear |R| = 4.647580e+03\n     90 Linear |R| = 4.647580e+03\n     91 Linear |R| = 4.647580e+03\n     92 Linear |R| = 4.647580e+03\n     93 Linear |R| = 4.647580e+03\n     94 Linear |R| = 4.647580e+03\n     95 Linear |R| = 4.647580e+03\n     96 Linear |R| = 4.647580e+03\n     97 Linear |R| = 4.647580e+03\n     98 Linear |R| = 4.647580e+03\n     99 Linear |R| = 4.647580e+03\n    100 Linear |R| = 4.647580e+03\n  Linear solve did not converge due to DIVERGED_ITS iterations 100",
                          "url": "https://github.com/idaholab/moose/discussions/22468#discussioncomment-3942250",
                          "updatedAt": "2022-10-23T03:26:07Z",
                          "publishedAt": "2022-10-23T03:26:07Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "Yeah I don\u2019t think that will work for fluids. You should look into field splits in moose. This will allow you to use different preconditionning for each physics",
                          "url": "https://github.com/idaholab/moose/discussions/22468#discussioncomment-3942407",
                          "updatedAt": "2022-10-23T05:05:52Z",
                          "publishedAt": "2022-10-23T05:05:52Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "js-jixu"
                          },
                          "bodyText": "Do you mean that I should use AMG for thermal-mechanical field and use other preconditioner for fluid field? Is there any case about field splits in MOOSE? I thought that MOOSE can only use one preconditioner in the Executioner block.",
                          "url": "https://github.com/idaholab/moose/discussions/22468#discussioncomment-3942421",
                          "updatedAt": "2022-10-23T05:15:27Z",
                          "publishedAt": "2022-10-23T05:15:26Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "AMG for thermomechanical, and maybe LU for fluids for now, or a nested field split on pressure and velocity",
                          "url": "https://github.com/idaholab/moose/discussions/22468#discussioncomment-3942424",
                          "updatedAt": "2022-10-23T05:17:53Z",
                          "publishedAt": "2022-10-23T05:17:53Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "js-jixu"
                          },
                          "bodyText": "I'll try this method as soon as possibile. Let's see if it solves the problem.",
                          "url": "https://github.com/idaholab/moose/discussions/22468#discussioncomment-3942475",
                          "updatedAt": "2022-10-23T13:54:47Z",
                          "publishedAt": "2022-10-23T05:49:55Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "https://mooseframework.inl.gov/source/preconditioners/FieldSplitPreconditioner.html",
                          "url": "https://github.com/idaholab/moose/discussions/22468#discussioncomment-3944126",
                          "updatedAt": "2022-10-23T14:50:23Z",
                          "publishedAt": "2022-10-23T14:50:23Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "js-jixu"
                          },
                          "bodyText": "I have tried various preconditioners. But since I don't know much about the math behind these preconditioners, I'm trying blindly. I've tried [Preconditioning] with both FSP and SMP, and here are some of what I've tried:\n# [Preconditioning]\n#   active = 'FSP'\n#   [FSP]\n#     type = FSP\n#     topsplit = 'up'\n#     [up]\n#       splitting = 'u p'\n\n#       splitting_type = additive\n\n#       # splitting_type = schur\n#       # petsc_options_iname = '-pc_fieldsplit_schur_fact_type  -pc_fieldsplit_schur_precondition'\n#       # petsc_options_value = 'full                            selfp'\n#     []\n#     [u]\n#       vars = 'velocity p'\n#       # petsc_options_iname = '-pc_type -sub_pc_type -sub_pc_factor_levels -ksp_gmres_restart'\n#       # petsc_options_value = 'asm      ilu          4                     200               '\n#       petsc_options_iname = '-pc_type -pc_factor_shift_type'\n#       petsc_options_value = 'lu       NONZERO'\n#     []\n#     [p]\n#       vars = 'disp_x disp_y disp_z Ts Tf'\n#       petsc_options_iname = '-pc_type -pc_hypre_type -pc_hypre_boomeramg_strong_threshold -pc_hypre_boomeramg_interp_type -pc_hypre_boomeramg_truncfactor'\n#       petsc_options_value = 'hypre    boomeramg      0.7                                    ext+i                           0.2                            '\n#     []\n#   []\n# []\n\n# [Preconditioning]\n#   [fsp]\n#     type = FSP\n#     topsplit = 'up'\n#     [up]\n#       splitting = 'u p'\n#       splitting_type = schur\n#       petsc_options_iname = '-pc_fieldsplit_schur_fact_type  -pc_fieldsplit_schur_precondition'\n#       petsc_options_value = 'full selfp'\n#     []\n#     [u]\n#       vars = 'velocity'\n#       petsc_options_iname = '-pc_type -ksp_type'\n#       petsc_options_value = '     hypre gmres'\n#     []\n#     [p]\n#       vars = 'p Ts Tf disp_x disp_y disp_z'\n#       petsc_options_iname = '-pc_type -ksp_type'\n#       petsc_options_value = '   jacobi    gmres'\n#     []\n#   []\n# []\n\n# [Preconditioning]\n#   [FSP]\n#     type = FSP\n#     petsc_options_iname = '-snes_type -ksp_type -ksp_rtol -ksp_atol -ksp_max_it -snes_atol -snes_rtol -snes_max_it -snes_max_funcs'\n#     petsc_options_value = 'newtonls     fgmres     1e-2     1e-15       200       1e-10        1e-15       200           100000'\n#     topsplit = 'uv'\n#     [uv]\n#       petsc_options_iname = '-pc_fieldsplit_schur_fact_type -pc_fieldsplit_schur_precondition'\n#       petsc_options_value = 'upper selfp'\n#       splitting = 'u v'\n#       splitting_type = schur\n#     []\n#     [u]\n#       vars = 'velocity'\n#       petsc_options_iname = '-pc_type -ksp_type -pc_hypre_type'\n#       petsc_options_value = '  hypre    preonly     boomeramg '\n#     []\n#     [v]\n#       vars = 'p Ts Tf disp_x disp_y disp_z'\n#       petsc_options_iname = '-pc_type -ksp_type -sub_pc_type -sub_pc_factor_levels'\n#       petsc_options_value = '  jacobi  preonly        ilu            3'\n#     []\n#   []\n# []\n\n# [Preconditioning]\n#   [SMP]\n#     type = SMP\n#     full = true\n#     solve_type = 'NEWTON'\n#   []\n# []\n\n[Executioner]\n  type = Transient\n  dt = 0.25\n  end_time = 0.5\n  steady_state_detection = true\n\n  solve_type = 'PJFNK'\n  petsc_options = '-snes_converged_reason -ksp_converged_reason -snes_linesearch_monitor'\n\n  # petsc_options_iname = '-pc_type -pc_factor_shift_type'\n  # petsc_options_value = 'lu       NONZERO'\n\n  # petsc_options_iname = '-pc_type -sub_pc_type -sub_pc_factor_levels -ksp_gmres_restart'\n  # petsc_options_value = 'asm      ilu          3                     200               '\n\n  # petsc_options_iname = '-pc_type -sub_pc_type'\n  # petsc_options_value = 'asm      lu          '\n\n  # petsc_options_iname = '-pc_type -sub_pc_type -pc_hypre_type'\n  # petsc_options_value = 'asm      hypre        boomeramg     '\n\n  # petsc_options_iname = '-pc_type -pc_hypre_type'\n  # petsc_options_value = 'hypre euclid'\n\n  # petsc_options_iname = '-pc_type -pc_factor_mat_solver_package'\n  # petsc_options_value = 'lu       mumps'\n\n  # petsc_options_iname = '-pc_type -pc_hypre_type -pc_hypre_boomeramg_strong_threshold -pc_hypre_boomeramg_interp_type -pc_hypre_boomeramg_truncfactor'\n  # petsc_options_value = 'hypre    boomeramg      0.7                                    ext+i                           0.2                            '\n\n  # petsc_options_iname = '-pc_type -pc_hypre_type -pc_hypre_boomeramg_strong_threshold -pc_hypre_boomeramg_agg_nl -pc_hypre_boomeramg_agg_num_paths -pc_hypre_boomeramg_max_levels -pc_hypre_boomeramg_coarsen_type -pc_hypre_boomeramg_interp_type -pc_hypre_boomeramg_P_max -pc_hypre_boomeramg_truncfactor'\n  # petsc_options_value = 'hypre    boomeramg      0.7                                  3                          4                                  25                            HMIS                             ext+i                           2                         0.3                            '\n\n  line_search = 'none'\n\n  nl_rel_tol = 1e-8\n  nl_abs_tol = 1e-8\n\n  nl_max_its = 30\n  l_max_its = 100\n  automatic_scaling = true\n  compute_scaling_once = false\n  off_diagonals_in_auto_scaling = true\n[]\n\nThese preconditioners look different, but they have one thing in common - the convergence is far less than -pc_type lu. \ud83e\udd21\nThat's all I understand about preconditioner right now. lu is the most convergent preconditioner because it is a direct solution method. But I saw on the website that LU is serial only. So is it that when I set -pc_type lu directly in the Executioner block, even though I use mpiexec -n 8 for the calculation, the computer is solving the problem serially. If I want to solve the problem with LU in parallel, I have to set -pc_type asm -sub_pc_type lu? Then I tried -pc_type asm -sub_pc_type lu, but the convergence is far worse than -pc_type lu, can you tell me what is the reason?\nFrom reading the moose-users group, the petsc manual and the information on the website I know that ilu is an incomplete lu, it has worse convergence than lu but is more memory efficient. As for the hypre boomramg, I tried a few settings, but none of them converged. Can you give me some advice on what to try next?",
                          "url": "https://github.com/idaholab/moose/discussions/22468#discussioncomment-3951770",
                          "updatedAt": "2022-10-24T14:39:47Z",
                          "publishedAt": "2022-10-24T14:39:15Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "A few things you could try:\n\nuse different solver packages for LU. Some perform better than others, some are parallel.\ntry a segregated physics setup using MultiApps. Solve the fluids and the thermo-mechanical problem in two different apps and use transfers to couple them",
                          "url": "https://github.com/idaholab/moose/discussions/22468#discussioncomment-3951994",
                          "updatedAt": "2022-10-24T14:55:58Z",
                          "publishedAt": "2022-10-24T14:55:57Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "js-jixu"
                          },
                          "bodyText": "use different solver packages for LU. Some perform better than others, some are parallel.\n\nSuch as mumps for LU? Is there any other solver package for LU?",
                          "url": "https://github.com/idaholab/moose/discussions/22468#discussioncomment-3952047",
                          "updatedAt": "2022-10-24T15:00:37Z",
                          "publishedAt": "2022-10-24T15:00:37Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      }
    ]
  }
}