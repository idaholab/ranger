{
  "discussions": {
    "pageInfo": {
      "hasNextPage": true,
      "endCursor": "Y3Vyc29yOnYyOpK5MjAyMS0xMi0xNVQxNDoyMjowMS0wNzowMM4AOSAR"
    },
    "edges": [
      {
        "node": {
          "title": "Modelling of Plastic hardening (with necking)",
          "author": {
            "login": "abarun22"
          },
          "bodyText": "Dear Wen,\nFurther to our earlier discussions at https://groups.google.com/g/moose-users/c/cWcA44gI9hQ/m/MgGaJPJjBAAJ\nI would like to update that the new plasticity model built with PieceWise hardening function (PWH) gives reasonably asseptable results. Please see the attached slides. You could now see how realistic the plastic deformation is localizing heavily near the left symmetric face. The earlier problem with PWH has been bypassed by disallowing certain spurious states just after the yield. The results are looking good (with experiments and Ansys) at small strains, however showing a strange behaviour afterwards. There seems to be a stress drop, but with a linear variation, which looks pretty odd. Conversion to true Stress/Pl.Strain input hardening parameters at first place does not produce agreeable results. I would be extremely pleased if you could let me know thoughts on this behaviour.\nPS. I am yet to perform a comparison with ANSYS at present due to some issues. Will let you know as soon as it is done.\nMoose_FEA_UG_16Nov2020.pptx\nKind regards,\nArun",
          "url": "https://github.com/idaholab/moose/discussions/16199",
          "updatedAt": "2022-06-10T14:44:53Z",
          "publishedAt": "2020-11-16T12:18:42Z",
          "category": {
            "name": "Q&A Modules: Solid mechanics"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "GiudGiud"
                  },
                  "bodyText": "@jiangwen84 @abarun22 can I close this? I imagine you guys had other occasions to talk about this over the last year",
                  "url": "https://github.com/idaholab/moose/discussions/16199#discussioncomment-1828709",
                  "updatedAt": "2022-06-10T14:44:54Z",
                  "publishedAt": "2021-12-16T22:07:18Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "abarun22"
                          },
                          "bodyText": "Yes please, this can be considered closed now.",
                          "url": "https://github.com/idaholab/moose/discussions/16199#discussioncomment-1829302",
                          "updatedAt": "2022-06-10T14:44:54Z",
                          "publishedAt": "2021-12-16T23:14:36Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "methods for improving mesh quality",
          "author": {
            "login": "japresa"
          },
          "bodyText": "I'm currently creating a geometry for my code with trelis/cubit. However, I'm stuck and am unable to improve the mesh quality at the corners of my geometry. (Code won't run due to this)\nI've tried using the pillowing and general refinement methods at the geometry's side-surfaces & at the walls of the holes near the poor quality sections. However, any mesh-improvement methods I try seem to move the deformities elsewhere.\nAny tips on how to improve mesh quality?",
          "url": "https://github.com/idaholab/moose/discussions/19615",
          "updatedAt": "2021-12-20T01:56:33Z",
          "publishedAt": "2021-12-13T05:10:35Z",
          "category": {
            "name": "Q&A General"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "GiudGiud"
                  },
                  "bodyText": "Hello\nYou can use MOOSE to smooth the meshes.\nOnce your mesh is loaded by a FileMeshGenerator, then use a smooth mesh generator\nhttps://mooseframework.inl.gov/source/meshgenerators/SmoothMeshGenerator.html\nGuillaume",
                  "url": "https://github.com/idaholab/moose/discussions/19615#discussioncomment-1798809",
                  "updatedAt": "2021-12-13T19:53:34Z",
                  "publishedAt": "2021-12-13T14:59:43Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "japresa"
                          },
                          "bodyText": "Going to try this. If this doesn't work, are there any other methods you know of?",
                          "url": "https://github.com/idaholab/moose/discussions/19615#discussioncomment-1802535",
                          "updatedAt": "2021-12-14T02:18:23Z",
                          "publishedAt": "2021-12-14T02:18:23Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "if very few nodes (like 10 or so) are problematic, you can move them one by one with https://mooseframework.inl.gov/source/meshgenerators/MoveNodeGenerator.html\nFor a mesh like this one (array of cylinders in a hex lattice), you could probably re-generate it using the moose mesh generators in the Reactor module\nhttps://mooseframework.inl.gov/modules/reactor/index.html",
                          "url": "https://github.com/idaholab/moose/discussions/19615#discussioncomment-1828932",
                          "updatedAt": "2021-12-16T22:37:59Z",
                          "publishedAt": "2021-12-16T22:37:59Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "Error during ghosting....",
          "author": {
            "login": "makeclean"
          },
          "bodyText": "I have a large(ish) problem running, coupled thermo-mechanical problem running well. I added contact, and now when I run the problem it fails during re-initing during ghosting\nBuilding mesh ......                                                                       [  7.37 s]\nCaching mesh information                                                                   [  1.83 s]\nCaching mesh information                                                                   [  1.80 s]\nBuilding node to element map                                                               [  1.00 s]\nCaching mesh information .                                                                 [  2.01 s]\nCaching mesh information                                                                   [  1.85 s]\nInitializing equation system ................................                              [ 33.81 s]\nCaching mesh information .                                                                 [  2.12 s]\nCaching mesh information                                                                   [  1.94 s]\nCaching mesh information                                                                   [  1.91 s]\n\nFramework Information:\nMOOSE Version:           git commit 5a5d066cb8 on 2021-03-10\nLibMesh Version:         ed76100f41840c34c146dd0a7f1ff5410370b489\nPETSc Version:           3.14.2\nSLEPc Version:           3.14.0\nCurrent Time:            Mon Sep 27 21:16:00 2021\nExecutable Timestamp:    Thu Mar 11 16:12:36 2021\n\nParallelism:\n  Num Processors:          30\n  Num Threads:             56\n\nMesh: \n  Parallel Type:           distributed (pre-split)\n  Mesh Dimension:          3\n  Spatial Dimension:       3\n  Nodes:                   \n    Total:                 6758745\n    Local:                 210785\n  Elems:                   \n    Total:                 36069737\n    Local:                 1202637\n  Num Subdomains:          5\n  Num Partitions:          1\n  Partitioner:             parmetis\n\nNonlinear System:\n  Num DOFs:                27034980\n  Num Local DOFs:          843140\n  Variables:               { \"temp\" \"disp_x\" \"disp_y\" \"disp_z\" } \n  Finite Element Types:    \"LAGRANGE\" \n  Approximation Orders:    \"FIRST\" \n\nAuxiliary System:\n  Num DOFs:                1050505106\n  Num Local DOFs:          34938546\n  Variables:               { \"temp_in_C\" \"radiation_flux\" } { \"stress_xx_nodal\" \"strain_xx_nodal\" \"stress_yy_nodal\" \n                             \"strain_yy_nodal\" \"stress_zz_nodal\" \"strain_zz_nodal\" \"vonmises_nodal\" } { \"penetration\" \n                             \"contact_pressure\" \"nodal_area_leftright\" \"paired_temp\" } \n  Finite Element Types:    \"LAGRANGE\" \"MONOMIAL\" \"LAGRANGE\" \n  Approximation Orders:    \"FIRST\" \"FIRST\" \"FIRST\" \n\nExecution Information:\n  Executioner:             Transient\n  TimeStepper:             ConstantDT\n  Solver Mode:             NEWTON\n  MOOSE Preconditioner:    SMP (auto)\n\nProjecting initial condition ...                                                           [  4.41 s]\nComputing initial stateful property values ..........................                      [ 27.87 s]\nCopying soultions back .                                                                   [  2.34 s]\nUpdating geometric search objects                                                          [  1.00 s]\nReiniting because of ghosting ............................................................\n..........................................................................................\n..........................................................................................\n..........................................................................................\n.......................................................--------------------------------------------------------------------------\nPrimary job  terminated normally, but 1 process returned\na non-zero exit code. Per user-direction, the job has been aborted.\n--------------------------------------------------------------------------\n--------------------------------------------------------------------------\nWARNING: Open MPI failed to TCP connect to a peer MPI process.  This\nshould not happen.\n\nYour Open MPI job may now fail.\n\n  Local host: cpu-p-31\n  PID:        184555\n  Message:    connect() to 10.43.161.29:1024 failed\n  Error:      Operation now in progress (115)\n--------------------------------------------------------------------------\n--------------------------------------------------------------------------\nAn MPI communication peer process has unexpectedly disconnected.  This\nusually indicates a failure in the peer process (e.g., a crash or\notherwise exiting without calling MPI_FINALIZE first).\n\nAlthough this local MPI process will likely now behave unpredictably\n(it may even hang or crash), the root cause of this problem is the\nfailure of the peer -- that is what you need to investigate.  For\nexample, there may be a core file that you can examine.  More\ngenerally: such peer hangups are frequently caused by application bugs\nor other external events.\n\n  Local host: cpu-p-8\n  Local PID:  170943\n  Peer host:  cpu-p-37\n--------------------------------------------------------------------------\n.--------------------------------------------------------------------------\nmpirun noticed that process rank 20 with PID 210143 on node cpu-p-28 exited on signal 11 (Segmentation fault).\n--------------------------------------------------------------------------\n[cpu-p-8:170901] 3 more processes have sent help message help-mpi-btl-tcp.txt / client connect fail\n[cpu-p-8:170901] Set MCA parameter \"orte_base_help_aggregate\" to 0 to see all help / error messages\n[cpu-p-8:170901] 3 more processes have sent help message help-mpi-btl-tcp.txt / peer hung up\nslurmstepd: error: task_p_post_term: rmdir(/sys/fs/cgroup/cpuset/slurm46950214/slurm46950214.4294967294_0) failed Device or resource busy\n\nIf it helps/matters, the mesh is pre-split first, this happens whether or not I used MPI or threads. I've tried adding more memory per CPU and a range of other things, any and all suggestions appreciated :)",
          "url": "https://github.com/idaholab/moose/discussions/18941",
          "updatedAt": "2022-08-03T19:55:24Z",
          "publishedAt": "2021-09-27T20:41:49Z",
          "category": {
            "name": "Q&A General"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "GiudGiud"
                  },
                  "bodyText": "I would first run it in devel mode to see that this code doesn't hit any asserts, which check for things that are not implemented or that are not supposed to happen.\nThen I would run it in debug mode and get a backtrace to see where the crash came from\nI would also update MOOSE to use the new perf_graph live print and get more info on memory consumption.\nMemory might really be the issue, with 27M dofs per rank. Have you checked that are not running out? (even just using top)\nThe 56 threads might be too much for some modules. Most of MOOSE will be happier with no threads and full MPI solves (though it should not crash). If the mesh is distributed and pre-split then the memory consumption will be the same as for threads.",
                  "url": "https://github.com/idaholab/moose/discussions/18941#discussioncomment-1392806",
                  "updatedAt": "2022-08-03T19:55:25Z",
                  "publishedAt": "2021-09-27T21:28:27Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "makeclean"
                          },
                          "bodyText": "I'm not sure it isn't memory, but merely adding contact would have to add an awful lot more memory, seeing as it runs fine without. I'll go through the stages you suggest. I've run my other calcs with pure MPI, but just added threads to see if it majorly impacted memory usage",
                          "url": "https://github.com/idaholab/moose/discussions/18941#discussioncomment-1392922",
                          "updatedAt": "2022-08-03T19:55:26Z",
                          "publishedAt": "2021-09-27T21:59:12Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "makeclean"
                          },
                          "bodyText": "Ok, Ive rebuilt, FYI this it the regular (not dbg or devel) run but just to show progress, today hopefully I'll get a debug or devel run working\nSetting Up\n  Finished Deleting Remote Elements                                             \n         [  9.01 s] [    5 MB]\n  Initializing\n    Updating Because Mesh Changed\n      Updating Mesh...                                                          \n         [ 22.66 s] [   25 MB]\n    Finished Updating Because Mesh Changed                                      \n         [ 22.68 s] [   29 MB]\n\n      Updating Mesh.....                                                        \n         [ 42.37 s] [   22 MB]\n    Finished Updating Because Mesh Changed                                               [ 42.39 s] [   26 MB]\n    Initializing Equation Systems...........                                             [ 71.95 s] [  152 MB]\n    Initializing Displaced Equation System............                                   [ 70.56 s] [   86 MB]\n...                                                                   [ 25.01 s] [    7 MB]\n    Finished Updating Because Mesh Changed                                               [ 25.02 s] [    7 MB]\n  Finished Initializing                                                                  [233.13 s] [  397 MB]\nFinished Setting Up                                                                      [244.08 s] [  461 MB]\nFramework Information:\nMOOSE Version:           git commit b5a350860f on 2021-09-28\nLibMesh Version:         aebb5a5c0e1f6d8cf523a720e19f70a6d17c0236\nPETSc Version:           3.15.1\nSLEPc Version:           3.15.1\nCurrent Time:            Wed Sep 29 01:59:53 2021\nExecutable Timestamp:    Tue Sep 28 17:52:04 2021\n\nParallelism:\n  Num Processors:          840\n  Num Threads:             1\n\nMesh: \n  Parallel Type:           distributed (pre-split)\n  Mesh Dimension:          3\n  Spatial Dimension:       3\n  Nodes:                   \n    Total:                 6758745\n    Local:                 8292\n    Min/Max/Avg:           6259/10934/8046\n  Elems:                   \n    Total:                 36069737\n    Local:                 42859\n    Min/Max/Avg:           41689/44221/42940\n  Num Subdomains:          5\n  Num Partitions:          1\n  Partitioner:             parmetis\n\nNonlinear System:\n  Num DOFs:                27034980\n  Num Local DOFs:          33168\n  Variables:               { \"temp\" \"disp_x\" \"disp_y\" \"disp_z\" } \n  Finite Element Types:    \"LAGRANGE\" \n  Approximation Orders:    \"FIRST\" \n\nAuxiliary System:\n  Num DOFs:                1050505106\n  Num Local DOFs:          1249804\n  Variables:               { \"temp_in_C\" \"radiation_flux\" } { \"stress_xx_nodal\" \"strain_xx_nodal\" \"stress_yy_nodal\" \n                             \"strain_yy_nodal\" \"stress_zz_nodal\" \"strain_zz_nodal\" \"vonmises_nodal\" } { \"penetration\" \n                             \"contact_pressure\" \"nodal_area_leftright\" \"paired_temp\" } \n  Finite Element Types:    \"LAGRANGE\" \"MONOMIAL\" \"LAGRANGE\" \n  Approximation Orders:    \"FIRST\" \"FIRST\" \"FIRST\" \n\nExecution Information:\n  Executioner:             Transient\n  TimeStepper:             ConstantDT\n  Solver Mode:             NEWTON\n  MOOSE Preconditioner:    SMP (auto)\n\n\n    Reinitializing Because of Geometric Search Objects...............................................------------------------------------------------\n--------------------------\nPrimary job  terminated normally, but 1 process returned\na non-zero exit code. Per user-direction, the job has been aborted.\n--------------------------------------------------------------------------\n--------------------------------------------------------------------------\nAn MPI communication peer process has unexpectedly disconnected.  This\nusually indicates a failure in the peer process (e.g., a crash or\notherwise exiting without calling MPI_FINALIZE first).\n\nAlthough this local MPI process will likely now behave unpredictably\n(it may even hang or crash), the root cause of this problem is the\nfailure of the peer -- that is what you need to investigate.  For\nexample, there may be a core file that you can examine.  More\ngenerally: such peer hangups are frequently caused by application bugs\nor other external events.\n\n  Local host: cpu-p-309\n  Local PID:  75474\n  Peer host:  cpu-p-575\n--------------------------------------------------------------------------\n.--------------------------------------------------------------------------\nmpirun noticed that process rank 681 with PID 154172 on node cpu-p-515 exited on signal 11 (Segmentation fault).\n--------------------------------------------------------------------------\n[cpu-p-65:278580] 176 more processes have sent help message help-mpi-btl-tcp.txt / peer hung up\n[cpu-p-65:278580] Set MCA parameter \"orte_base_help_aggregate\" to 0 to see all help / error messages\n7 total processes killed (some possibly by mpirun during cleanup)\nslurmstepd: error: task_p_post_term: rmdir(/sys/fs/cgroup/cpuset/slurm46974006/slurm46974006.4294967294_0) failed Device or resource busy",
                          "url": "https://github.com/idaholab/moose/discussions/18941#discussioncomment-1400345",
                          "updatedAt": "2022-08-03T19:55:38Z",
                          "publishedAt": "2021-09-29T06:14:29Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "makeclean"
                          },
                          "bodyText": "Ok this ones a little weird, I can build dbg fine, but I can't build devel;\nmake -j8 METHOD=devel\nUsing HIT from /home/dc-davi4/rds/rds-ukaea-ap001/moose_dev/moose/framework/contrib/hit\nLinking Library /home/dc-davi4/rds/rds-ukaea-ap001/moose_dev/moose/framework/contrib/pcre/libpcre-devel.la...\nLinking Library /home/dc-davi4/rds/rds-ukaea-ap001/moose_dev/moose/framework/contrib/gtest/libgtest.la...\nLinking Library /home/dc-davi4/rds/rds-ukaea-ap001/moose_dev/moose/framework/contrib/hit/libhit-devel.la...\nCompiling C++ (in devel mode) /home/dc-davi4/rds/rds-ukaea-ap001/moose_dev/moose/modules/chemical_reactions/build/unity_src/actions_Unity.C...\nCompiling C++ (in devel mode) /home/dc-davi4/rds/rds-ukaea-ap001/moose_dev/moose/modules/chemical_reactions/build/unity_src/materials_Unity.C...\nCompiling C++ (in devel mode) /home/dc-davi4/rds/rds-ukaea-ap001/moose_dev/moose/modules/chemical_reactions/src/base/ChemicalReactionsApp.C...\nCompiling C++ (in devel mode) /home/dc-davi4/rds/rds-ukaea-ap001/moose_dev/moose/modules/external_petsc_solver/build/unity_src/timesteppers_Unity.C...\nCompiling C++ (in devel mode) /home/dc-davi4/rds/rds-ukaea-ap001/moose_dev/moose/modules/external_petsc_solver/build/unity_src/mesh_Unity.C...\n/usr/bin/ld: cannot find -lmesh_devel\n/usr/bin/ld: cannot find -ltimpi_devel\n/usr/bincollect2: error: ld returned 1 exit status\n/ld: cannot find -lmesh_devel\n/usr/bin/ld: cannot find -ltimpi_devel\ncollect2: error: ld returned 1 exit status\n/usr/bin/ld: cannot find -lmesh_devel\n/usr/bin/ld: cannot find -ltimpi_devel\ncollect2: error: ld returned 1 exit status\nmake: *** [/home/dc-davi4/rds/rds-ukaea-ap001/moose_dev/moose/framework/contrib/hit/libhit-devel.la] Error 1\nmake: *** Waiting for unfinished jobs....\nmake: *** [/home/dc-davi4/rds/rds-ukaea-ap001/moose_dev/moose/framework/contrib/gtest/libgtest.la] Error 1\nmake: *** [/home/dc-davi4/rds/rds-ukaea-ap001/moose_dev/moose/framework/contrib/pcre/libpcre-devel.la] Error 1\n\nAny ideas?",
                          "url": "https://github.com/idaholab/moose/discussions/18941#discussioncomment-1400385",
                          "updatedAt": "2022-08-03T19:56:14Z",
                          "publishedAt": "2021-09-29T06:23:18Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "makeclean"
                          },
                          "bodyText": "Am I being dim, should I be rebuilding the entire stack with METHOD=devel?",
                          "url": "https://github.com/idaholab/moose/discussions/18941#discussioncomment-1400453",
                          "updatedAt": "2022-10-05T08:43:30Z",
                          "publishedAt": "2021-09-29T06:34:42Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "loganharbour"
                          },
                          "bodyText": "To build with devel you need it in METHODS when you build libmesh. Something like:\nMETHODS=\u201copt devel dbg\u201d /path/to/moose/scripts/update_and_rebuild_libmesh.sh",
                          "url": "https://github.com/idaholab/moose/discussions/18941#discussioncomment-1402784",
                          "updatedAt": "2022-10-05T08:43:30Z",
                          "publishedAt": "2021-09-29T14:01:27Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "makeclean"
                          },
                          "bodyText": "Ok, we have liftoff, but Im none the wiser\nInitializing\n    Updating Because Mesh Changed\n      Updating Mesh..                                                                    [ 15.73 s] [   25 MB]\n    Finished Updating Because Mesh Changed                                               [ 15.77 s] [   29 MB]\n......                                                                [ 40.87 s] [   22 MB]\n    Finished Updating Because Mesh Changed                                               [ 40.91 s] [   26 MB]\n    Initializing Equation Systems............                                            [ 75.58 s] [  151 MB]\n    Initializing Displaced Equation System...........                                    [ 66.40 s] [   88 MB]\n..                                                                    [ 18.31 s] [    6 MB]\n    Finished Updating Because Mesh Changed                                               [ 18.34 s] [    6 MB]\n  Finished Initializing                                                                  [217.63 s] [  398 MB]\nFinished Setting Up                                                                      [235.30 s] [  463 MB]\nFramework Information:\nMOOSE Version:           git commit b657ae26aa on 2021-09-29\nLibMesh Version:         aebb5a5c0e1f6d8cf523a720e19f70a6d17c0236\nPETSc Version:           3.15.1\nSLEPc Version:           3.15.1\nCurrent Time:            Thu Sep 30 00:35:14 2021\nExecutable Timestamp:    Wed Sep 29 21:32:31 2021\n\nParallelism:\n  Num Processors:          840\n  Num Threads:             1\n\nMesh: \n  Parallel Type:           distributed (pre-split)\n  Mesh Dimension:          3\n  Spatial Dimension:       3\n  Nodes:                   \n    Total:                 6758745\n    Local:                 8292\n    Min/Max/Avg:           6259/10934/8046\n  Elems:                   \n    Total:                 36069737\n    Local:                 42859\n    Min/Max/Avg:           41689/44221/42940\n  Num Subdomains:          5\n  Num Partitions:          1\n  Partitioner:             parmetis\n\nNonlinear System:\n  Num DOFs:                27034980\n  Num Local DOFs:          33168\n  Variables:               { \"temp\" \"disp_x\" \"disp_y\" \"disp_z\" } \n  Finite Element Types:    \"LAGRANGE\" \n  Approximation Orders:    \"FIRST\" \n\nAuxiliary System:\n  Num DOFs:                1050505106\n  Num Local DOFs:          1249804\n  Variables:               { \"temp_in_C\" \"radiation_flux\" } { \"stress_xx_nodal\" \"strain_xx_nodal\" \"stress_yy_nodal\" \n                             \"strain_yy_nodal\" \"stress_zz_nodal\" \"strain_zz_nodal\" \"vonmises_nodal\" } { \"penetration\" \n                             \"contact_pressure\" \"nodal_area_leftright\" \"paired_temp\" } \n  Finite Element Types:    \"LAGRANGE\" \"MONOMIAL\" \"LAGRANGE\" \n  Approximation Orders:    \"FIRST\" \"FIRST\" \"FIRST\" \n\nExecution Information:\n  Executioner:             Transient\n  TimeStepper:             ConstantDT\n  Solver Mode:             NEWTON\n  MOOSE Preconditioner:    SMP (auto)\n\n\n    Finished Projecting Initial Solutions                                                [  7.47 s] [    0 MB]\n    Reinitializing Because of Geometric Search Objects..........................................................Assertion `_elements[i]' failed.\n\n[709] /home/dc-davi4/rds/rds-ukaea-ap001/moose_dev/moose/scripts/../libmesh/src/mesh/distributed_mesh.C, line 470, compiled Sep 29 2021 at 20:50:11\nAssertion `_elements[i]' failed.\n\n[801] /home/dc-davi4/rds/rds-ukaea-ap001/moose_dev/moose/scripts/../libmesh/src/mesh/distributed_mesh.C, line 470, compiled Sep 29 2021 at 20:50:11\nAssertion `_elements[i]' failed.\n\n[802] /home/dc-davi4/rds/rds-ukaea-ap001/moose_dev/moose/scripts/../libmesh/src/mesh/distributed_mesh.C, line 470, compiled Sep 29 2021 at 20:50:11\nAssertion `_elements[i]' failed.\n\n[807] /home/dc-davi4/rds/rds-ukaea-ap001/moose_dev/moose/scripts/../libmesh/src/mesh/distributed_mesh.C, line 470, compiled Sep 29 2021 at 20:50:11\nAssertion `_elements[i]' failed.\n\nAssertion `_elements[i]' failed.",
                          "url": "https://github.com/idaholab/moose/discussions/18941#discussioncomment-1409665",
                          "updatedAt": "2022-10-05T08:43:37Z",
                          "publishedAt": "2021-09-30T15:08:40Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "ah this is unfortunate.\nCan you run this inside a debugger with a breakpoint on MPI_Abort ?\nThis page should help\nhttps://mooseframework.inl.gov/application_development/debugging.html#!",
                          "url": "https://github.com/idaholab/moose/discussions/18941#discussioncomment-1410060",
                          "updatedAt": "2022-10-02T15:50:49Z",
                          "publishedAt": "2021-09-30T16:13:50Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "makeclean"
                          },
                          "bodyText": "In debug mode, the calculation takes more than 36 hours to start, just building the initial mesh so never gets to where it needs to be. Im going to try and make an MVP that has the same features.",
                          "url": "https://github.com/idaholab/moose/discussions/18941#discussioncomment-1423665",
                          "updatedAt": "2022-10-02T15:50:49Z",
                          "publishedAt": "2021-10-04T09:06:30Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "that is pretty slow. Devel mode should be a little faster.\nWhen hitting a libmesh assert, we often may not need the full backtrace with code lines either btw, since we know which line crashes and can trace it back manually",
                          "url": "https://github.com/idaholab/moose/discussions/18941#discussioncomment-1427259",
                          "updatedAt": "2022-10-02T15:50:49Z",
                          "publishedAt": "2021-10-04T23:16:50Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "Any news on this? devel-build should really be faster. And now that I think of it, since we have the final line, even an opt build backtrace could be workable",
                          "url": "https://github.com/idaholab/moose/discussions/18941#discussioncomment-1498922",
                          "updatedAt": "2022-10-02T15:50:50Z",
                          "publishedAt": "2021-10-18T22:14:46Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "Visualising Peridynamics Simulation Results",
          "author": {
            "login": "ABallisat"
          },
          "bodyText": "Hello all,\nI am starting to use the Peridynamics module and was wondering what tools people use for visualising the results? I have tried Paraview and Peacock but they show the mesh as a connected grid as in the attached image. I was hoping to be able see the individual particles, as in the image on the Peridynamics module main page. I am probably missing something obvious but any help greatly appreciated!\nAlex",
          "url": "https://github.com/idaholab/moose/discussions/16496",
          "updatedAt": "2022-07-06T06:42:17Z",
          "publishedAt": "2020-12-15T15:17:59Z",
          "category": {
            "name": "Q&A Tools"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "GiudGiud"
                  },
                  "bodyText": "Hello\nPeople use paraview and peacock for visualization mostly.\nTo achieve an image like the peridynamics module one, you can use the 'points' in paraview. They will be colored based on the value of the function visualized. And there size can be customized.\nI think that image is still showing the mesh, but restricted to the solid phase, and deformed by creep and all the other phenomena from irradiation.\nGuillaume",
                  "url": "https://github.com/idaholab/moose/discussions/16496#discussioncomment-1828694",
                  "updatedAt": "2022-07-06T06:42:54Z",
                  "publishedAt": "2021-12-16T22:04:22Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": []
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "Multiapps user object based transfer - Seg fault with UserObjectInterface",
          "author": {
            "login": "abarun22"
          },
          "bodyText": "Dear all,\nI am trying to develop an user object based multi-apps transfer mechanism along the lines of MultiAppUserObjectTransfer.  The issue being that i could not get the basic framework to execute for the simplest of cases. There seems to be an seg-fault problem with the inclusion of UserObjectInterface which is a direct base class of the new transfer class that i am currently developing. Execution is OK without UserObjectInterface, however with the cost of undefined reference to getUserObjectByName and therefore i continued inheriting this class and moved on to debug the seg-fault. I tried to check this issue in the debug mode and obtained the following trace back.\n\n#1  0x00007ffff7bc881a in std::_Rb_tree<std::__cxx11::basic_string<char, std::char_traits, std::allocator >, std::pair<std::__cxx11::basic_string<char, std::char_traits, std::allocator > const, libMesh::Parameters::Value*>, std::_Select1st<std::pair<std::__cxx11::basic_string<char, std::char_traits, std::allocator > const, libMesh::Parameters::Value*> >, std::less<std::__cxx11::basic_string<char, std::char_traits, std::allocator > >, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits, std::allocator > const, libMesh::Parameters::Value*> > >::find (this=0x311, __k=...) at /usr/local/depot/gcc-7.3.0/include/c++/7.3.0/bits/stl_tree.h:2536\n#2  0x00007ffff7bc725b in std::__cxx1998::map<std::__cxx11::basic_string<char, std::char_traits, std::allocator >, libMesh::Parameters::Value*, std::less<std::__cxx11::basic_string<char, std::char_traits, std::allocator > >, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits, std::allocator > const, libMesh::Parameters::Value*> > >::find (this=0x311, __x=...) at /usr/local/depot/gcc-7.3.0/include/c++/7.3.0/bits/stl_map.h:1189\n#3  0x00007ffff7bc54f0 in std::__debug::map<std::__cxx11::basic_string<char, std::char_traits, std::allocator >, libMesh::Parameters::Value*, std::less<std::__cxx11::basic_string<char, std::char_traits, std::allocator > >, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits, std::allocator > const, libMesh::Parameters::Value*> > >::find (this=0x2f9, __x=...) at /usr/local/depot/gcc-7.3.0/include/c++/7.3.0/debug/map.h:574\n#4  0x00007ffff6a95306 in libMesh::Parameters::have_parameter<FEProblemBase*> (this=0x2f1, name=...)\nat /home/abalasub/Working/Projects/moose/scripts/../libmesh/installed/include/libmesh/parameters.h:407\n#5  0x00007ffff6a95a95 in libMesh::Parameters::get<FEProblemBase*> (this=0x2f1, name=...)\nat /home/abalasub/Working/Projects/moose/scripts/../libmesh/installed/include/libmesh/parameters.h:426\n#6  0x00007ffff6a9415f in InputParameters::getCheckedPointerParam<FEProblemBase*> (this=0x2f1, name=..., error_string=...)\nat /home/abalasub/Working/Projects/moose/framework/build/header_symlinks/InputParameters.h:1211\n#7  0x00007ffff2454c90 in UserObjectInterface::UserObjectInterface (this=0xf6df18, moose_object=0xf6d800)\nat /home/abalasub/Working/Projects/moose/framework/src/userobject/UserObjectInterface.C:25\n#8  0x00007ffff1cd51f3 in MultiAppTransferQuantity_UO::MultiAppTransferQuantity_UO (this=0xf6d800, parameters=...,\n__in_chrg=, __vtt_parm=)\nat /home/abalasub/Working/Projects/moose/framework/src/transfers/MultiAppTransferQuantity_UO.C:33\n#9  0x00007ffff1d5782d in __gnu_cxx::new_allocator<MultiAppTransferQuantity_UO>::construct<MultiAppTransferQuantity_UO, InputParameters const&> (this=0x7fffffffbc27, __p=0xf6d800, __args#0=...)\n#10 0x00007ffff1d54e84 in std::allocator_traits<std::allocator<MultiAppTransferQuantity_UO> >::construct<MultiAppTransferQuantity_UO, InputParameters const&> (__a=..., __p=0xf6d800, __args#0=...)\nat /usr/local/depot/gcc-7.3.0/include/c++/7.3.0/bits/alloc_traits.h:475\n#11 0x00007ffff1d50cff in std::_Sp_counted_ptr_inplace<MultiAppTransferQuantity_UO, std::allocator<MultiAppTransferQuantity_UO>, (__gnu_cxx::_Lock_policy)2>::_Sp_counted_ptr_inplace<InputParameters const&> (this=0xf6d7f0, __a=...)\nat /usr/local/depot/gcc-7.3.0/include/c++/7.3.0/bits/shared_ptr_base.h:526\n#12 0x00007ffff1d4befb in std::__shared_count<(__gnu_cxx::_Lock_policy)2>::__shared_count<MultiAppTransferQuantity_UO, std::al---Type  to continue, or q  to quit---\nlocator<MultiAppTransferQuantity_UO>, InputParameters const&> (this=0x7fffffffbdb8, __a=...)\nat /usr/local/depot/gcc-7.3.0/include/c++/7.3.0/bits/shared_ptr_base.h:637\n#13 0x00007ffff1d46686 in std::__shared_ptr<MultiAppTransferQuantity_UO, (__gnu_cxx::_Lock_policy)2>::__shared_ptr<std::allocator<MultiAppTransferQuantity_UO>, InputParameters const&> (this=0x7fffffffbdb0, __tag=..., __a=...)\nat /usr/local/depot/gcc-7.3.0/include/c++/7.3.0/bits/shared_ptr_base.h:1295\n#14 0x00007ffff1d3efd7 in std::shared_ptr<MultiAppTransferQuantity_UO>::shared_ptr<std::allocator<MultiAppTransferQuantity_UO>, InputParameters const&> (this=0x7fffffffbdb0, __tag=..., __a=...)\nat /usr/local/depot/gcc-7.3.0/include/c++/7.3.0/bits/shared_ptr.h:344\n#15 0x00007ffff1d33fc7 in std::allocate_shared<MultiAppTransferQuantity_UO, std::allocator<MultiAppTransferQuantity_UO>, InputParameters const&> (__a=..., __args#0=...) at /usr/local/depot/gcc-7.3.0/include/c++/7.3.0/bits/shared_ptr.h:691\n#16 0x00007ffff1d2251f in std::make_shared<MultiAppTransferQuantity_UO, InputParameters const&> (__args#0=...)\nat /usr/local/depot/gcc-7.3.0/include/c++/7.3.0/bits/shared_ptr.h:707\n#17 0x00007ffff1d0d8d0 in moose::internal::buildObj<MultiAppTransferQuantity_UO> (parameters=...)\nat /home/abalasub/Working/Projects/moose/framework/build/header_symlinks/Registry.h:146\n#18 0x00007ffff2bc6187 in Factory::create (this=0x7ffff7ebb8f0, obj_name=..., name=..., parameters=..., tid=0,\nprint_deprecated=false) at /home/abalasub/Working/Projects/moose/framework/src/base/Factory.C:131\n#19 0x00007ffff1912324 in Factory::create (this=0x7ffff7ebb8f0, obj_name=..., name=..., parameters=..., tid=0)\nat /home/abalasub/Working/Projects/moose/framework/build/header_symlinks/Factory.h:303\n#20 0x00007ffff18b901b in FEProblemBase::addTransfer (this=0xd97660, transfer_name=..., name=..., parameters=...)\nat /home/abalasub/Working/Projects/moose/framework/src/problems/FEProblemBase.C:4482\n#21 0x00007ffff2340c8f in AddTransferAction::act (this=0xa9cfc0)\nat /home/abalasub/Working/Projects/moose/framework/src/actions/AddTransferAction.C:30\n#22 0x00007ffff232f5ad in Action::timedAct (this=0xa9cfc0)\nat /home/abalasub/Working/Projects/moose/framework/src/actions/Action.C:93\n#23 0x00007ffff2334023 in ActionWarehouse::executeActionsWithAction (this=0x7ffff7ebb510, task=...)\nat /home/abalasub/Working/Projects/moose/framework/src/actions/ActionWarehouse.C:392\n#24 0x00007ffff2333acd in ActionWarehouse::executeAllActions (this=0x7ffff7ebb510)\nat /home/abalasub/Working/Projects/moose/framework/src/actions/ActionWarehouse.C:352\n#25 0x00007ffff2b1abd5 in MooseApp::runInputFile (this=0x7ffff7e6c020)\nat /home/abalasub/Working/Projects/moose/framework/src/base/MooseApp.C:1017\n#26 0x00007ffff2b1d600 in MooseApp::run (this=0x7ffff7e6c020)\nat /home/abalasub/Working/Projects/moose/framework/src/base/MooseApp.C:1281\n#27 0x0000000000412c91 in main (argc=3, argv=0x7fffffffda98) at /home/abalasub/Working/Projects/submodel_repo/src/main.C:33\n\nA detailed analysis of traceback reveals the problem runs very deep in to the libmesh functionalities and that it is harder to find the exact cause of this issue. I wonder if there is any we could do here to find the right fix for this issue. Attached here are the modified sources and the input files used for this simulation, which might possibly throw some hints as to check where things are going wrong. Any suggestions here are highly appreciated.\nKind regards,\nArun\n08112021.zip",
          "url": "https://github.com/idaholab/moose/discussions/19322",
          "updatedAt": "2022-07-08T08:03:21Z",
          "publishedAt": "2021-11-08T19:00:43Z",
          "category": {
            "name": "Q&A General"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "GiudGiud"
                  },
                  "bodyText": "Hello\nIt seems the issue you are getting is because of this InputParameters::getCheckedPointerParam<FEProblemBase*>\nThis is used by the UO interface to get access to the FEProblem. i would put some print statements there to understand when this is being run, maybe it s being ran too early and the problem has not been created yet. I doubt it s that though, Transfers should be created fairly late.\nI think you have moved forward on this, based on this other discussion #19485\nGuillaume",
                  "url": "https://github.com/idaholab/moose/discussions/19322#discussioncomment-1828607",
                  "updatedAt": "2022-07-08T08:03:19Z",
                  "publishedAt": "2021-12-16T21:51:07Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": []
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "A question in SmearedCracking",
          "author": {
            "login": "xuxiaobei1995"
          },
          "bodyText": "Hi all,\n Recently I'm doing some work about cracking based on SmearedCracking. I want to realize two things:\n (1) Adjust the Young's modulus and Poisson's ratio depending on the number of cracks (For example, E_crack = E_intatct * (0.6)^N, N means the number of cracks).\n (2) When the cracked region is under compressive stresses and the temperature is above a given value, the cracks \"heal\" so that everything turn back to the original status.\n Because I knows little about the theory of the tensor mechanics, The code is difficult for me to understand. Does anyone know how to realize these two things? Any suggestion is appreciated.\n\nBest Regards,\nXiaobei",
          "url": "https://github.com/idaholab/moose/discussions/19445",
          "updatedAt": "2022-07-06T21:43:59Z",
          "publishedAt": "2021-11-21T10:55:44Z",
          "category": {
            "name": "Q&A Modules: Solid mechanics"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "GiudGiud"
                  },
                  "bodyText": "Hello\nThere s pretty good docs around smeared cracking models\nhttps://mooseframework.inl.gov/source/materials/ComputeSmearedCrackingStress.html#!\nand softening models dependent on the number of cracks\nhttps://mooseframework.inl.gov/source/materials/PowerLawSoftening.html\nGuillaume",
                  "url": "https://github.com/idaholab/moose/discussions/19445#discussioncomment-1828464",
                  "updatedAt": "2022-07-06T21:44:56Z",
                  "publishedAt": "2021-12-16T21:45:41Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": []
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "creating a function that returns random value between min and max",
          "author": {
            "login": "vermaprk"
          },
          "bodyText": "Hi\nI am trying to make a function which returns a random value between min and max. But when i run these files it returns always '0'.\nI checked my input file with a parsedfunction but it works well in that case.\ncan somebody please help me find the bug in my code. (I am beginner in C++)\n <Codes>\n------------------------------------------------------------------------------------------------------------------------------------------------\n<Source FIle>\n------------------------------------------------------------------------------------------------------------------------------------------------\n\n#include \"RndConstantFunction.h\"\n#include \"MooseRandom.h\"\n\nregisterMooseObject(\"vsubraApp\", RndConstantFunction);\n\nInputParameters\nRndConstantFunction::validParams()\n{\n   InputParameters params = Function::validParams();\n   params.addClassDescription(\n     \"A function that returns random number between min and max\");\n     params.addParam<Real>(\"min\", 0.0, \"The constant value\");\n     params.addParam<Real>(\"max\", 1.0, \"The constant value\");\n     return params;\n }\n RndConstantFunction::RndConstantFunction(const InputParameters & parameters)\n   : Function(parameters),\n   _min(parameters.get<Real>(\"min\")),\n   _max(parameters.get<Real>(\"max\"))\n {\n }\n\nReal\n RndConstantFunction::value(const Point & p)\n {\n   // Random number between min and max\n   Real rand_num = MooseRandom::rand(0);\n\n   return rand_num * (_max - _min) + _min;\n }\n\n------------------------------------------------------------------------------------------------------------------------------------------------\n<Header FIle>\n------------------------------------------------------------------------------------------------------------------------------------------------\n\n#pragma once\n\n#include \"Function.h\"\n\nclass RndConstantFunction : public Function\n{\npublic:\n  static InputParameters validParams();\n\n  RndConstantFunction(const InputParameters & parameters);\n\n  virtual Real value(const Point & p);\n\nprotected:\n  const Real & _min;\n  const Real & _max;\n\n};\n---------------------------------------------------------------------------------------------------------------------------------------------------\n<input file>\n---------------------------------------------------------------------------------------------------------------------------------------------------\n\n[StochasticTools]\n[]\n\n[Mesh]\n  type = GeneratedMesh\n  dim = 1\n[]\n\n[Postprocessors]\n  [function_val]\n    type = FunctionValuePostprocessor\n    function = fun\n  []\n[]\n\n[Functions/fun]\n  type = RndConstantFunction\n  min  = '4'\n  max  = '10'\n[]\n\n[Controls/receiver]\n  type = SamplerReceiver\n[]",
          "url": "https://github.com/idaholab/moose/discussions/19595",
          "updatedAt": "2022-11-25T12:56:00Z",
          "publishedAt": "2021-12-10T07:11:17Z",
          "category": {
            "name": "Q&A General"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "GiudGiud"
                  },
                  "bodyText": "Hello\nPlease use triple quotes to format code when posting on discussions.\nThe way you are setting _min and _max is odd. Maybe that was the old way\nCan you do this instead:\n_min(getParam<Real>(\"min\")),\nWhen you can MooseRandom::rand(0) you are asking for a particular state (index 0) for that random number generator.\nCan you use ::rand() instead?\nGuillaume",
                  "url": "https://github.com/idaholab/moose/discussions/19595#discussioncomment-1787345",
                  "updatedAt": "2023-06-23T15:14:52Z",
                  "publishedAt": "2021-12-10T18:11:01Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "vermaprk"
                          },
                          "bodyText": "I already tried with ::rand(). Still it is returning 0",
                          "url": "https://github.com/idaholab/moose/discussions/19595#discussioncomment-1787908",
                          "updatedAt": "2023-06-23T15:14:52Z",
                          "publishedAt": "2021-12-10T19:33:16Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "dschwen"
                          },
                          "bodyText": "The 0 is an index to a map of RNG states, not a specific state per se (i.e. it should not always return the same value, but a separate independent stream of values than for example ::rand(1)).\nNote that this way of generating random numbers will not be parallel consistent and is generally discouraged.",
                          "url": "https://github.com/idaholab/moose/discussions/19595#discussioncomment-1788207",
                          "updatedAt": "2023-06-23T15:14:52Z",
                          "publishedAt": "2021-12-10T20:33:45Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "vermaprk"
                          },
                          "bodyText": "but in this case it is returning zero always irrespective of\n\n::rand()\n\n\n::rand(0)\n\n\nrand(1)",
                          "url": "https://github.com/idaholab/moose/discussions/19595#discussioncomment-1812040",
                          "updatedAt": "2023-06-23T15:14:54Z",
                          "publishedAt": "2021-12-15T11:24:09Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "rand() works fine for me. I just checked.\nare _min and _max set properly?\nIf you add\n_console << _min << \" \" << _max << \" \" << MooseRandom::rand() << std::endl;\nin your function what does it print?",
                          "url": "https://github.com/idaholab/moose/discussions/19595#discussioncomment-1828321",
                          "updatedAt": "2023-06-23T15:14:55Z",
                          "publishedAt": "2021-12-16T21:38:16Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "Print the variable value",
          "author": {
            "login": "avtarsinghh1991"
          },
          "bodyText": "I am quite new to MOOSE and C++. So just wondering how can I  make sure the value given in input file is properly passed to the kernel file or material file.\nI mean is there any method to print the value or matrix in the kernel file?\nThanks in advance.",
          "url": "https://github.com/idaholab/moose/discussions/19642",
          "updatedAt": "2022-06-02T14:32:13Z",
          "publishedAt": "2021-12-15T17:15:10Z",
          "category": {
            "name": "Q&A Modules: General"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "friedmud"
                  },
                  "bodyText": "Just for your own purposes of feeling comfortable that MOOSE is doing the right thing you can always add a quick std::cout << _my_param_value << std::endl; in computeQpResidual to make sure the value is coming through.  Obviously, this is not something you want to have in there for a long time (it will cause millions of print outs!) - but it will give you the confidence that you're doing things correctly in the beginning :-)\nYou can also see what MOOSE is reading from your input file by using --show-input on the command-line.  This will cause MOOSE to echo out what it thinks it read from your input file (and show you all of the default values for all parameters you didn't specify).",
                  "url": "https://github.com/idaholab/moose/discussions/19642#discussioncomment-1815271",
                  "updatedAt": "2022-06-02T14:32:37Z",
                  "publishedAt": "2021-12-15T18:01:36Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "avtarsinghh1991"
                          },
                          "bodyText": "Thanks.\nwhen I am using\n\n\n--show-input\n\n\nit says command not found.",
                          "url": "https://github.com/idaholab/moose/discussions/19642#discussioncomment-1815422",
                          "updatedAt": "2022-06-02T14:32:38Z",
                          "publishedAt": "2021-12-15T18:11:29Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "friedmud"
                          },
                          "bodyText": "That is a command-line option for your executable... so do:\n./my_moose_program -i my_input  --show-input",
                          "url": "https://github.com/idaholab/moose/discussions/19642#discussioncomment-1815540",
                          "updatedAt": "2022-06-02T14:33:34Z",
                          "publishedAt": "2021-12-15T18:25:15Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "avtarsinghh1991"
                          },
                          "bodyText": "Thank you very much. It helps a lot.",
                          "url": "https://github.com/idaholab/moose/discussions/19642#discussioncomment-1827303",
                          "updatedAt": "2022-06-02T14:33:38Z",
                          "publishedAt": "2021-12-16T19:39:37Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "The .pvtu extension should be used when writing VTK files in libMesh",
          "author": {
            "login": "rcontinuum"
          },
          "bodyText": "Hello,\nI just want to share the following observation:\nIf I set in [Outputs] vtk = true [] and execute an input file in serial mode I get a group of vtk and vtu files like\ntest_out_000.vtk\ntest_out_001.vtk\ntest_out_000_0.vtu\ntest_out_001_0.vtu\n\nNow, if I open the groups of vtk-files in paraview then I get a paraview error \"A reader for \".../test_out_000.vtk\" could not be found\".\nI tried paraview versions 5.9.1 and 5.5.2 (from the paraview download page).\nIf I rename the *.vtk-files to *.pvtu-files then paraview loads the renamed files with no error.\nIn the case I run a moose app in parallel *.pvtu-files are written and the problem does not occur.\nThe moose app gives in serial mode a hint \"The .pvtu extension should be used when writing VTK files in libMesh.\"\nIn https://mooseframework.inl.gov/docs/doxygen/libmesh/vtk__io_8C_source.html   around line 256\none finds a comment that vtk-files would work too, but maybe that is not correct anymore.\nEdit: typo",
          "url": "https://github.com/idaholab/moose/discussions/19553",
          "updatedAt": "2022-06-17T03:36:19Z",
          "publishedAt": "2021-12-06T15:55:43Z",
          "category": {
            "name": "Q&A Tools"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "GiudGiud"
                  },
                  "bodyText": "Hello\nI just tried on a sample input file with paraview 5.9.1 on mac and was able to open the .vtu file generated by MOOSE.\nI think you need to open the .vtu file with paraview, not the .vtk file.\nGuillaume",
                  "url": "https://github.com/idaholab/moose/discussions/19553#discussioncomment-1762639",
                  "updatedAt": "2022-06-17T03:36:22Z",
                  "publishedAt": "2021-12-07T05:10:48Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "rcontinuum"
                          },
                          "bodyText": "Thank you for looking into this.\nYes, I can open the vtu-files too. But only single ones, i.e. one at a time. paraview (on linux) does not identify the vtu-files as a group.\nSee my screenshot\n\nIt could be due to the numbering of the vtu-files. Both end with _0, which may mean \"Piece\" number 0? Whereas the generated vtk-files have consecutive numbers at the end, _000.vtk and _001.vtk. The vtk-files are just files which basically \"point\" to the corresponding vtu-file (which contain the \"real\" simulation data).\nLike in test_out_000.vtk\n...\n<Piece Source=\"test_out_000_0.vtu\"/>\n...\n\n\nIf I do in a bash terminal:  mmv \"*.vtk\" \"#1.pvtu\"  (rename all *.vtk to *.pvtu; multiple move) then these renamed files get identified as a pvtu-group too and can be opened as a group of files with no error message. And I can play the fields as a \"movie/animation\". Basically I assume, paraview \"runs\" through the group of pvtu-files and loads the corresponding \"real\" simulation data from the corresponding vtu-files.\nDo you see the same behavior on Mac?\nI mean, if yes it should be a simple modification in the source code. Basically, always write files with pvtu-ending (in serial and parallel) \"pointing\" to the vtu-files which contains the \"real\" data. Just use always the ending .pvtu instead of .vtk (in searial mode).\nRalf\nPS: Sure, I can always perform a mmv \"*.vtk\" \"#1.pvtu\"after the run. So, it's nothing essential.",
                          "url": "https://github.com/idaholab/moose/discussions/19553#discussioncomment-1763414",
                          "updatedAt": "2022-06-17T03:36:23Z",
                          "publishedAt": "2021-12-07T08:42:07Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "Paraview will let you load more files from the GUI I think.\nI dont know why we have the _0, suffix on the .vtu. I think it makes sense for the .pvtu.\n@roystgnr any ideas on this?",
                          "url": "https://github.com/idaholab/moose/discussions/19553#discussioncomment-1766136",
                          "updatedAt": "2022-06-17T03:36:28Z",
                          "publishedAt": "2021-12-07T15:43:21Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "roystgnr"
                          },
                          "bodyText": "Looks like we're writing out pvtu format even in serial right now (or at least we're handing an MPI communicator to VTK and that's what it's deciding to do in that case), with a comment in the libMesh source saying this is fine since Paraview understands that special case.  So you ask VTKIO to write \"foo.pvtu\", and it writes the header data to that, and then it writes a \"foo_#.vtu\" file for each processor rank #.  The catch is that, if you ask for an extension other than pvtu, we yell at you but then we do as you say, and Paraview etc. don't understand that.  So unless we want to add special-case code to an already undermaintained code path, the fix might be to just have Moose VTKOutput.C always ask for a .pvtu extension?\nBut I must still not be understanding this, because: how is this a problem cropping up now?  The patch enabling parallel writes and warning about non-pvtu extensions went into libMesh nearly 9 years ago, and it looks like John was editing the Moose output to match years later than that.",
                          "url": "https://github.com/idaholab/moose/discussions/19553#discussioncomment-1768497",
                          "updatedAt": "2022-06-24T01:04:47Z",
                          "publishedAt": "2021-12-07T20:00:58Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "people were probably loading up the vtu instead of the vtk file.\nSo sounds like we just need to write pvtu instead of vtk to be good here",
                          "url": "https://github.com/idaholab/moose/discussions/19553#discussioncomment-1769642",
                          "updatedAt": "2022-06-24T01:25:09Z",
                          "publishedAt": "2021-12-08T01:00:06Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "rcontinuum"
                          },
                          "bodyText": "Background: I was playing around with vtk = true and thought the MOOSE VTK-output files are not fully behaving like I would expect in serial mode. But in parallel mode it behave like I expected (from a user point of view using paraview). I (intent to) use vtk-files for development/debugging, typically meshes with one or a few elements, as they are in ASCII. And an exodus-file needs ncdump to make them readable for a human.\nI just wanted to report my observation. I mean, it's no a big deal for me, I can always rename with mmv.\n\nthe fix might be to just have Moose VTKOutput.C always ask for a .pvtu extension?\n\nThat was at least my first thought and even if I'm not familiar with your code I thought that should by like modifying \"one\" line of code (which is a \"dangerous\" assumption from my side). I don't know the precise VTK definition of \"parallel\" files, but in principle they should work for \"n=1\", i.e. serial, too.\n\nhow is this a problem cropping up now?\n\nI started with looking into MOOSE recently, so I cannot tell you.\nMaybe paraview (or VTK-lib) a few years ago was not that \"picky\" concerning *.vtk and *.pvtu extensions and their content. But this is a speculation from my side.",
                          "url": "https://github.com/idaholab/moose/discussions/19553#discussioncomment-1772259",
                          "updatedAt": "2022-06-24T01:25:16Z",
                          "publishedAt": "2021-12-08T12:20:17Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              },
              {
                "node": {
                  "author": {
                    "login": "rcontinuum"
                  },
                  "bodyText": "Shall I open an issue on this topic?",
                  "url": "https://github.com/idaholab/moose/discussions/19553#discussioncomment-1811213",
                  "updatedAt": "2022-06-24T01:04:48Z",
                  "publishedAt": "2021-12-15T08:32:32Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "Sure but its a libmesh issue i think",
                          "url": "https://github.com/idaholab/moose/discussions/19553#discussioncomment-1813201",
                          "updatedAt": "2022-06-24T01:04:48Z",
                          "publishedAt": "2021-12-15T14:33:04Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "Please make sure to document the workaround there btw",
                          "url": "https://github.com/idaholab/moose/discussions/19553#discussioncomment-1813208",
                          "updatedAt": "2022-06-24T01:04:49Z",
                          "publishedAt": "2021-12-15T14:33:22Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "roystgnr"
                          },
                          "bodyText": "It's a Moose issue, and at least in theory it was noted in #19581 and fixed by #19582 last week.  Looks like Github doesn't automatically generate backlinks to referenced discussions the way it does to issues and PRs?  That's annoying.  Sorry, I'd have mentioned it here manually if I'd known that was necessary.",
                          "url": "https://github.com/idaholab/moose/discussions/19553#discussioncomment-1817197",
                          "updatedAt": "2022-06-24T01:04:52Z",
                          "publishedAt": "2021-12-15T21:17:21Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "rcontinuum"
                          },
                          "bodyText": "Thank you for fixing this so fast!",
                          "url": "https://github.com/idaholab/moose/discussions/19553#discussioncomment-1821319",
                          "updatedAt": "2022-06-24T01:26:29Z",
                          "publishedAt": "2021-12-16T07:45:56Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "rcontinuum"
                          },
                          "bodyText": "Sorry, I'd have mentioned it here manually if I'd known that was necessary.\n\nWell, at least now I see in the right most column of this page after scrolling up \"Events\".",
                          "url": "https://github.com/idaholab/moose/discussions/19553#discussioncomment-1821379",
                          "updatedAt": "2022-06-24T01:26:29Z",
                          "publishedAt": "2021-12-16T07:55:12Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "Finite Volume \"Interior\" Boundary Condition",
          "author": {
            "login": "maxnezdyur"
          },
          "bodyText": "Is there an \"interior\" boundary condition in Moose? I am trying to simulate flow through a 2D channel. In the middle of the channel, there is a side set. I want Moose to run for some time with the side set not as a boundary condition, and then at some point, I will turn it into a wall or some other boundary condition. I am getting the error that \"The INSFVMomentumAdvection object mass is not completely bounded by INSFVBCs\" if I don't include any boundary condition for that specific side set. The side set completely blocks the channel when it is turned on.",
          "url": "https://github.com/idaholab/moose/discussions/19636",
          "updatedAt": "2022-10-14T12:36:40Z",
          "publishedAt": "2021-12-15T13:07:53Z",
          "category": {
            "name": "Q&A Modules: Navier-Stokes"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "GiudGiud"
                  },
                  "bodyText": "Hello\nYou can have an interior sideset but we currently dont allow interior boundary conditions in finite volume. It's not something that cant be done it's just that most of the time that will be an error in the input rather than something desirable.\nThere's multiple options for doing what you want to do.\n\nrestart the simulation at the point where you want to block the channel, loading up the previous velocity and pressure fields, with the mesh as you intend with a blockage\nhave a volumetric blockage instead of a sideset. If you set a very high friction coefficient you should be able to essentially cut the flow. Note that if the flow has nowhere else to go it ll still go through, but with a very high pressure drop\ncreate an interface kernel that will penalize (with a lagrange multiplier) flow going through that sideset. Just a constraint on v_normal should do.\n\nWorking with a boundary condition \"that turns on\" at some point seems difficult. The advection kernel examines at the beginning of the simulation all boundaries and determines which one it would execute on and with which behavior for Rhie Chow interpolation. This one would first be a normal region then become a wall, so the RC interpolation differs between those two cases.\n@lindsayad might have a different opinion\nGuillaume",
                  "url": "https://github.com/idaholab/moose/discussions/19636#discussioncomment-1813501",
                  "updatedAt": "2022-07-15T14:22:24Z",
                  "publishedAt": "2021-12-15T15:06:23Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "lindsayad"
                          },
                          "bodyText": "Yea I think the easiest thing at this point would be to do the restart option that @GiudGiud recommended. After #18563 things would get a little simpler for this, but we still need to know what the flow boundaries are so that we can implicitly run advection kernels on outflow boundaries. Maybe in the future we can make that a Controllable parameter but that's not in the cards at the moment.",
                          "url": "https://github.com/idaholab/moose/discussions/19636#discussioncomment-1817261",
                          "updatedAt": "2022-07-15T14:22:24Z",
                          "publishedAt": "2021-12-15T21:22:01Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      }
    ]
  }
}