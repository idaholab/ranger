{
  "discussions": {
    "pageInfo": {
      "hasNextPage": true,
      "endCursor": "Y3Vyc29yOnYyOpK5MjAyMS0wNi0wM1QxMToxNDoyMS0wNjowMM4AM7BO"
    },
    "edges": [
      {
        "node": {
          "title": "tutorial Darcy simulations not converging from step07d onwards.",
          "author": {
            "login": "garciapintado"
          },
          "bodyText": "Dear all,\nI am new to MOOSE and cloned it from the repository at around 20-05-2021. My interest is on porous flow simulations.\nGoing through the Darcy tutorial steps, the simulations have gone very well up to step07_adaptivity, including problems step7a, step7b & step7c. From there onwards things are not so good [using untouched files as they are cloned]:\nproblem step7d_adapt_blocks.i :: running from command line [on an iMAC] convergence starts nicely, but at time step 15 the convergence starts to struggle. This only get worse, and from step 29 onwards the convergence is terribly slow (~1 minute per time step) and eventually it gets completely stuck.\nI've tried to change some Executioner options (e.g. to \"solver_type = PJFNK\" ) and nothing that I've tried seems able to solve the problem. BTW, in the video tutorial, also Andrew simulation got stuck in this problem, and the he showed results from a stored run. So, I am wondering if there is some current issue going on.\nLater on, following problems also get stuck eventually. For example, running [now from peacock with two threads] problem step10_micro.i, the solver goes very well until step 572 (more than half way of the simulation set 1000 timesteps), where it suddenly crashes with the error:\nNonlinear solve did not converge due to DIVERGED_LINE_SEARCH iterations 10\n Solve Did NOT Converge!\nAborting as solve did not converge\n\n*** ERROR ***\nThe following error occurred in the object \"TimeStepper\", of type \"ConstantDT\".\n\nSolve failed and timestep already at or below dtmin, cannot continue!\nI am sorry I can find my way around these issues. Please could you help? Has anyone been able to run this simulations lately as they are in the repository?\nBest wishes,\nJavier",
          "url": "https://github.com/idaholab/moose/discussions/17997",
          "updatedAt": "2022-08-02T05:51:40Z",
          "publishedAt": "2021-06-03T09:35:36Z",
          "category": {
            "name": "Q&A Getting Started"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "garciapintado"
                  },
                  "bodyText": "Dear All,\nMy fault. Changing the PETSc preconditioning DOES SOLVE the issue. For me, setting the options in the [Executioner] block:\n[Executioner]\n  ...\n  petsc_options_iname = '-pc_type -pc_factor_mat_solver'\n  petsc_options_value = 'lu mumps'\n  ...\n[]\n\nmakes step7d problem in the tutorial converge nicely, and further running it with 4 threads make it run impressively fast in my iMAC.\nBest wishes,\nJavier",
                  "url": "https://github.com/idaholab/moose/discussions/17997#discussioncomment-821679",
                  "updatedAt": "2022-08-02T05:51:49Z",
                  "publishedAt": "2021-06-03T16:13:03Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "aeslaughter"
                          },
                          "bodyText": "Thanks for the update.",
                          "url": "https://github.com/idaholab/moose/discussions/17997#discussioncomment-835259",
                          "updatedAt": "2022-08-02T05:51:50Z",
                          "publishedAt": "2021-06-07T14:37:29Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "the number of time steps in postprocessing",
          "author": {
            "login": "snugook1108"
          },
          "bodyText": "Hi, did you know which type/variable setup for the number of time steps in postprocessing?",
          "url": "https://github.com/idaholab/moose/discussions/17996",
          "updatedAt": "2022-12-09T01:48:06Z",
          "publishedAt": "2021-06-03T06:36:32Z",
          "category": {
            "name": "Q&A General"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "GiudGiud"
                  },
                  "bodyText": "Hello\nNot sure I fully understand your question. Postprocessing is done by default at the end of every timestep in moose. This can be controlled using the execute_on parameter to most objects. You can make a custom execute_on option that does the postprocessing only when you wish. Also please note the Output objects are also controlled with this system.\nMaybe look at https://mooseframework.inl.gov/source/interfaces/SetupInterface.html which has more information on how that system works.\nBest,\nGuillaume",
                  "url": "https://github.com/idaholab/moose/discussions/17996#discussioncomment-822857",
                  "updatedAt": "2022-12-09T01:48:06Z",
                  "publishedAt": "2021-06-03T18:41:51Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "aeslaughter"
                          },
                          "bodyText": "Just to clarify the output side: the \"execute_on\" in an Output object (i.e, [Outputs] in your input file) dictates when an the Output object is executed, it has no control on when the information being computed occurs.\nhttps://mooseframework.inl.gov/syntax/Outputs/index.html",
                          "url": "https://github.com/idaholab/moose/discussions/17996#discussioncomment-835243",
                          "updatedAt": "2022-12-09T01:48:15Z",
                          "publishedAt": "2021-06-07T14:33:59Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "Equal stresses across gas-liquid interface using INS",
          "author": {
            "login": "keniley1"
          },
          "bodyText": "Hello all,\nI'm trying to model an argon jet interacting with a liquid water surface. The setup is essentially a cylindrical tube with a hot tungsten needle at the center, with the tip of the needle reaching temperatures around 2000-2500 K. The tip of the needle is suspended over a reservoir of initially stationary liquid water at room temperature. The flow at the inlet is 8.8 cm/s and the inner radius of the inlet tube is 2 mm, so we believe laminar flow is a very safe assumption. I was able to set up a four region problem (gas phase, heated needle, gas flow tube surrounding the needle, and water) including the incompressible Navier-Stokes equations in the gas and liquid and heat transfer in all 4 regions (see the attached image). I'm using the RZ INS equations in this case.\n\nI'd like to see how the flow induced in the liquid water will affect the temperature distribution and, eventually, evaporation from the liquid.  Right now I'm simply setting the radial component of the velocities equal to each other at the interface and setting the z-component to zero, but I believe a better no slip boundary condition would be equal stress terms at the gas-liquid interface based on this paper: https://iopscience.iop.org/article/10.1088/0022-3727/48/42/424007/meta\nFollowing the Moose INS paper published a couple years ago (https://www.sciencedirect.com/science/article/pii/S0965997817310591) I think this would require an Interface Kernel with the (-p I + \\mu \\nabla \\vec{u}) terms set equal to each other on either side of the interface. I couldn't find anything like this in the INS tests.  I guess this can be split into three questions:\n\nAm I interpreting an \"equal stress\" interfacial condition correctly?\nDoes anything like this exist in Moose?\nIf not, how difficult would it be to implement?\n\nEDIT:\nI was able to run these simulations by setting the y component of the velocity equal to zero at the water interface and setting no BC on the x component of velocity. (Previously I was setting vel_x equal at the interface.) I applied no interfacial BC for the pressure or temperature. The idea was that setting no BC on an interface will enforce natural continuity conditions since the variables vel_x, vel_y, p, and T exist in both blocks. I think that's true with temperature, but I have no idea what setting no interfacial condition means for velocity or pressure.\nThe results seem much more reasonable than before and qualitatively the velocity profiles in the gas and liquid look like I would expect, but I'm still not confident that I am enforcing the correct boundary conditions here. What would a continuity of normal and shear stress interfacial condition look like in Moose?",
          "url": "https://github.com/idaholab/moose/discussions/17220",
          "updatedAt": "2022-07-07T12:33:42Z",
          "publishedAt": "2021-03-03T23:31:07Z",
          "category": {
            "name": "Q&A Modules: Navier-Stokes"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "GiudGiud"
                  },
                  "bodyText": "Hello\nSorry we missed this. Your edit made it pop back up on our radar.\nA few questions about what you are trying to do:\n\nare you going to track the two species (argon and H2O) in the gaseous domain?\nare you still trying to model the movement of the water-gas interface? Or are you satisfied with vy=0 ?\n\nI dont think anyone has done this in MOOSE yet, but the community is large so I may just be unaware.\nMaking an interface kernel that sets the terms to be equal would not be hard to do.\nBest,\nGuillaume",
                  "url": "https://github.com/idaholab/moose/discussions/17220#discussioncomment-805225",
                  "updatedAt": "2022-07-07T12:35:13Z",
                  "publishedAt": "2021-05-31T04:49:34Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "keniley1"
                          },
                          "bodyText": "Thanks for the reply!\n\nare you going to track the two species (argon and H2O) in the gaseous domain?\n\nNo, I am only interested in the velocity and temperature profiles in both regions at the moment.\n\nare you still trying to model the movement of the water-gas interface? Or are you satisfied with vy=0 ?\n\nThe inlet speed is quite low and the flow is laminar so I am content with a static surface, vy = 0. I would definitely be interested to see how I could deal with surface deformation in the future though.\n-Shane",
                          "url": "https://github.com/idaholab/moose/discussions/17220#discussioncomment-806824",
                          "updatedAt": "2022-07-07T12:35:23Z",
                          "publishedAt": "2021-05-31T13:06:31Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "Hi Shane\nOk single species should be easier. We are adding multi-species transport to our finite volume Navier Stokes implementation, but it's not quite ready yet. We won't be developing species tracking in FE afaik.\nSurface deformation is actually quite tricky. I don't think it's impossible, but we have added capabilities for fluid-structure interaction, not fluid-fluid interaction.\nI think an interface kernel is the right object to model an equal stress boundary, and it should not be too hard to do. Whether it's the correct thing to do, I think it makes physical sense to have continuity of the stresses.\nYou already did an integration by parts on this term and are looking at the surface contribution right?\nWhat family of variables are you using? Are you sure you want no-slip BCs (=continuous velocities)? It seems to me like the gas would flow faster than the fluid.\nGuillaume",
                          "url": "https://github.com/idaholab/moose/discussions/17220#discussioncomment-818952",
                          "updatedAt": "2022-07-07T12:35:23Z",
                          "publishedAt": "2021-06-03T05:18:09Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "keniley1"
                          },
                          "bodyText": "You already did an integration by parts on this term and are looking at the surface contribution right?\n\nPressure is integrated by parts, if that's what you mean. All I did was apply the INS kernels in RZ coordinates (INSMassRZ, INSMomentumLaplaceFormRZ, and INSTemperature). What I'm trying to do is set the appropriate boundary condition for two immiscible liquids. That should be continuity of normal and shear stresses across the interface but I have no idea how to actually create that condition. (I agree that it would be an interface kernel, though.)\n\nWhat family of variables are you using?\n\nI am using second order lagrange variables for the velocity and temperature and first order lagrange for pressure. integrate_p_by_parts is set to true.\n\nAre you sure you want no-slip BCs (=continuous velocities)? It seems to me like the gas would flow faster than the fluid.\n\nI am not applying no slip BCs on the interface anymore. Now only vel_y components are zero at the interface, but no condition is applied for vel_x. As you say, the gas should be moving quite a bit faster than the liquid. That was actually the point that led to this question!\nRight now I have variables p, vel_x, and vel_y, and T which all exist in both gas and liquid blocks, and I set no interfacial conditions for vel_x or pressure. With these conditions the results look qualitatively good -- the gas is moving much faster than the liquid and a convective cell forms in the water. Even so, I am just not convinced that continuity of normal and shear stress is being properly enforced if I set no interface condition.\nSo I guess my question now is: what would a stress continuity interface kernel look like?  I believe the stress component is\npI - \\mu \\grad u\nbut this forms a tensor, and I cannot figure out how that can be applied in an interface kernel.\nI've created a branch with a couple input files to demonstrate what I'm doing, if that would help. I'm running these in another Moose app (zapdos), but they only use Moose kernels so the input files should run anywhere with heat conduction and navier stokes modules. They are in zapdos/problems/cfd_tests in this branch:\nhttps://github.com/keniley1/zapdos/tree/cfd_interface_tests\nThe pin_water.i file is the geometry I presented above. The two_fluid_pipe.i file is a simpler steady problem consisting of two immiscible fluids driven by a pressure differential through a pipe.",
                          "url": "https://github.com/idaholab/moose/discussions/17220#discussioncomment-821199",
                          "updatedAt": "2022-07-07T12:35:27Z",
                          "publishedAt": "2021-06-03T14:42:22Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "I think using this continuous variable family defined over both domains will impose continuity of velocity and pressure, which is not what you want.\nI think you should have two sets of variables defined on each domain, with pretty much the same kernels but different material properties.\nThe connection between the two domain could then be done with an interface kernel. The interface kernel would impose the stress continuity as a constraint, normal and tangeantial components, with a Lagrange multiplier (one for each maybe?).\nWhat do you think about this?\nI'm not very familiar with FE interface kernels. We'll have to tag more expert people later on",
                          "url": "https://github.com/idaholab/moose/discussions/17220#discussioncomment-824350",
                          "updatedAt": "2022-07-11T12:27:04Z",
                          "publishedAt": "2021-06-04T05:48:52Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "keniley1"
                          },
                          "bodyText": "I'm not sure how to apply Lagrange multipliers here or how it would apply to stress conservation, but I'm willing to learn and try it out!\nAt any rate, I decided to try to go forward with an InterfaceKernel. I just brute forced it so the code is hideous, but I basically just computed each component of the 2D stress tensor by hand and set the \"Element\" stress component equal to the \"Neighbor\" stress component (and vice-versa). This requires applying only two interface kernels, one for each velocity component. I really didn't think this would work because I cannot wrap my head around the idea of a tensor interface condition, but to my surprise, this gave me the correct analytical solution for the pipe flow problem I uploaded. I also needed to use MatchedValueBC to force the velocities to be equal at the interface. I believe that makes sense.\nI've attached plots of (a) the 2D x-velocity profile, and (b) 1D x-velocity profiles in the two regions. In (b), the black curve is the numerical solution and red dotted curve is the analytical one. I got the analytical solution from Bird's book Transport Phenomena (2nd edition, section 2.5, \"Flow of Two Adjacent Immiscible Fluids\").  The interface kernel is called \"StressContinuity\" and is in the branch I linked to previously.  I used an ADInterfaceKernel so I didn't have to bother with jacobians. The percent difference from the analytical solution is basically 0.\nParameters:\nPipe length - 1\nPipe width - 0.25\npressure difference - 10\nBlock 0 (bottom) -  \\mu = 3, \\rho = 2\nBlock 1 (top) - \\mu = 1, \\rho = 1\nEven more surprising: this is the exact same solution that I get when I keep the single continuous variable across both regions. This makes no sense to me because I totally agreed with you -- I didn't think using a continuous variable would apply the correct interfacial condition. Apparently it does. I have no idea how this works!",
                          "url": "https://github.com/idaholab/moose/discussions/17220#discussioncomment-827165",
                          "updatedAt": "2022-07-11T12:27:04Z",
                          "publishedAt": "2021-06-04T18:59:11Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "Well if you force variable continuity, and use the same kernels, and essentially have the same contributions to the residual from the interface kernels as you would from kernels (this part I am unsure, it feels like with variable continuity you may have done that), then it's re-assuring that you got the same solution with two variables defined on each part of the domain and with one variable defined on the whole domain.\nSo the benchmark has continuous velocities. Do you think this should apply to the gas-liquid case too?",
                          "url": "https://github.com/idaholab/moose/discussions/17220#discussioncomment-832970",
                          "updatedAt": "2022-07-11T12:27:07Z",
                          "publishedAt": "2021-06-07T04:08:25Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "keniley1"
                          },
                          "bodyText": "I believe so, yes. It's certainly an approximation, but the flow in my problem is laminar, no surface deformation is observed in the experiment, and the gas is nonreactive (it's an argon environment over liquid water) so I think the immiscible fluid assumption still holds. The continuous velocities with equal stress tensors has also been used in a similar problems in the past (see this paper), so there's a precedent. I guess this question is answered!  Thanks for the advice.\nIf there is any interest in having a stress continuity interface kernel in Moose I would not mind generalizing the one I made to 3D and submitting a PR. That said, I'm not sure if it has any use since it appears to be equivalent to using a single velocity vector.",
                          "url": "https://github.com/idaholab/moose/discussions/17220#discussioncomment-835189",
                          "updatedAt": "2022-07-11T12:27:07Z",
                          "publishedAt": "2021-06-07T14:25:05Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "May 2021 News",
          "author": {
            "login": "aeslaughter"
          },
          "bodyText": "May 2021 News",
          "url": "https://github.com/idaholab/moose/discussions/18019",
          "updatedAt": "2021-06-07T14:23:47Z",
          "publishedAt": "2021-06-07T14:23:23Z",
          "category": {
            "name": "News"
          },
          "comments": {
            "edges": []
          }
        }
      },
      {
        "node": {
          "title": "Question on coupling between phase field and tensor mechanics",
          "author": {
            "login": "JingShuShi"
          },
          "bodyText": "Dear MOOSE team,\nI have few general questions regarding the coupling between phase field and tensor mechanics:\nBy default, a single phase field simulation uses Eulerian/spatial meshes that don't deform, while a single tensor mechanics simulation uses Lagrangian/material meshes that will deform. When they are coupled together, which mesh type is used?\nIf the material meshes are used, how do we think about the mass conservation in a coupled RVE? For instance, if we have solid and gas phases in a RVE, the solid will flow in/out of the domain due to the mass diffusion, thus the total mass can not be conserved inside the RVE, which gives problem justifying the mass periodicity at the boundary.\nIf spatial meshes are used, how do the meshes deform? Or how do phase field variables influence the traction at the boundary?\nHope you could give me some insights/hints to the questions. Thanks in advance.\nBest regards,\nHao",
          "url": "https://github.com/idaholab/moose/discussions/17919",
          "updatedAt": "2022-06-08T15:51:08Z",
          "publishedAt": "2021-05-25T12:43:59Z",
          "category": {
            "name": "Q&A Modules: Phase field"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "jiangwen84"
                  },
                  "bodyText": "Can you formulate your phase field equations on a deformed configuration? You can potentially solve phase field equations on a deformed mesh by setting use_displaced_mesh = true.",
                  "url": "https://github.com/idaholab/moose/discussions/17919#discussioncomment-783477",
                  "updatedAt": "2022-06-08T15:51:23Z",
                  "publishedAt": "2021-05-25T21:49:48Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "hugary1995"
                          },
                          "bodyText": "I think it depends on the phase field model. If his phase field describes an Eulerian interface, then he has to use some Eulerian-Lagrangian methods to couple with tensor_mechanics. If his phase field is Lagrangian, there is no issue.\nI doubt this is related to use_displaced_mesh.",
                          "url": "https://github.com/idaholab/moose/discussions/17919#discussioncomment-785754",
                          "updatedAt": "2022-06-08T15:51:23Z",
                          "publishedAt": "2021-05-26T11:16:05Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "JingShuShi"
                          },
                          "bodyText": "@hugary1995 I am thinking of solid diffusion in a polycrystalline structure/RVE, where grains are diffusing by concentration field and moving as a rigid body at the same time. The diffusional interface is by default a Lagrangian problem, but to formulate and track this interface this would be very cumbersome and time consuming. Whereas phase field approach bring this problem into Eulerian description and avoid tracking the interface specifically. Please correct me if my thoughts are off somewhere...\n@jiangwen84 I noticed  use_displaced_mesh can be used in tensor mechanics, but not sure how this will affect the coupling.\nMy key problem is in thinking through how the phase field simulation can change the RVE volume via diffusion and advection, i.e., boundaries deforms according to phase field variables, such that I don't need to think of remeshing every timestep to find where the boundary sits, then we could evaluate properties with the right RVE volume. Then I got stuck in this Eulerian-Lagrangian RVE setting...",
                          "url": "https://github.com/idaholab/moose/discussions/17919#discussioncomment-785939",
                          "updatedAt": "2022-06-08T15:51:25Z",
                          "publishedAt": "2021-05-26T12:05:17Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "SudiptaBiswas"
                          },
                          "bodyText": "You shouldn't need use_displaced_mesh = true unless you have large deformation. For small deformations, we have coupled phase-field with mechanics without any issues.\nWhich phase-field model are you using?  In general, phase-field does not change the volume and you shouldn't need to track the interface. Maybe explain what you are trying to do in a bit more detail.",
                          "url": "https://github.com/idaholab/moose/discussions/17919#discussioncomment-787620",
                          "updatedAt": "2022-06-08T15:51:40Z",
                          "publishedAt": "2021-05-26T17:40:49Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "JingShuShi"
                          },
                          "bodyText": "Okay, I want to simulate the densification in a solid state free sintering with a RVE, then we could apply mechanical loads with different micro-structure at different densities to check homogenized mechanical properties. If I consider free sintering without external load in a periodic RVE, there are in general two ways to achieve densification: 1. fix domain and let mass flow into this domain at the boundary; 2. keep total solid mass constant and shrink the total domain volume. As material will flow/move inside the domain due to diffusion and advection, the domain boundary should also move accordingly. This is where I got into Eulerian-Lagrangian settings of the RVE. But you pointed out in general the phase-field does not change the volume, would it still be possible to achieve densification using the phase-field method?",
                          "url": "https://github.com/idaholab/moose/discussions/17919#discussioncomment-790794",
                          "updatedAt": "2022-06-22T00:03:28Z",
                          "publishedAt": "2021-05-27T08:04:26Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "SudiptaBiswas"
                          },
                          "bodyText": "The densification from a phase-field sintering simulation is calculated in terms of the reduction in free surfaces and/or internal porosity. You can find some of our sintering work in the following papers,\nhttps://www.sciencedirect.com/science/article/pii/S2352431616300438\nhttps://link.springer.com/article/10.1007/s10853-017-1846-3\nhttps://www.sciencedirect.com/science/article/pii/S0927025619305877",
                          "url": "https://github.com/idaholab/moose/discussions/17919#discussioncomment-799989",
                          "updatedAt": "2022-06-22T00:03:28Z",
                          "publishedAt": "2021-05-28T23:31:31Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "JingShuShi"
                          },
                          "bodyText": "Thanks for sharing the interesting papers, they are really helpful. In the first two papers, the mechanical loads are applied to the boundary with prescribed displacements instead of the traction boundary with fixed loads, the solid and void phases are lumped together like a composite material and the composite elasticity tensor is used in the mechanical equilibrium calculation. If one uses the stress at the boundary instead, would it lead to some convergence problem like mesh distortion as void phase has very low elasticity so they could not carry any loads? In your second paper, the last figure with 2 particles deforming in 3D looks very nice, but they deform so much at the end and would small deformation assumption still be valid there?\nThe last paper gives a good overview on the density evaluation methods during sintering, the MC algorithm to evaluate the relative density seems to be a good approach. But all the methods need a post-process step and seem difficult to correlate to homogenization. If one wants to shrink the domain with a global strain that corresponds to local particle movements, how would you suggest to achieve this in MOOSE?",
                          "url": "https://github.com/idaholab/moose/discussions/17919#discussioncomment-803906",
                          "updatedAt": "2022-06-22T00:03:29Z",
                          "publishedAt": "2021-05-30T15:59:19Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "SudiptaBiswas"
                          },
                          "bodyText": "Yes, instead of the applied displacement, you can use the pressure boundary condition. To avoid numerical issues, you will have to assign a small non-zero stiffness for the void.  Yes, in the 3D example, the deformation was kept within the elastic limit.\nYou can change the volume of an RVE using the GlobalStrain approach. See here, https://www.sciencedirect.com/science/article/pii/S0168874X20301165",
                          "url": "https://github.com/idaholab/moose/discussions/17919#discussioncomment-811781",
                          "updatedAt": "2022-06-22T00:03:59Z",
                          "publishedAt": "2021-06-01T16:04:07Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "JingShuShi"
                          },
                          "bodyText": "Yes, I get you applied small non-zero stiffness for the void phase, the only thing I am still puzzling is that when you apply a pressure load on the top of a 2D domain with particles in the center and not touching the boundary, the void phase will take the load first and deform, then transfer to solid phase. If the void stiffness is very small, the deformation on void elements will be much larger than on solid phase, or in other words, void phase could not take any loads, only solid phase can, how is the problem overcome in this setting? Maybe I misunderstood how the two phase composite works in mechanical module...\nThe second paper looks very promising, is there a way to correlate particle rigid body motion to the GlobalStrain? Because in all the paper it clearly stated that rigid body motion is the key point to the volume shrinkage during sintering... If this feature is not there, maybe I could contribute in developing it, then I probably will need more help/guidance from the expert like you.",
                          "url": "https://github.com/idaholab/moose/discussions/17919#discussioncomment-814829",
                          "updatedAt": "2022-06-22T00:04:21Z",
                          "publishedAt": "2021-06-02T09:09:53Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "SudiptaBiswas"
                          },
                          "bodyText": "The stiffness of the void was selected in a way to avoid such issues. Also, for small displacement problems, the calculation is done on the undisplaced mesh. No, GlobalStrain has not been connected to rigid-body motion.",
                          "url": "https://github.com/idaholab/moose/discussions/17919#discussioncomment-821741",
                          "updatedAt": "2022-06-22T00:04:57Z",
                          "publishedAt": "2021-06-03T16:26:20Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "JingShuShi"
                          },
                          "bodyText": "Thanks for explanations, maybe connecting rigid-body motion with GlobalStrain is a way out to my problem, it will be a GlobalStrain only coming from stress free rigid-body motion, or purely due to diffusion induced rigid-body motion, how would you suggest to do this in MOOSE?",
                          "url": "https://github.com/idaholab/moose/discussions/17919#discussioncomment-833717",
                          "updatedAt": "2022-06-22T00:04:57Z",
                          "publishedAt": "2021-06-07T08:22:54Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "hydraulic-head gradient (initial condition)",
          "author": {
            "login": "Traiwit"
          },
          "bodyText": "Hi guys,\nI am trying to set a hydraulic-head gradient on 3D geometry, is there any simple method to work around this.\nI tried to set the side boundary with different gradients but that doesn't give me the results I want (I want it to follow the red line as attached).\nThank you guys.\n@WilkAndy I think you are the expert on this topic, you might be able to quickly help, thanks!\nKind regards,\nTraiwit\n[ICs]\n  [./porepressure]\n    type = FunctionIC\n    variable = porepressure\n    function = ini_pp\n  [../]\n[]\n\n[BCs]\n     [./pp_z2]\n       type = DirichletBC\n       variable = porepressure\n       boundary = 'back'\n       value = -9810000\n     [../]\n     [./pp_z1]\n       type = DirichletBC\n       variable = porepressure\n       boundary = 'front'\n       value = 0\n     [../]\n     [./water_grad_x1]\n       type = FunctionDirichletBC\n       variable = porepressure\n       boundary = 'bottom'\n       function = watergradx1\n     [../]\n     [./water_grad_x2]\n       type = FunctionDirichletBC\n       variable = porepressure\n       boundary = 'top'\n       function = watergradx2\n     [../]\n[]\n\n[Functions]\n  [./ini_pp]\n    type = PiecewiseLinear\n    axis = z\n      x = '0 900 1000'\n      y = '-9810000 0 0'\n  [../]\n  [./watergradx1]\n    type = PiecewiseLinear\n    axis = z\n    x = '0 900 1000'\n    y = '-9810000 0 0'\n  [../]\n  [./watergradx2]\n    type = PiecewiseLinear\n    axis = z\n    x = '0 700 1000'\n    y = '-9810000 0 0'\n  [../]\n[]",
          "url": "https://github.com/idaholab/moose/discussions/18014",
          "updatedAt": "2023-03-12T18:19:41Z",
          "publishedAt": "2021-06-07T01:55:48Z",
          "category": {
            "name": "Q&A Modules: General"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "Traiwit"
                  },
                  "bodyText": "okay guys, think about it again, this is physically impossible, since the fluid level probs should be controlled by Pc. Moreover, the fluid contact in the same hydraulic system should be flat.",
                  "url": "https://github.com/idaholab/moose/discussions/18014#discussioncomment-832815",
                  "updatedAt": "2023-07-20T13:55:59Z",
                  "publishedAt": "2021-06-07T02:40:06Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "author": {
                    "login": "WilkAndy"
                  },
                  "bodyText": "In steady-state, given the same BCs on all the vertical sides of the model (eg, hydrostatic) this head configuration is impossible, as you note.  However , these types of hydraulic gradients are always observed in nature.  This is usually because of some sort of recharge that is happening at y=-big (in your model) - often in some nearby mountain range - and discharge that is happening at y=big (in your model) - often in a valley or floodplain or ocean, etc - along with an aquitard \"cap\" in the model domain that prevents vertical movement of water to the topography.\nTo get this initial condition in a model can be difficult or hard, depending on how you approach the problem.  You can take the hard route by extending your model domain so it includes the recharge and discharge points, and running a sequence of models with different recharge/discharge and hydraulic properties until your model matches observations.  This is possibly the \"best\" type of modelling approach since it most strongly suggests you've got a model that reflects reality.  However, doing the calibration to observation is rather time consuming, and often when you extend the model you're encountered with a bunch of unknowns, which makes your model \"weaker\" since you have to somehow prescribe hydraulic properties, lithologies, recharge zones, etc, that you don't know anything much about.\nInstead, you often simply fix the BCs such that the steady-state matches your observations, without worrying too much about why or how those boundary conditions arise.  Of course, this would be inappropriate if the observations have been influenced by recent water abstractions (in this case, the BCs might be simple hydrostatic, but the ICs would be what you describe).  In MOOSE, you could useFunctions to define these BCs and ICs.  I often use a ParsedFuntion, and always try to use only 1 or a small number of such Functions (e.g. use the same function in all BCs and ICs).  Throughout the aquifers you can assume hydrostatic, unless it disagrees with observations.  These hydrostatic lines \"jump\" as you go through the aquitards.   I hope you understand what i mean: as you move vertically the porepressure (or head) looks like a lightning bolt: \u26a1 .\na",
                  "url": "https://github.com/idaholab/moose/discussions/18014#discussioncomment-832942",
                  "updatedAt": "2023-07-20T13:56:10Z",
                  "publishedAt": "2021-06-07T03:55:48Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "Traiwit"
                          },
                          "bodyText": "Noted, thank you @WilkAndy,\nMay I have a quick question about the excavation with hydro.\nHow do I let the pore-pressure of the excavated block = 0, it seems that I cannot control it via [Materials] block like Young modulus.\nFrom your coal-mining problem, I see you control it with the Sink term (but that is at the boundary)\nI am not sure if it's possible to do the same in the middle of the geometry.\nKind regards,\nTraiwit\n  [./roof_porepressure]\n    type = PorousFlowPiecewiseLinearSink\n    variable = porepressure\n    pt_vals = '-1E3 1E3'\n    multipliers = '-1 1'\n    fluid_phase = 0\n    flux_function = roof_conductance\n    boundary = roof\n  [../]\n\n  [./roof_conductance]\n    type = ParsedFunction\n    vars = 'end_t ymin ymax   maxval minval'\n    vals = '0.5   0    1000.0 1E7      0'\n    value = 'if(y<ymin+(ymax-ymin)*min(t/end_t,1),maxval,minval)'\n  [../]",
                          "url": "https://github.com/idaholab/moose/discussions/18014#discussioncomment-832966",
                          "updatedAt": "2023-07-20T13:56:11Z",
                          "publishedAt": "2021-06-07T04:04:03Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "WilkAndy"
                          },
                          "bodyText": "Why do you care about the porepressure in an excavated block, since it has been removed from your model?",
                          "url": "https://github.com/idaholab/moose/discussions/18014#discussioncomment-832972",
                          "updatedAt": "2023-07-20T13:56:12Z",
                          "publishedAt": "2021-06-07T04:09:11Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "Traiwit"
                          },
                          "bodyText": "true that's a very valid point, so basically I should just set porepressure BC around the excavated block to be 0 to model the movement of the fluid after excavation.\nThanks again @WilkAndy",
                          "url": "https://github.com/idaholab/moose/discussions/18014#discussioncomment-832988",
                          "updatedAt": "2023-08-04T08:53:40Z",
                          "publishedAt": "2021-06-07T04:13:51Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "WilkAndy"
                          },
                          "bodyText": "Yep, a DirichletBC or FunctionDirichletBC will do nicely, i think.   (The advantage of the PorousFlowPiecewiseLinearSink is that you have a bit more control on how much water is coming into the excavation, but DirichletBC will be fine for you.)",
                          "url": "https://github.com/idaholab/moose/discussions/18014#discussioncomment-833000",
                          "updatedAt": "2023-08-04T08:53:41Z",
                          "publishedAt": "2021-06-07T04:19:20Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "Traiwit"
                          },
                          "bodyText": "Perfect got it, thanks again @WilkAndy\n\n  [add_side_sets_block6]\n    type = SideSetsAroundSubdomainGenerator\n    block = 6\n    input = add_side_sets\n    normals = '0  0  1\n               0  1  0\n               1  0  0\n               0  0 -1\n               0 -1  0\n              -1  0  0'\n    fixed_normal = true\n    new_boundary = 'front6 top6 right6 back6 bottom6 left6'\n    variance = 0.5\n  []\n\n  [./water_grad_block6]\n            type = FunctionDirichletBC\n            variable = porepressure\n            boundary = 'front6 top6 right6 back6 bottom6 left6'\n            function = pp_block6\n  [../]\n\n[./pp_block6]\n    type = ParsedFunction\n  value = 'if(t>2,0,-9.81*1000*(1000-z))'\n  [../]",
                          "url": "https://github.com/idaholab/moose/discussions/18014#discussioncomment-833184",
                          "updatedAt": "2023-08-04T08:53:41Z",
                          "publishedAt": "2021-06-07T05:44:50Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "Error in loading Microstructure from Dream.3D",
          "author": {
            "login": "KamalnathOSU"
          },
          "bodyText": "Dear MOOSE team,\nI tried to load the polycrystal microstructure from Dream.3D to perform grain growth simulation. But I am getting an error. Do you know how to resolve this error.\nDream.3D Export:\n\nHere is my input file moose input script: grain_growth.i.txt\nAnd the Dream.3D microstructure file: grain_size10.txt\nThis is my error\n*** Warning, This code is deprecated and will be removed in future versions:\nEBSDMesh is deprecated, please use the EBSDMeshGenerator instead. For example:\n\n[Mesh]\n  type = EBDSMesh\n  filename = my_ebsd_data.dat\n[]\n\nbecomes\n\n[Mesh]\n  [ebsd_mesh]\n    type = EBDSMeshGenerator\n    filename = my_ebsd_data.dat\n  []\n[]\nStack frames: 14\n0: libMesh::print_trace(std::ostream&)\n1: void moose::internal::mooseDeprecatedStream<ConsoleStream const, char const (&) [238]>(ConsoleStream const&, bool, char const (&) [238])\n2: EBSDMesh::EBSDMesh(InputParameters const&)\n3: std::shared_ptr<MooseObject> moose::internal::buildObj<EBSDMesh>(InputParameters const&)\n4: Factory::create(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, InputParameters&, unsigned int, bool)\n5: SetupMeshAction::act()\n6: Action::timedAct()\n7: ActionWarehouse::executeActionsWithAction(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)\n8: ActionWarehouse::executeAllActions()\n9: MooseApp::runInputFile()\n10: MooseApp::run()\n11: ../.././bull-opt() [0x40272c]\n12: __libc_start_main\n13: ../.././bull-opt() [0x40296e]\n\nUniformly refining mesh                                                                    [  1.00 s]\n\n\n*** ERROR ***\nThe following error occurred in the object \"ebsd_reader\", of type \"EBSDReader\".\n\nData points must be on the interior of the mesh elements. In EBSDReader ebsd_reader\n\nStack frames: 18\n0: libMesh::print_trace(std::ostream&)\n1: moose::internal::mooseErrorRaw(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)\n2: callMooseErrorRaw(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&, MooseApp*)\n3: void MooseObject::mooseError<char const (&) [73], std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&>(char const (&) [73], std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) const\n4: EBSDReader::indexFromPoint(libMesh::Point const&) const\n5: EBSDReader::readFile()\n6: EBSDReader::EBSDReader(InputParameters const&)\n7: std::shared_ptr<MooseObject> moose::internal::buildObj<EBSDReader>(InputParameters const&)\n8: Factory::create(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, InputParameters&, unsigned int, bool)\n9: FEProblemBase::addUserObject(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, InputParameters&)\n10: Action::timedAct()\n11: ActionWarehouse::executeActionsWithAction(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)\n12: ActionWarehouse::executeAllActions()\n13: MooseApp::runInputFile()\n14: MooseApp::run()\n15: ../.././bull-opt() [0x40272c]\n16: __libc_start_main\n17: ../.././bull-opt() [0x40296e]\napplication called MPI_Abort(MPI_COMM_WORLD, 1) - process 0\n[unset]: write_line error; fd=-1 buf=:cmd=abort exitcode=1\n:\nsystem msg for write_line failure : Bad file descriptor\n\n\nRegards,\nKamal",
          "url": "https://github.com/idaholab/moose/discussions/17440",
          "updatedAt": "2022-06-16T12:30:44Z",
          "publishedAt": "2021-03-28T02:56:11Z",
          "category": {
            "name": "Q&A Modules: Phase field"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "KamalnathOSU"
                  },
                  "bodyText": "I also tried to update the mesh type to \"EBSDMeshGenerator\" but it gave another error saying that the \"init_mesh\" is not a registered task.",
                  "url": "https://github.com/idaholab/moose/discussions/17440#discussioncomment-539767",
                  "updatedAt": "2022-06-16T12:31:21Z",
                  "publishedAt": "2021-03-28T02:57:48Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "permcody"
                          },
                          "bodyText": "I think that particular error message may be out of date (also an issue, but a separate one from this): Try changing your block to this (e.g. drop that middle layer of nesting)\n[Mesh]\n    type = EBDSMeshGenerator\n    filename = my_ebsd_data.dat\n[]\n\nIf this fixes the intermediate error, please let us know so we can update the error message to be more useful.",
                          "url": "https://github.com/idaholab/moose/discussions/17440#discussioncomment-560258",
                          "updatedAt": "2022-06-16T12:31:21Z",
                          "publishedAt": "2021-04-01T21:28:08Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "KamalnathOSU"
                          },
                          "bodyText": "Hi !\nSorry to respond late. I was on holidays.\nNo. it does not fix the error.",
                          "url": "https://github.com/idaholab/moose/discussions/17440#discussioncomment-593199",
                          "updatedAt": "2022-06-16T12:31:23Z",
                          "publishedAt": "2021-04-10T05:42:06Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              },
              {
                "node": {
                  "author": {
                    "login": "laagesen"
                  },
                  "bodyText": "I believe I ran into this error a few years ago. I have some notes on it at the office but since we are working from home I don't have access to it. If I remember right, the problem comes from an error in how Dream3D writes data out. As you see in grain_size10.txt, it puts the data points on x=-32, y=-32 etc. This sits right on top of the boundaries of the elements, which is what the error message is saying. I believe I was able to work around this by changing X_MIN, Y_MIN, Z_MIN, X_MAX, Y_MAX, Z_MAX manually in the text file so they did not align exactly with the locations of the data points.",
                  "url": "https://github.com/idaholab/moose/discussions/17440#discussioncomment-545492",
                  "updatedAt": "2022-06-16T12:31:23Z",
                  "publishedAt": "2021-03-29T20:20:42Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "author": {
                    "login": "KamalnathOSU"
                  },
                  "bodyText": "So, If I make  X_MIN=-32.0001, will it work ? Also, Each data-point from Dream.3D will taken as a nodal data point. Or Each data-point in Dream.3D will taken as elemental point in MOOSE.\n\nThanks,\nKamal\n\u2026\n________________________________\nFrom: Larry Aagesen ***@***.***>\nSent: Monday, March 29, 2021 4:20 PM\nTo: idaholab/moose ***@***.***>\nCc: Kadirvel, Kamal ***@***.***>; Author ***@***.***>\nSubject: Re: [idaholab/moose] Error in loading Microstructure from Dream.3D (#17440)\n\n\nI believe I ran into this error a few years ago. I have some notes on it at the office but since we are working from home I don't have access to it. If I remember right, the problem comes from an error in how Dream3D writes data out. As you see in grain_size10.txt, it puts the data points on x=-32, y=-32 etc. This sits right on top of the boundaries of the elements, which is what the error message is saying. I believe I was able to work around this by changing X_MIN, Y_MIN, Z_MIN, X_MAX, Y_MAX, Z_MAX manually in the text file so they did not align exactly with the locations of the data points.\n\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub<https://urldefense.com/v3/__https://github.com/idaholab/moose/discussions/17440*discussioncomment-545492__;Iw!!KGKeukY!nbFVmDHLvuy-J5BfPP6MHX1pdtZkkM9DBTc1X_w_ZHIVPW7RNqFDw4JBf3LLO9tEmSWCg-_A2KI$>, or unsubscribe<https://urldefense.com/v3/__https://github.com/notifications/unsubscribe-auth/AIUJ4LMJL6PJYNWQ46V2JCDTGDOKTANCNFSM4Z5R2KZQ__;!!KGKeukY!nbFVmDHLvuy-J5BfPP6MHX1pdtZkkM9DBTc1X_w_ZHIVPW7RNqFDw4JBf3LLO9tEmSWClIk2Ic8$>.",
                  "url": "https://github.com/idaholab/moose/discussions/17440#discussioncomment-545562",
                  "updatedAt": "2022-06-16T12:31:23Z",
                  "publishedAt": "2021-03-29T20:34:31Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "laagesen"
                          },
                          "bodyText": "I think I actually shifted everything by -0.5. But changing to X_MIN=-32.0001 X_MAX=31.9999 would probably also work. Give it a try",
                          "url": "https://github.com/idaholab/moose/discussions/17440#discussioncomment-545598",
                          "updatedAt": "2022-06-16T12:32:04Z",
                          "publishedAt": "2021-03-29T20:43:17Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "permcody"
                          },
                          "bodyText": "I'm not very familiar with Dream3D, but I've worked quite a bit with the EBSD data that it produces. I believe the reader that we have generates the mesh to line up at nodes (not elements). You can see that here:\n\n  \n    \n      moose/modules/phase_field/src/meshgenerators/EBSDMeshGenerator.C\n    \n    \n         Line 144\n      in\n      c9c0f8f\n    \n  \n  \n    \n\n        \n          \n           _xmax = nr[0] * _geometry.d[0] + _geometry.min[0]; \n        \n    \n  \n\n\nThe EBSD reader code is fairly straight forward in that we grab all of the geometry information from the EBSD data file itself to build the mesh. We have a few examples of working EBSD meshes checked in that you can review for how it works:\nhttps://github.com/idaholab/moose/blob/next/modules/phase_field/test/tests/grain_tracker_test/test.txt",
                          "url": "https://github.com/idaholab/moose/discussions/17440#discussioncomment-560293",
                          "updatedAt": "2022-06-16T12:32:01Z",
                          "publishedAt": "2021-04-01T21:36:53Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "KamalnathOSU"
                          },
                          "bodyText": "Thank you very much for your inputs. after shifting everything to -0.5, it works fine.",
                          "url": "https://github.com/idaholab/moose/discussions/17440#discussioncomment-593200",
                          "updatedAt": "2022-06-16T12:32:02Z",
                          "publishedAt": "2021-04-10T05:43:00Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              },
              {
                "node": {
                  "author": {
                    "login": "zengfy-hust"
                  },
                  "bodyText": "can you please provide the dream3d pipline of your grain_size_10.txt file ? I tried to make a similar test just like yours ,but the feature id is mach more than 200 and my sever not calculate .",
                  "url": "https://github.com/idaholab/moose/discussions/17440#discussioncomment-832888",
                  "updatedAt": "2022-06-16T12:32:01Z",
                  "publishedAt": "2021-06-07T03:26:10Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": []
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "Error Executing an Input File (Tutorial 01)",
          "author": {
            "login": "rl3fz"
          },
          "bodyText": "Hello everyone, I'm on Step 2 of the tutorial, and after following the instructions to execute the  'pressure_diffusion.i' file, I keep getting:\n*** ERROR ***\nUnable to open file ... Check to make sure that it exists and that you have read permission.\nI've tried the other execution methods listed, I've googled around, and I've changed permissions for both the file and the folder it belongs to, but nothing seems to work. I also tried putting it in the simple_diffusion folder from the previous example, but I just received a different error.\nAny advice would be greatly appreciated.",
          "url": "https://github.com/idaholab/moose/discussions/18011",
          "updatedAt": "2022-06-23T15:14:09Z",
          "publishedAt": "2021-06-04T23:17:28Z",
          "category": {
            "name": "Q&A Getting Started"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "GiudGiud"
                  },
                  "bodyText": "Hello\nCan you please paste the command you are running and the content of the directory with the permissions (ls -l)\nBest,\nGuillaume",
                  "url": "https://github.com/idaholab/moose/discussions/18011#discussioncomment-827858",
                  "updatedAt": "2022-06-23T15:14:11Z",
                  "publishedAt": "2021-06-04T23:37:54Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "rl3fz"
                          },
                          "bodyText": "command: ../babbler-opt -i pressure_diffusion.i\ncontents and permissions: pressure_diffusion.i  pressure_diffusion.i.txt\nSorry if the permissions aren't there- I'm using Windows, and the most analogous commands I could find were 'dir' and 'ls', which gave me the same list",
                          "url": "https://github.com/idaholab/moose/discussions/18011#discussioncomment-827894",
                          "updatedAt": "2022-06-23T15:14:13Z",
                          "publishedAt": "2021-06-05T00:02:50Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "You mean Windows Subsystem for Linux right?\nIf you have ls, you could try ls -l",
                          "url": "https://github.com/idaholab/moose/discussions/18011#discussioncomment-828003",
                          "updatedAt": "2022-06-23T15:14:13Z",
                          "publishedAt": "2021-06-05T01:24:41Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "rl3fz"
                          },
                          "bodyText": "Yes, thank you; it gave me the following:\ntotal 8\n---------- 1 rl3fz rl3fz 1497 Jun  3 15:24 pressure_diffusion.i\n---------- 1 rl3fz rl3fz 1550 Jun  4 18:17 pressure_diffusion.i.txt",
                          "url": "https://github.com/idaholab/moose/discussions/18011#discussioncomment-829424",
                          "updatedAt": "2022-06-23T15:14:14Z",
                          "publishedAt": "2021-06-05T15:59:28Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "-------- means you have no permissions over these files. It should look something like -rw-rw-r-- giving you and your user group the right to write and read those files.\nSo could you please use chmod +rw pressure_diffusion* then report back\n-the ls -l output\n-whether you can run the input file now",
                          "url": "https://github.com/idaholab/moose/discussions/18011#discussioncomment-829454",
                          "updatedAt": "2022-11-21T14:43:56Z",
                          "publishedAt": "2021-06-05T16:11:24Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "rl3fz"
                          },
                          "bodyText": "ls -l output:\n-rw-r--r-- 1 rl3fz rl3fz 1497 Jun  3 15:24 pressure_diffusion.i\n-rw-r--r-- 1 rl3fz rl3fz 1550 Jun  4 18:17 pressure_diffusion.i.txt\nAnd it worked! Solve Converged! Thank you very much!",
                          "url": "https://github.com/idaholab/moose/discussions/18011#discussioncomment-829624",
                          "updatedAt": "2022-11-21T14:44:00Z",
                          "publishedAt": "2021-06-05T17:40:54Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              },
              {
                "node": {
                  "author": {
                    "login": "GiudGiud"
                  },
                  "bodyText": "Note that a common reason for permissions to be broken in WSL is that you are editing these files, then saving them, from a Windows text editor. I am not sure what the fix is. It's actually working fine on my machine with Atom.",
                  "url": "https://github.com/idaholab/moose/discussions/18011#discussioncomment-829468",
                  "updatedAt": "2022-11-21T14:44:07Z",
                  "publishedAt": "2021-06-05T16:13:28Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": []
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "Libmesh error",
          "author": {
            "login": "hsheldon"
          },
          "bodyText": "I'm getting this error while trying to build libmesh:\nerror: invalid conversion from \u2018MPI_Comm {aka ompi_communicator_t*}\u2019 to \u2018TIMPI::communicator {aka int}\u2019 [-fpermissive]\nthis->_comm->get() = PETSC_COMM_SELF;\nAny suggestions what could be causing this? I've not had this problem previously.",
          "url": "https://github.com/idaholab/moose/discussions/18008",
          "updatedAt": "2022-06-30T14:43:37Z",
          "publishedAt": "2021-06-04T04:38:52Z",
          "category": {
            "name": "Q&A General"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "hsheldon"
                  },
                  "bodyText": "Ignore that, looks like a module wasn't loaded. Seems to be fixed now.",
                  "url": "https://github.com/idaholab/moose/discussions/18008#discussioncomment-824374",
                  "updatedAt": "2022-06-30T14:43:37Z",
                  "publishedAt": "2021-06-04T05:55:04Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": []
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "MOOSE compiling error: \u2018MPI_Comm\u2019 does not name a type",
          "author": {
            "login": "wuwenkun"
          },
          "bodyText": "Dear all,\nI was trying to compile MOOSE on an HPC cluster but after doing \"make -j 4\" in the test folder I got the following:\nUsing HIT from /home/wuw/projects/moose/framework/contrib/hit\nRebuilding symlinks in /home/wuw/projects/moose/framework/build/header_symlinks\nRebuilding symlinks in /home/wuw/projects/moose/test/build/header_symlinks\nChecking if header needs updating: /home/wuw/projects/moose/framework/include/base/MooseRevision.h...\nCreating Unity Directory /home/wuw/projects/moose/framework/build/unity_src\nCopying default MOOSE configuration to: /home/wuw/projects/moose/framework/include/base/MooseConfig.h...\nCompiling C++ (in opt mode) /home/wuw/projects/moose/framework/contrib/pcre/src/pcrecpp.cc...\nCompiling C++ (in opt mode) /home/wuw/projects/moose/framework/contrib/pcre/src/pcre_stringpiece.cc...\nCompiling C (in opt mode) /home/wuw/projects/moose/framework/contrib/pcre/src/pcre_version.c...\nCompiling C (in opt mode) /home/wuw/projects/moose/framework/contrib/pcre/src/pcre_config.c...\nCompiling C (in opt mode) /home/wuw/projects/moose/framework/contrib/pcre/src/pcre_tables.c...\nCompiling C (in opt mode) /home/wuw/projects/moose/framework/contrib/pcre/src/pcre_newline.c...\nCompiling C (in opt mode) /home/wuw/projects/moose/framework/contrib/pcre/src/pcre_fullinfo.c...\nCompiling C (in opt mode) /home/wuw/projects/moose/framework/contrib/pcre/src/pcre_valid_utf8.c...\nCompiling C (in opt mode) /home/wuw/projects/moose/framework/contrib/pcre/src/pcre_string_utils.c...\nCompiling C (in opt mode) /home/wuw/projects/moose/framework/contrib/pcre/src/pcre_globals.c...\nCompiling C (in opt mode) /home/wuw/projects/moose/framework/contrib/pcre/src/pcre_study.c...\nCompiling C (in opt mode) /home/wuw/projects/moose/framework/contrib/pcre/src/pcre_ord2utf8.c...\nCompiling C (in opt mode) /home/wuw/projects/moose/framework/contrib/pcre/src/pcre_maketables.c...\nCompiling C (in opt mode) /home/wuw/projects/moose/framework/contrib/pcre/src/pcre_jit_compile.c...\nCompiling C (in opt mode) /home/wuw/projects/moose/framework/contrib/pcre/src/pcre_dfa_exec.c...\nCompiling C (in opt mode) /home/wuw/projects/moose/framework/contrib/pcre/src/pcre_exec.c...\nCompiling C (in opt mode) /home/wuw/projects/moose/framework/contrib/pcre/src/pcre_chartables.c...\nCompiling C (in opt mode) /home/wuw/projects/moose/framework/contrib/pcre/src/pcre_compile.c...\nCompiling C (in opt mode) /home/wuw/projects/moose/framework/contrib/pcre/src/pcre_ucd.c...\nCompiling C (in opt mode) /home/wuw/projects/moose/framework/contrib/pcre/src/pcre_byte_order.c...\nCompiling C (in opt mode) /home/wuw/projects/moose/framework/contrib/pcre/src/pcre_xclass.c...\nCompiling C (in opt mode) /home/wuw/projects/moose/framework/contrib/pcre/src/pcre_get.c...\nCompiling C (in opt mode) /home/wuw/projects/moose/framework/contrib/pcre/src/pcre_refcount.c...\nCompiling C++ (in opt mode) /home/wuw/projects/moose/framework/contrib/gtest/gtest-all.cc...\nCompiling C++ (in opt mode) /home/wuw/projects/moose/framework/contrib/hit/parse.cc...\nCompiling C++ (in opt mode) /home/wuw/projects/moose/framework/contrib/hit/lex.cc...\nCompiling C++ (in opt mode) /home/wuw/projects/moose/framework/contrib/hit/braceexpr.cc...\nBuilding and linking /home/wuw/projects/moose/framework/contrib/hit/hit.so...\nCompiling C++ (in opt mode) /home/wuw/projects/moose/framework/contrib/exodiff/exodiff.C...\nCompiling C++ (in opt mode) /home/wuw/projects/moose/framework/contrib/exodiff/exo_entity.C...\nCompiling C++ (in opt mode) /home/wuw/projects/moose/framework/contrib/exodiff/side_set.C...\nCompiling C++ (in opt mode) /home/wuw/projects/moose/framework/contrib/exodiff/STRINGLIB_tokenize.C...\nCompiling C++ (in opt mode) /home/wuw/projects/moose/framework/contrib/exodiff/iqsort.C...\nCompiling C++ (in opt mode) /home/wuw/projects/moose/framework/contrib/exodiff/map.C...\nCompiling C++ (in opt mode) /home/wuw/projects/moose/framework/contrib/exodiff/add_to_log.C...\nCompiling C++ (in opt mode) /home/wuw/projects/moose/framework/contrib/exodiff/exo_block.C...\nCompiling C++ (in opt mode) /home/wuw/projects/moose/framework/contrib/exodiff/ED_SystemInterface.C...\nCompiling C++ (in opt mode) /home/wuw/projects/moose/framework/contrib/exodiff/FileInfo.C...\nCompiling C++ (in opt mode) /home/wuw/projects/moose/framework/contrib/exodiff/SL_tokenize.C...\nCompiling C++ (in opt mode) /home/wuw/projects/moose/framework/contrib/exodiff/check.C...\nCompiling C++ (in opt mode) /home/wuw/projects/moose/framework/contrib/exodiff/Tolerance.C...\nCompiling C++ (in opt mode) /home/wuw/projects/moose/framework/contrib/exodiff/create_file.C...\nCompiling C++ (in opt mode) /home/wuw/projects/moose/framework/contrib/exodiff/stringx.C...\nCompiling C++ (in opt mode) /home/wuw/projects/moose/framework/contrib/exodiff/GetLongOpt.C...\nCompiling C++ (in opt mode) /home/wuw/projects/moose/framework/contrib/exodiff/node_set.C...\nCompiling C++ (in opt mode) /home/wuw/projects/moose/framework/contrib/exodiff/util.C...\nCompiling C++ (in opt mode) /home/wuw/projects/moose/framework/contrib/exodiff/exoII_read.C...\nCreating Unity Directory /home/wuw/projects/moose/test/build/unity_src\nCreating Unity /home/wuw/projects/moose/framework/build/unity_src/src_Unity.C\nSymlinking MOOSE configure /home/wuw/projects/moose/framework/build/header_symlinks/MooseConfig.h\nCreating Unity /home/wuw/projects/moose/framework/build/unity_src/outputs_Unity.C\nCreating Unity /home/wuw/projects/moose/framework/build/unity_src/outputs_png_Unity.C\nCreating Unity /home/wuw/projects/moose/framework/build/unity_src/outputs_formatters_Unity.C\nCreating Unity /home/wuw/projects/moose/framework/build/unity_src/controls_Unity.C\nCreating Unity /home/wuw/projects/moose/framework/build/unity_src/reporters_Unity.C\nCreating Unity /home/wuw/projects/moose/framework/build/unity_src/timeintegrators_Unity.C\nCreating Unity /home/wuw/projects/moose/framework/build/unity_src/fvbcs_Unity.C\nCreating Unity /home/wuw/projects/moose/framework/build/unity_src/meshgenerators_Unity.C\nCreating Unity /home/wuw/projects/moose/framework/build/unity_src/relationshipmanagers_Unity.C\nCreating Unity /home/wuw/projects/moose/framework/build/unity_src/vectorpostprocessors_Unity.C\nCreating Unity /home/wuw/projects/moose/framework/build/unity_src/problems_Unity.C\nCreating Unity /home/wuw/projects/moose/framework/build/unity_src/partitioner_Unity.C\nCreating Unity /home/wuw/projects/moose/framework/build/unity_src/timesteppers_Unity.C\nCreating Unity /home/wuw/projects/moose/framework/build/unity_src/auxkernels_Unity.C\nCreating Unity /home/wuw/projects/moose/framework/build/unity_src/fviks_Unity.C\nCreating Unity /home/wuw/projects/moose/framework/build/unity_src/predictors_Unity.C\nCreating Unity /home/wuw/projects/moose/framework/build/unity_src/constraints_Unity.C\nCreating Unity /home/wuw/projects/moose/framework/build/unity_src/transfers_Unity.C\nCreating Unity /home/wuw/projects/moose/framework/build/unity_src/bcs_Unity.C\nCreating Unity /home/wuw/projects/moose/framework/build/unity_src/interfacekernels_Unity.C\nCreating Unity /home/wuw/projects/moose/framework/build/unity_src/interfaces_Unity.C\nCreating Unity /home/wuw/projects/moose/framework/build/unity_src/dgkernels_Unity.C\nCreating Unity /home/wuw/projects/moose/framework/build/unity_src/markers_Unity.C\nCreating Unity /home/wuw/projects/moose/framework/build/unity_src/dampers_Unity.C\nCreating Unity /home/wuw/projects/moose/framework/build/unity_src/linesearches_Unity.C\nCreating Unity /home/wuw/projects/moose/framework/build/unity_src/preconditioners_Unity.C\nCreating Unity /home/wuw/projects/moose/framework/build/unity_src/executioners_Unity.C\nCreating Unity /home/wuw/projects/moose/framework/build/unity_src/materials_Unity.C\nCreating Unity /home/wuw/projects/moose/framework/build/unity_src/geomsearch_Unity.C\nCreating Unity /home/wuw/projects/moose/framework/build/unity_src/systems_Unity.C\nCreating Unity /home/wuw/projects/moose/framework/build/unity_src/multiapps_Unity.C\nCreating Unity /home/wuw/projects/moose/framework/build/unity_src/postprocessors_Unity.C\nCreating Unity /home/wuw/projects/moose/framework/build/unity_src/actions_Unity.C\nCreating Unity /home/wuw/projects/moose/framework/build/unity_src/functions_Unity.C\nCreating Unity /home/wuw/projects/moose/framework/build/unity_src/indicators_Unity.C\nCreating Unity /home/wuw/projects/moose/framework/build/unity_src/userobject_Unity.C\nCreating Unity /home/wuw/projects/moose/framework/build/unity_src/loops_Unity.C\nCreating Unity /home/wuw/projects/moose/framework/build/unity_src/nodalkernels_Unity.C\nCreating Unity /home/wuw/projects/moose/framework/build/unity_src/variables_Unity.C\nCreating Unity /home/wuw/projects/moose/framework/build/unity_src/fvkernels_Unity.C\nCreating Unity /home/wuw/projects/moose/framework/build/unity_src/dirackernels_Unity.C\nCreating Unity /home/wuw/projects/moose/framework/build/unity_src/distributions_Unity.C\nCreating Unity /home/wuw/projects/moose/framework/build/unity_src/ics_Unity.C\nCreating Unity /home/wuw/projects/moose/framework/build/unity_src/mesh_Unity.C\nCreating Unity /home/wuw/projects/moose/framework/build/unity_src/kernels_Unity.C\nCreating Unity /home/wuw/projects/moose/framework/build/unity_src/parser_Unity.C\nCreating Unity /home/wuw/projects/moose/framework/build/unity_src/restart_Unity.C\nCreating Unity /home/wuw/projects/moose/framework/build/unity_src/samplers_Unity.C\nCreating Unity /home/wuw/projects/moose/framework/build/unity_src/splits_Unity.C\nCompiling C++ (in opt mode) /home/wuw/projects/moose/framework/src/utils/PerfGraph.C...\nCompiling C++ (in opt mode) /home/wuw/projects/moose/framework/src/utils/PetscDMMoose.C...\nCompiling C++ (in opt mode) /home/wuw/projects/moose/framework/src/utils/MooseEnumBase.C...\nCompiling C++ (in opt mode) /home/wuw/projects/moose/framework/src/utils/FileLineInfo.C...\nCompiling C++ (in opt mode) /home/wuw/projects/moose/framework/src/utils/ExecFlagEnum.C...\nIn file included from /home/wuw/projects/moose/framework/build/header_symlinks/MooseTypes.h:12,\nfrom /home/wuw/projects/moose/framework/build/header_symlinks/PerfGraph.h:13,\nfrom /home/wuw/projects/moose/framework/src/utils/PerfGraph.C:10:\n/home/wuw/projects/moose/framework/build/header_symlinks/Moose.h:215:1: error: \u2018MPI_Comm\u2019 does not name a type\n215 | MPI_Comm swapLibMeshComm(MPI_Comm new_comm);\n| ^~~~~~~~\n/home/wuw/projects/moose/framework/build/header_symlinks/Moose.h:222:29: error: expected \u2018)\u2019 before \u2018new_comm\u2019\n222 |   ScopedCommSwapper(MPI_Comm new_comm) : _orig(swapLibMeshComm(new_comm)) {}\n|                    ~        ^~~~~~~~~\n|                             )\n/home/wuw/projects/moose/framework/build/header_symlinks/Moose.h:231:3: error: \u2018MPI_Comm\u2019 does not name a type\n231 |   MPI_Comm _orig;\n|   ^~~~~~~~\n/home/wuw/projects/moose/framework/build/header_symlinks/Moose.h: In destructor \u2018virtual Moose::ScopedCommSwapper::~ScopedCommSwapper()\u2019:\n/home/wuw/projects/moose/framework/build/header_symlinks/Moose.h:223:50: error: \u2018_orig\u2019 was not declared in this scope\n223 |   virtual ~ScopedCommSwapper() { swapLibMeshComm(_orig); }\n|                                                  ^~~~~\n/home/wuw/projects/moose/framework/build/header_symlinks/Moose.h:223:34: error: \u2018swapLibMeshComm\u2019 was not declared in this scope\n223 |   virtual ~ScopedCommSwapper() { swapLibMeshComm(_orig); }\n|                                  ^~~~~~~~~~~~~~~\n/home/wuw/projects/moose/framework/build/header_symlinks/Moose.h: In member function \u2018void Moose::ScopedCommSwapper::forceSwap()\u2019:\n/home/wuw/projects/moose/framework/build/header_symlinks/Moose.h:228:22: error: \u2018_orig\u2019 was not declared in this scope\n228 |   void forceSwap() { _orig = swapLibMeshComm(_orig); }\n|                      ^~~~~\n/home/wuw/projects/moose/framework/build/header_symlinks/Moose.h:228:30: error: \u2018swapLibMeshComm\u2019 was not declared in this scope\n228 |   void forceSwap() { _orig = swapLibMeshComm(_orig); }\n|                              ^~~~~~~~~~~~~~~\nIn file included from /home/wuw/projects/moose/framework/build/header_symlinks/MooseError.h:12,\nfrom /home/wuw/projects/moose/framework/build/header_symlinks/MooseUtils.h:16,\nfrom /home/wuw/projects/moose/framework/src/utils/MooseEnumBase.C:11:\n/home/wuw/projects/moose/framework/build/header_symlinks/Moose.h:215:1: error: \u2018MPI_Comm\u2019 does not name a type\n215 | MPI_Comm swapLibMeshComm(MPI_Comm new_comm);\n| ^~~~~~~~\n/home/wuw/projects/moose/framework/build/header_symlinks/Moose.h:222:29: error: expected \u2018)\u2019 before \u2018new_comm\u2019\n222 |   ScopedCommSwapper(MPI_Comm new_comm) : _orig(swapLibMeshComm(new_comm)) {}\n|                    ~        ^~~~~~~~~\n|                             )\n/home/wuw/projects/moose/framework/build/header_symlinks/Moose.h:231:3: error: \u2018MPI_Comm\u2019 does not name a type\n231 |   MPI_Comm _orig;\n|   ^~~~~~~~\n/home/wuw/projects/moose/framework/build/header_symlinks/Moose.h: In destructor \u2018virtual Moose::ScopedCommSwapper::~ScopedCommSwapper()\u2019:\n/home/wuw/projects/moose/framework/build/header_symlinks/Moose.h:223:50: error: \u2018_orig\u2019 was not declared in this scope\n223 |   virtual ~ScopedCommSwapper() { swapLibMeshComm(_orig); }\n|                                                  ^~~~~\n/home/wuw/projects/moose/framework/build/header_symlinks/Moose.h:223:34: error: \u2018swapLibMeshComm\u2019 was not declared in this scope\n223 |   virtual ~ScopedCommSwapper() { swapLibMeshComm(_orig); }\n|                                  ^~~~~~~~~~~~~~~\n/home/wuw/projects/moose/framework/build/header_symlinks/Moose.h: In member function \u2018void Moose::ScopedCommSwapper::forceSwap()\u2019:\n/home/wuw/projects/moose/framework/build/header_symlinks/Moose.h:228:22: error: \u2018_orig\u2019 was not declared in this scope\n228 |   void forceSwap() { _orig = swapLibMeshComm(_orig); }\n|                      ^~~~~\n/home/wuw/projects/moose/framework/build/header_symlinks/Moose.h:228:30: error: \u2018swapLibMeshComm\u2019 was not declared in this scope\n228 |   void forceSwap() { _orig = swapLibMeshComm(_orig); }\n|                              ^~~~~~~~~~~~~~~\nIn file included from /home/wuw/projects/moose/framework/build/header_symlinks/MultiMooseEnum.h:13,\nfrom /home/wuw/projects/moose/framework/build/header_symlinks/ExecFlagEnum.h:13,\nfrom /home/wuw/projects/moose/framework/src/utils/ExecFlagEnum.C:10:\n/home/wuw/projects/moose/framework/build/header_symlinks/Moose.h:215:1: error: \u2018MPI_Comm\u2019 does not name a type\n215 | MPI_Comm swapLibMeshComm(MPI_Comm new_comm);\n| ^~~~~~~~\n/home/wuw/projects/moose/framework/build/header_symlinks/Moose.h:222:29: error: expected \u2018)\u2019 before \u2018new_comm\u2019\n222 |   ScopedCommSwapper(MPI_Comm new_comm) : _orig(swapLibMeshComm(new_comm)) {}\n|                    ~        ^~~~~~~~~\n|                             )\n/home/wuw/projects/moose/framework/build/header_symlinks/Moose.h:231:3: error: \u2018MPI_Comm\u2019 does not name a type\n231 |   MPI_Comm _orig;\n|   ^~~~~~~~\n/home/wuw/projects/moose/framework/build/header_symlinks/Moose.h: In destructor \u2018virtual Moose::ScopedCommSwapper::~ScopedCommSwapper()\u2019:\n/home/wuw/projects/moose/framework/build/header_symlinks/Moose.h:223:50: error: \u2018_orig\u2019 was not declared in this scope\n223 |   virtual ~ScopedCommSwapper() { swapLibMeshComm(_orig); }\n|                                                  ^~~~~\n/home/wuw/projects/moose/framework/build/header_symlinks/Moose.h:223:34: error: \u2018swapLibMeshComm\u2019 was not declared in this scope\n223 |   virtual ~ScopedCommSwapper() { swapLibMeshComm(_orig); }\n|                                  ^~~~~~~~~~~~~~~\n/home/wuw/projects/moose/framework/build/header_symlinks/Moose.h: In member function \u2018void Moose::ScopedCommSwapper::forceSwap()\u2019:\n/home/wuw/projects/moose/framework/build/header_symlinks/Moose.h:228:22: error: \u2018_orig\u2019 was not declared in this scope\n228 |   void forceSwap() { _orig = swapLibMeshComm(_orig); }\n|                      ^~~~~\n/home/wuw/projects/moose/framework/build/header_symlinks/Moose.h:228:30: error: \u2018swapLibMeshComm\u2019 was not declared in this scope\n228 |   void forceSwap() { _orig = swapLibMeshComm(_orig); }\n|                              ^~~~~~~~~~~~~~~\nmake: *** [/home/wuw/projects/moose/framework/src/utils/ExecFlagEnum.x86_64-pc-linux-gnu.opt.lo] Error 1\nmake: *** Waiting for unfinished jobs....\nmake: *** [/home/wuw/projects/moose/framework/src/utils/MooseEnumBase.x86_64-pc-linux-gnu.opt.lo] Error 1\nmake: *** [/home/wuw/projects/moose/framework/src/utils/PerfGraph.x86_64-pc-linux-gnu.opt.lo] Error 1\nThe modules that I am using are:\n\nStdEnv   2) cmake/3.14.2-gvwazz3   3) valgrind/3.13.0   4) intel-oneapi/2021.2.0.2883   5) gcc/9.2.0-pkmzczt\n\nPython libraries are not included because I was told that intel-oneapi includes them from the intel python distribution.\nI have also attached the log files here. I would really appreciate if you could give me some suggestions on how to fix it.\nRegards,\nWenkun\nconfig.log\nlibmesh_diagnostic.log",
          "url": "https://github.com/idaholab/moose/discussions/17961",
          "updatedAt": "2022-06-10T20:16:52Z",
          "publishedAt": "2021-05-29T03:06:17Z",
          "category": {
            "name": "Q&A Getting Started"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "GiudGiud"
                  },
                  "bodyText": "Hi Wenkun\nIt looks like the compiler is not finding MPI. Could you please try loading an MPI library (maybe a module, mpich, mvapich, openmpi etc) that was build using intel-oneapi?\n@milljm @permcody anyone you know using intel oneapi for moose?\nBest,\nGuillaume",
                  "url": "https://github.com/idaholab/moose/discussions/17961#discussioncomment-805214",
                  "updatedAt": "2022-06-10T20:16:56Z",
                  "publishedAt": "2021-05-31T04:41:55Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "rrezakhani"
                          },
                          "bodyText": "Hi Guillaume,\nI am getting similar error when trying to compile moose tests. Here is the first error:\n#=======================================================================================\nUsing HIT from /home/rr262/projects/raccoon/moose/moosetools/contrib/hit\nCompiling C++ (in opt mode) /home/rr262/projects/raccoon/moose/framework/build/unity_src/transfers_Unity.C...\nIn file included from /home/rr262/projects/raccoon/moose/framework/build/header_symlinks/MooseTypes.h:12,\nfrom /home/rr262/projects/raccoon/moose/framework/build/header_symlinks/DataIO.h:14,\nfrom /home/rr262/projects/raccoon/moose/framework/build/header_symlinks/RestartableData.h:13,\nfrom /home/rr262/projects/raccoon/moose/framework/build/header_symlinks/ReporterData.h:12,\nfrom /home/rr262/projects/raccoon/moose/framework/build/header_symlinks/ReporterTransferInterface.h:12,\nfrom /home/rr262/projects/raccoon/moose/framework/build/header_symlinks/MultiAppCloneReporterTransfer.h:11,\nfrom /home/rr262/projects/raccoon/moose/framework/src/transfers/MultiAppCloneReporterTransfer.C:10,\nfrom /home/rr262/projects/raccoon/moose/framework/build/unity_src/transfers_Unity.C:2:\n/home/rr262/projects/raccoon/moose/framework/build/header_symlinks/Moose.h:215:1: error: 'MPI_Comm' does not name a type\n215 | MPI_Comm swapLibMeshComm(MPI_Comm new_comm);\n#=======================================================================================\nI have the modules I used to compile petsc and libmesh loaded here:\n\nshared   2) DefaultModules   3) cpu/0.15.4   4) gcc/10.2.0   5) python/3.8.5   6) cmake/3.18.2   7) slurm/expanse/20.02.3   8) mvapich2/2.3.4\n\nWenkun, did you figure out the problem?\nCheers,\nRoozbeh",
                          "url": "https://github.com/idaholab/moose/discussions/17961#discussioncomment-808118",
                          "updatedAt": "2022-06-10T20:16:56Z",
                          "publishedAt": "2021-05-31T18:17:59Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "wuwenkun"
                          },
                          "bodyText": "Hi Guillaume,\nI load a set of new modules as following and restarted from building PETSc:\n\nStdEnv               3) mvapich2/2.3.4-blues-lf335hv   5) intel-oneapi/2021.2.0.2883\ngcc/10.2.0-z53hda3   4) cmake/3.18.4-fygx2f7           6) valgrind/3.13.0\n\nThis time it got stuck at \"Configuring SUPERLU_DIST with cmake; this may take several minutes\"... I have actually waited for a few hours before I force quit the compiling. Not sure which of the modules messed something up...\nRegards,\nWenkun",
                          "url": "https://github.com/idaholab/moose/discussions/17961#discussioncomment-808949",
                          "updatedAt": "2022-06-10T20:16:56Z",
                          "publishedAt": "2021-06-01T00:51:05Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "@rrezakhani can you check which compiler is being used? You should be using the mpi-wrapped compilers, not the vanilla one.\n@wuwenkun I havent seen anyone having issues installing superlu yet. Could you please try again?\nAre you using the update_and_rebuild_petsc script? If so, you could just comment out the --download-super_dist=1\\ line",
                          "url": "https://github.com/idaholab/moose/discussions/17961#discussioncomment-809022",
                          "updatedAt": "2022-06-10T20:17:00Z",
                          "publishedAt": "2021-06-01T01:34:07Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "wuwenkun"
                          },
                          "bodyText": "@GiudGiud I tried but it still stuck at the same place. I did what you suggested and commented out the superlu package download and it did help finish building PETSc. However, I have the following error when I tested if PETSc was correctly installed:\nRunning check examples to verify correct installation\nUsing PETSC_DIR=/home/wuw/projects/moose/scripts/../petsc and PETSC_ARCH=arch-moose\nPossible error running C/C++ src/snes/tutorials/ex19 with 1 MPI process\nSee http://www.mcs.anl.gov/petsc/documentation/faq.html\n[mpiexec@blueslogin3] wait_proxies_to_terminate (../../../../../src/pm/i_hydra/mpiexec/intel/i_mpiexec.c:542): downstream from host blueslogin3 was killed by signal 11 (Segmentation fault)\n[mpiexec@blueslogin3] main (../../../../../src/pm/i_hydra/mpiexec/mpiexec.c:2118): assert (pg->intel.exitcodes != NULL) failed\nPossible error running C/C++ src/snes/tutorials/ex19 with 2 MPI processes\nSee http://www.mcs.anl.gov/petsc/documentation/faq.html\n[mpiexec@blueslogin3] wait_proxies_to_terminate (../../../../../src/pm/i_hydra/mpiexec/intel/i_mpiexec.c:542): downstream from host blueslogin3 was killed by signal 11 (Segmentation fault)\n[mpiexec@blueslogin3] main (../../../../../src/pm/i_hydra/mpiexec/mpiexec.c:2118): assert (pg->intel.exitcodes != NULL) failed\n1,5c1,2\n< lid velocity = 0.0016, prandtl # = 1., grashof # = 1.\n<   0 SNES Function norm 0.0406612\n<   1 SNES Function norm 4.12227e-06\n<   2 SNES Function norm 6.098e-11\n< Number of SNES iterations = 2\n\n[mpiexec@blueslogin3] wait_proxies_to_terminate (../../../../../src/pm/i_hydra/mpiexec/intel/i_mpiexec.c:542): downstream from host blueslogin3 was killed by signal 11 (Segmentation fault)\n[mpiexec@blueslogin3] main (../../../../../src/pm/i_hydra/mpiexec/mpiexec.c:2118): assert (pg->intel.exitcodes != NULL) failed\n/home/wuw/projects/moose/petsc/src/snes/tutorials\nPossible problem with ex19 running with hypre, diffs above\n=========================================\n1,9c1,2\n< lid velocity = 0.0625, prandtl # = 1., grashof # = 1.\n<   0 SNES Function norm 0.239155\n<     0 KSP Residual norm 0.235858\n<     1 KSP Residual norm < 1.e-11\n<   1 SNES Function norm 6.81968e-05\n<     0 KSP Residual norm 2.30906e-05\n<     1 KSP Residual norm < 1.e-11\n<   2 SNES Function norm < 1.e-11\n< Number of SNES iterations = 2\n\n\n\n[mpiexec@blueslogin3] wait_proxies_to_terminate (../../../../../src/pm/i_hydra/mpiexec/intel/i_mpiexec.c:542): downstream from host blueslogin3 was killed by signal 11 (Segmentation fault)\n[mpiexec@blueslogin3] main (../../../../../src/pm/i_hydra/mpiexec/mpiexec.c:2118): assert (pg->intel.exitcodes != NULL) failed\n/home/wuw/projects/moose/petsc/src/snes/tutorials\nPossible problem with ex19 running with mumps, diffs above\n=========================================\nCompleted test examples\n\nI will try a different combination of modules and see how things will go. Again thanks for your patient advice.\nRegards,\nWenkun",
                          "url": "https://github.com/idaholab/moose/discussions/17961#discussioncomment-811772",
                          "updatedAt": "2022-06-23T08:48:39Z",
                          "publishedAt": "2021-06-01T16:01:31Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "wuwenkun"
                          },
                          "bodyText": "Another try with\n\nStdEnv      3) intel-oneapi/2021.2.0.2883   5) cmake/3.14.2-gvwazz3\ngcc/7.4.0   4) mvapich2/2.3-blues-hgzwj2b   6) valgrind/3.13.0\n\nPETSc installation went through but got stuck at building libmesh:\n\n----------- Configuring libMesh -------------\nchecking build system type... x86_64-pc-linux-gnu\nchecking host system type... x86_64-pc-linux-gnu\nchecking target system type... x86_64-pc-linux-gnu\nchecking for a BSD-compatible install... /home/wuw/projects/moose/scripts/../libmesh/build-aux/install-sh -C\nchecking whether build environment is sane... yes\nchecking for a thread-safe mkdir -p... /usr/bin/mkdir -p\nchecking for gawk... gawk\nchecking whether make sets $(MAKE)... yes\nchecking whether make supports nested variables... yes\nchecking whether UID '8998' is supported by ustar format... yes\nchecking whether GID '20001' is supported by ustar format... yes\nchecking how to create a ustar tar archive... gnutar\nchecking whether make supports nested variables... (cached) yes\nchecking whether to enable maintainer-specific portions of Makefiles... no\nchecking for src/base/libmesh.C... no\n<<< Configuring build directory for VPATH build >>>\nchecking for perl... /usr/bin/perl\nnote: MPI library path not given...\nnote: MPI library path not given...\nchecking whether make supports the include directive... yes (GNU style)\nchecking whether the C compiler works... yes\nchecking for C compiler default output file name... a.out\nchecking for suffix of executables...\nchecking whether we are cross compiling... no\nchecking for suffix of object files... o\nchecking whether we are using the GNU C compiler... yes\nchecking whether mpicc accepts -g... yes\nchecking for mpicc option to accept ISO C89... none needed\nchecking whether mpicc understands -c and -o together... yes\nchecking dependency style of mpicc... gcc3\nchecking whether we are using the GNU Fortran compiler... yes\nchecking whether mpif90 accepts -g... yes\nchecking whether we are using the GNU Fortran 77 compiler... yes\nchecking whether mpif77 accepts -g... yes\nchecking whether we are using the GNU C++ compiler... no\nchecking whether mipcxx accepts -g... no\nchecking dependency style of mipcxx... none\nWARNING:\n\n\n\nUnrecognized compiler: \"mipcxx\" <<<\nYou will likely need to modify\nMake.common directly to specify\nproper compiler flags\nchecking for a sed that does not truncate output... /usr/bin/sed\nchecking for C++ compiler vendor... unknown\nconfigure: Seeking a C++ standard between \"2011\" and \"2017\"\nchecking whether mipcxx supports C++17 features by default... no\nchecking whether mipcxx supports C++17 features with -std=gnu++17... no\nchecking whether mipcxx supports C++17 features with -std=gnu++1z... no\nchecking whether mipcxx supports C++17 features with -std=c++17... no\nchecking whether mipcxx supports C++17 features with +std=c++17... no\nchecking whether mipcxx supports C++17 features with -h std=c++17... no\nchecking whether mipcxx supports C++17 features with -std=c++1z... no\nchecking whether mipcxx supports C++17 features with +std=c++1z... no\nchecking whether mipcxx supports C++17 features with -h std=c++1z... no\nconfigure: No compiler with C++17 support was found\nconfigure: Did not find C++17 standard support\nchecking whether mipcxx supports C++14 features by default... no\nchecking whether mipcxx supports C++14 features with -std=gnu++14... no\nchecking whether mipcxx supports C++14 features with -std=gnu++1y... no\nchecking whether mipcxx supports C++14 features with -std=c++14... no\nchecking whether mipcxx supports C++14 features with +std=c++14... no\nchecking whether mipcxx supports C++14 features with -h std=c++14... no\nchecking whether mipcxx supports C++14 features with -std=c++1y... no\nchecking whether mipcxx supports C++14 features with +std=c++1y... no\nchecking whether mipcxx supports C++14 features with -h std=c++1y... no\nconfigure: No compiler with C++14 support was found\nconfigure: Did not find C++14 standard support\nchecking whether mipcxx supports C++11 features by default... no\nchecking whether mipcxx supports C++11 features with -std=gnu++11... no\nchecking whether mipcxx supports C++11 features with -std=gnu++0x... no\nchecking whether mipcxx supports C++11 features with -std=c++11... no\nchecking whether mipcxx supports C++11 features with +std=c++11... no\nchecking whether mipcxx supports C++11 features with -h std=c++11... no\nchecking whether mipcxx supports C++11 features with -std=c++0x... no\nchecking whether mipcxx supports C++11 features with +std=c++0x... no\nchecking whether mipcxx supports C++11 features with -h std=c++0x... no\nconfigure: error: *** A compiler with support for C++11 language features is required.\nRunning make -j 1...\nmake: *** No targets specified and no makefile found.  Stop.",
                          "url": "https://github.com/idaholab/moose/discussions/17961#discussioncomment-811973",
                          "updatedAt": "2023-03-01T03:02:20Z",
                          "publishedAt": "2021-06-01T16:47:35Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "The error message is about not having support for C++11 with your compiler.\nCan you please check that you are actuallyusing the gcc 7.4 compiler? Because it should support C++11",
                          "url": "https://github.com/idaholab/moose/discussions/17961#discussioncomment-812559",
                          "updatedAt": "2023-03-01T03:02:32Z",
                          "publishedAt": "2021-06-01T19:09:59Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "wuwenkun"
                          },
                          "bodyText": "config.log\nlibmesh_diagnostic.log\nThat was what I thought... Unfortunately I forgot to save the libmesh_diagnostic.log file first before I tried something else. I will go back and try with gcc 7.4 again. Before that please let me post another (failed) setting with log files attached. I guess this time our gcc 8.2 compiler is not working properly...\n\nStdEnv   2) intel-oneapi/2021.2.0.2883   3) cmake/3.14.2-gvwazz3   4) gcc/8.2.0-g7hppkz   5) mpich/3.3-psm-psm2-45nkyx4\n\nPETSc was built successfully. When configuring libmesh, I first got some warnings like \"comparison between pointer and zero character constant\", and finally\nlibtool: warning: '/blues/gpfs/software/centos7/spack/opt/spack/linux-centos7-x86_64/gcc-8.1.0/gcc-8.2.0-g7hppkz/lib64/../lib64/libstdc++.la' seems to be moved\n/usr/bin/ld: cannot find -liconv\ncollect2: error: ld returned 1 exit status\nmake[1]: *** [libmesh_opt.la] Error 1\nmake[1]: Leaving directory `/gpfs/fs1/home/wuw/projects/moose/libmesh/build'\nmake: *** [all-recursive] Error 1\nDo you think I should try to get rid of this intel-oneapi thing? This is what our support team has suggested me to use, it is supposed to include everything that I need like mpi and python 3.x ... But since I am including other mpi compilers anyway, if I could find a good python 3.x module I think this intel-oneapi might not be necessary... Although we only have a few options with python 3.x libraries and the odd thing is that some specific gcc compilers need to be loaded first but usually they are not working well with mpich/mvapich.... I will try to find one combination that works...\nAgain, thanks for your help Guillaume!\nRegards,\nWenkun",
                          "url": "https://github.com/idaholab/moose/discussions/17961#discussioncomment-813377",
                          "updatedAt": "2023-03-01T03:02:37Z",
                          "publishedAt": "2021-06-02T00:02:14Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "Hi Wenkun\nYou need to make sure that the MPI library you are loading has been compiled with the compiler you are trying to use.\nWhat do mpicc --version and 'gcc --version' return?\nNothing wrong with one-api a priori, but keep in mind you are loading both the gcc and the intel compilers here, so you need to be careful about consistently using the same one, and be careful about which mpi library is being used if one is included in your one-api module.\nI do not recommend loading all the intel suite just to get a python module. You can get python through anaconda.\nIf you have a support team for your cluster, I recommend they help you install moose. They will be aware of what has been loaded in each module that they created.\nGuillaume",
                          "url": "https://github.com/idaholab/moose/discussions/17961#discussioncomment-813414",
                          "updatedAt": "2023-03-01T03:03:17Z",
                          "publishedAt": "2021-06-02T00:18:47Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "wuwenkun"
                          },
                          "bodyText": "Hi Guillaume,\nI have tried to contact our support team but the only useful message from them is:\n\"I have been using the following modules to build C++11 codes.\n\nStdEnv 2) gcc/9.2.0-pkmzczt 3) intel-oneapi/2021.1.0.2659\"\n\nI have tried to follow up with them like what I did here but they are not responding to my query after :( so again I really appreciate your patience with me.\n\n\nStdEnv   2) cmake/3.14.2-gvwazz3   3) valgrind/3.13.0   4) intel-oneapi/2021.2.0.2883   5) gcc/9.2.0-pkmzczt\nmpicc --version and gcc --version both return gcc (GCC) 9.2.0\n\n\nStdEnv   2) gcc/10.2.0-z53hda3   3) mvapich2/2.3.4-blues-lf335hv   4) cmake/3.18.4-fygx2f7\nmpicc --version and gcc --version both return gcc (Spack GCC) 10.2.0\n\n\nStdEnv   2) gcc/7.4.0   3) mvapich2/2.3-blues-hgzwj2b   4) cmake/3.14.2-gvwazz3   5) valgrind/3.13.0   6) anaconda3/5.2.0\nmpicc --version and gcc --version both return gcc (GCC) 7.4.0\nI don't know why I got the the error message about not having support for C++11 with my compiler...",
                          "url": "https://github.com/idaholab/moose/discussions/17961#discussioncomment-813896",
                          "updatedAt": "2023-03-01T03:03:19Z",
                          "publishedAt": "2021-06-02T04:00:47Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "So I just learned that intel compilers are not supported by the way.\nhttps://mooseframework.inl.gov/getting_started/installation/manual_installation_gcc.html\n\n2 or 3 should all work afaik.\nWhat do the CC and CXX environment variables point to?",
                          "url": "https://github.com/idaholab/moose/discussions/17961#discussioncomment-814241",
                          "updatedAt": "2023-10-11T13:14:27Z",
                          "publishedAt": "2021-06-02T06:23:03Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              },
              {
                "node": {
                  "author": {
                    "login": "wuwenkun"
                  },
                  "bodyText": "Thanks to @GiudGiud , the problem is solved. For those who may have similar problems and don't want to go through all the replies above. A short answer for this question is to make sure that CC and CXX point to mpicc and mpicxx after you load your modules.",
                  "url": "https://github.com/idaholab/moose/discussions/17961#discussioncomment-821939",
                  "updatedAt": "2022-06-10T20:17:07Z",
                  "publishedAt": "2021-06-03T17:14:21Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": []
                  }
                }
              }
            ]
          }
        }
      }
    ]
  }
}