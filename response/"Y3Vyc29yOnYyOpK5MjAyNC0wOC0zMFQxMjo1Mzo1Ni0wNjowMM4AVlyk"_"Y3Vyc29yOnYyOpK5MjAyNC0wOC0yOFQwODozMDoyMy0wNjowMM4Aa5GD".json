{
  "discussions": {
    "pageInfo": {
      "hasNextPage": true,
      "endCursor": "Y3Vyc29yOnYyOpK5MjAyNC0wOC0yOFQwODozMDoyMy0wNjowMM4Aa5GD"
    },
    "edges": [
      {
        "node": {
          "title": "Moose installation without sudo permissions _glibc older versions",
          "author": {
            "login": "vermaprk"
          },
          "bodyText": "Check these boxes if you have followed the posting rules.\n\n Q&A General is the most appropriate section for my question\n I have consulted the posting Guidelines on the Discussions front page\n I have searched the Discussions forum and my question has not been asked before\n I have searched the MOOSE website and the documentation does not answer my question\n I have formatted my post following the posting guidelines (screenshots as a last resort, triple back quotes around pasted text)\n\nQuestion\nHello\nI recently tried to upgrade moose on my university server (without sudo permissions).\n\nCreating conda environment using conda create -n moose moose-dev=2024.08.26 mpich\ngives me error to update to update __glibc to 2.28 or higher as follow:\n\nChannels:\n - https://conda.software.inl.gov/public\n - conda-forge\nPlatform: linux-64\nCollecting package metadata (repodata.json): done\nSolving environment: failed\n\nLibMambaUnsatisfiableError: Encountered problems while solving:\n  - nothing provides __glibc >=2.28,<3.0.a0 needed by c-ares-1.33.0-ha66036c_0\n\nCould not solve for environment specs\nThe following package could not be installed\n\u2514\u2500 moose-dev 2024.08.26**  is not installable because it requires\n   \u2514\u2500 moose-peacock 2024.08.12.* , which requires\n      \u2514\u2500 moose-mpi 2024.08.12.* , which requires\n         \u2514\u2500 c-ares 1.33.0 ha66036c_0, which requires\n            \u2514\u2500 __glibc >=2.28,<3.0.a0 , which is missing on the system.\n\nUpgrading __glibc requires me to update a number of packages that is a tedious task as most of the gnu softwares installed in /bin at server is outdated.\nInstead of doing this:\nI created conda environment using\nconda create -n moose moose mpich\nSo, I get a warning during moose installation as:\nWARNING: (CondaVersionMismatch(...), \"Conda package 'moose-dev' is currently at version '2024.07.19' and the required version is '2024.08.26'.\\nThe correct version can be installed via:\\n    conda install moose-dev=2024.08.26\")\nI have ignored this warning for time being as I dont want to upgrade the __glibc right now.\nBut doing this makes me not able to run the mpiexec command for utilizing parallel processing. The error is as follow:\n\nSLURM_CLUSTER_NAME = param-shakti\nSLURM_JOB_ACCOUNT = sreerajes\nSLURM_JOB_ID = 1537885\nSLURM_JOB_NAME = tiny\nSLURM_JOB_NODELIST = cn[039-040]\nSLURM_JOB_USER = 19es92r03\nSLURM_JOB_UID = 6905\nSLURM_JOB_PARTITION = shared\nSLURM_TASK_PID = 49164\nSLURM_SUBMIT_DIR = /scratch/19es92r03/O4_progress\nSLURM_CPUS_ON_NODE = 35\nSLURM_NTASKS = 36\nSLURM_TASK_PID = 49164\n==========================================\n\n^[[33m\n*** Warning, This code is deprecated and will be removed in future versions:\n/scratch/19es92r03/O4_progress/input_original_updated.i:350: (Outputs/other/interval):\n'interval' has been deprecated and will be removed on 02/01/2025. Please use 'time_step_interval' instead.\n^[[39m\nAutoDiff exception: Unknown serialization file version (this message will only be shown once per process)\n\n^[[31m\n*** ERROR ***\nFailed to take order 1 derivative in material Mobility_coefficient^[[39m\n\nAbort(1) on node 0 (rank 0 in comm 0): application called MPI_Abort(MPI_COMM_WORLD, 1) - process 0\n\nI am in a hurry, so should I downgrade the moose version to conda compatible, or is there any other way out? Also is this parallel processing error solely due to conda and moose mismatch or some other issue ?\nThe older version of moose worked fine on multiple processing on server.\nThanks",
          "url": "https://github.com/idaholab/moose/discussions/28513",
          "updatedAt": "2024-09-01T05:16:13Z",
          "publishedAt": "2024-08-30T18:08:01Z",
          "category": {
            "name": "Q&A General"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "milljm"
                  },
                  "bodyText": "The only thing you can do in this case, is building the entire stack on your own, without the use of our Conda packages. Indeed, when running on HPC Clusters, it is more desirable not using Conda packages.\nSo in essence, you'd be doing the right thing by utilizing your cluster's native module(s) system.",
                  "url": "https://github.com/idaholab/moose/discussions/28513#discussioncomment-10502469",
                  "updatedAt": "2024-08-30T18:22:31Z",
                  "publishedAt": "2024-08-30T18:22:29Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": []
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "Restarting Simulations with Different Processor Counts in MOOSE",
          "author": {
            "login": "shrituntunroy"
          },
          "bodyText": "Hi MOOSE Team,\nI\u2019m a new MOOSE user currently learning how to work with the framework.\nI have a question about restarting a simulation in a MOOSE-based application. Specifically, I\u2019d like to know if it\u2019s possible to restart a simulation using a different number of processors than the original run.\nI\u2019m aware of the --recover option using checkpoints, which works well when the number of processors remains the same across both runs. However, I\u2019ve encountered issues when trying to restart with a different number of processors. Could you provide guidance on how to handle this situation?\nThank you for your help.",
          "url": "https://github.com/idaholab/moose/discussions/28506",
          "updatedAt": "2024-08-30T12:51:13Z",
          "publishedAt": "2024-08-30T08:10:39Z",
          "category": {
            "name": "Q&A Modules: General"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "GiudGiud"
                  },
                  "bodyText": "Hello\nWe do not support this using checkpoint.\nYou can attempt N-to-M restarts using exodus files (either as the main mesh file, or using a SolutionUserObject), but there are a number of items (stateful properties, older variable values) that will not get restarted.\nhttps://mooseframework.inl.gov/application_usage/restart_recover.html\nGuillaume",
                  "url": "https://github.com/idaholab/moose/discussions/28506#discussioncomment-10498766",
                  "updatedAt": "2024-08-30T12:51:13Z",
                  "publishedAt": "2024-08-30T12:51:13Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": []
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "Tests failing after new installation on Mac",
          "author": {
            "login": "hsheldon"
          },
          "bodyText": "Check these boxes if you have followed the posting rules.\n\n I have consulted the Posting Guidelines.\n I have searched the Discussions Forum and MOOSE Framework Troubleshooting and have not found what I was looking for\n Q&A Getting Started is the most appropriate category for my question (trouble installing, beginner user, ...)\n\nIssue or question about MOOSE\nI have removed all previous installations of Conda and MOOSE from my MacBook (M1 chip), reinstalled and built the tests. I am getting lots of failed tests, see attached log file. I have also attached the build output, which is showing some warnings. I have been through the troubleshooting page and can't find a solution. Please help!\nbuild_test_warnings.txt\ntests_failed.txt\n(Optional) code in question / simulation log / errors\nNo response\nEncountering Errors? Please include diagnostic output\n(moose) she341@COTTON-BM test % ../scripts/diagnostics.sh \n####################################################################################################\nInfluential Environment Variables\n\nCC=mpicc\nCC_FOR_BUILD=/Users/she341/miniforge/envs/moose/bin/arm64-apple-darwin20.0.0-clang\nCFLAGS=-ftree-vectorize -fPIC -fstack-protector-strong -O2 -pipe -isystem /Users/she341/miniforge/envs/moose/include\nCONDA_CHANNEL=https://conda.software.inl.gov/public\nCONDA_DEFAULT_ENV=moose\nCONDA_EXE=/Users/she341/miniforge/bin/conda\nCONDA_PREFIX=/Users/she341/miniforge/envs/moose\nCONDA_PREFIX_1=/Users/she341/miniforge\nCONDA_PROMPT_MODIFIER=(moose) \nCONDA_PYTHON_EXE=/Users/she341/miniforge/bin/python\nCONDA_SHLVL=2\nCONDA_TOOLCHAIN_BUILD=arm64-apple-darwin20.0.0\nCONDA_TOOLCHAIN_HOST=arm64-apple-darwin20.0.0\nCPPFLAGS=-D_FORTIFY_SOURCE=2 -isystem /Users/she341/miniforge/envs/moose/include\nCURL_CA_BUNDLE=\nCXX=mpicxx\nCXXFLAGS=-ftree-vectorize -fPIC -fstack-protector-strong -O2 -pipe -stdlib=libc++ -fvisibility-inlines-hidden -fmessage-length=0 -isystem /Users/she341/miniforge/envs/moose/include -std=c++17\nCXX_FOR_BUILD=/Users/she341/miniforge/envs/moose/bin/arm64-apple-darwin20.0.0-clang++\nF77=mpif77\nF90=mpif90\nF95=/Users/she341/miniforge/envs/moose/bin/arm64-apple-darwin20.0.0-gfortran\nFC=mpif90\nFC_FOR_BUILD=/Users/she341/miniforge/envs/moose/bin/arm64-apple-darwin20.0.0-gfortran\nFFLAGS=-march=armv8.3-a -ftree-vectorize -fPIC -fno-stack-protector -O2 -pipe -isystem /Users/she341/miniforge/envs/moose/include\nFI_PROVIDER=tcp\nHDF5_DIR=/Users/she341/miniforge/envs/moose\nLD=arm64-apple-darwin20.0.0-ld\nLDFLAGS=-Wl,-headerpad_max_install_names -Wl,-dead_strip_dylibs -Wl,-rpath,/Users/she341/miniforge/envs/moose/lib -L/Users/she341/miniforge/envs/moose/lib\nLDFLAGS_LD=-headerpad_max_install_names -dead_strip_dylibs -rpath /Users/she341/miniforge/envs/moose/lib -L/Users/she341/miniforge/envs/moose/lib\nLIBMESH_DIR=/Users/she341/miniforge/envs/moose/libmesh\nMOOSEPF=/Users/she341/projects/moose/modules/porous_flow/porous_flow-opt\nMOOSE_JOBS=6\nMOOSE_NO_CODESIGN=true\nPATH=/Users/she341/.local/bin:/Users/she341/miniforge/envs/moose/bin:/Users/she341/miniforge/condabin:/opt/homebrew/bin:/opt/homebrew/sbin:/usr/local/bin:/System/Cryptexes/App/usr/bin:/usr/bin:/bin:/usr/sbin:/sbin:/Library/TeX/texbin:/usr/local/laps:/usr/local/munki:/var/run/com.apple.security.cryptexd/codex.system/bootstrap/usr/local/bin:/var/run/com.apple.security.cryptexd/codex.system/bootstrap/usr/bin:/var/run/com.apple.security.cryptexd/codex.system/bootstrap/usr/appleinternal/bin:/Users/she341/miniforge/envs/moose/wasp/bin\nPETSC_DIR=/Users/she341/miniforge/envs/moose/petsc\nREQUESTS_CA_BUNDLE=\nSSL_CERT_FILE=\nWASP_DIR=/Users/she341/miniforge/envs/moose/wasp\n####################################################################################################\nCompiler(s) (CC CXX FC F77 F90):\n\nwhich $CC; /Users/she341/miniforge/envs/moose/bin/mpicc\n$CC --version; clang version 16.0.6\n$CC -show; arm64-apple-darwin20.0.0-clang -I/Users/she341/miniforge/envs/moose/include -I/Users/she341/miniforge/envs/moose/include -L/Users/she341/miniforge/envs/moose/lib -Wl,-rpath,/Users/she341/miniforge/envs/moose/lib -I/Users/she341/miniforge/envs/moose/include -L/Users/she341/miniforge/envs/moose/lib -lmpi -lpmpi\n\nwhich $CXX; /Users/she341/miniforge/envs/moose/bin/mpicxx\n$CXX --version; clang version 16.0.6\n$CXX -show; arm64-apple-darwin20.0.0-clang++ -I/Users/she341/miniforge/envs/moose/include -I/Users/she341/miniforge/envs/moose/include -L/Users/she341/miniforge/envs/moose/lib -Wl,-rpath,/Users/she341/miniforge/envs/moose/lib -I/Users/she341/miniforge/envs/moose/include -L/Users/she341/miniforge/envs/moose/lib -lmpicxx -lmpi -lpmpi\n\nwhich $FC; /Users/she341/miniforge/envs/moose/bin/mpif90\n$FC --version; GNU Fortran (GCC) 12.3.0\n$FC -show; arm64-apple-darwin20.0.0-gfortran -I/Users/she341/miniforge/envs/moose/include -L/Users/she341/miniforge/envs/moose/lib -Wl,-rpath,/Users/she341/miniforge/envs/moose/lib -I/Users/she341/miniforge/envs/moose/include -I/Users/she341/miniforge/envs/moose/include -L/Users/she341/miniforge/envs/moose/lib -lmpifort -lmpi -lpmpi\n\nwhich $F77; /Users/she341/miniforge/envs/moose/bin/mpif77\n$F77 --version; GNU Fortran (GCC) 12.3.0\n$F77 -show; arm64-apple-darwin20.0.0-gfortran -I/Users/she341/miniforge/envs/moose/include -fallow-argument-mismatch -L/Users/she341/miniforge/envs/moose/lib -Wl,-rpath,/Users/she341/miniforge/envs/moose/lib -I/Users/she341/miniforge/envs/moose/include -I/Users/she341/miniforge/envs/moose/include -L/Users/she341/miniforge/envs/moose/lib -lmpifort -lmpi -lpmpi\n\nwhich $F90; /Users/she341/miniforge/envs/moose/bin/mpif90\n$F90 --version; GNU Fortran (GCC) 12.3.0\n$F90 -show; arm64-apple-darwin20.0.0-gfortran -I/Users/she341/miniforge/envs/moose/include -L/Users/she341/miniforge/envs/moose/lib -Wl,-rpath,/Users/she341/miniforge/envs/moose/lib -I/Users/she341/miniforge/envs/moose/include -I/Users/she341/miniforge/envs/moose/include -L/Users/she341/miniforge/envs/moose/lib -lmpifort -lmpi -lpmpi\n\nOK\n####################################################################################################\nPython Sanity Checks\n\n/usr/bin/env python3 --version; (reporting as: Python 3.11.8) matches\nwhich python3 python;\n\n/Users/she341/miniforge/envs/moose/bin/python3 --version; == Python 3.11.8\n/Users/she341/miniforge/envs/moose/bin/python --version; == Python 3.11.8\n\nOK\n####################################################################################################\nPython Modules (TestHarness, run-ability)\n\nOK\n####################################################################################################\nMOOSE Repository/Conda Version Checks\n\n              Installed     Required\n\nOK\n\nchecks PASSED\n(moose) she341@COTTON-BM test %",
          "url": "https://github.com/idaholab/moose/discussions/28505",
          "updatedAt": "2024-09-01T22:25:02Z",
          "publishedAt": "2024-08-30T00:37:47Z",
          "category": {
            "name": "Q&A Getting Started"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "GiudGiud"
                  },
                  "bodyText": "Hello\nThis is a known failure. it is solved in the moose/next branch already.\nThe python package deepdiff, which we rely on for the test suite for the failing tests, was updated and performs checks differently.\nYou can safely ignore all the SCHEMADIFF failures\nGuillaume",
                  "url": "https://github.com/idaholab/moose/discussions/28505#discussioncomment-10492879",
                  "updatedAt": "2024-08-30T01:05:53Z",
                  "publishedAt": "2024-08-30T01:05:52Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "milljm"
                          },
                          "bodyText": "Also, I've pinned this issue on Discussions, with a workaround: #28494",
                          "url": "https://github.com/idaholab/moose/discussions/28505#discussioncomment-10498315",
                          "updatedAt": "2024-08-30T12:06:51Z",
                          "publishedAt": "2024-08-30T12:06:50Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "Help for building MOOSE in a offline HPC",
          "author": {
            "login": "shrituntunroy"
          },
          "bodyText": "Check these boxes if you have followed the posting rules.\n\n I have consulted the Posting Guidelines.\n I have searched the Discussions Forum and MOOSE Framework Troubleshooting and have not found what I was looking for\n Q&A Getting Started is the most appropriate category for my question (trouble installing, beginner user, ...)\n\nIssue or question about MOOSE\nHi Moose Team,\nI am a new MOOSE user and currently learning to use MOOSE. I am installing moose in a offline HPC (on which I dont have sudo access)  following this method - https://mooseframework.inl.gov/getting_started/installation/offline_installation.html\nI have already installed these offline packages in my system and they are working correctly.\nBut in the HPC, I am getting following error related to clang compiler:\n/home/lus03/vikramr/projects/moose/scripts\nINFO: Checking for HDF5...\nINFO: HDF5 library not detected, opting to download via PETSc...\n=============================================================================================\n                         Configuring PETSc to compile on your system\n=============================================================================================\nTESTING: checkCCompiler from config.setCompilers(config/BuildSystem/config/setCompilers.py:1427)\n*********************************************************************************************\n           UNABLE to CONFIGURE with GIVEN OPTIONS (see configure.log for details):\n---------------------------------------------------------------------------------------------\n             C compiler you provided with -CC= cannot be found or does not work.\n*********************************************************************************************\n\nThere was an error. Exiting...\n[vikramr@atulya335 scripts]$ module load openmpi-gcc/4.0.1\n[vikramr@atulya335 scripts]$ ./update_and_rebuild_petsc.sh --CC=$CC --CXX=$CXX --FC=$FC --with-packages-download-dir=~/projects/downloads\n/home/lus03/vikramr/projects/moose/scripts\nINFO: Checking for HDF5...\nINFO: HDF5 library not detected, opting to download via PETSc...\n=============================================================================================\n                         Configuring PETSc to compile on your system\n=============================================================================================\nTESTING: checkCCompiler from config.setCompilers(config/BuildSystem/config/setCompilers.py:1427)\n*********************************************************************************************\n           UNABLE to CONFIGURE with GIVEN OPTIONS (see configure.log for details):\n---------------------------------------------------------------------------------------------\n             C compiler you provided with -CC= cannot be found or does not work.\n*********************************************************************************************\n\nThere was an error. Exiting...\n[vikramr@atulya335 scripts]$ export CC=mpicc CXX=mpicxx FC=mpif90 F90=mpif90 F77=mpif77\n[vikramr@atulya335 scripts]$ ./update_and_rebuild_petsc.sh --CC=$CC --CXX=$CXX --FC=$FC --with-packages-download-dir=~/projects/downloads\n/home/lus03/vikramr/projects/moose/scripts\nINFO: Checking for HDF5...\nINFO: HDF5 library not detected, opting to download via PETSc...\n=============================================================================================\n                         Configuring PETSc to compile on your system\n=============================================================================================\n=============================================================================================\n                                     ***** WARNING *****\n    Found environment variable: CC=mpicc. Ignoring it, since its also set on command line\n=============================================================================================\n=============================================================================================\n                                     ***** WARNING *****\n   Found environment variable: CXX=mpicxx. Ignoring it, since its also set on command line\n=============================================================================================\n=============================================================================================\n                                     ***** WARNING *****\n    Found environment variable: FC=mpif90. Ignoring it, since its also set on command line\n=============================================================================================\n=============================================================================================\n                                     ***** WARNING *****\n  Found environment variable: F77=mpif77. Ignoring it! Use \"./configure F77=$F77\" if you\n  really want to use this value\n=============================================================================================\n=============================================================================================\n                                     ***** WARNING *****\n  Found environment variable: F90=mpif90. Ignoring it! Use \"./configure F90=$F90\" if you\n  really want to use this value\n=============================================================================================\nTESTING: checkCxxDialect from config.setCompilers(config/BuildSystem/config/setCompilers.py:773)\n*********************************************************************************************\n           UNABLE to CONFIGURE with GIVEN OPTIONS (see configure.log for details):\n---------------------------------------------------------------------------------------------\n  Using CUDA dialect C++11 as lower bound due to package(s):\n  - hypre\n  - strumpack\n  - SuperLU_DIST\n  But CUDA compiler (clang) appears non-compliant with C++11 or didn't accept:\n  - -std=gnu++20\n  - -std=c++20\n  - -std=gnu++17\n  - -std=c++17\n  - -std=gnu++14\n  - -std=c++14\n  - -std=gnu++11\n  - -std=c++11\n*********************************************************************************************\n\nThere was an error. Exiting...\n\nI have tried hiding the clang compiler by exporting the following line - export clang=0 in bashrc but still I m getting the same error.\nIn my pc I didnt had clang but still moose installed correctly\nKindly help me for resolving this error.\n(Optional) code in question / simulation log / errors\nNo response\nEncountering Errors? Please include diagnostic output\n##################################################################################################\nInfluential Environment Variables\n\nCC=mpicc\nCONDA_CHANNEL=https://conda.software.inl.gov/public\nCONDA_SHLVL=0\nCURL_CA_BUNDLE=\nCXX=mpicxx\nF77=mpif77\nF90=mpif90\nFC=mpif90\nLD_LIBRARY_PATH=/dlocal/sysapps/openmpi-gcc-4.0.1/lib64:/dlocal/sysapps/gcc-9.2.0/lib64:/dlocal/sysapps/gcc-9.2.0/lib:/home/lus03/vikramr/app/gcc/gcc1230/lib64:/home/lus03/vikramr/app/gcc/gcc1230/lib:/home/lus03/vikramr/app/gcc/mpc121/lib:/home/lus03/vikramr/app/gcc/mpfr410/lib:/home/lus03/vikramr/app/gcc/gmp621/lib:/home/lus03/vikramr/app/gcc/gcc1230/lib:/home/lus03/vikramr/app/gcc/mpc121/lib:/home/lus03/vikramr/app/gcc/mpfr410/lib:/home/lus03/vikramr/app/gcc/gmp621/lib:/home/lus03/vikramr/app/gcc/gcc1230/lib64:/home/lus03/vikramr/app/gcc/gcc1230/lib:/home/lus03/vikramr/app/gcc/mpc121/lib:/home/lus03/vikramr/app/gcc/mpfr410/lib:/home/lus03/vikramr/app/gcc/gmp621/lib:/home/lus03/vikramr/app/gcc/gcc1230/lib:/home/lus03/vikramr/app/gcc/mpc121/lib:/home/lus03/vikramr/app/gcc/mpfr410/lib:/home/lus03/vikramr/app/gcc/gmp621/lib:\nMODULESHOME=/usr/share/Modules\nMOOSE_JOBS=6\nPATH=/home/lus03/vikramr/.python3/3.7.4/bin:/dlocal/sysapps/anaconda3/2019.10/bin/:/dlocal/sysapps/openmpi-gcc-4.0.1/bin/:/dlocal/sysapps/gcc-9.2.0/bin:/home/lus03/vikramr/app/python/Python-3.8.0:/home/lus03/vikramr/app/cmake/cmake-3.28.3/bin:/home/lus03/vikramr/app/python/Python-3.8.0:/home/lus03/vikramr/app/gcc/gcc1230/bin:/home/lus03/vikramr/app/cmake/cmake-3.28.3/bin:/usr/bin:/usr/sbin:/usr/lib64/qt-3.3/bin:/usr/condabin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/usr/local/anupam:/opt/VirtualGL/bin:/opt/ibutils/bin:.:/home/lus03/vikramr/app/lammps2023/lammps-2Aug2023/src:/home/lus03/vikramr/.local/bin:/home/lus03/vikramr/bin:/home/lus03/vikramr/app/lammps2023/lammps-2Aug2023/src\nREQUESTS_CA_BUNDLE=\nSSL_CERT_FILE=\n\n##################################################################################################\nCompiler(s) (CC CXX FC F77 F90):\n\nCC=/dlocal/sysapps/openmpi-gcc-4.0.1/bin/mpicc\nCC -show:\ngcc -I/dlocal/sysapps/openmpi-gcc-4.0.1/include/openmpi -I/dlocal/sysapps/openmpi-gcc-4.0.1/include/openmpi/opal/mca/hwloc/hwloc201/hwloc/include -I/dlocal/sysapps/openmpi-gcc-4.0.1/include/openmpi/opal/mca/event/libevent2022/libevent -I/dlocal/sysapps/openmpi-gcc-4.0.1/include/openmpi/opal/mca/event/libevent2022/libevent/include -I/dlocal/sysapps/openmpi-gcc-4.0.1/include -pthread -Wl,-rpath -Wl,/dlocal/sysapps/openmpi-gcc-4.0.1/lib64 -Wl,--enable-new-dtags -L/dlocal/sysapps/openmpi-gcc-4.0.1/lib64 -lmpi\nCC version:     gcc (GCC) 9.2.0\n\nCXX=/dlocal/sysapps/openmpi-gcc-4.0.1/bin/mpicxx\nCXX -show:\ng++ -I/dlocal/sysapps/openmpi-gcc-4.0.1/include/openmpi -I/dlocal/sysapps/openmpi-gcc-4.0.1/include/openmpi/opal/mca/hwloc/hwloc201/hwloc/include -I/dlocal/sysapps/openmpi-gcc-4.0.1/include/openmpi/opal/mca/event/libevent2022/libevent -I/dlocal/sysapps/openmpi-gcc-4.0.1/include/openmpi/opal/mca/event/libevent2022/libevent/include -I/dlocal/sysapps/openmpi-gcc-4.0.1/include -pthread -Wl,-rpath -Wl,/dlocal/sysapps/openmpi-gcc-4.0.1/lib64 -Wl,--enable-new-dtags -L/dlocal/sysapps/openmpi-gcc-4.0.1/lib64 -lmpi\nCXX version:    g++ (GCC) 9.2.0\n\nFC=/dlocal/sysapps/openmpi-gcc-4.0.1/bin/mpif90\nFC -show:\ngfortran -I/dlocal/sysapps/openmpi-gcc-4.0.1/include -pthread -I/dlocal/sysapps/openmpi-gcc-4.0.1/lib64 -Wl,-rpath -Wl,/dlocal/sysapps/openmpi-gcc-4.0.1/lib64 -Wl,--enable-new-dtags -L/dlocal/sysapps/openmpi-gcc-4.0.1/lib64 -lmpi_usempi -lmpi_mpifh -lmpi\nFC version:     GNU Fortran (GCC) 9.2.0\n\nF77=/dlocal/sysapps/openmpi-gcc-4.0.1/bin/mpif77\nF77 -show:\ngfortran -I/dlocal/sysapps/openmpi-gcc-4.0.1/include -pthread -I/dlocal/sysapps/openmpi-gcc-4.0.1/lib64 -Wl,-rpath -Wl,/dlocal/sysapps/openmpi-gcc-4.0.1/lib64 -Wl,--enable-new-dtags -L/dlocal/sysapps/openmpi-gcc-4.0.1/lib64 -lmpi_usempi -lmpi_mpifh -lmpi\nF77 version:    GNU Fortran (GCC) 9.2.0\n\nF90=/dlocal/sysapps/openmpi-gcc-4.0.1/bin/mpif90\nF90 -show:\ngfortran -I/dlocal/sysapps/openmpi-gcc-4.0.1/include -pthread -I/dlocal/sysapps/openmpi-gcc-4.0.1/lib64 -Wl,-rpath -Wl,/dlocal/sysapps/openmpi-gcc-4.0.1/lib64 -Wl,--enable-new-dtags -L/dlocal/sysapps/openmpi-gcc-4.0.1/lib64 -lmpi_usempi -lmpi_mpifh -lmpi\nF90 version:    GNU Fortran (GCC) 9.2.0\n\nOK\n\n##################################################################################################\nPython Sanity Checks\n\nVerify `/usr/bin/env python3 --version` (reporting as: Python 3.7.4),\nmatches versions for: `which python3 && which python`\n\nOK\n\n##################################################################################################\nPython Modules (TestHarness, run-ability)\n\nOK",
          "url": "https://github.com/idaholab/moose/discussions/28466",
          "updatedAt": "2024-08-30T12:08:45Z",
          "publishedAt": "2024-08-26T07:56:02Z",
          "category": {
            "name": "Q&A Getting Started"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "milljm"
                  },
                  "bodyText": "With the mention of Cuda, I wouldn't be surprised if GCC 9.x is too old. I hope I am wrong. Tagging @grmnptr for possible confirmation...\nAlso, would it be possible for you to attach the configure.log it mentions? It should reside:\n/home/lus03/vikramr/projects/moose/petsc/configure.log",
                  "url": "https://github.com/idaholab/moose/discussions/28466#discussioncomment-10451498",
                  "updatedAt": "2024-08-26T12:44:36Z",
                  "publishedAt": "2024-08-26T12:44:35Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "author": {
                    "login": "shrituntunroy"
                  },
                  "bodyText": "Hi Jason,\nThankyou for your reply.\nPlease find the configure.log file.\nI have also tried gcc 12.3.0 but still I am getting the same error. Is it possible to build moose without cuda so as to avoid this error\nconfigure.log -\nconfigure.log",
                  "url": "https://github.com/idaholab/moose/discussions/28466#discussioncomment-10458956",
                  "updatedAt": "2024-08-27T05:45:45Z",
                  "publishedAt": "2024-08-27T05:45:44Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "it is still finding clang when looking for a compiler for cuda code.\nExecuting: clang --version\nstdout:\nclang version 3.4.2 (tags/RELEASE_34/dot2-final)\nTarget: x86_64-redhat-linux-gnu\nThread model: posix\n\nlet's try to find clang (which clang) then remove it from your PATH\nwe certainly can compile without cuda support",
                          "url": "https://github.com/idaholab/moose/discussions/28466#discussioncomment-10461507",
                          "updatedAt": "2024-08-27T10:11:04Z",
                          "publishedAt": "2024-08-27T10:11:04Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "milljm"
                          },
                          "bodyText": "Looks like its in /usr/bin according to the configure.log. Not a PATH we can easily remove.",
                          "url": "https://github.com/idaholab/moose/discussions/28466#discussioncomment-10462778",
                          "updatedAt": "2024-08-27T12:26:07Z",
                          "publishedAt": "2024-08-27T12:26:05Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "shrituntunroy"
                          },
                          "bodyText": "Hi Giudicelli ,\nThanks for your reply\nWhich clang returns the following -\n[vikramr@atulya335 ~]$ which clang\n/usr/bin/clang\nI have tried removing the usr/bin/ from the path but I am unable to run the script as shown below\n[vikramr@atulya335 scripts]$ which clang\n/usr/bin/clang\n[vikramr@atulya335 scripts]$ export PATH=$(echo $PATH | sed -e 's|:/usr/bin||g' -e 's|/usr/bin:||g')\n[vikramr@atulya335 scripts]$ which clang\n/usr/bin/which: no clang in (/home/lus03/vikramr/.python3/3.7.4/bin:/dlocal/sysapps/anaconda3/2019.10/bin/:/dlocal/sysapps/openmpi-gcc-4.0.1/bin/:/home/lus03/vikramr/app/python/Python-3.8.0:/home/lus03/vikramr/app/gcc/gcc1230/bin:/home/lus03/vikramr/app/cmake/cmake-3.28.3/bin:/usr/mpi/gcc/openmpi-4.0.2rc3/bin/:/usr/sbin:/usr/lib64/qt-3.3/bin:/usr/condabin:/usr/local/bin:/usr/local/sbin:/usr/sbin:/usr/local/anupam:/opt/VirtualGL/bin:/opt/ibutils/bin:.:/home/lus03/vikramr/app/lammps2023/lammps-2Aug2023/src:/home/lus03/vikramr/.local/bin:/home/lus03/vikramr/bin)\n[vikramr@atulya335 scripts]$ ./update_and_rebuild_petsc.sh --skip-submodule-update --with-packages-download-dir=~/projects/downloads\n/usr/bin/env: bash: No such file or directory\nI also tried an alias\nalias clang='echo \"clang is disabled\"'\n\nbut still it results in same error as in configure.log.\nCan you suggest some method so as to compile petsc without using clang or cuda",
                          "url": "https://github.com/idaholab/moose/discussions/28466#discussioncomment-10462989",
                          "updatedAt": "2024-08-27T12:45:37Z",
                          "publishedAt": "2024-08-27T12:45:31Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "milljm"
                          },
                          "bodyText": "yeah, you can't remove /usr/bin from PATH. Nothing will work afterwards. I am surprised that which worked to be honest.",
                          "url": "https://github.com/idaholab/moose/discussions/28466#discussioncomment-10463722",
                          "updatedAt": "2024-08-27T13:53:04Z",
                          "publishedAt": "2024-08-27T13:52:59Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "Jason is right we wont be able to do that.\nI'm not seeing --with-cuda in the configure command.\nI am seeing this at the top of the configure log though\nPython version:\n3.7.4 (default, Aug 13 2019, 20:35:49) \n[GCC 7.3.0]",
                          "url": "https://github.com/idaholab/moose/discussions/28466#discussioncomment-10463817",
                          "updatedAt": "2024-08-27T14:03:57Z",
                          "publishedAt": "2024-08-27T14:00:00Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "so let's clean this PATH still. Make sure the conda python is found first, and the newer GCC too.\nPATH is read from beginning (left) to the end",
                          "url": "https://github.com/idaholab/moose/discussions/28466#discussioncomment-10463837",
                          "updatedAt": "2024-08-27T14:01:54Z",
                          "publishedAt": "2024-08-27T14:01:53Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              },
              {
                "node": {
                  "author": {
                    "login": "shrituntunroy"
                  },
                  "bodyText": "Thank you Jason and Guillaume,\nFor your replies and support.\nI successfully compiled and installed moose in the HPC system by installing and compiling a newer version of llvm and clang.",
                  "url": "https://github.com/idaholab/moose/discussions/28466#discussioncomment-10495437",
                  "updatedAt": "2024-08-30T07:49:54Z",
                  "publishedAt": "2024-08-30T07:49:53Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": []
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "Automatic scaling implementation question",
          "author": {
            "login": "starkekr"
          },
          "bodyText": "Check these boxes if you have followed the posting rules.\n\n Q&A General is the most appropriate section for my question\n I have consulted the posting Guidelines on the Discussions front page\n I have searched the Discussions forum and my question has not been asked before\n I have searched the MOOSE website and the documentation does not answer my question\n I have formatted my post following the posting guidelines (screenshots as a last resort, triple back quotes around pasted text)\n\nQuestion\nI am wondering how the automatic scaling feature is implemented by default. I see that there is some documentation here:\nhttps://mooseframework.inl.gov/source/systems/NonlinearSystemBase.html.\nIt seems that Jacobian scaling is implemented by default and I have a question about this. Specifically, say that our kernels set up a linear system Ax=b, does the automatic scaling set up an auxillary system, A'x=b' and solve this system (where presumably A' now has a better condition number)? Also with diagonal scaling the matrix A' is typically written in the form A'=DAE (D & E are both diagonal matrices), and b'=E^(-1)b. It seems to me that in MOOSE D is the inverse of largest absolute value of diag(A) and E is the identity. Is this correct?\nApparently each variable also has a scaling factor thats gets added to this in some way",
          "url": "https://github.com/idaholab/moose/discussions/28496",
          "updatedAt": "2024-08-29T22:20:13Z",
          "publishedAt": "2024-08-29T16:51:04Z",
          "category": {
            "name": "Q&A General"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "starkekr"
                  },
                  "bodyText": "I made a mistake in the post, b'=Db, and you recover the solution with x=E^(-1)x",
                  "url": "https://github.com/idaholab/moose/discussions/28496#discussioncomment-10489803",
                  "updatedAt": "2024-08-29T16:54:09Z",
                  "publishedAt": "2024-08-29T16:54:08Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "author": {
                    "login": "GiudGiud"
                  },
                  "bodyText": "does the automatic scaling set up an auxillary system\n\nWe should be modifying the existing one instead of creating a new one.\n\nIt seems to me that in MOOSE D is the inverse of largest absolute value of diag(A)\n\nThis is on a per-variable basis (well really groups of variables, they can be grouped for auto-scaling). So D isnt a single value.\n\nApparently each variable also has a scaling factor thats gets added to this in some way\n\nThis is for the manual scaling system. If you use this and automatic scaling, the manual scaling factor wont do much as the automatic scaling factors will adapt to include them",
                  "url": "https://github.com/idaholab/moose/discussions/28496#discussioncomment-10492253",
                  "updatedAt": "2024-08-29T22:20:14Z",
                  "publishedAt": "2024-08-29T22:20:13Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": []
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "Stochstic term in Allen-Cahn equation",
          "author": {
            "login": "mdh23rct"
          },
          "bodyText": "Dear MOOSE experts,\nWould you be kind to let me know how to add a stochastic term in the Allen-Cahn equation in MOOSE?\n\nI have attached an image of the equation here. The last term on the right-hand side of the equation stands for the stochastic term.\nI would appreciate if you could manage time to reply.\nThanks, and best regards.",
          "url": "https://github.com/idaholab/moose/discussions/28429",
          "updatedAt": "2024-08-29T21:15:03Z",
          "publishedAt": "2024-08-19T17:10:56Z",
          "category": {
            "name": "Q&A Modules: Phase field"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "lynnmunday"
                  },
                  "bodyText": "Would some kind of initial condition for that term work seeded with a random distribution like this:\n[AuxVariables]\n  [./strength]\n    order = CONSTANT\n    family = MONOMIAL\n  [../]\n[]\n\n[ICs]\n  [./strength]\n    type = VolumeWeightedWeibull\n    variable = strength\n    reference_volume = 1e-7\n    weibull_modulus = 12.0\n    median = 130e6\n  [../]\n[]",
                  "url": "https://github.com/idaholab/moose/discussions/28429#discussioncomment-10389418",
                  "updatedAt": "2024-08-19T23:47:39Z",
                  "publishedAt": "2024-08-19T23:47:39Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "mdh23rct"
                          },
                          "bodyText": "Dear Dr. @lynnmunday,\nThank you for your advice. But how to add the stochastic term with the Allen-Chan equation? Do I need any kernel for that?\nThanks, and best regards.",
                          "url": "https://github.com/idaholab/moose/discussions/28429#discussioncomment-10390528",
                          "updatedAt": "2024-08-20T03:13:58Z",
                          "publishedAt": "2024-08-20T03:13:08Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "lynnmunday"
                          },
                          "bodyText": "I'm not familiar with this equation but if you just need to seed your domain with a random material property, this is the way to do that and then you can read that material property into your model as is done in the above example.",
                          "url": "https://github.com/idaholab/moose/discussions/28429#discussioncomment-10400369",
                          "updatedAt": "2024-08-20T21:06:19Z",
                          "publishedAt": "2024-08-20T21:06:18Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "zahidhasan83"
                          },
                          "bodyText": "@lynnmunday\nDear Dr. Lynn,\nI need to add a random number (R3), as shown in this equation:\n\nWould you be kind to advise me how to do it in MOOSE?\nThanks, and best regards.",
                          "url": "https://github.com/idaholab/moose/discussions/28429#discussioncomment-10468097",
                          "updatedAt": "2024-08-27T22:21:09Z",
                          "publishedAt": "2024-08-27T22:20:45Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "lynnmunday"
                          },
                          "bodyText": "I have no idea what this equation is doing.   What I have above is something that will seed an auxvariable with a random number over some distribution.  It looks like you could random multiply this auxvariable by your material.",
                          "url": "https://github.com/idaholab/moose/discussions/28429#discussioncomment-10468436",
                          "updatedAt": "2024-08-27T23:30:51Z",
                          "publishedAt": "2024-08-27T23:30:50Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "lynnmunday"
                          },
                          "bodyText": "@chaibhave Will you look at this.",
                          "url": "https://github.com/idaholab/moose/discussions/28429#discussioncomment-10491901",
                          "updatedAt": "2024-08-29T21:15:03Z",
                          "publishedAt": "2024-08-29T21:15:03Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "Automatic scaling question",
          "author": {
            "login": "starkekr"
          },
          "bodyText": "Check these boxes if you have followed the posting rules.\n\n Q&A General is the most appropriate section for my question\n I have consulted the posting Guidelines on the Discussions front page\n I have searched the Discussions forum and my question has not been asked before\n I have searched the MOOSE website and the documentation does not answer my question\n I have formatted my post following the posting guidelines (screenshots as a last resort, triple back quotes around pasted text)\n\nQuestion",
          "url": "https://github.com/idaholab/moose/discussions/28495",
          "updatedAt": "2024-08-29T16:51:18Z",
          "publishedAt": "2024-08-29T16:24:20Z",
          "category": {
            "name": "Q&A General"
          },
          "comments": {
            "edges": []
          }
        }
      },
      {
        "node": {
          "title": "MOOSE WorkShop training Registration",
          "author": {
            "login": "jiezhou1985"
          },
          "bodyText": "Hi guys, just want to know when we could have the feedback/decision on our workshop training registration. I did register for Oct. workshop at UIUC. Maybe the time is too further away? Really looking forward to participating in.",
          "url": "https://github.com/idaholab/moose/discussions/26855",
          "updatedAt": "2024-08-28T21:24:12Z",
          "publishedAt": "2024-02-21T15:29:10Z",
          "category": {
            "name": "Q&A General"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "GiudGiud"
                  },
                  "bodyText": "Hello\nYes we ll typically email out one to two months ahead of time that's it.\nWe dont typically send auto-acceptance emails but we might start at some point\nGuillaume",
                  "url": "https://github.com/idaholab/moose/discussions/26855#discussioncomment-8545298",
                  "updatedAt": "2024-02-21T15:35:45Z",
                  "publishedAt": "2024-02-21T15:35:44Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "jiezhou1985"
                          },
                          "bodyText": "it sounds great, so, could I confidently say that we are picked? :), since earlier plan could make some cheaper flight or living expenses. Thanks!",
                          "url": "https://github.com/idaholab/moose/discussions/26855#discussioncomment-8545742",
                          "updatedAt": "2024-02-21T16:03:33Z",
                          "publishedAt": "2024-02-21T16:03:31Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "yes. We do not typically refuse anyone for MOOSE training (it s open source). For BISON, it's happened before",
                          "url": "https://github.com/idaholab/moose/discussions/26855#discussioncomment-8545768",
                          "updatedAt": "2024-02-21T16:05:49Z",
                          "publishedAt": "2024-02-21T16:05:48Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "jiezhou1985"
                          },
                          "bodyText": "Thanks! Looking forward to the training!",
                          "url": "https://github.com/idaholab/moose/discussions/26855#discussioncomment-8545884",
                          "updatedAt": "2024-02-21T16:16:16Z",
                          "publishedAt": "2024-02-21T16:16:15Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "jiezhou1985"
                          },
                          "bodyText": "Hello, since the date is approaching, not sure whether the registration confirmation is sending out? Do we have any expected date for this confirmation and guidance? Thanks!",
                          "url": "https://github.com/idaholab/moose/discussions/26855#discussioncomment-10467617",
                          "updatedAt": "2024-08-27T20:59:26Z",
                          "publishedAt": "2024-08-27T20:59:26Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "@permcody",
                          "url": "https://github.com/idaholab/moose/discussions/26855#discussioncomment-10469301",
                          "updatedAt": "2024-08-28T02:09:15Z",
                          "publishedAt": "2024-08-28T02:09:10Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "permcody"
                          },
                          "bodyText": "@jiezhou1985 - I see that you are registered. We will send out more detailed instructions soon (within the next two weeks) on travel and an agenda. You may start looking for flights and making arrangements to attend. I have every expectation that the workshop will occur.",
                          "url": "https://github.com/idaholab/moose/discussions/26855#discussioncomment-10479290",
                          "updatedAt": "2024-08-28T19:44:55Z",
                          "publishedAt": "2024-08-28T19:44:53Z",
                          "isAnswer": true
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "jiezhou1985"
                          },
                          "bodyText": "Thanks so much, looking forward to it!",
                          "url": "https://github.com/idaholab/moose/discussions/26855#discussioncomment-10480020",
                          "updatedAt": "2024-08-28T21:24:12Z",
                          "publishedAt": "2024-08-28T21:24:12Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "MOOSE/BISON builds but fails to run inputs",
          "author": {
            "login": "gardnerru"
          },
          "bodyText": "Check these boxes if you have followed the posting rules.\n\n I have consulted the Posting Guidelines.\n I have searched the Discussions Forum and MOOSE Framework Troubleshooting and have not found what I was looking for\n Q&A Getting Started is the most appropriate category for my question (trouble installing, beginner user, ...)\n\nIssue or question about MOOSE\nI am attempting to build an updated BiSON, while the code builds without error, I get an illegal hardware instruction when running inputs. I tested this with BIsON and the heat_transfer module. I am running Intel mac with OS 14.6.1 and have gone as far as removing moose conda, conda itself, and starting over with the instructions as listed on the BISoN getting started with a new clone but keep hitting the same error. (By new clone I mean rm -rf bison, clone bison, submodule init recursive)\nI see that MOOSE still has a testing target for Intel with a slightly older OS that is green, which leads to a user problem I know. A quick google of the error only led to a list of M1 issues.\nThoughts?\n(Optional) code in question / simulation log / errors\n../../../../heat_transfer-opt -i const_hw.i \n[1]    18209 illegal hardware instruction  ../../../../heat_transfer-opt -i const_hw.i\nEncountering Errors? Please include diagnostic output\nNo response",
          "url": "https://github.com/idaholab/moose/discussions/28472",
          "updatedAt": "2024-09-26T15:55:11Z",
          "publishedAt": "2024-08-26T20:04:00Z",
          "category": {
            "name": "Q&A Getting Started"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "milljm"
                  },
                  "bodyText": "This seems to be hitting more and more folks... #28340 (reply in thread)\nThe gist is to downgrade your version of moose-libmesh (details in link). This is not a fix, just a workaround until we figure out how to proceed.",
                  "url": "https://github.com/idaholab/moose/discussions/28472#discussioncomment-10456184",
                  "updatedAt": "2024-08-26T20:55:46Z",
                  "publishedAt": "2024-08-26T20:55:45Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "gardnerru"
                          },
                          "bodyText": "Ahh. I saw that but wasnt sure it would help here. Ill give it a go and report",
                          "url": "https://github.com/idaholab/moose/discussions/28472#discussioncomment-10456237",
                          "updatedAt": "2024-08-26T21:02:42Z",
                          "publishedAt": "2024-08-26T21:02:41Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "gardnerru"
                          },
                          "bodyText": "@milljm That did work for me. Ill let you decide if you want to mark this as an answer and ill keep watching for updates. Thanks :)",
                          "url": "https://github.com/idaholab/moose/discussions/28472#discussioncomment-10456792",
                          "updatedAt": "2024-08-26T23:01:41Z",
                          "publishedAt": "2024-08-26T23:01:40Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "milljm"
                          },
                          "bodyText": "We're identifying the issue: #28484",
                          "url": "https://github.com/idaholab/moose/discussions/28472#discussioncomment-10477205",
                          "updatedAt": "2024-08-28T15:43:06Z",
                          "publishedAt": "2024-08-28T15:42:44Z",
                          "isAnswer": true
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "Deciding the Number of Cores",
          "author": {
            "login": "ashishdhole"
          },
          "bodyText": "Hello,\nI am working on grain growth related model with 6400 grains in a box of 2000x2000. I find my simulations are taking really long time. Now the website says I need to use 1 core per 30k DOF's. but when using adaptive meshing, this DOF's changes with every timesteps. I tried printing ndof for each timestep which gives me the real time information on dof but then I have to stop the simulation and run with new number of cores. I tried restart option using \"--recover' but the restart option is only available for same number of cores.\nCan you suggest anything that can make the simulation faster. I was told that this type of simulations with same number of grains won't take much time to process.\nfollowing is my system's starting DOF looks like\nParallelism:\n  Num Processors:          400\n  Num Threads:             1\n\nMesh:\n  Parallel Type:           replicated\n  Mesh Dimension:          2\n  Spatial Dimension:\t   2\n  Nodes:\n    Total:                 641601\n    Local:                 1705\n    Min/Max/Avg:           1485/1724/1604\n  Elems:\n    Total:                 640000\n    Local:                 1606\n    Min/Max/Avg:           1554/1640/1600\n  Num Subdomains:          1\n  Num Partitions:          400\n  Partitioner:             metis\n\nNonlinear System:\n  Num DOFs:                64160100\n  Num Local DOFs:          170500\n  Num Constrained DOFs:    160100\n  Local Constrained DOFs:  2800\n  Variables:               { \"gr0\" \"gr1\" \"gr2\" \"gr3\" \"gr4\" ... \"gr95\" \"gr96\" \"gr97\" \"gr98\" \"gr99\" }\n  Finite Element Types:    \"LAGRANGE\"\n  Approximation Orders:    \"FIRST\"\n\nAuxiliary System:\n  Num DOFs:                3843202\n  Num Local DOFs:          9834\n  Num Constrained DOFs:    3202\n  Local Constrained DOFs:  56\n  Variables:               \"bnds\" { \"unique_grains\" \"var_indices\" } \"phi\" { \"err_bnds\" \"ind_bnds\" }\n  Finite Element Types:    \"LAGRANGE\" \"MONOMIAL\" \"LAGRANGE\" \"MONOMIAL\"\n  Approximation Orders:    \"FIRST\" \"CONSTANT\" \"FIRST\" \"CONSTANT\"\n\nExecution Information:\n  Executioner:             Transient\n  TimeStepper:             IterationAdaptiveDT\n  TimeIntegrator:          BDF2\n  Solver Mode:             Preconditioned JFNK\n  PETSc Preconditioner:    hypre boomeramg\n\nthis is what my execution block looks like\n[Executioner]\n  type = Transient\n  scheme = bdf2\n  solve_type = PJFNK #Preconditioned JFNK (default)\n  petsc_options_iname = '-pc_type -pc_hypre_type'\n  petsc_options_value = 'hypre    boomeramg'\n  steady_state_detection = true\n  steady_state_start_time = 0\n  steady_state_tolerance = 1e-8\n  automatic_scaling = true\n  compute_scaling_once = false\n  use_pre_SMO_residual = true\n  l_abs_tol = 1.0e-6\n  nl_abs_tol = 1.0e-6\n  l_tol = 1.0e-6\n  l_max_its = 30\n  nl_max_its = 30\n  nl_rel_tol = 1.0e-6\n  start_time = 0.0\n  #num_steps = 2\n  end_time = 20000000000\n  dtmin = 1e-20\n  #dt = 1\n  line_search = none\n\n    [TimeStepper]\n    type = IterationAdaptiveDT\n    cutback_factor = 0.8\n    dt = 0.1\n    growth_factor = 1.3\n  []\n[]\n[Adaptivity]\n  initial_steps = 3\n  max_h_level = 2\n  marker = err_bnds\n  [Markers]\n    [err_bnds]\n      type = ErrorFractionMarker\n      coarsen = 0.3\n      refine = 0.7\n      indicator = ind_bnds\n    []\n  []\n  [Indicators]\n    [ind_bnds]\n      type = GradientJumpIndicator\n      variable = bnds\n    []\n  []\n[]\n\nthank you",
          "url": "https://github.com/idaholab/moose/discussions/28361",
          "updatedAt": "2024-08-28T14:30:23Z",
          "publishedAt": "2024-08-13T16:37:53Z",
          "category": {
            "name": "Q&A Modules: Phase field"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "GiudGiud"
                  },
                  "bodyText": "Hello\nThat's a lot of grain variables.\n@laagesen are we used to that many?\nAt this point I would expect re-implementing the module to use array variables is the thing to do to get great performance.\nOtherwise profile an iteration using these instructions, then let's focus on what's actually slow\nhttps://mooseframework.inl.gov/application_development/profiling.html",
                  "url": "https://github.com/idaholab/moose/discussions/28361#discussioncomment-10330936",
                  "updatedAt": "2024-08-13T22:28:38Z",
                  "publishedAt": "2024-08-13T22:28:37Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "ashishdhole"
                          },
                          "bodyText": "At this point I would expect re-implementing the module to use array variables is the thing to do to get great performance.\n\nHello,\nCan you explain this?\nProfiling will help me identify what is taking long time., but, as this is a custom kernel I am sure they are not so optimized. Still the simulation of such number of grains should not take this long time.\nThanks",
                          "url": "https://github.com/idaholab/moose/discussions/28361#discussioncomment-10331012",
                          "updatedAt": "2024-08-13T22:50:33Z",
                          "publishedAt": "2024-08-13T22:50:32Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "With so many variables, I expect we can vectorize the assembly of the nonlinear system using arrayKernels",
                          "url": "https://github.com/idaholab/moose/discussions/28361#discussioncomment-10331095",
                          "updatedAt": "2024-08-13T23:08:38Z",
                          "publishedAt": "2024-08-13T23:08:37Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "ashishdhole"
                          },
                          "bodyText": "After reducing my order parameters from 100 to 16, the simulation runtime is significantly improved. is there any rule to follow when choosing such number? Because once I start the simulation on HPC, I don't want to stop it and make changes in my input file. is there any other changes in the executioner block you think might help me improve the performance.\nThank you",
                          "url": "https://github.com/idaholab/moose/discussions/28361#discussioncomment-10331148",
                          "updatedAt": "2024-08-13T23:25:01Z",
                          "publishedAt": "2024-08-13T23:25:01Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "I ll let the phase field experts comment on how to chose this order parameter\nYou can always work on improving the preconditioning, tuning your hypre parameters here",
                          "url": "https://github.com/idaholab/moose/discussions/28361#discussioncomment-10331203",
                          "updatedAt": "2024-08-13T23:40:21Z",
                          "publishedAt": "2024-08-13T23:40:20Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "laagesen"
                          },
                          "bodyText": "you can definitely reduce the number of order parameters using the GrainTracker system as described here:\nhttps://mooseframework.inl.gov/source/postprocessors/GrainTracker.html\nI think you can use ~8 order parameters for 2D and ~25 for 3D if you use GrainTracker",
                          "url": "https://github.com/idaholab/moose/discussions/28361#discussioncomment-10360391",
                          "updatedAt": "2024-08-16T15:25:49Z",
                          "publishedAt": "2024-08-16T15:25:49Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "ashishdhole"
                          },
                          "bodyText": "Hello,\nI have an put file as follows\n[Mesh]\n  type = GeneratedMesh\n  dim = 3\n  nx = 50\n  ny = 50\n  nz = 50\n  xmin = 0\n  xmax = 500\n  ymin = 0\n  ymax = 500\n  zmin = 0\n  zmax = 500\n  unifortm_refine = 2\n[]\n[GlobalParams]\n  op_num = 80\n  var_name_base = gr\n  length_scale = 1.0e-6\n  time_scale = 1.0\n[]\n\n[Variables]\n  [PolycrystalVariables]\n    order = FIRST\n    family = LAGRANGE\n  []\n[]\n[Modules]\n  [AdvanceFrictionPressureGG]\n    g = phi\n  []\n[]\n\n[UserObjects]\n  [voronoi]\n    type = PolycrystalVoronoi\n    grain_num = 27000 # Number of grains\n    rand_seed = 1234\n    coloring_algorithm = jp\n    int_width = 4\n  []\n  [grain_tracker]\n    type = GrainTracker\n    verbosity_level = 0\n    compute_var_to_feature_map = true\n  []\n[]\n[ICs]\n  [PolycrystalICs]\n    [PolycrystalColoringIC]\n      polycrystal_ic_uo = voronoi\n    []\n  []\n[]\n...\n\nwith 27000 grains in 3d, As you have mentioned that I need ~25 op_num for 3d,\nSetting Up\n  Initializing\n    Initializing Equation Systems.                                                       [^[[33m 18.04 s^[[39m] [^[[33m  524 MB^[[39m]\n  Finished Initializing                                                                  [^[[33m 19.08 s^[[39m] [^[[33m  524 MB^[[39m]\nFinished Setting Up                                                                      [^[[33m 25.90 s^[[39m] [^[[33m  524 MB^[[39m]\nFramework Information:\nMOOSE Version:           git commit 8b30259223 on 2024-04-17\nLibMesh Version:         7dbd90ade88cb16a5e855a4c345454c9c146ebec\nPETSc Version:           3.20.3\nSLEPc Version:           3.20.1\nCurrent Time:            Tue Aug 27 03:34:47 2024\nExecutable Timestamp:    Thu Aug 15 19:47:37 2024\n\nParallelism:\n  Num Processors:          400\n  Num Threads:             1\n\nMesh:\n  Parallel Type:           replicated\n  Mesh Dimension:          3\n  Spatial Dimension:\t   3\n  Nodes:\n    Total:                 132651\n    Local:                 496\n    Min/Max/Avg:           156/525/331\n  Elems:\n    Total:                 125000\n    Local:                 305\n    Min/Max/Avg:           304/321/312\n  Num Subdomains:          1\n  Num Partitions:          400\n  Partitioner:             metis\n\nNonlinear System:\n  Num DOFs:                9285570\n  Num Local DOFs:          34720\n  Num Constrained DOFs:    535570\n  Local Constrained DOFs:  3640\n  Variables:               { \"gr0\" \"gr1\" \"gr2\" \"gr3\" \"gr4\" ... \"gr65\" \"gr66\" \"gr67\" \"gr68\" \"gr69\" }\n  Finite Element Types:    \"LAGRANGE\"\n  Approximation Orders:    \"FIRST\"\n\nAuxiliary System:\n  Num DOFs:                890302\n  Num Local DOFs:          2517\n  Num Constrained DOFs:    15302\n  Local Constrained DOFs:  104\n  Variables:               \"bnds\" { \"unique_grains\" \"var_indices\" } \"phi\" { \"err_bnds\" \"ind_bnds\" \"pid\"\n                             }\n  Finite Element Types:    \"LAGRANGE\" \"MONOMIAL\" \"LAGRANGE\" \"MONOMIAL\"\n  Approximation Orders:    \"FIRST\" \"CONSTANT\" \"FIRST\" \"CONSTANT\"\n\nExecution Information:\n  Executioner:             Transient\n  TimeStepper:             IterationAdaptiveDT\n  TimeIntegrator:          BDF2\n  Solver Mode:             Preconditioned JFNK\n  PETSc Preconditioner:    hypre boomeramg strong_threshold: 0.7 (auto)\n\n^[[31mLEGACY MODES ENABLED:^[[39m\n This application uses the legacy initial residual evaluation behavior. The legacy behavior performs an often times redundant residual evaluation before the solution modifying objects are executed prior to t$\n^[[39m\nCurrently Executing\n  Performing Initial Setup\n    Computing User Objects\n      Computing Polycrystal Initial Condition..                                          [^[[33m 21.44 s^[[39m] [^[[33m  535 MB^[[39m]\n      Currently Finalizing Polycrystal Initial Condition\n        Finalizing Polycrystal Initial Condition\n          Communicating and Merging                                                      [^[[33m  7.31 s^[[39m] [^[[33m  904 MB^[[39m]\n        Finished Finalizing Polycrystal Initial Condition                                [^[[33m  7.79 s^[[39m] [^[[33m  905 MB^[[39m]\n\n^[[31m\n*** ERROR ***\n/gpfs/fs1/home/m/militzer/drashish/moose-projects/pfubc/3d/fp_3d.i:16: (GlobalParams/op_num):\n    Unable to find a valid grain to op coloring, Make sure you have created enough variables to hold a\n    valid polycrystal initial condition (no grains represented by the same variable should be allowed to\n    touch, ~8 for 2D, ~25 for 3D)?^[[39m\n\n--------------------------------------------------------------------------\nMPI_ABORT was invoked on rank 0 in communicator MPI_COMM_WORLD\nwith errorcode 1.\n\nNOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.\nYou may or may not see output from other processes, depending on\nexactly when Open MPI kills them.\n--------------------------------------------------------------------------\nsrun: Job step aborted: Waiting up to 62 seconds for job step to finish.\nslurmstepd: error: *** STEP 13478274.0 ON nia0996 CANCELLED AT 2024-08-27T03:36:42 ***\n      Still Finalizing Polycrystal Initial Condition..............srun: error: nia0999: tasks 240-316,318-319: Killed\nsrun: Terminating StepId=13478274.0\nsrun: error: nia0996: task 0: Exited with exit code 1\nsrun: error: nia0996: tasks 1-53,55-79: Killed\nsrun: error: nia0997: tasks 80-128,130-159: Killed\nsrun: error: nia1000: tasks 320-378,380-399: Killed\nsrun: error: nia0996: task 54: Killed\nsrun: error: nia0999: task 317: Killed\nsrun: error: nia0997: task 129: Killed\nsrun: error: nia0998: tasks 160-239: Killed\nsrun: error: nia1000: task 379: Killed\nDONE!!\n\nmy simulations still fails with error showing not enough op_num.\nIs there a way I can figure out the for certain number of order parameters I need certain number of op_num in the input file.\nThank you.",
                          "url": "https://github.com/idaholab/moose/discussions/28361#discussioncomment-10468347",
                          "updatedAt": "2024-08-27T23:07:42Z",
                          "publishedAt": "2024-08-27T23:07:40Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "@laagesen\nhave you tried increasing it?",
                          "url": "https://github.com/idaholab/moose/discussions/28361#discussioncomment-10469284",
                          "updatedAt": "2024-08-28T02:06:54Z",
                          "publishedAt": "2024-08-28T02:06:54Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "ashishdhole"
                          },
                          "bodyText": "Yes. If I increase it too much the simulation runs. But then it's very slow.",
                          "url": "https://github.com/idaholab/moose/discussions/28361#discussioncomment-10469294",
                          "updatedAt": "2024-08-28T02:08:26Z",
                          "publishedAt": "2024-08-28T02:08:23Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "is there a sweet spot?",
                          "url": "https://github.com/idaholab/moose/discussions/28361#discussioncomment-10469306",
                          "updatedAt": "2024-08-28T02:09:25Z",
                          "publishedAt": "2024-08-28T02:09:25Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "ashishdhole"
                          },
                          "bodyText": "I haven't checked the minimum number. Just made op_num to 200 and it was running.",
                          "url": "https://github.com/idaholab/moose/discussions/28361#discussioncomment-10469316",
                          "updatedAt": "2024-08-28T02:11:14Z",
                          "publishedAt": "2024-08-28T02:11:08Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              },
              {
                "node": {
                  "author": {
                    "login": "ashishdhole"
                  },
                  "bodyText": "Hello,\nIn any case, how do we choose the optimum number of cores to use when adaptive mesh is involved? The checkpoint recover works with the same number of cores only. is there a way I can figure out the number of cores for an efficient simulation run?\nthank you",
                  "url": "https://github.com/idaholab/moose/discussions/28361#discussioncomment-10333113",
                  "updatedAt": "2024-08-14T05:04:03Z",
                  "publishedAt": "2024-08-14T05:04:02Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "I would say plan for the final number of dofs per core to be above 20k\nWith adaptivity it's tough because you don't know how many dofs you will end up with",
                          "url": "https://github.com/idaholab/moose/discussions/28361#discussioncomment-10337098",
                          "updatedAt": "2024-08-14T12:50:13Z",
                          "publishedAt": "2024-08-14T12:50:12Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      }
    ]
  }
}