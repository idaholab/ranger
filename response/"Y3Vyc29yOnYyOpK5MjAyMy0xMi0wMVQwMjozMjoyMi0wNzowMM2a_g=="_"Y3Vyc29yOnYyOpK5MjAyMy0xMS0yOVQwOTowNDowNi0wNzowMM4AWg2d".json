{
  "discussions": {
    "pageInfo": {
      "hasNextPage": true,
      "endCursor": "Y3Vyc29yOnYyOpK5MjAyMy0xMS0yOVQwOTowNDowNi0wNzowMM4AWg2d"
    },
    "edges": [
      {
        "node": {
          "title": "Issues when install MOOSE to HPC (offline)",
          "author": {
            "login": "ljeft"
          },
          "bodyText": "Hi,\nI am trying to install MOOSE to HPC(offline) followed offfline_installation.\nI finished \"Prepare Directory\" step, but when I go to the \"Build Libraries\" step that run\n./update_and_rebuild_petsc.sh --skip-submodule-update --with-packages-download-dir=~/projects/downloads\n./update_and_rebuild_libmesh.sh --skip-submodule-update\n./update_and_rebuild_wasp.sh --skip-submodule-update\n\nstill need networt for download them.\nWhat's the right method of offline installation?",
          "url": "https://github.com/idaholab/moose/discussions/26137",
          "updatedAt": "2023-12-01T01:49:36Z",
          "publishedAt": "2023-11-23T15:10:11Z",
          "category": {
            "name": "Q&A General"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "GiudGiud"
                  },
                  "bodyText": "Hello\nWhat packages have you downloaded before going offline? And where did you place them?\nAll 3 scripts require placing pre-downloaded packages and setting environment variables for the directories\nGuillaume",
                  "url": "https://github.com/idaholab/moose/discussions/26137#discussioncomment-7656722",
                  "updatedAt": "2023-11-24T03:45:10Z",
                  "publishedAt": "2023-11-24T03:45:09Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "ljeft"
                          },
                          "bodyText": "I followed the steps for offline installation\ncd ~/projects/moose ./scripts/update_and_rebuild_petsc.sh  --with-packages-download-dir=~/projects/downloads\nThese are the packages I installed on downloads\n/projects/downloads$ curl -L -O https://bitbucket.org/petsc/pkg-fblaslapack/get/v3.4.2-p3.tar.gz\\\n curl -L -O https://web.cels.anl.gov/projects/petsc/download/externalpackages/hdf5-1.12.2.tar.bz2\\\n curl -L -O https://github.com/hypre-space/hypre/archive/v2.29.0.tar.gz\\\n curl -L -O https://bitbucket.org/petsc/pkg-metis/get/v5.1.0-p11.tar.gz\\\n curl -L -O https://gitlab.com/slepc/slepc/-/archive/8cd5b338c8d505feaba64739b6f1374b14835c4a/slepc-8cd5b338c8d505feaba64739b6f1374b14835c4a.tar.gz\\\n curl -L -O https://bitbucket.org/petsc/pkg-parmetis/get/v4.0.3-p9.tar.gz\\\n curl -L -O https://web.cels.anl.gov/projects/petsc/download/externalpackages/scotch-v7.0.3.tar.gz\\\n curl -L -O https://web.cels.anl.gov/projects/petsc/download/externalpackages/MUMPS_5.6.1.tar.gz\\\n curl -L -O https://github.com/Reference-ScaLAPACK/scalapack/archive/5bad7487f496c811192334640ce4d3fc5f88144b.tar.gz\\\n curl -L -O https://github.com/xiaoyeli/superlu_dist/archive/02b7c0d71bc33e785d098b0f8e4c26414bb8e39a.tar.gz\\\n curl -L -O https://github.com/pghysels/STRUMPACK/archive/v7.1.4.tar.gz\n\nAfter going offline, I run ./update_and_rebuild_petsc.sh --skip-submodule-update --with-packages-download-dir=~/projects/downloads\ni still need download\n(base) [ghfund3_a47@login02 scripts]$ ./update_and_rebuild_petsc.sh --skip-submodule-update --with-packages-download-dir=~/projects/downloads\n/public/home/ghfund3_a47/projects/moose/scripts\nINFO: Checking for HDF5...\nINFO: HDF5 library not detected, opting to download via PETSc...\nDownload the following packages to /public/home/ghfund3_a47/projects/downloads \n\nhypre ['git clone https://github.com/hypre-space/hypre', 'https://github.com/hypre-space/hypre/archive/v2.29.0.tar.gz']\nmetis ['git clone https://bitbucket.org/petsc/pkg-metis.git', 'https://bitbucket.org/petsc/pkg-metis/get/v5.1.0-p11.tar.gz']\nslepc ['git clone https://gitlab.com/slepc/slepc.git', 'https://gitlab.com/slepc/slepc/-/archive/8cd5b338c8d505feaba64739b6f1374b14835c4a/slepc-8cd5b338c8d505feaba64739b6f1374b14835c4a.tar.gz']\nparmetis ['git clone https://bitbucket.org/petsc/pkg-parmetis.git', 'https://bitbucket.org/petsc/pkg-parmetis/get/v4.0.3-p9.tar.gz']\nptscotch ['git clone https://gitlab.inria.fr/scotch/scotch.git', 'https://gitlab.inria.fr/scotch/scotch/-/archive/v7.0.3/scotch-v7.0.3.tar.gz', 'https://web.cels.anl.gov/projects/petsc/download/externalpackages/scotch-v7.0.3.tar.gz']\nmumps ['https://graal.ens-lyon.fr/MUMPS/MUMPS_5.6.1.tar.gz', 'https://web.cels.anl.gov/projects/petsc/download/externalpackages/MUMPS_5.6.1.tar.gz']\nscalapack ['git clone https://github.com/Reference-ScaLAPACK/scalapack', 'https://github.com/Reference-ScaLAPACK/scalapack/archive/5bad7487f496c811192334640ce4d3fc5f88144b.tar.gz']\nsuperlu_dist ['git clone https://github.com/xiaoyeli/superlu_dist', 'https://github.com/xiaoyeli/superlu_dist/archive/02b7c0d71bc33e785d098b0f8e4c26414bb8e39a.tar.gz']\nstrumpack ['git clone https://github.com/pghysels/STRUMPACK', 'https://github.com/pghysels/STRUMPACK/archive/v7.1.4.tar.gz']\n\nI tried to download these packages and then copy them to moose/download",
                          "url": "https://github.com/idaholab/moose/discussions/26137#discussioncomment-7657142",
                          "updatedAt": "2023-11-24T05:25:33Z",
                          "publishedAt": "2023-11-24T05:25:33Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "Ok that s good.\nYou can also pass additional options to skip these packages.\nI think the main remaining one is HDF5? Do you have that installed on your system?",
                          "url": "https://github.com/idaholab/moose/discussions/26137#discussioncomment-7660825",
                          "updatedAt": "2023-11-24T13:50:40Z",
                          "publishedAt": "2023-11-24T13:50:39Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "ljeft"
                          },
                          "bodyText": "Yes,I have installed on my system ,and I have build PETSc, libMesh, and WASP\nI tried to build moose\ncd ~/projects/moose/test\nmake -j 6\n\nI get a error , this is very strange, I don't know how to solve\nfatal: Not a git repository (or any parent up to mount point /public/home/ghfund3_a47)\nStopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\ncut: /.git: No such file or directory\nfatal: Not a git repository (or any parent up to mount point /public/home/ghfund3_a47)\nStopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\ncut: /.git: No such file or directory\nLinking Library /public/home/ghfund3_a47/projects/moose/framework/contrib/pcre/libpcre-opt.la...\nLinking Library /public/home/ghfund3_a47/projects/moose/framework/contrib/hit/libhit-opt.la...\nCompiling C++ (in opt mode) /public/home/ghfund3_a47/projects/moose/framework/contrib/exodiff/exo_entity.C...\nCompiling C++ (in opt mode) /public/home/ghfund3_a47/projects/moose/framework/contrib/exodiff/Tolerance.C...\nCompiling C++ (in opt mode) /public/home/ghfund3_a47/projects/moose/framework/contrib/exodiff/exoII_read.C...\nCompiling C++ (in opt mode) /public/home/ghfund3_a47/projects/moose/framework/contrib/exodiff/check.C...\ngcc: fatal error: cannot read spec file 'libgomp.spec': No such file or directory\ncompilation terminated.\nmake: *** [/public/home/ghfund3_a47/projects/moose/framework/contrib/hit/libhit-opt.la] Error 1\nmake: *** Waiting for unfinished jobs....\ngcc: fatal error: cannot read spec file 'libgomp.spec': No such file or directory\ncompilation terminated.",
                          "url": "https://github.com/idaholab/moose/discussions/26137#discussioncomment-7664546",
                          "updatedAt": "2023-11-25T03:07:06Z",
                          "publishedAt": "2023-11-25T03:07:05Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "The git stuff is expected if you copy pasted the folder instead of git cloning it\nThe libgomp error is from your compiler.\nCould you please run the diagnostics script in moose/scripts and pasting the output here?",
                          "url": "https://github.com/idaholab/moose/discussions/26137#discussioncomment-7666096",
                          "updatedAt": "2023-11-25T13:08:31Z",
                          "publishedAt": "2023-11-25T13:08:30Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "ljeft"
                          },
                          "bodyText": "Sat Nov 25 13:48:28 UTC 2023\n\nSystem Arch: CentOS Linux release 7.6.1810 (Core)\n\nMOOSE Package Version: Custom Build\n\nCPU Count: 32\n\nMemory Free: 55416.148 MB\n\n$CC not set\n\nMPICC:\nwhich mpicc:\n        /opt/mpi/bin/mpicc\nmpicc -show:\n        gcc -I/opt/mpi/include -pthread -L/opt/hwloc//lib -Wl,-rpath -Wl,/opt/hwloc//lib -Wl,-rpath -Wl,/opt/mpi/lib -Wl,--enable-new-dtags -L/opt/mpi/lib -lmpi\n\nCOMPILER gcc:\ngcc (GCC) 7.3.1 20180303 (Red Hat 7.3.1-5)\nCopyright (C) 2017 Free Software Foundation, Inc.\nThis is free software; see the source for copying conditions.  There is NO\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n\nPython:\n        /public/home/ghfund3_a47/mambaforge3/bin/python\n        Python 3.10.6\n\nMODULES NOT AVAILABLE\n\nPETSC_DIR not set\n\nENVIRONMENT:\nAMDGPU_TARGETS=gfx906\n_CE_CONDA=\n_CE_M=\nC_INCLUDE_PATH=/opt/dtk-22.10/include:/opt/dtk-22.10/llvm/include:/opt/dtk/include:/opt/dtk/llvm/include:\nCONDA_DEFAULT_ENV=base\nCONDA_EXE=/public/home/ghfund3_a47/mambaforge3/bin/conda\nCONDA_PREFIX=/public/home/ghfund3_a47/mambaforge3\nCONDA_PROMPT_MODIFIER=(base) \nCONDA_PYTHON_EXE=/public/home/ghfund3_a47/mambaforge3/bin/python\nCONDA_SHLVL=1\nCPLUS_INCLUDE_PATH=/opt/dtk-22.10/include:/opt/dtk-22.10/llvm/include:/opt/dtk/include:/opt/dtk/llvm/include:\nDTKROOT=/opt/dtk-22.10\nHIP_PATH=/opt/dtk-22.10/hip\nHIP_VISIBLE_DEVICES=0,1\nHISTCONTROL=ignoredups\nHISTSIZE=1000\nHOME=/public/home/ghfund3_a47\nHOSTNAME=90ad3610e888\nhttp_proxy=http://ghfund3_c13:ghfund3_c13_PWD@172.16.0.40:17928/\nhttps_proxy=http://ghfund3_c13:ghfund3_c13_PWD@172.16.0.40:17928/\nINFOPATH=/opt/rh/devtoolset-7/root/usr/share/info\nLANG=en_US.UTF-8\nLANGUAGE=en_US.UTF-8\nLC_ALL=en_US.UTF-8\nLD_LIBRARY_PATH=/usr/local/lib/:/usr/local/lib64/:/opt/mpi/lib:/opt/dtk-22.10/hip/lib:/opt/dtk-22.10/llvm/lib:/opt/dtk-22.10/lib:/opt/dtk-22.10/lib64:/opt/dtk/hip/lib:/opt/dtk/llvm/lib:/opt/dtk/lib:/opt/dtk/lib64:/opt/rh/devtoolset-7/root/usr/lib64:/opt/rh/devtoolset-7/root/usr/lib:/opt/rh/devtoolset-7/root/usr/lib64/dyninst:/opt/rh/devtoolset-7/root/usr/lib/dyninst:/opt/rh/devtoolset-7/root/usr/lib64:/opt/rh/devtoolset-7/root/usr/lib:/opt/mpi/lib:/opt/hwloc/lib:/usr/local/lib/:/usr/local/lib64/:\nLESSOPEN=||/usr/bin/lesspipe.sh %s\nLOGNAME=ghfund3_a47\nLS_COLORS=rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=01;05;37;41:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.Z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.jpg=01;35:*.jpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.axv=01;35:*.anx=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=01;36:*.au=01;36:*.flac=01;36:*.mid=01;36:*.midi=01;36:*.mka=01;36:*.mp3=01;36:*.mpc=01;36:*.ogg=01;36:*.ra=01;36:*.wav=01;36:*.axa=01;36:*.oga=01;36:*.spx=01;36:*.xspf=01;36:\nMAIL=/var/spool/mail/ghfund3_a47\nMANPATH=/opt/rh/devtoolset-7/root/usr/share/man:/opt/mpi/share/man:\nMETHODS=opt\nMOOSE_JOBS=6\nPATH=/public/home/ghfund3_a47/mambaforge3/bin:/usr/local/bin:/opt/mpi/bin:/opt/cmake/bin:/opt/dtk-22.10/bin:/opt/dtk-22.10/llvm/bin:/opt/dtk-22.10/hip/bin:/opt/dtk-22.10/hip/bin/hipify:/opt/dtk/bin:/opt/dtk/llvm/bin:/opt/dtk/hip/bin:/opt/dtk/hip/bin/hipify:/opt/rh/devtoolset-7/root/usr/bin:/opt/mpi/bin:/opt/hwloc/bin:/opt/cmake/bin:/usr/local/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/public/home/ghfund3_a47/cmake3.18/bin:/public/home/ghfund3_a47/gcc9.3/bin\nPCP_DIR=/opt/rh/devtoolset-7/root\nPERL5LIB=/opt/rh/devtoolset-7/root//usr/lib64/perl5/vendor_perl:/opt/rh/devtoolset-7/root/usr/lib/perl5:/opt/rh/devtoolset-7/root//usr/share/perl5/vendor_perl\nPWD=/public/home/ghfund3_a47/projects/moose/scripts\nPYTHONPATH=/usr/local/:/opt/rh/devtoolset-7/root/usr/lib64/python2.7/site-packages:/opt/rh/devtoolset-7/root/usr/lib/python2.7/site-packages:/usr/local/:\nROCM_PATH=/opt/dtk-22.10\nSHELL=/bin/bash\nSHLVL=18\nSSH_CLIENT=173.0.48.0 59102 22\nSSH_CONNECTION=173.0.48.0 59102 173.0.249.3 22\nSSH_TTY=/dev/pts/0\nSUDO_COMMAND=/bin/scl enable devtoolset-7  'su'\nSUDO_GID=12055\nSUDO_UID=3777\nSUDO_USER=ghfund3_a47\ntask_name=\nTERM=xterm\nUSER=ghfund3_a47\nUSERNAME=root\n_=/usr/bin/env\nX_SCLS=devtoolset-7",
                          "url": "https://github.com/idaholab/moose/discussions/26137#discussioncomment-7666285",
                          "updatedAt": "2023-11-25T13:48:57Z",
                          "publishedAt": "2023-11-25T13:48:57Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "GCC is too old at 7.3. I can't recall the link right now but the requirement is 7.5\nYou ll need to use a different compiler. Git clean (there cannot be any leftover compiles objects from the previous install) then re install basically everything",
                          "url": "https://github.com/idaholab/moose/discussions/26137#discussioncomment-7666315",
                          "updatedAt": "2023-11-25T13:58:55Z",
                          "publishedAt": "2023-11-25T13:56:29Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "ljeft"
                          },
                          "bodyText": "I set up the environment,this is the script.\n\nWed 29 Nov 2023 09:41:26 AM CST\nRUNNING AS ROOT\nSystem Arch: Not Available\nMOOSE Package Version: Custom Build\nCPU Count: 32\nMemory Free: 92492.648 MB\n$CC not set\nMPICC:\nwhich mpicc:\n/opt/openmpi-4.1.6/bin/mpicc\nmpicc -show:\ngcc -I/opt/openmpi-4.1.6/include -pthread -L/opt/openmpi-4.1.6/lib -Wl,-rpath -Wl,/opt/openmpi-4.1.6/lib -Wl,--enable-new-dtags -lmpi\nCOMPILER gcc:\ngcc (GCC) 11.4.0\nCopyright (C) 2021 Free Software Foundation, Inc.\nThis is free software; see the source for copying conditions.  There is NO\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\nPython:\n/usr/local/bin/python\nPython 3.7.12\nMODULES NOT AVAILABLE\nPETSC_DIR not set\nENVIRONMENT:\nHOME=/root\nHOSTNAME=3b7b755c8da0\nLANG=en_US.UTF-8\nLANGUAGE=en_US.UTF-8\nLC_ALL=en_US.UTF-8\nLOGNAME=root\nLS_COLORS=rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=00:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:.tar=01;31:.tgz=01;31:.arc=01;31:.arj=01;31:.taz=01;31:.lha=01;31:.lz4=01;31:.lzh=01;31:.lzma=01;31:.tlz=01;31:.txz=01;31:.tzo=01;31:.t7z=01;31:.zip=01;31:.z=01;31:.dz=01;31:.gz=01;31:.lrz=01;31:.lz=01;31:.lzo=01;31:.xz=01;31:.zst=01;31:.tzst=01;31:.bz2=01;31:.bz=01;31:.tbz=01;31:.tbz2=01;31:.tz=01;31:.deb=01;31:.rpm=01;31:.jar=01;31:.war=01;31:.ear=01;31:.sar=01;31:.rar=01;31:.alz=01;31:.ace=01;31:.zoo=01;31:.cpio=01;31:.7z=01;31:.rz=01;31:.cab=01;31:.wim=01;31:.swm=01;31:.dwm=01;31:.esd=01;31:.jpg=01;35:.jpeg=01;35:.mjpg=01;35:.mjpeg=01;35:.gif=01;35:.bmp=01;35:.pbm=01;35:.pgm=01;35:.ppm=01;35:.tga=01;35:.xbm=01;35:.xpm=01;35:.tif=01;35:.tiff=01;35:.png=01;35:.svg=01;35:.svgz=01;35:.mng=01;35:.pcx=01;35:.mov=01;35:.mpg=01;35:.mpeg=01;35:.m2v=01;35:.mkv=01;35:.webm=01;35:.ogm=01;35:.mp4=01;35:.m4v=01;35:.mp4v=01;35:.vob=01;35:.qt=01;35:.nuv=01;35:.wmv=01;35:.asf=01;35:.rm=01;35:.rmvb=01;35:.flc=01;35:.avi=01;35:.fli=01;35:.flv=01;35:.gl=01;35:.dl=01;35:.xcf=01;35:.xwd=01;35:.yuv=01;35:.cgm=01;35:.emf=01;35:.ogv=01;35:.ogx=01;35:.aac=00;36:.au=00;36:.flac=00;36:.m4a=00;36:.mid=00;36:.midi=00;36:.mka=00;36:.mp3=00;36:.mpc=00;36:.ogg=00;36:.ra=00;36:.wav=00;36:.oga=00;36:.opus=00;36:.spx=00;36:*.xspf=00;36:\nMAIL=/var/mail/root\nOLDPWD=/public/home/ghfund3_a47/projects/moose\nPATH=/opt/openmpi-4.1.6/bin:/opt/gcc-11.4/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin\nPWD=/public/home/ghfund3_a47/projects/moose/scripts\nSHELL=/bin/bash\nSHLVL=1\nSUDO_COMMAND=/usr/bin/su\nSUDO_GID=12055\nSUDO_UID=3777\nSUDO_USER=ghfund3_a47\nTERM=xterm\nTZ=Asia/Shanghai\nUSER=root\n_=/usr/bin/env\n\nHowever , When I built moose a new problem arose.\n\nfatal: not a git repository (or any parent up to mount point /public/home)\nStopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\ncut: /usr/bin/git/.git: Not a directory\nfatal: not a git repository (or any parent up to mount point /public/home)\nStopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\ncut: /usr/bin/git/.git: Not a directory\nLinking Executable /public/home/ghfund3_a47/projects/moose/framework/contrib/exodiff/exodiff...\n/usr/bin/ld: cannot find -lxml2\ncollect2: error: ld returned 1 exit status",
                          "url": "https://github.com/idaholab/moose/discussions/26137#discussioncomment-7698800",
                          "updatedAt": "2023-11-29T01:59:49Z",
                          "publishedAt": "2023-11-29T01:59:47Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "You need to install libxml development headers. Maybe ask your cluster admins?\nor if you can:\napt-get install libxml2-dev",
                          "url": "https://github.com/idaholab/moose/discussions/26137#discussioncomment-7699015",
                          "updatedAt": "2023-11-29T02:45:47Z",
                          "publishedAt": "2023-11-29T02:45:29Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "ljeft"
                          },
                          "bodyText": "I solved the problem by doing a Google search, running git init, and now the error is that I can't find python packaging, and I try to install it offline.\nTraceback (most recent call last):\n  File \"/public/home/ghfund3_a47/projects/moose/framework/scripts/get_repo_revision.py\", line 19, in <module>\n    from packaging import version\nModuleNotFoundError: No module named 'packaging'\nChecking if header needs updating: /public/home/ghfund3_a47/projects/moose/framework/include/base/MooseRevision.h...\n\nFailed to generate MooseRevision.h\n\nmake: *** [/public/home/ghfund3_a47/projects/moose/framework/moose.mk:348: /public/home/ghfund3_a47/projects/moose/framework/include/base/MooseRevision.h] Error 1",
                          "url": "https://github.com/idaholab/moose/discussions/26137#discussioncomment-7699060",
                          "updatedAt": "2023-11-29T02:54:31Z",
                          "publishedAt": "2023-11-29T02:54:30Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "This is a missing python package. pip install packaging or mamba install packaging will solve that",
                          "url": "https://github.com/idaholab/moose/discussions/26137#discussioncomment-7699152",
                          "updatedAt": "2023-11-29T03:07:28Z",
                          "publishedAt": "2023-11-29T03:07:28Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              },
              {
                "node": {
                  "author": {
                    "login": "ljeft"
                  },
                  "bodyText": "I change the gcc\nI get a erorr\nfatal: Not a git repository (or any parent up to mount point /public/home/ghfund3_a47)\nStopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\ncut: /.git: No such file or directory\nfatal: Not a git repository (or any parent up to mount point /public/home/ghfund3_a47)\nStopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\ncut: /.git: No such file or directory\nLinking Executable /public/home/ghfund3_a47/projects/moose/framework/contrib/exodiff/exodiff...\nCompiling C++ (in opt mode) /public/home/ghfund3_a47/projects/moose/test/build/unity_src/executors_Unity.C...\nCompiling C++ (in opt mode) /public/home/ghfund3_a47/projects/moose/test/build/unity_src/outputs_Unity.C...\nCompiling C++ (in opt mode) /public/home/ghfund3_a47/projects/moose/test/build/unity_src/reporters_Unity.C...\nCompiling C++ (in opt mode) /public/home/ghfund3_a47/projects/moose/test/build/unity_src/markers_Unity.C...\nCompiling C++ (in opt mode) /public/home/ghfund3_a47/projects/moose/test/build/unity_src/fvkernels_Unity.C...\ng++: fatal error: cannot read spec file 'libgomp.spec': No such file or directory\ncompilation terminated.\nmake: *** [/public/home/ghfund3_a47/projects/moose/framework/contrib/exodiff/exodiff] Error 1\nmake: *** Waiting for unfinished jobs....",
                  "url": "https://github.com/idaholab/moose/discussions/26137#discussioncomment-7667036",
                  "updatedAt": "2023-11-25T15:04:15Z",
                  "publishedAt": "2023-11-25T15:04:14Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "What s the output of the diagnostics script now?",
                          "url": "https://github.com/idaholab/moose/discussions/26137#discussioncomment-7667834",
                          "updatedAt": "2023-11-25T18:10:37Z",
                          "publishedAt": "2023-11-25T18:10:36Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "How to create a new stateful material property at restart, which is needed by material object at restart",
          "author": {
            "login": "michaelsal75"
          },
          "bodyText": "Hello,\nwe are trying to make a restart in which the previous simulation includes a crystal plasticity model without damage\nand the current simulation includes a damage model, thus requiring an additional stateful material property, called \"hist\",\nrepresenting the history of the elastic energy.\nIn the previous simulation we use this object:\nhttps://github.com/ngrilli/c_pfor_am/blob/main/src/materials/ComputeDislocationCrystalPlasticityStress.C\nIn the restart simulation we use a similar one with damage:\nhttps://github.com/ngrilli/c_pfor_am/blob/main/src/materials/ComputeCrystalPlasticityStressDamage.C\nIn the constructor of the material class ComputeCrystalPlasticityStressDamage in the current simulation,\nthere is a declaration:\n_H(declareProperty(\"hist\"))\nwhich is not present in the material object of the previous simulation.\nI expected this to create a new stateful material property (initialized at 0) and to be able to restart,\nthe same that I would do with an auxvariable, however we get the error:\n\"There is a mismatch in the stateful material properties stored during checkpoint\"\nsaying that \"hist\" is not available in the \"Stored stateful properties\" of the previous output file.\nIs there a way to solve this problem?\nCan we add a new stateful material property in a restart input file?\nWe tried to define a new material with the same name in the restart input file using GenericConstantMaterial\nbut of course it complains that \"hist\" is declared by multiple materials.\nThank you very much for your help.",
          "url": "https://github.com/idaholab/moose/discussions/26192",
          "updatedAt": "2023-11-30T15:32:35Z",
          "publishedAt": "2023-11-29T17:37:01Z",
          "category": {
            "name": "Q&A General"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "lindsayad"
                  },
                  "bodyText": "@loganharbour this error message is yours and I know you touched this stuff in your recent refactors of restart. Any suggestions on this?",
                  "url": "https://github.com/idaholab/moose/discussions/26192#discussioncomment-7708425",
                  "updatedAt": "2023-11-29T18:27:55Z",
                  "publishedAt": "2023-11-29T18:27:54Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "author": {
                    "login": "loganharbour"
                  },
                  "bodyText": "Was this capability supported previously? I don't think that it was (see the comment below) \n  \n    \n      moose/framework/src/problems/FEProblemBase.C\n    \n    \n         Line 1152\n      in\n      5ce9f89\n    \n  \n  \n    \n\n        \n          \n           // Here we will initialize the stateful properties once more since they may have been updated \n        \n    \n  \n\n\nI'm actively working on this in #25840, but the priority isn't the highest at the moment.",
                  "url": "https://github.com/idaholab/moose/discussions/26192#discussioncomment-7708909",
                  "updatedAt": "2023-11-29T19:16:00Z",
                  "publishedAt": "2023-11-29T19:15:46Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "author": {
                    "login": "ngrilli"
                  },
                  "bodyText": "@loganharbour  thank you very much for working on this feature.\nI believe for the moment it will work if we manually add the material properties in the previous simulation\nusing GenericConstantMaterial, i.e. a material property with the same name as the one that will be used\nin the new material object in the restart simulation, and then we restart with the new material object.",
                  "url": "https://github.com/idaholab/moose/discussions/26192#discussioncomment-7719241",
                  "updatedAt": "2023-11-30T15:32:35Z",
                  "publishedAt": "2023-11-30T15:32:35Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": []
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "Error when testing MOOSE on the UCSD Expanse cluster",
          "author": {
            "login": "lichanghao"
          },
          "bodyText": "Hi there,\nI tried to use mamba to configure the MOOSE compiling environment and the compilation can pass on the Expanse cluster. However, when I run the tests, multiple items cannot pass due to similar error for the mpiexec:\npre\nmisc/mpi_setup.basic_mpirun_works: Working Directory: /home/cli1/moose_projects/moose/test/tests/misc/mpi_setup\nmisc/mpi_setup.basic_mpirun_works: Running command: mpirun -n 2 hostname\nmisc/mpi_setup.basic_mpirun_works: [mpiexec@exp-7-15] HYDU_sock_write (utils/sock/sock.c:254): write error (Bad file descriptor)\nmisc/mpi_setup.basic_mpirun_works: [mpiexec@exp-7-15] HYD_pmcd_pmiserv_send_signal (pm/pmiserv/pmiserv_cb.c:176): unable to write data to proxy\nmisc/mpi_setup.basic_mpirun_works: [mpiexec@exp-7-15] ui_cmd_cb (pm/pmiserv/pmiserv_pmci.c:42): unable to send signal downstream\nmisc/mpi_setup.basic_mpirun_works: [mpiexec@exp-7-15] HYDT_dmxu_poll_wait_for_event (tools/demux/demux_poll.c:76): callback returned error status\nmisc/mpi_setup.basic_mpirun_works: [mpiexec@exp-7-15] HYD_pmci_wait_for_completion (pm/pmiserv/pmiserv_pmci.c:160): error waiting for event\nmisc/mpi_setup.basic_mpirun_works: [mpiexec@exp-7-15] main (ui/mpich/mpiexec.c:325): process manager error waiting for completion\nmisc/mpi_setup.basic_mpirun_works: \nmisc/mpi_setup.basic_mpirun_works ........................................................... FAILED (TIMEOUT)\n\nIf you can give me a hint on how to deal with this error, or you need me to provide further details, just let me know. Thank you so much for your help.",
          "url": "https://github.com/idaholab/moose/discussions/26029",
          "updatedAt": "2023-11-30T15:21:49Z",
          "publishedAt": "2023-11-10T19:37:16Z",
          "category": {
            "name": "Q&A Getting Started"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "milljm"
                  },
                  "bodyText": "Its almost as if you are not \"allowed\" to use MPI. You might be constrained to only use the provided MPI wrapper designed for that cluster (do not use Mamba while on HPC). This may be a \"SLURM\" cluster for example. Where you are only allowed to run in parallel with srun (instead of mpirun).\nOne trick that might work, if this is indeed a SLURM cluster:\nexport MOOSE_MPI_COMMAND=`srun`\nAnd then attempt to run tests.\nAnother possible reason for the error; most clusters will want you to be operating on a compute node, instead of a head node. I cannot tell which one you are using.",
                  "url": "https://github.com/idaholab/moose/discussions/26029#discussioncomment-7554287",
                  "updatedAt": "2023-11-13T13:50:12Z",
                  "publishedAt": "2023-11-13T13:50:11Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "lichanghao"
                          },
                          "bodyText": "Thank you for the rapid reply. I double checked and the HPC environment does not allow explicit call of mpirun, and srun can be only used to apply interactive nodes.\nNow I use the HPC-installed compilers to recompile moose, then submit the parallel job by the slurm script. Everything works well.",
                          "url": "https://github.com/idaholab/moose/discussions/26029#discussioncomment-7719133",
                          "updatedAt": "2023-11-30T15:21:50Z",
                          "publishedAt": "2023-11-30T15:21:49Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "Issue getting started with MOOSE",
          "author": {
            "login": "CM518"
          },
          "bodyText": "Hi,\nI am using the INL HPC and am struggling to get MOOSE working.\nWhen trying to build MOOSE using make -j 6 in /projects/moose/test I get the error \u201cPETSc was configured with MPICH but now appears to be compiling using a non-MPICH mpi.h\u201d.\nI have tried following troubleshooting and making sure the Conda environment is active and up to date, with the latest version of the moose packages but to no avail.\nI have also tried ./update_and_rebuild_petsc.sh in /projects/moose/scripts and this returns the error \u201cError configuring SUPERLU_DIST with CMake\u201d.\nI have looked at discussions around these topics but unfortunately none have solved my issue.\nAny help would be appreciated, thank you in advance.",
          "url": "https://github.com/idaholab/moose/discussions/26188",
          "updatedAt": "2023-11-30T13:57:52Z",
          "publishedAt": "2023-11-29T15:27:16Z",
          "category": {
            "name": "Q&A Getting Started"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "GiudGiud"
                  },
                  "bodyText": "Hello\nAre you following these instructions?\nYou should not be using conda on INL HPC\nhttps://mooseframework.inl.gov/getting_started/installation/inl_hpc_install_moose.html\nWhat is the exact error for the rebuild_petsc? There should be more context\nGuillaume",
                  "url": "https://github.com/idaholab/moose/discussions/26188#discussioncomment-7706508",
                  "updatedAt": "2023-11-29T15:49:15Z",
                  "publishedAt": "2023-11-29T15:49:15Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "CM518"
                          },
                          "bodyText": "Hi Guillaume,\nThank you for your help, I had been following those instructions but when the tests failed I went into the troubleshooting page where it only discussed rebuilding MOOSE using Conda. I have now started again and this time MOOSE has built which is great but when running the tests the samplers/distribute.scale/execute test failed (this must have been the original error which took me to the troubleshooting page). Please see the below error report. This was the only test to fail.\nsamplers/distribute.scale/execute: Working Directory: /home/mccoconn/projects/moose/test/tests/samplers/distribute\nsamplers/distribute.scale/execute: Running command: /home/mccoconn/projects/moose/test/tests/samplers/distribute/execute.py \nsamplers/distribute.scale/execute: mpiexec -n 1 /home/mccoconn/projects/moose/test/moose_test-opt -i distribute.i Outputs/file_base=distribute_1 Postprocessors/test/test_type=getGlobalSamples Samplers/sampler/num_rows=1\nsamplers/distribute.scale/execute: mpiexec -n 4 /home/mccoconn/projects/moose/test/moose_test-opt -i distribute.i Outputs/file_base=distribute_4 Postprocessors/test/test_type=getGlobalSamples Samplers/sampler/num_rows=1\nsamplers/distribute.scale/execute: Traceback (most recent call last):\nsamplers/distribute.scale/execute:   File \"/home/mccoconn/projects/moose/test/tests/samplers/distribute/execute.py\", line 47, in <module>\nsamplers/distribute.scale/execute:     execute('distribute.i', 'distribute_none', 1, args.processors, 'getGlobalSamples')\nsamplers/distribute.scale/execute:   File \"/home/mccoconn/projects/moose/test/tests/samplers/distribute/execute.py\", line 29, in execute\nsamplers/distribute.scale/execute:     local = pandas.read_csv('{}.csv'.format(file_base))\nsamplers/distribute.scale/execute:   File \"/apps/moose/stack/moose-tools-2023.10.19/lib/python3.10/site-packages/pandas/io/parsers/readers.py\", line 948, in read_csv\nsamplers/distribute.scale/execute:     return _read(filepath_or_buffer, kwds)\nsamplers/distribute.scale/execute:   File \"/apps/moose/stack/moose-tools-2023.10.19/lib/python3.10/site-packages/pandas/io/parsers/readers.py\", line 611, in _read\nsamplers/distribute.scale/execute:     parser = TextFileReader(filepath_or_buffer, **kwds)\nsamplers/distribute.scale/execute:   File \"/apps/moose/stack/moose-tools-2023.10.19/lib/python3.10/site-packages/pandas/io/parsers/readers.py\", line 1448, in __init__\nsamplers/distribute.scale/execute:     self._engine = self._make_engine(f, self.engine)\nsamplers/distribute.scale/execute:   File \"/apps/moose/stack/moose-tools-2023.10.19/lib/python3.10/site-packages/pandas/io/parsers/readers.py\", line 1705, in _make_engine\nsamplers/distribute.scale/execute:     self.handles = get_handle(\nsamplers/distribute.scale/execute:   File \"/apps/moose/stack/moose-tools-2023.10.19/lib/python3.10/site-packages/pandas/io/common.py\", line 863, in get_handle\nsamplers/distribute.scale/execute:     handle = open(\nsamplers/distribute.scale/execute: FileNotFoundError: [Errno 2] No such file or directory: 'distribute_4.csv'\nsamplers/distribute.scale/execute: mpiexec -n 1 /home/mccoconn/projects/moose/test/moose_test-opt -i distribute.i Outputs/file_base=distribute_1 Postprocessors/test/test_type=getGlobalSamples Samplers/sampler/num_rows=1\nsamplers/distribute.scale/execute: mpiexec -n 4 /home/mccoconn/projects/moose/test/moose_test-opt -i distribute.i Outputs/file_base=distribute_4 Postprocessors/test/test_type=getGlobalSamples Samplers/sampler/num_rows=1\nsamplers/distribute.scale/execute: Traceback (most recent call last):\nsamplers/distribute.scale/execute:   File \"/home/mccoconn/projects/moose/test/tests/samplers/distribute/execute.py\", line 47, in <module>\nsamplers/distribute.scale/execute:     execute('distribute.i', 'distribute_none', 1, args.processors, 'getGlobalSamples')\nsamplers/distribute.scale/execute:   File \"/home/mccoconn/projects/moose/test/tests/samplers/distribute/execute.py\", line 29, in execute\nsamplers/distribute.scale/execute:     local = pandas.read_csv('{}.csv'.format(file_base))\nsamplers/distribute.scale/execute:   File \"/apps/moose/stack/moose-tools-2023.10.19/lib/python3.10/site-packages/pandas/io/parsers/readers.py\", line 948, in read_csv\nsamplers/distribute.scale/execute:     return _read(filepath_or_buffer, kwds)\nsamplers/distribute.scale/execute:   File \"/apps/moose/stack/moose-tools-2023.10.19/lib/python3.10/site-packages/pandas/io/parsers/readers.py\", line 611, in _read\nsamplers/distribute.scale/execute:     parser = TextFileReader(filepath_or_buffer, **kwds)\nsamplers/distribute.scale/execute:   File \"/apps/moose/stack/moose-tools-2023.10.19/lib/python3.10/site-packages/pandas/io/parsers/readers.py\", line 1448, in __init__\nsamplers/distribute.scale/execute:     self._engine = self._make_engine(f, self.engine)\nsamplers/distribute.scale/execute:   File \"/apps/moose/stack/moose-tools-2023.10.19/lib/python3.10/site-packages/pandas/io/parsers/readers.py\", line 1705, in _make_engine\nsamplers/distribute.scale/execute:     self.handles = get_handle(\nsamplers/distribute.scale/execute:   File \"/apps/moose/stack/moose-tools-2023.10.19/lib/python3.10/site-packages/pandas/io/common.py\", line 863, in get_handle\nsamplers/distribute.scale/execute:     handle = open(\nsamplers/distribute.scale/execute: FileNotFoundError: [Errno 2] No such file or directory: 'distribute_4.csv'\nsamplers/distribute.scale/execute: \nsamplers/distribute.scale/execute: \nsamplers/distribute.scale/execute: Exit Code: 1\nsamplers/distribute.scale/execute: ################################################################################\nsamplers/distribute.scale/execute: Tester failed, reason: CRASH\nsamplers/distribute.scale/execute: \nsamplers/distribute.scale/execute ............................................................. FAILED (CRASH)",
                          "url": "https://github.com/idaholab/moose/discussions/26188#discussioncomment-7718032",
                          "updatedAt": "2023-11-30T13:47:01Z",
                          "publishedAt": "2023-11-30T13:47:00Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "I dont see anything obvious.\n@somu15 seen a failure there before?",
                          "url": "https://github.com/idaholab/moose/discussions/26188#discussioncomment-7718193",
                          "updatedAt": "2023-11-30T13:57:53Z",
                          "publishedAt": "2023-11-30T13:57:52Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "Is there a way in MOOSE to perform convergence check on variables in Explicit solver",
          "author": {
            "login": "chunhuizhao478"
          },
          "bodyText": "Hi all, I would like to solve poroelasticity equation using explicit solver, I acknowledge the existence of porous flow modulus but it's fully implicit, I want to estimate how far we could go in the explicit solver way.\nAs shown in the equations above, we solve displacement u from first equation 1, and plug into equation 2 for pressure p, until convergence is achieved if both u p relative error is below the threshold, we forbid the marching in time. I'm not sure if there is something in the control system for example we could utilize for this purpose. I want to know how feasible this approach is in MOOSE, thanks!",
          "url": "https://github.com/idaholab/moose/discussions/26199",
          "updatedAt": "2023-11-30T03:59:18Z",
          "publishedAt": "2023-11-29T21:42:14Z",
          "category": {
            "name": "Q&A General"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "GiudGiud"
                  },
                  "bodyText": "Hello\nTo define arbirtary convergence criteria you can use this:\nhttps://mooseframework.inl.gov/source/userobjects/Terminator.html\nOtherwise we are going to be working on a new system, called Convergence, that will enable everything convergence related.\nIt s not ready yet\nGuillaume",
                  "url": "https://github.com/idaholab/moose/discussions/26199#discussioncomment-7711023",
                  "updatedAt": "2023-11-29T22:26:17Z",
                  "publishedAt": "2023-11-29T22:26:17Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "chunhuizhao478"
                          },
                          "bodyText": "Thanks @GiudGiud. I checked this function, it may look like what I want, however, I don't want to cut the time step by half (just iterative at current time step), but I want to save the results I have for this iteration before a restart so I could compare the relative error, is there a way to achieve this?",
                          "url": "https://github.com/idaholab/moose/discussions/26199#discussioncomment-7711879",
                          "updatedAt": "2023-11-30T00:53:46Z",
                          "publishedAt": "2023-11-30T00:53:45Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "This object can terminate the simulation normally. Cutting the timestep is not the only thing it can do\nThe docs mention how to do that iirc",
                          "url": "https://github.com/idaholab/moose/discussions/26199#discussioncomment-7712020",
                          "updatedAt": "2023-11-30T01:22:01Z",
                          "publishedAt": "2023-11-30T01:22:00Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "chunhuizhao478"
                          },
                          "bodyText": "I understand if I set fail_mode = HARD, it will terminate the simulation, however I don't want the simulation ends (which is handled by setting fail_mode = SOFT, but also I want the time to stay at current value until some criterion is met, is that possible?",
                          "url": "https://github.com/idaholab/moose/discussions/26199#discussioncomment-7712773",
                          "updatedAt": "2023-11-30T03:34:39Z",
                          "publishedAt": "2023-11-30T03:33:48Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "ok so you want to call it convergence and accept the time step. Not sure we have that",
                          "url": "https://github.com/idaholab/moose/discussions/26199#discussioncomment-7712932",
                          "updatedAt": "2023-11-30T03:59:28Z",
                          "publishedAt": "2023-11-30T03:59:18Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "External Driving force to flat grain boundary migration",
          "author": {
            "login": "ashishdhole"
          },
          "bodyText": "Hello All, I want to know if we can add an external driving force to a flat grain boundary in a 2D or 3D space. I am trying to see the interaction of grain boundary and insoluble particles and want my flat grain boundary to move from one one side of the box to other. Is there any example I can look into? Thank you",
          "url": "https://github.com/idaholab/moose/discussions/26196",
          "updatedAt": "2023-11-29T23:05:59Z",
          "publishedAt": "2023-11-29T20:04:41Z",
          "category": {
            "name": "Q&A Modules: Phase field"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "GiudGiud"
                  },
                  "bodyText": "Hello\nSo this would be a load applied on a surface inside the mesh?\nWould you apply it on the sides of elements or on nodes?\nCould you use a volumetric load insteasd?\nGuillaume",
                  "url": "https://github.com/idaholab/moose/discussions/26196#discussioncomment-7709665",
                  "updatedAt": "2023-11-29T20:24:18Z",
                  "publishedAt": "2023-11-29T20:24:17Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "ashishdhole"
                          },
                          "bodyText": "I am sorry, I didn't get your question? Can we use a function inside a polycrystalkernel to be acting as an external driving force?",
                          "url": "https://github.com/idaholab/moose/discussions/26196#discussioncomment-7709973",
                          "updatedAt": "2023-11-29T20:53:33Z",
                          "publishedAt": "2023-11-29T20:53:32Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "This kernel / action ?\nhttps://mooseframework.inl.gov/source/actions/PolycrystalKernelAction.html",
                          "url": "https://github.com/idaholab/moose/discussions/26196#discussioncomment-7709989",
                          "updatedAt": "2023-11-29T20:55:10Z",
                          "publishedAt": "2023-11-29T20:55:09Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "ashishdhole"
                          },
                          "bodyText": "Yes",
                          "url": "https://github.com/idaholab/moose/discussions/26196#discussioncomment-7710057",
                          "updatedAt": "2023-11-29T20:59:46Z",
                          "publishedAt": "2023-11-29T20:59:45Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "I dont see an option.\nI think you need to look into using kernels individually instead of the action",
                          "url": "https://github.com/idaholab/moose/discussions/26196#discussioncomment-7710198",
                          "updatedAt": "2023-11-29T21:10:21Z",
                          "publishedAt": "2023-11-29T21:10:20Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "ashishdhole"
                          },
                          "bodyText": "Is there any example I can look into. two grains with individual kernels in normal grain growth model?",
                          "url": "https://github.com/idaholab/moose/discussions/26196#discussioncomment-7710415",
                          "updatedAt": "2023-11-29T21:31:25Z",
                          "publishedAt": "2023-11-29T21:31:25Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "@amjokisaari @laagesen",
                          "url": "https://github.com/idaholab/moose/discussions/26196#discussioncomment-7710461",
                          "updatedAt": "2023-11-29T21:34:57Z",
                          "publishedAt": "2023-11-29T21:34:56Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              },
              {
                "node": {
                  "author": {
                    "login": "laagesen"
                  },
                  "bodyText": "Hi @ashishdhole , it might be possible to force a flat GB to move in a simulation, but it would be unphysical. Classical theory of grain boundary growth states that GB velocity is proportional to curvature, see for example the textbook by Porter and Easterling. If there is no curvature, there will be no GB motion. So, we should not expect a flat GB to move. I would instead embed a circular grain inside another grain, then you will get GB motion at a known rate. Have a look here for an example:\nhttps://mooseframework.inl.gov/modules/phase_field/Grain_Growth_Model.html\nIn the Model Verification section.",
                  "url": "https://github.com/idaholab/moose/discussions/26196#discussioncomment-7710727",
                  "updatedAt": "2023-11-29T21:54:50Z",
                  "publishedAt": "2023-11-29T21:54:48Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "ashishdhole"
                          },
                          "bodyText": "Thank you @laagesen I understand that the flat grain movement is unphysical, But I have seen papers performing the flat grain movement to see the interaction of grain boundary with particles. (e.g. Tonks, Michael R., Yongfeng Zhang, Aaron Butterfield, and Xian-Ming Bai. \"Development of a grain boundary pinning model that considers particle size distribution using the phase field method.\" Modelling and Simulation in Materials Science and Engineering 23, no. 4 (2015): 045009.) Even if it is unphysical is there a way to do it in moose?",
                          "url": "https://github.com/idaholab/moose/discussions/26196#discussioncomment-7710939",
                          "updatedAt": "2023-11-29T22:15:08Z",
                          "publishedAt": "2023-11-29T22:15:08Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              },
              {
                "node": {
                  "author": {
                    "login": "laagesen"
                  },
                  "bodyText": "It looks like this capability was implemented in Marmot, as is stated in the paper, and it looks like it is still in the Marmot repo. However it has not been transferred to MOOSE. Are you affiliated with an institution that has a Marmot license, or could request one?",
                  "url": "https://github.com/idaholab/moose/discussions/26196#discussioncomment-7711135",
                  "updatedAt": "2023-11-29T22:44:39Z",
                  "publishedAt": "2023-11-29T22:44:38Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "ashishdhole"
                          },
                          "bodyText": "No, My institute do not have Marmot license. we are exploring moose for the first time under the impression that moose can handle large scale simulations easily and less time and computational resources. Flat grain movement and its interactions are the initial tests we want to perform to move further into 3D spaces. Is there any alternate way you can think of? Say using 'BicrystalCircleGrainICAction' and keeping the center of the circular grain out of the mesh such that it still has the curvature but looks flat. \"This is just what I can think of right now\" Will it work?",
                          "url": "https://github.com/idaholab/moose/discussions/26196#discussioncomment-7711171",
                          "updatedAt": "2023-11-29T22:51:44Z",
                          "publishedAt": "2023-11-29T22:51:43Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "laagesen"
                          },
                          "bodyText": "I think you could create a circular grain that way and it would move a little bit, but it would soon flatten out and lose its driving force for motion.",
                          "url": "https://github.com/idaholab/moose/discussions/26196#discussioncomment-7711193",
                          "updatedAt": "2023-11-29T22:53:57Z",
                          "publishedAt": "2023-11-29T22:53:57Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "ashishdhole"
                          },
                          "bodyText": "yes. It is not moving as expected. I think Circular grain in a box is the only thing I can do at this moment. I hope this feature is added to moose in future versions. Thank you all for your prompt replies and help.\nBest Regards\nAshish Dhole",
                          "url": "https://github.com/idaholab/moose/discussions/26196#discussioncomment-7711275",
                          "updatedAt": "2023-11-29T23:06:00Z",
                          "publishedAt": "2023-11-29T23:05:59Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "Static linear analysis of the beam. Executioner parameters",
          "author": {
            "login": "andrey1887"
          },
          "bodyText": "Hello. I looked through beam analysis examples of TensorMechanics module https://mooseframework.inl.gov/modules/tensor_mechanics/beam_vandv.html.\nHelp me please to understand: why  Transient type and NEWTON solve_type are used.\nIf i need to do static analysis for linear problem maybe more appropriate types should be used?",
          "url": "https://github.com/idaholab/moose/discussions/26190",
          "updatedAt": "2023-11-29T20:35:32Z",
          "publishedAt": "2023-11-29T16:17:54Z",
          "category": {
            "name": "Q&A Modules: Solid mechanics"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "GiudGiud"
                  },
                  "bodyText": "Hello\nTransient is often used in analysis to simulate loading steps. If the time derivative is not added to the kernels, it s equivalent to a steady solve on every step\nGuillaume",
                  "url": "https://github.com/idaholab/moose/discussions/26190#discussioncomment-7709129",
                  "updatedAt": "2023-11-29T19:34:24Z",
                  "publishedAt": "2023-11-29T19:34:23Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "andrey1887"
                          },
                          "bodyText": "Thank you @GiudGiud, and what about solve_type?",
                          "url": "https://github.com/idaholab/moose/discussions/26190#discussioncomment-7709175",
                          "updatedAt": "2023-11-29T19:39:21Z",
                          "publishedAt": "2023-11-29T19:39:20Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "solve_type of Newton makes sense if the problem is nonlinear.\nIf it s truly linear, you can use a LINEAR solve_type",
                          "url": "https://github.com/idaholab/moose/discussions/26190#discussioncomment-7709634",
                          "updatedAt": "2023-11-29T20:21:57Z",
                          "publishedAt": "2023-11-29T20:21:56Z",
                          "isAnswer": true
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "andrey1887"
                          },
                          "bodyText": "Thank you.",
                          "url": "https://github.com/idaholab/moose/discussions/26190#discussioncomment-7709785",
                          "updatedAt": "2023-11-29T20:35:32Z",
                          "publishedAt": "2023-11-29T20:35:32Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "Bounds in optimization",
          "author": {
            "login": "am-tc01"
          },
          "bodyText": "Hi,\nI am working with optimization and realized that the parameters' values that the Optimize solver take do not strictly respect the upper_bounds and lower_bounds. Sometimes the parameters' value can go beyond the bounds as well. For example, in this test, the parameter value in initial_condition is smaller than the lower_bounds. It works even if I change the solver to TAOBLMVM. Is that supposed to be so?\nRegards.",
          "url": "https://github.com/idaholab/moose/discussions/26160",
          "updatedAt": "2023-11-29T17:08:54Z",
          "publishedAt": "2023-11-27T14:43:04Z",
          "category": {
            "name": "Q&A Modules: General"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "GiudGiud"
                  },
                  "bodyText": "Hello\nInitial conditions are a special case, they are not coming from the optimization solve.\nDo you get out of bounds values from the output of the solver?",
                  "url": "https://github.com/idaholab/moose/discussions/26160#discussioncomment-7681873",
                  "updatedAt": "2023-11-27T14:53:57Z",
                  "publishedAt": "2023-11-27T14:53:56Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "am-tc01"
                          },
                          "bodyText": "But shouldn't it throw an error even if the initial value is out of bounds? The first iteration the solver takes, uses the initial value. What if it converges with the initial value?\nI have made an example where I call it converged as soon as the value of objective function is smaller than the threshold. In such case, the output of the solver could be out of bounds. Let me see if I can make a reproduceable case.",
                          "url": "https://github.com/idaholab/moose/discussions/26160#discussioncomment-7682053",
                          "updatedAt": "2023-11-27T15:04:14Z",
                          "publishedAt": "2023-11-27T15:04:13Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "I dont see why we would impose that restriction.\nIf the bounds are complicated to process, that would mean that the user has to do some significant work to just initialize the simulation well enough to meet the acceptance criterion",
                          "url": "https://github.com/idaholab/moose/discussions/26160#discussioncomment-7682088",
                          "updatedAt": "2023-11-27T15:07:32Z",
                          "publishedAt": "2023-11-27T15:07:31Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "am-tc01"
                          },
                          "bodyText": "Hi,\nSo for this case, I get out of bound values from the output of the solver.\nIt seems that it converges for the given criteria but the output I get for the heat_source (301) is greater than the upper_bounds (300),\nmoose_optimization_test.zip",
                          "url": "https://github.com/idaholab/moose/discussions/26160#discussioncomment-7691300",
                          "updatedAt": "2023-11-28T11:24:59Z",
                          "publishedAt": "2023-11-28T11:24:58Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "@lynnmunday or @grmnptr want to look into it?\nMaybe we re missing a check",
                          "url": "https://github.com/idaholab/moose/discussions/26160#discussioncomment-7691760",
                          "updatedAt": "2023-11-28T12:20:23Z",
                          "publishedAt": "2023-11-28T12:20:22Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "maxnezdyur"
                          },
                          "bodyText": "[OptimizationReporter]\n  type = OptimizationReporter\n  parameter_names = 'heat_source'\n  num_values = '1'\n  initial_condition = '300'. <---- IC of 300 which is right at the upper bound\n  lower_bounds = '0.1'\n  upper_bounds = '300'\n  measurement_points = '0.2 0.2 0\n                        0.8 0.6 0\n                        0.2 1.4 0\n                        0.8 1.8 0'\n  measurement_values = '1.98404 1.91076 1.56488 1.23863'\n[]\n\ntao_fd_delta = 1 <---- step size of 1 is used for finite differencing\ngatol = 1E-8\ngrtol = 1E-8\ngttol = 1E-8\nfmin = 0.001\n\n[Executioner]\n  type = Optimize\n  tao_solver = taoblmvm\n  petsc_options_iname = '-tao_fd_gradient   -tao_fd_hessian     -tao_gatol    -tao_fmin    -tao_cmonitor  -tao_fd_delta'  <---- you are using finite differencing for the gradient\n  petsc_options_value = ' true               true            \t  ${gatol}\t    ${fmin}\t\t  \ttrue      \t   ${tao_fd_delta}'\n  verbose = true\n[]\n\nYou are using finite differencing with a step size of 1 (which I would make sure is not too large), and have an initial condition right at the upper bound. MOOSE does not control how TAO does FD, so I believe that's what you are getting a heat source of 301.",
                          "url": "https://github.com/idaholab/moose/discussions/26160#discussioncomment-7692035",
                          "updatedAt": "2023-11-28T12:52:01Z",
                          "publishedAt": "2023-11-28T12:52:00Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "am-tc01"
                          },
                          "bodyText": "Thanks for looking into this! I just wanted to reproduce a case where the output of the solver is out of the bounds, hence the strange values. But if you change upper_bounds to say 299.5 you'll still get a value of heat_source (300.5) which is beyond the bounds. Of course it depends on FD_DELTA. But in some sense upper and lower bounds are not respected strictly.",
                          "url": "https://github.com/idaholab/moose/discussions/26160#discussioncomment-7692185",
                          "updatedAt": "2023-11-28T13:10:31Z",
                          "publishedAt": "2023-11-28T13:10:30Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "maxnezdyur"
                          },
                          "bodyText": "But if you change upper_bounds to say 299.5 you'll still get a value of heat_source (300.5) which is beyond the bounds.\n\nDo you mean the converged value is 300.5 or that the first step is 300.5? There are other cases where the bounds are not strictly respected. IIRC if you use a \"unit\" line search when using the BQNLS method then the bound won't be respected during the line search. All the bounds are handled by TAO, so I would look at their documentation at possible conflicts with options used.",
                          "url": "https://github.com/idaholab/moose/discussions/26160#discussioncomment-7692308",
                          "updatedAt": "2023-11-28T13:22:25Z",
                          "publishedAt": "2023-11-28T13:22:24Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "am-tc01"
                          },
                          "bodyText": "The converged value is 300.5",
                          "url": "https://github.com/idaholab/moose/discussions/26160#discussioncomment-7692335",
                          "updatedAt": "2023-11-28T13:26:23Z",
                          "publishedAt": "2023-11-28T13:26:22Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "maxnezdyur"
                          },
                          "bodyText": "Can you paste a few lines of the monitor that gets printed out. I think it may be an outputting issue, where the last output is actually the FD gradient check aka 299.5 + 1 and the actual answer that you are converging on is 299.5. If you decrease the FD delta to 0.1, would  your final answer be 299.6?",
                          "url": "https://github.com/idaholab/moose/discussions/26160#discussioncomment-7692383",
                          "updatedAt": "2023-11-28T13:30:48Z",
                          "publishedAt": "2023-11-28T13:30:37Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "am-tc01"
                          },
                          "bodyText": "This is the output from OptimizationReporter with FD delta=1:\ngrad_heat_source,heat_source,measurement_time,measurement_values,measurement_xcoord,measurement_ycoord,measurement_zcoord,misfit_values,simulation_values\n0,300.5,0,1.98404,0.2,0.2,0,-0.0058508197670573,1.9781891802329\n0,0,0,1.91076,0.8,0.6,0,-0.014190147372656,1.8965698526273\n0,0,0,1.56488,0.2,1.4,0,-0.017321388655594,1.5475586113444\n0,0,0,1.23863,0.8,1.8,0,-0.0093261938743641,1.2293038061256\n\nand this is the output with FD delta=0.1:\ngrad_heat_source,heat_source,measurement_time,measurement_values,measurement_xcoord,measurement_ycoord,measurement_zcoord,misfit_values,simulation_values\n0,299.6,0,1.98404,0.2,0.2,0,-0.0060129731557681,1.9780270268442\n0,0,0,1.91076,0.8,0.6,0,-0.014584642680112,1.8961753573199\n0,0,0,1.56488,0.2,1.4,0,-0.017803741485438,1.5470762585146\n0,0,0,1.23863,0.8,1.8,0,-0.0095855652419727,1.229044434758\n\nso yes, the final answer is 299.6",
                          "url": "https://github.com/idaholab/moose/discussions/26160#discussioncomment-7692888",
                          "updatedAt": "2023-11-28T14:17:53Z",
                          "publishedAt": "2023-11-28T14:17:51Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "A question about the implementation of B-bar in StressDivergenceTensors",
          "author": {
            "login": "TJT-post95"
          },
          "bodyText": "Hello MOOSE:\nIn the simulation of incompressible material, the B-bar method is applied in MOOSE to solve the volumetric locking problem. While reading the code in StressDivergenceTensors, I am temporarily stuck with confusion. For example, in the member function computeQpJacobian(), only B0*(C0000+C0011+C0022)*(Bvol_0-B0)/3 seems to be computed for B^T_i * C * Bvol_j, where for x direction (_component = 0).\nAccording to Bower's Applied Mechanics of Solids, it seems that (B0*(C0000+C0011+C0022)+B1*(C0100+C0111+C0122)+B2*(C0200+C0211+C0222))*(Bvol_0-B0)/3 would be here?\nI'm looking forward to the comments.\nThanks!",
          "url": "https://github.com/idaholab/moose/discussions/25965",
          "updatedAt": "2024-01-16T03:02:54Z",
          "publishedAt": "2023-11-04T16:02:49Z",
          "category": {
            "name": "Q&A Modules: Solid mechanics"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "GiudGiud"
                  },
                  "bodyText": "@cpritam @sveerara",
                  "url": "https://github.com/idaholab/moose/discussions/25965#discussioncomment-7590054",
                  "updatedAt": "2023-11-16T16:16:40Z",
                  "publishedAt": "2023-11-16T16:16:39Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "author": {
                    "login": "TJT-post95"
                  },
                  "bodyText": "I will take the Cook's Membrane mentioned by MOOSE as a benchmark to test the implementation of B-bar in StressDivergenceTensors.",
                  "url": "https://github.com/idaholab/moose/discussions/25965#discussioncomment-7704688",
                  "updatedAt": "2023-11-29T13:16:23Z",
                  "publishedAt": "2023-11-29T13:16:22Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "@recuero",
                          "url": "https://github.com/idaholab/moose/discussions/25965#discussioncomment-7704780",
                          "updatedAt": "2023-11-29T13:25:18Z",
                          "publishedAt": "2023-11-29T13:25:17Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "TJT-post95"
                          },
                          "bodyText": "Thanks\uff01\ud83d\ude04",
                          "url": "https://github.com/idaholab/moose/discussions/25965#discussioncomment-7707019",
                          "updatedAt": "2023-11-29T16:31:04Z",
                          "publishedAt": "2023-11-29T16:31:03Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              },
              {
                "node": {
                  "author": {
                    "login": "recuero"
                  },
                  "bodyText": "It seems that your analysis is focused on the Jacobian calculations, which do not change your simulation results (they can, for sure, change its convergence behavior). You can use the finite difference preconditioner to check the correctness of the Jacobian calculations for the B-bar formulation and compare with your own.",
                  "url": "https://github.com/idaholab/moose/discussions/25965#discussioncomment-7706984",
                  "updatedAt": "2023-11-29T16:27:43Z",
                  "publishedAt": "2023-11-29T16:27:42Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "TJT-post95"
                          },
                          "bodyText": "OK\uff01I will have a try.",
                          "url": "https://github.com/idaholab/moose/discussions/25965#discussioncomment-7707036",
                          "updatedAt": "2023-11-29T16:32:05Z",
                          "publishedAt": "2023-11-29T16:32:05Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "The threadJoin function and finalize function of the UserObject class",
          "author": {
            "login": "hityyds"
          },
          "bodyText": "I'm planning to write a subclass of DomainUserObject to implement integration calculations for variables over all faces of a mesh. For reference, I've examined two classes, NodalArea and ElementSidesL2Norm. According to the MOOSE website, the NodalArea object computes the tributary area of each node on a contact surface, while ElementSidesL2Norm computes the L2 norm of a variable over element sides. However, I'm curious about how MOOSE implements the traversal of these classes on the mesh.\nThey are subclasses of InternalSideUserObject and SideUserObject, respectively, and both of these base classes have references to Elem and Side that are const-qualified:\n/// pointer to the current element object\n  const Elem * const & _current_elem;\n\n/// current side of the current element\n  const unsigned int & _current_side;\n\nFrom the MOOSE code, I suspect that the threadJoin and finalize functions handle the information transfer and processing for calculations over all element faces. All subclasses of UserObject (including NodalArea and ElementSidesL2Norm) have these two functions. In UserObject.h, their code comments are as follows:\n  /**\n   * Finalize.  This is called _after_ execute() and _after_ threadJoin()!  This is probably where\n   * you want to do MPI communication!\n   */\n  virtual void finalize() = 0;\n  /**\n\n\n   * Must override.\n   *\n   * @param uo The UserObject to be joined into _this_ object.  Take the data from the uo object and\n   * \"add\" it into the data for this object.\n   */\n  virtual void threadJoin(const UserObject & uo) = 0;\n\nElementSidesL2Norm inherits from InternalSideIntegralPostprocessor, and in InternalSideIntegralPostprocessor, MOOSE defines the threadJoin and finalize functions:\nvoid\nInternalSideIntegralPostprocessor::threadJoin(const UserObject & y)\n{\n  const InternalSideIntegralPostprocessor & pps =\n      static_cast<const InternalSideIntegralPostprocessor &>(y);\n  _integral_value += pps._integral_value;\n}\n\nvoid\nInternalSideIntegralPostprocessor::finalize()\n{\n  gatherSum(_integral_value);\n}\n\nFor NodalArea, the definitions of these two functions are as follows:\nvoid\nNodalArea::threadJoin(const UserObject & fred)\n{\n  const NodalArea & na = dynamic_cast<const NodalArea &>(fred);\n\n  std::map<const Node *, Real>::const_iterator it = na._node_areas.begin();\n  const std::map<const Node *, Real>::const_iterator it_end = na._node_areas.end();\n  for (; it != it_end; ++it)\n  {\n    _node_areas[it->first] += it->second;\n  }\n}\n\nvoid\nNodalArea::finalize()\n{\n\n  const std::map<const Node *, Real>::iterator it_end = _node_areas.end();\n  for (std::map<const Node *, Real>::iterator it = _node_areas.begin(); it != it_end; ++it)\n  {\n    const Node * const node = it->first;\n    dof_id_type dof = node->dof_number(_system.number(), _variable->number(), 0);\n    _aux_solution.set(dof, 0);\n  }\n  _aux_solution.close();\n\n  for (std::map<const Node *, Real>::iterator it = _node_areas.begin(); it != it_end; ++it)\n  {\n    const Node * const node = it->first;\n    dof_id_type dof = node->dof_number(_system.number(), _variable->number(), 0);\n    _aux_solution.add(dof, it->second);\n  }\n  _aux_solution.close();\n}\n\nRegarding the definition in NodalArea, I find it quite perplexing. While I can understand the accumulation of _integral_value in ElementSidesL2Norm, why is there an accumulation of _node_areas in the threadJoin function of NodalArea? Additionally, the current NodalArea object seems to possess nodal information on other element sides. Since threadJoin already facilitates information exchange between different UserObjects, why is the finalize function necessary?\nThe implementation of threadJoin and finalize functions gives me the impression that objects declared using ElementSidesL2Norm and NodalArea don't just have information from one element side but rather seem to hold the computation results for all mesh elements. This issue has been bothering me for quite some time, and I would greatly appreciate any guidance if someone could provide some insight!!!",
          "url": "https://github.com/idaholab/moose/discussions/26171",
          "updatedAt": "2024-01-11T13:11:18Z",
          "publishedAt": "2023-11-28T15:25:23Z",
          "category": {
            "name": "Q&A General"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "GiudGiud"
                  },
                  "bodyText": "Hello\n\nthreadJoin and finalize functions gives me the impression that objects declared using ElementSidesL2Norm and NodalArea don't just have information from one element side but rather seem to hold the computation results for all mesh elements.\n\nWell yes they do hold computational results for all 'mesh elements' (as opposed to just a single piece of data). In different ways, as ElementSidesL2Norm computes a single number and NodalArea computes one number per node, but these threadJoin and finalize steps are meant to reduce information across threads and parallel processes respectively.\nThreadJoin is across threads. Any thread can have computed any part of the nodal area of any node.\nFinalize reduces across MPI processes. Any MPI process can have computed any part of the nodal area of any node.\nFor both of these we need reduce across the workers to only keep one number per-node\nGuillaume",
                  "url": "https://github.com/idaholab/moose/discussions/26171#discussioncomment-7694604",
                  "updatedAt": "2023-11-28T16:47:28Z",
                  "publishedAt": "2023-11-28T16:47:27Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "hityyds"
                          },
                          "bodyText": "Thank you very much for your response. I have received your assistance several times recently. Regarding your reply, I have the following understanding; I'm not sure if my interpretation is correct.\n\nWell yes they do hold computational results for all 'mesh elements' (as opposed to just a single piece of data).\n\nDoes this imply that there are NodalArea and ElementSideL2Norm objects, each associated with a face on a mesh cell, and even though each object contains information for only one face, it ultimately stores the computation results for all cells? Could this potentially lead to significant memory wastage since the results for all faces are duplicated multiple times?\n\nthese threadJoin and finalize steps are meant to reduce information across threads and parallel processes respectively.\n\nIn terms of the execution logic, does MOOSE initially consolidate the computation results for all threads within each process by invoking the threadJoin function, and subsequently call the finalize function to aggregate the computation results for all processes? This would ensure that each NodalArea and ElementSideL2Norm object holds the complete computation results for the entire mesh.",
                          "url": "https://github.com/idaholab/moose/discussions/26171#discussioncomment-7699184",
                          "updatedAt": "2023-11-29T03:13:36Z",
                          "publishedAt": "2023-11-29T03:12:39Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "To the first one, yes and no\nWe only have one copy of the object doing the work for every thread and every MPI process. We don't need one object per element, each object can process multiple elements.\nHowever they each hold data that will need to be reduced at the end (after they have been accumulated on the thread/process object, from the elements/nodes that that copy examined)\nFor the NodalArea that data is on a per node basis. So yes it can be fairly large and replicating it will cause memory issues. However, it is not of the size of the entire mesh's number of nodes. It s only sized to the nodes that this object is actually looking at. So we do not expect a total replication.\nWhen you run in this kind of memory concerns, you may consider distributing the mesh. This will ensure process-storage remains local as each process will only see part of the mesh",
                          "url": "https://github.com/idaholab/moose/discussions/26171#discussioncomment-7704954",
                          "updatedAt": "2023-11-29T13:49:44Z",
                          "publishedAt": "2023-11-29T13:44:18Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "To the second one yes.\nTheeadJoin first to reduce across threads then finalize to reduce across processes.\nI think these are global all-to-all reductions (for processes at least) though it would be good to check. This means that at the end, the entire-mesh reduction is stored on every process.",
                          "url": "https://github.com/idaholab/moose/discussions/26171#discussioncomment-7704981",
                          "updatedAt": "2023-11-29T13:46:37Z",
                          "publishedAt": "2023-11-29T13:46:37Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "hityyds"
                          },
                          "bodyText": "Therefore, if the program is running on three processes, each invoking two threads, there will be six copies. You used \"reduce\" to describe the functionality of the TheadJoin and finalize functions. Will these six copies persist even after executing the TheadJoin and finalize functions?\n\nThey are subclasses of InternalSideUserObject and SideUserObject, respectively, and both of these base classes have references to Elem and Side that are const-qualified:\n/// pointer to the current element object\n  const Elem * const & _current_elem;\n\n/// current side of the current element\n  const unsigned int & _current_side;\n\n\nFurthermore, as I mentioned in the question, these objects have references to elem and side that are const-qualified. In this context, how do they handle computations involving multiple elems? I haven't undergone formal programming education, but based on my understanding, this referencing approach doesn't seem to enable an object to perform calculations on multiple elems because it only owns data related to one elem side.",
                          "url": "https://github.com/idaholab/moose/discussions/26171#discussioncomment-7705579",
                          "updatedAt": "2023-11-29T14:34:41Z",
                          "publishedAt": "2023-11-29T14:34:40Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "Therefore, if the program is running on three processes, each invoking two threads, there will be six copies.\n\nyes\n\nWill these six copies persist even after executing the TheadJoin and finalize functions?\n\nyes, for the next iteration\n\nFurthermore, as I mentioned in the question, these objects have references to elem and side that are const-qualified. In this context, how do they handle computations involving multiple elems?\n\nthe reference is const, but the thing it references can change under the hood. That is done by the Assembly class usually. Here I think it's done by the Threaded side-element loop. The 'constness' is only local to the object, it means that NodalArea cannot modify that reference, not that that reference cannot ever change from somewhere else",
                          "url": "https://github.com/idaholab/moose/discussions/26171#discussioncomment-7705824",
                          "updatedAt": "2023-11-29T14:52:47Z",
                          "publishedAt": "2023-11-29T14:52:46Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "hityyds"
                          },
                          "bodyText": "/// pointer to the current element object\n  const Elem * const & _current_elem;\n\n\nIs this not declaring a constant pointer to a constant element? I always thought that neither the pointer should point to a new address nor should the value being pointed to be changed.\n\nHere I think it's done by the Threaded side-element loop.\n\nI suspect that MOOSE performs the mesh traversal through the loop in ThreadedElementLoopBase::operator()(const RangeType & range, bool bypass_threading), which repeatedly calls ComputeUserObjectsThread::onInternalSide(const Elem * elem, unsigned int side) and other UserObjects' computation functions. However, I couldn't find in ComputeUserObjectsThread::onInternalSide() how MOOSE invokes the relevant elem and side for the computation based on the input parameters ('elem' and 'side'). Instead, it seems MOOSE repeatedly calls a batch of InternalSideUserObject objects without changing elem and side.\nvoid\nComputeUserObjectsThread::onInternalSide(const Elem * elem, unsigned int side)\n{\n  // Pointer to the neighbor we are currently working on.\n  const Elem * neighbor = elem->neighbor_ptr(side);\n\n  // Get the global id of the element and the neighbor\n  const dof_id_type elem_id = elem->id(), neighbor_id = neighbor->id();\n\n  if (_internal_side_objs.size() == 0 && _domain_objs.size() == 0)\n    return;\n  if (!((neighbor->active() && (neighbor->level() == elem->level()) && (elem_id < neighbor_id)) ||\n        (neighbor->level() < elem->level())))\n    return;\n\n  _fe_problem.prepareFace(elem, _tid);\n  _fe_problem.reinitNeighbor(elem, side, _tid);\n\n  // Set up Sentinels so that, even if one of the reinitMaterialsXXX() calls throws, we\n  // still remember to swap back during stack unwinding.\n  SwapBackSentinel face_sentinel(_fe_problem, &FEProblem::swapBackMaterialsFace, _tid);\n  _fe_problem.reinitMaterialsFace(elem->subdomain_id(), _tid);\n\n  SwapBackSentinel neighbor_sentinel(_fe_problem, &FEProblem::swapBackMaterialsNeighbor, _tid);\n  _fe_problem.reinitMaterialsNeighbor(neighbor->subdomain_id(), _tid);\n\n  for (const auto & uo : _internal_side_objs)\n    if (!uo->blockRestricted() || uo->hasBlocks(neighbor->subdomain_id()))\n      uo->execute();\n\n  for (auto & uo : _domain_objs)\n    if (!uo->blockRestricted() || uo->hasBlocks(neighbor->subdomain_id()))\n    {\n      uo->preExecuteOnInternalSide();\n      uo->executeOnInternalSide();\n    }\n}",
                          "url": "https://github.com/idaholab/moose/discussions/26171#discussioncomment-7706484",
                          "updatedAt": "2023-11-29T15:51:25Z",
                          "publishedAt": "2023-11-29T15:47:23Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "const Elem * const & _current_elem;\n\nthis is a reference to a constant pointer to a const element (either that or a const reference to an element pointer, not sure)\n1st const says that NodalArea does not modify this element\n2nd const says that NodalArea does not modify this pointer (once it is set)\nThe important thing is that the element can change! Just not changed by NodalArea",
                          "url": "https://github.com/idaholab/moose/discussions/26171#discussioncomment-7706534",
                          "updatedAt": "2023-11-29T15:51:53Z",
                          "publishedAt": "2023-11-29T15:51:53Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "hityyds"
                          },
                          "bodyText": "Thank you very much for your response!",
                          "url": "https://github.com/idaholab/moose/discussions/26171#discussioncomment-7706686",
                          "updatedAt": "2023-11-29T16:04:07Z",
                          "publishedAt": "2023-11-29T16:04:06Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      }
    ]
  }
}