{
  "discussions": {
    "pageInfo": {
      "hasNextPage": true,
      "endCursor": "Y3Vyc29yOnYyOpK5MjAyMS0wMy0zMFQxMzo0MzozMS0wNjowMM4AMhFE"
    },
    "edges": [
      {
        "node": {
          "title": "GPERF_DIR: cannot compile in debug mode",
          "author": {
            "login": "WilkAndy"
          },
          "bodyText": "I get:\nprojects/moose/modules/geochemistry/unit/> METHOD=dbg make     \n/Users/wil04q/projects/moose/framework/build.mk:50: *** It does not make sense to profile with the dbg method due to assertions. Please unset GPERF_DIR.  Stop.\n\nIs this desirable?   I compile in debug mode by default during development, don't you?",
          "url": "https://github.com/idaholab/moose/discussions/17515",
          "updatedAt": "2022-06-17T16:07:11Z",
          "publishedAt": "2021-04-06T00:33:39Z",
          "category": {
            "name": "Q&A General"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "GiudGiud"
                  },
                  "bodyText": "I think most of us use devel now. It's a lot faster",
                  "url": "https://github.com/idaholab/moose/discussions/17515#discussioncomment-572498",
                  "updatedAt": "2022-06-17T16:07:11Z",
                  "publishedAt": "2021-04-06T00:42:35Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "WilkAndy"
                          },
                          "bodyText": "OK, i'll move to that too.",
                          "url": "https://github.com/idaholab/moose/discussions/17515#discussioncomment-572625",
                          "updatedAt": "2022-06-17T16:07:11Z",
                          "publishedAt": "2021-04-06T01:36:05Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "WilkAndy"
                          },
                          "bodyText": "This doesn't work either, since i get:\nprojects/moose/modules/geochemistry/> METHOD=devel make -j 2                    \n/Users/wil04q/projects/moose/framework/build.mk:50: *** It does not make sense to profile with the devel method due to assertions. Please unset GPERF_DIR.  Stop.",
                          "url": "https://github.com/idaholab/moose/discussions/17515#discussioncomment-572846",
                          "updatedAt": "2022-06-17T16:07:11Z",
                          "publishedAt": "2021-04-06T03:09:34Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "Ah should have known you'd get that still, asserts are still there in devel.\nYou'll need a 'prof' build to profile it",
                          "url": "https://github.com/idaholab/moose/discussions/17515#discussioncomment-573000",
                          "updatedAt": "2022-06-17T16:07:11Z",
                          "publishedAt": "2021-04-06T04:32:38Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "WilkAndy"
                          },
                          "bodyText": "i don't want to profile it.  i want to debug the code - hence use of METHOD=dbg",
                          "url": "https://github.com/idaholab/moose/discussions/17515#discussioncomment-573042",
                          "updatedAt": "2022-06-17T16:07:24Z",
                          "publishedAt": "2021-04-06T04:56:39Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "Can you unset GPERF_DIR? It thinks you want to profile it because this environment variable is set",
                          "url": "https://github.com/idaholab/moose/discussions/17515#discussioncomment-573060",
                          "updatedAt": "2022-06-17T16:07:24Z",
                          "publishedAt": "2021-04-06T05:06:15Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "WilkAndy"
                          },
                          "bodyText": "Yea, i can and that works fine.  But why has MOOSE set that env var automatically?",
                          "url": "https://github.com/idaholab/moose/discussions/17515#discussioncomment-573105",
                          "updatedAt": "2022-06-17T16:07:24Z",
                          "publishedAt": "2021-04-06T05:35:19Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "YaqiWang"
                          },
                          "bodyText": "If MOOSE sets GPERF_DIR automatically, we need to turn that error to a warning. We assumed that users set this environment variable explicitly thus they know what they are trying to do. But I doubt MOOSE sets that though. Maybe double check your bash profile?",
                          "url": "https://github.com/idaholab/moose/discussions/17515#discussioncomment-573337",
                          "updatedAt": "2022-06-17T16:07:24Z",
                          "publishedAt": "2021-04-06T06:44:19Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "WilkAndy"
                          },
                          "bodyText": "OK, here it is...\n/Users/wil04q/> cat .zshrc\nalias emacs=\"/Applications/Emacs.app/Contents/MacOS/Emacs\"\nPROMPT='%n@%m: %d/> '\n\nexport VTKINCLUDE_DIR=/opt/moose/VTK-8.2.0/clang-9.0.0/include/vtk-8.2\nexport VTKLIB_DIR=/opt/moose/VTK-8.2.0/clang-9.0.0/lib\nexport LD_LIBRARY_PATH=/opt/moose/VTK-8.2.0/clang-9.0.0/lib:$LD_LIBRARY_PATH\nexport PYTHONPATH=$PYTHONPATH:/opt/moose/VTK-8.2.0/lib/python3.7/site-packages\n# use ./scripts/update_and_rebuild_libmesh.sh --enable-vtk\n\n#MOOSE_ENVIRONMENT\n# Uncomment to enable autojump:\n# export MOOSE_JUMP=true\n\n# Uncomment to enable pretty prompt:\n# export MOOSE_PROMPT=true\n\n# Source MOOSE profile\nif [ -f /opt/moose/environments/moose_profile ]; then\n        . /opt/moose/environments/moose_profile\n\n        # Make the moose compiler stack available.\n        # Note: if you have any additional package managers installed\n        # (Homebrew, Macports, Fink, etc) know that you must perform\n        # the following command _after_ the source commands for the\n        # afore mentioned package managers.\n        module load moose-dev-clang\nfi\n#ENDMOOSE_ENVIRONMENT\n\nexport PATH=\"/Applications/CMake.app/Contents/bin\":\"$PATH\"\n\nI believe i haven't made any changes to the moose environment.\n/Users/wil04q/> env | grep GP\nGPERF_DIR=/opt/moose/gperftools-2.7\n\nThe GPERF_DIR is set by the moose-dev-clang module, which loads the gperftools-2.7 module:\n/Users/wil04q/> module list  \nCurrently Loaded Modulefiles:\n 1) moose/.gcc-9.2.0                                6) moose-tools            \n 2) moose/.clang-9.0.0                              7) moose/.gperftools-2.7  \n 3) moose/.mpich-3.3_clang-9.0.0                    8) miniconda              \n 4) moose/.petsc-3.11.4_mpich-3.3_clang-9.0.0-opt   9) moose-dev-clang",
                          "url": "https://github.com/idaholab/moose/discussions/17515#discussioncomment-574013",
                          "updatedAt": "2022-06-17T16:07:24Z",
                          "publishedAt": "2021-04-06T09:36:16Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "I'm unfamiliar with modules on Mac. Are these the same as the HPC modules? Who created these?",
                          "url": "https://github.com/idaholab/moose/discussions/17515#discussioncomment-575331",
                          "updatedAt": "2022-06-17T16:07:27Z",
                          "publishedAt": "2021-04-06T14:54:04Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "cticenhour"
                          },
                          "bodyText": "@GiudGiud That is the old moose environment package. Note the \"source moose profile\" comment in the .zshrc excerpt.",
                          "url": "https://github.com/idaholab/moose/discussions/17515#discussioncomment-575370",
                          "updatedAt": "2022-06-17T16:07:27Z",
                          "publishedAt": "2021-04-06T15:01:09Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              },
              {
                "node": {
                  "author": {
                    "login": "WilkAndy"
                  },
                  "bodyText": "Small problem with \"devel\":\nLinking Library /Users/wil04q/projects/moose/framework/contrib/pcre/libpcre-devel.la...\nld: library not found for -lmesh_devel\nclang-9: error: linker command failed with exit code 1 (use -v to see invocation)\nmake: *** [/Users/wil04q/projects/moose/framework/contrib/pcre/libpcre-devel.la] Error 1\nmake: *** Waiting for unfinished jobs....\n\nIs this library supposed to be automatically built, or do we need to modify a makefile/whatever somewhere?",
                  "url": "https://github.com/idaholab/moose/discussions/17515#discussioncomment-572678",
                  "updatedAt": "2022-06-17T16:07:16Z",
                  "publishedAt": "2021-04-06T02:00:18Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "It should be automatic. clobberall then try again?",
                          "url": "https://github.com/idaholab/moose/discussions/17515#discussioncomment-572699",
                          "updatedAt": "2022-06-17T16:07:18Z",
                          "publishedAt": "2021-04-06T02:11:19Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "WilkAndy"
                          },
                          "bodyText": "This did not work (produced the same error as above)\nprojects/moose/modules/geochemistry/> METHOD=devel make clobberall\nprojects/moose/modules/geochemistry/> METHOD=devel make",
                          "url": "https://github.com/idaholab/moose/discussions/17515#discussioncomment-572830",
                          "updatedAt": "2022-06-17T16:07:18Z",
                          "publishedAt": "2021-04-06T03:05:00Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "manjaro moose conda conflicts",
          "author": {
            "login": "zhanghg1983"
          },
          "bodyText": "Hi,guys,I am a new moose and conda user,\nand my OS is manjaro ,\nall I want to is to install moose in my OS ,successfully\nbut I almost mess up after many times try.\nthe error was like:\nunsatisfiableError: The following specifications were found to be incompatible with each other:\nOutput in format: Requested package -> Available versions\nThanks for any help\nmooseerror.txt\nmooseerror1.txt",
          "url": "https://github.com/idaholab/moose/discussions/16650",
          "updatedAt": "2022-10-21T11:52:05Z",
          "publishedAt": "2021-01-09T00:08:56Z",
          "category": {
            "name": "Q&A Getting Started"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "milljm"
                  },
                  "bodyText": "I think you need to include the conda-forge channel (add an additional --channel conda-forge to your command). Hard to say though. Conflict resolution and displaying the conflict, is a rough go for Conda (in my honest opinion).\nAlso, I highly suggest you not employ the use of sudo when using conda. It should not be necessary, unless you are attempting to administer a multi-user machine, wishing to make the Conda packages you are about to install, available to everyone on the machine.\nVery rarely have I seen this requirement. Most folks enjoy installing their own instance of Conda to their home directories. Making them the owner (without needing sudo).",
                  "url": "https://github.com/idaholab/moose/discussions/16650#discussioncomment-270446",
                  "updatedAt": "2022-10-21T11:52:09Z",
                  "publishedAt": "2021-01-09T00:54:00Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "zhanghg1983"
                          },
                          "bodyText": "Hi,milljm, Thank you very much for the help. So sorry for  replying so lately. after receving your suggestions. I tried another several times,but still failed.\nToday,I went through some blogs about conda, and someone said delete the ~/.condarc may work.\nI tried and it works, still don't know why. hopefully It will offer some help for the ones with simliar problems.",
                          "url": "https://github.com/idaholab/moose/discussions/16650#discussioncomment-573884",
                          "updatedAt": "2022-10-21T11:52:27Z",
                          "publishedAt": "2021-04-06T09:12:08Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "How can I prevent divergence with adaptive timesteps?",
          "author": {
            "login": "ke7kto"
          },
          "bodyText": "I'm working on adding an adaptive timestep to my simulation, but I'm getting convergence issues. I then tried applying adaptive timesteppers to example 8, which causes the executable to error out because of divergence at any step size.\nI've tried AB2PredictorCorrector and DT2 for the adaptive timesteps, and both end with errors. Is there some sort of a tutorial on appropriate settings for these timesteppers, and what solvers/preconditioners work well with them? Or on common pitfalls that should be avoided?\nex08_adaptive.i.txt\nex08ab2.i.txt",
          "url": "https://github.com/idaholab/moose/discussions/17508",
          "updatedAt": "2023-03-02T08:36:23Z",
          "publishedAt": "2021-04-05T16:59:15Z",
          "category": {
            "name": "Q&A General"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "ke7kto"
                  },
                  "bodyText": "Seems like the parameter nl_abs_tol was helpful to put in the Executioner block, as mentioned here. With this set to an arbitrary value, I do have convergence.",
                  "url": "https://github.com/idaholab/moose/discussions/17508#discussioncomment-571421",
                  "updatedAt": "2023-03-02T08:36:25Z",
                  "publishedAt": "2021-04-05T18:30:13Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "WilkAndy"
                          },
                          "bodyText": "Hopefully not too arbitrary, heheheh",
                          "url": "https://github.com/idaholab/moose/discussions/17508#discussioncomment-572136",
                          "updatedAt": "2023-03-02T08:36:25Z",
                          "publishedAt": "2021-04-05T22:00:27Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "Survey: Development of spline-based FEM (IGA) technologies in MOOSE",
          "author": {
            "login": "GregVernon"
          },
          "bodyText": "MOOSE Community,\nAs you may have heard, we at Coreform have been partnering with INL on some MOOSE developments.  Primarily these have included adding spline basis function technologies to MOOSE and the MOOSE ecosystem, thereby enabling spline-based FEM (often referred to as Isogeometric Analysis or \"IGA\").  We also develop Coreform Cubit, a meshing and model-preparation software that is often used with MOOSE.\nTo help identify and prioritize features, we've put together a short nine-question survey to solicit your input and feedback.  We will share the results of the survey with the MOOSE community once the survey is completed (maybe after a week or two). Your responses will help Coreform, and other MOOSE developers, identify and prioritize desired features to add to MOOSE and Coreform Cubit for the MOOSE community!\n- Coreform\nLink to Survey",
          "url": "https://github.com/idaholab/moose/discussions/17021",
          "updatedAt": "2022-07-20T10:10:42Z",
          "publishedAt": "2021-02-16T19:45:06Z",
          "category": {
            "name": "Q&A General"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "GregVernon"
                  },
                  "bodyText": "Thank you to everyone who responded to the survey!  I've attached the results of the survey to this comment in the hopes that you find them insightful, if not helpful for your own endeavors!\nMOOSE_Survey_Results.pdf",
                  "url": "https://github.com/idaholab/moose/discussions/17021#discussioncomment-568446",
                  "updatedAt": "2022-07-20T10:10:52Z",
                  "publishedAt": "2021-04-04T19:10:04Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": []
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "3D spinodal decomposition",
          "author": {
            "login": "Amir1361"
          },
          "bodyText": "Hello,\nI am trying to have a 3D simulation of spinodal decomposition. First, I used \"GeneratedMesh,\" and it works with a small mesh number. But when I increased the nx, ny, and nz, I was out of memory.\n\"mpiexec noticed that process rank 0 with PID 66797 on node cpu110 exited on signal 9 (Killed).\"\nThen, I changed it to \"DistributedRectilinearMeshGenerator\" to run it with more mesh numbers. But I got the following error:\n\"^[[31m\n*** ERROR ***\nTask init_mesh is not registered to build MeshGenerator derived objects^[[39m\n\nMPI_ABORT was invoked on rank 0 in communicator MPI_COMM_WORLD\nwith errorcode 1.\nNOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.\nYou may or may not see output from other processes, depending on\nexactly when Open MPI kills them.\n[cpu102:07986] 7 more processes have sent help message help-mpi-api.txt / mpi-abort\n[cpu102:07986] Set MCA parameter \"orte_base_help_aggregate\" to 0 to see all help / error messages\"\nHere is my mesh part in the input file:\n[Mesh]\ntype = DistributedRectilinearMeshGenerator\ndim = 3\nelem_type = QUAD4\nnx = 25\nny = 25\nnz = 25\nxmax = 100\nymax = 100\nzmax = 100\n[]\nCould you please help me to solve this?\nBest,\nAmir",
          "url": "https://github.com/idaholab/moose/discussions/17427",
          "updatedAt": "2022-08-04T10:26:38Z",
          "publishedAt": "2021-03-24T19:59:52Z",
          "category": {
            "name": "Q&A Modules: Phase field"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "aeslaughter"
                  },
                  "bodyText": "Do you have mesh adaptivity enabled?",
                  "url": "https://github.com/idaholab/moose/discussions/17427#discussioncomment-527766",
                  "updatedAt": "2022-08-04T10:27:03Z",
                  "publishedAt": "2021-03-25T03:03:10Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "jiangwen84"
                          },
                          "bodyText": "On top of @aeslaughter 's question, are you using a direct solver, i.e. LU?\nBTW, your element_type = QUAD4 does not make sense for a 3D domain.",
                          "url": "https://github.com/idaholab/moose/discussions/17427#discussioncomment-527848",
                          "updatedAt": "2022-08-04T10:27:03Z",
                          "publishedAt": "2021-03-25T03:46:06Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "Amir1361"
                          },
                          "bodyText": "Thank you for your replies.\nThis is my input file: FeCrCo_3D.txt\nI removed the \"element_type = QUAD4\", but it doesn't work yet. How can I enable the mesh adaptivity?",
                          "url": "https://github.com/idaholab/moose/discussions/17427#discussioncomment-528108",
                          "updatedAt": "2022-08-04T10:27:04Z",
                          "publishedAt": "2021-03-25T06:05:28Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "permcody"
                          },
                          "bodyText": "Even with DistributedRectilinearMeshGenerator you still need to set your parallel_type = distributed to run with distributed mesh. However, I don't think this problem is big enough to require distributed so I tried it without. It ran OK as the per core memory usage was about just over 2GB after 3 time steps. Depending on your system and how many MPI ranks you used, you can figure out if that would exceed your available memory. I would expect that number to continue to climb, but not too much beyond that. I then tried it with distributed and the memory usage stayed well under 2GB (~1.3GB).\nAnother very interesting thing I noted was how slow DistributedRectilinearMeshGenerator was. It took a very long time to generate the mesh. Using the simple \"GeneratoredMesh\" object it was only a split second. I know the former uses less memory but I'm a little surprised with how much slower it was. We probably haven't tried it much with medium size problems like this. It really is for very large problems.\nSo your input file works, just make sure you aren't running yourself out of memory!",
                          "url": "https://github.com/idaholab/moose/discussions/17427#discussioncomment-530094",
                          "updatedAt": "2022-08-04T10:27:05Z",
                          "publishedAt": "2021-03-25T14:59:31Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "jiangwen84"
                          },
                          "bodyText": "Adding a sub-block will fix the error.\n[Mesh]\n[drmg]\ntype = DistributedRectilinearMeshGenerator\ndim = 3\nnx = 25\nny = 25\nnz = 25\nxmax = 100\nymax = 100\nzmax = 100\n[]\n[]\n\n\nI am not sure if switching to distributed mesh will resolve your memory issue. I ran your input file with 10 MPI procs, and roughly each process requires a maximum 3-4 Gb memory. That seems to be reasonable to me. You might want to request more memory on you HPC to large 3D simulation.",
                          "url": "https://github.com/idaholab/moose/discussions/17427#discussioncomment-530128",
                          "updatedAt": "2023-04-19T19:43:32Z",
                          "publishedAt": "2021-03-25T15:07:29Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "Amir1361"
                          },
                          "bodyText": "Thank you very much! I do not have any problem with following mesh size:\n[Mesh]\n[drmg]\ntype = DistributedRectilinearMeshGenerator\ndim = 3\nnx = 25\nny = 25\nnz = 25\nxmax = 100\nymax = 100\nzmax = 100\n[]\n[]\nBut when I want to increase nx, ny, nz and xmax, ymax, zmax:\n[Mesh]\n[drmg]\ntype = DistributedRectilinearMeshGenerator\ndim = 3\nnx = 100\nny = 100\nnz = 100\nxmax = 200\nymax = 200\nzmax = 200\n[]\nI get the memory error:\n\"mpiexec noticed that process rank 0 with PID 142272 on node cpu102 exited on signal 9 (Killed).\"\nI am running my job on cluster computer (Boise State University). Is there any way to solve this issue? Thank you very much for your help!\nAmir",
                          "url": "https://github.com/idaholab/moose/discussions/17427#discussioncomment-531298",
                          "updatedAt": "2023-04-19T19:43:33Z",
                          "publishedAt": "2021-03-25T19:28:20Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "jiangwen84"
                          },
                          "bodyText": "To run a 3D problem with 100x100x100 definitely requires a lot of memory usage:-) So you have to work with your HPC admin to increase the memory for your simulation.",
                          "url": "https://github.com/idaholab/moose/discussions/17427#discussioncomment-536719",
                          "updatedAt": "2023-04-19T19:43:36Z",
                          "publishedAt": "2021-03-27T03:07:19Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "permcody"
                          },
                          "bodyText": "Amir, I suggest that when you run, you start up a \"top\" process on the lead node in your batch job and watch memory usage to see where you are at. If you are only a little over (it runs for past the mesh stage and dies in the solver), one way to get the extra memory you need is to simply not use all the cores on each node (e.g. if your nodes have 32 processors each, try running your problem using only 24 or 28 cores on the nodes). Doing this with a batch scheduling system is fairly straightforward. Your million element mesh shouldn't take too much memory (Several hundred MB on each rank), so there are other factors that may be causing you to run out of memory related to the sizes of your equation systems or other resident memory. Let us know if you need any further guidance.",
                          "url": "https://github.com/idaholab/moose/discussions/17427#discussioncomment-560349",
                          "updatedAt": "2023-04-19T19:43:36Z",
                          "publishedAt": "2021-04-01T21:54:35Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "Amir1361"
                          },
                          "bodyText": "@permcody Thank you very much for your comments. I will test the different options. Thank you for your help; I appreciate it.",
                          "url": "https://github.com/idaholab/moose/discussions/17427#discussioncomment-561047",
                          "updatedAt": "2023-04-19T19:43:36Z",
                          "publishedAt": "2021-04-02T03:53:20Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "No energy evolution in Grand Potential Phase Field model",
          "author": {
            "login": "scottedmuller"
          },
          "bodyText": "Hi All,\nI am developing a Grand Potential Phase Field model of a binary system in moose and it is having some really odd issues. The energies look right in both phases but I can supersaturate one phase a ton without causing any evolution. I can look at the free energy and see that it is increased appropriately in the given phase, indicating there should be a driving force for the energy to minimize, but no changes occur. Does anyone have any specific advice for troubleshooting a lack of energy minimization in my simulations? The energy is not increasing either there is just no change at all.\nThanks,\nScott",
          "url": "https://github.com/idaholab/moose/discussions/17437",
          "updatedAt": "2022-07-18T07:10:52Z",
          "publishedAt": "2021-03-26T17:44:57Z",
          "category": {
            "name": "Q&A Modules: Phase field"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "laagesen"
                  },
                  "bodyText": "Hi Scott- when you say the total energy is not decreasing, how are you determining that? Are you using a postprocessor to sum the local free energy density? Bear in mind that when you are using a grand potential model, it is the total grand potential that should decrease and not the Helmholtz free energy (although I think the first should imply the second). Also, what are your initial conditions? Just want to make sure it is not stuck in a metastable state.",
                  "url": "https://github.com/idaholab/moose/discussions/17437#discussioncomment-545469",
                  "updatedAt": "2022-07-18T07:11:02Z",
                  "publishedAt": "2021-03-29T20:14:18Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "scottedmuller"
                          },
                          "bodyText": "Hi Larry,\nI output both the grand potential and \"regular\" free energy as a Material block (just for looking at in Paraview). I've summed over the domain of the Grand Potential free energy density, and it is also not changing, neither increasing or decreasing (unless I change the mobilities in dramatic non-physical ways). The boundary conditions are periodic, and I'm currently considering a 1-D case for simplicity, with a domain of 10 microns. For the initial conditions, I use BoundingBoxIC to make a 4 micron region in the middle of the domain the solid (eta = 1) and everywhere else liquid (eta = 0), and I set the interface width (int_width) to 0.5 microns.\n\nI use a similar BoundingBoxIC for the chemical potential, with the solid region being set to zero (mu = 0), and the liquid region chosen based on the desired level of saturation.\n\nI've tested a variety of mu values for the liquid, including absurdly high values corresponding to concentrations close to the solid, but it makes no difference in the evolution of the system.\nDiffusion in the liquid and solid is on the order of 10^-3 and 10^-5 um^2/us respectively, and chi (partial of omega wrt mu) is on the order of 10^-5. When the mobility of the order parameter is set close to (but still above) the mobility of the chemical potential, nothing evolves at all.\nNot sure how helpful this is, but when I artificially increase the diffusion by a few orders of magnitude, and increase the order parameter mobility (eta) to make sure evolution is diffusion-limited, it produces odd behavior in the order parameter after a large number of steps:\n\nA state that I would think would be impossible. The chemical potential in this case is\n\nAgain, not sure how useful this is. I know there are a lot of random things that can be done to mess with a PF model to produce weird non-physical effects, but maybe it can help with troubleshooting?\nPlease let me know what other information I can give you to help diagnose the problem. Thank you very much for your help!\n-Scott",
                          "url": "https://github.com/idaholab/moose/discussions/17437#discussioncomment-555232",
                          "updatedAt": "2022-07-18T07:11:04Z",
                          "publishedAt": "2021-04-01T00:06:21Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "laagesen"
                          },
                          "bodyText": "Hi Scott, a couple of questions for you:\n-Are you starting from the example file moose/modules/phase_field/test/tests/GrandPotentialPFM/GrandPotentialPFM.i? If so please make sure your MOOSE repo is up to date; there was a bug fix to this implemented a few months ago (see #16343)\n-What are the free energies you are using for the solid and liquid phases?\n-If you set diffusivities in both phases to 1 does the problem persist?\n-If so can you please paste in the solver output from the first time step?",
                          "url": "https://github.com/idaholab/moose/discussions/17437#discussioncomment-555309",
                          "updatedAt": "2022-07-18T07:11:10Z",
                          "publishedAt": "2021-04-01T00:21:38Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "scottedmuller"
                          },
                          "bodyText": "I developed my model by hand, based mostly on Plapp's formulation from his 2011 paper (http://dx.doi.org/10.1103/PhysRevE.84.031601). I'm using a parabolic free energy for the solid, and I was originally using a free energy derived from the ideal solution model for the liquid, but I interpolated it as a parabolic free energy during troubleshooting, in case there were compatibility issues between the free energies.\nI just tested setting the diffusivities in both phases equal to 1, and the problem actually goes away! For the most part. I tested it with different values for the order parameter L's mobility, and evolution of the system changes quite a bit. When I set both the mobility and both diffusion coefficients to 1, I get the final state as\n\nWhich, as I understand it, is close to what we would expect for the chemical potential mu. The solver output is:\nMesh:\n  Parallel Type:           replicated\n  Mesh Dimension:          1\n  Spatial Dimension:       1\n  Nodes:\n    Total:                 101\n    Local:                 14\n  Elems:\n    Total:                 100\n    Local:                 13\n  Num Subdomains:          1\n  Num Partitions:          8\n  Partitioner:             metis\n\nNonlinear System:\n  Num DOFs:                202\n  Num Local DOFs:          28\n  Variables:               { \"eta\" \"mu\" }\n  Finite Element Types:    \"LAGRANGE\"\n  Approximation Orders:    \"FIRST\"\n\nAuxiliary System:\n  Num DOFs:                1500\n  Num Local DOFs:          195\n  Variables:               { \"local_GP_FE\" \"local_FE\" \"M_mu\" \"chi\" \"drho_eta\" ... \"rho\" \"rhoEq_l\" \"w_l\"\n                             \"w_loc\" \"w_s\" }\n  Finite Element Types:    \"MONOMIAL\"\n  Approximation Orders:    \"CONSTANT\"\n\nExecution Information:\n  Executioner:             Transient\n  TimeStepper:             IterationAdaptiveDT\n  Solver Mode:             Preconditioned JFNK\n  MOOSE Preconditioner:    SMP\n\n\nTime Step 0, time = 0\n\nPostprocessor Values:\n+----------------+----------------+----------------+\n| time           | total_FE       | total_GP_FE    |\n+----------------+----------------+----------------+\n|   0.000000e+00 |   0.000000e+00 |   0.000000e+00 |\n+----------------+----------------+----------------+\n\n\nTime Step 1, time = 1e-08, dt = 1e-08\n\nPerforming automatic scaling calculation\n\n 0 Nonlinear |R| = 3.167606e-06\n      0 Linear |R| = 3.167606e-06\n      1 Linear |R| = 1.755020e-09\n  Linear solve converged due to CONVERGED_RTOL iterations 1\n 1 Nonlinear |R| = 1.755160e-09\nNonlinear solve converged due to CONVERGED_FNORM_ABS iterations 1\n Solve Converged!\n\nPostprocessor Values:\n+----------------+----------------+----------------+\n| time           | total_FE       | total_GP_FE    |\n+----------------+----------------+----------------+\n|   0.000000e+00 |   0.000000e+00 |   0.000000e+00 |\n|   1.000000e-08 |   2.117288e-01 |  -2.158171e-01 |\n+----------------+----------------+----------------+\n\nJust to give more information, if I keep diffusion equal to one and set L = 10, the system evolves to\n\nAnd if L = 100, I get\n\nIf I instead reduce L to 0.1, I get\n\nThe best of these is when L and the diffusivities are equal to 1, which almost feels like blind luck that I happened to find values that behave well. When I return the diffusivity to its original value, or to a constant value on the order to the liquid diffusivity, and then reduce L proportionally, I get the same problem as before where nothing evolves at all. I'm not sure how I can exploit the working model (where L=D=1) to choose a value for L that will work, there must be another piece I'm missing that plays a role in the mobilities' interplay.",
                          "url": "https://github.com/idaholab/moose/discussions/17437#discussioncomment-560352",
                          "updatedAt": "2022-07-18T07:11:10Z",
                          "publishedAt": "2021-04-01T21:55:37Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "laagesen"
                          },
                          "bodyText": "Hey Scott, the example in the repository I mentioned before is also based on Plapp's 2011 paper. So you could compare that to the model you've developed to see if there are any differences in the implementation.\nI think that you may need to make some adjustments to your solver tolerances, time step, or problem scaling. Looking at your solver output, I notice that the original residual at the start of your first time step is |R| = 3.167606e-06. Let me explain what the residual means. When we set the governing equations up, we normally move all terms to the LHS of the equation so that the RHS of the equation is 0. The \"residual\" is what the numerical solver is finding for the RHS of the equation (which we would like to be zero or close to it).\nIn your case, the solver executes one nonlinear iteration and exits with a residual |R| = 1.755160e-09. Normally we would like to see the residual decrease much more than that, like 8 or 9 orders of magnitude decrease. So I think the anomalous results you are getting is because the problem is not being solved to sufficiently high accuracy. Although 10^-9 seems like a small number, what we consider small in this context depends on how your problem is scaled and your time step size. Since you start out with a pretty small residual, it needs to decrease quite a lot more than 3 orders of magnitude.\nFirst thing to do is figure out why the solver is exiting. The solver will exit if either the absolute or relative tolerance criteria is met. The relative tolerance criteria is set by the parameter nl_rel_tol in your input file. For that to succeed, the final residual divided by original residual (at the beginning of the time step) must be < nl_rel_tol. This is how we normally like the solver to exit, and a value of 10^-8 is usually a good value to use. You may also exit if the absolute tolerance criterion is met. This is controlled by the parameter nl_abs_tol; if your residual is smaller than this the solver declares success. The problem with this is that what constitutes a small number varies on your time step size, problem scaling and other factors. My guess of what is happening is that you have a value of something like nl_abs_tol = 2e-9 set such that your solver is exiting prematurely. So if that is the case I would set it to a much lower number or remove that parameter completely (in which case the default value of 1e-50 will be used).\nOnce you figure that out and make sure that your nl_rel_tol is set to a reasonable number, you should be able to increase your time step size significantly. That should increase the initial residual and then when the relative tolerance criterion is met the solve will proceed.\nI think the reason you saw some evolution with L=D=1 and none at all for the smaller numbers that you were previously using is that with smaller L and D, the initial residual was probably below a set value of nl_abs_tol, so the solver declared success at the beginning of the problem and didn't actually do anything.",
                          "url": "https://github.com/idaholab/moose/discussions/17437#discussioncomment-560449",
                          "updatedAt": "2022-07-19T22:22:03Z",
                          "publishedAt": "2021-04-01T22:23:12Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "Mixed element types?",
          "author": {
            "login": "joe61vette"
          },
          "bodyText": "I am using Cubit and for one region I would like to use \"tetmesh\".  When I do, the result is a mixture of \"tets\" and \"pyramids\".  This region would be one block for which I would normally set an element type.  But..\nIs it possibly to run a problem with a MOOSE-based code that has such a mix of element types?  If so, how should I set the element type?\nThanks,\nJoe Kelly",
          "url": "https://github.com/idaholab/moose/discussions/17478",
          "updatedAt": "2022-12-13T22:10:07Z",
          "publishedAt": "2021-03-31T21:30:02Z",
          "category": {
            "name": "Q&A Meshing"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "WilkAndy"
                  },
                  "bodyText": "You can certainly use MOOSE to run a model containing a mix of element types, and you shouldn't need to set the element type manually - MOOSE will just handle everything automatically.  There are only a few examples of this in the tests, for instance, many of the tests using AnnularMeshGenerator that creates QUAD4 and TRI3 elements in a single mesh.  However,  because of the constraints from the Exodus mesh definition, you're going to have to put your TETs into one block (also called \"subdomain\" in parts of MOOSE) and PYRAMIDs into another block.  By the way, this gives you the freedom of prescribing different physics to the TETs than the PYRAMIDs, if you needed to, although it doesn't sound like you actually want to do that.",
                  "url": "https://github.com/idaholab/moose/discussions/17478#discussioncomment-554883",
                  "updatedAt": "2022-12-13T22:10:07Z",
                  "publishedAt": "2021-03-31T21:39:25Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "joe61vette"
                          },
                          "bodyText": "Thanks Andy.\nUnfortunately, there is no easy way to separate the pyramids from the tets.  The pyramids get automatically generated to bridge from a neighboring region that uses quads. Maybe it is possible to convert the pyramids to tets?  I'll look at doing that.\nJoe",
                          "url": "https://github.com/idaholab/moose/discussions/17478#discussioncomment-554894",
                          "updatedAt": "2022-12-13T22:11:03Z",
                          "publishedAt": "2021-03-31T21:44:37Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "WilkAndy"
                          },
                          "bodyText": "So this has become a CUBIT question.  I'm not a CUBIT expert - is there some way to \"select all PYRAMIDs within a region and add them to a block\"?",
                          "url": "https://github.com/idaholab/moose/discussions/17478#discussioncomment-554907",
                          "updatedAt": "2022-12-13T22:11:03Z",
                          "publishedAt": "2021-03-31T21:49:09Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "joe61vette"
                          },
                          "bodyText": "Thanks again Andy.  I found a way to mesh this to avoid using tetmesh.  So, for now at least, my problem is solved.  May have to revisit this again later as pyramids provide a great transition from quads.  As I have a lot of long relatively thin regions, a map mesh that is swept is generally the best way to go. Unfortunately, there are sometimes thin wedge shaped adjoining regions for which tets are the best.  Pyramids provide the transition but with no clearly defined boundary.\nJoe",
                          "url": "https://github.com/idaholab/moose/discussions/17478#discussioncomment-557440",
                          "updatedAt": "2022-12-13T22:11:04Z",
                          "publishedAt": "2021-04-01T13:01:42Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              },
              {
                "node": {
                  "author": {
                    "login": "joe61vette"
                  },
                  "bodyText": "Andy, thanks to your suggestion about finding a command to group all pyramids in a block, I believe that I have found a solution for this.  Namely:\nBlock 1 add volume 1                    # puts all elements of volume 1 in block 1\nBlock 1 remove pyramid all           # removes all pyramid elements from block 1\nBlock 2 add volume 1                   # puts all elements of volume 1 in block 2\nBlock 2 remove tet all                  # removes all tet elements from block 2\nI think that will solve my problem.  You know Cubit has a lot of capability but sometimes it is difficult for a casual user to find it.\nJoe",
                  "url": "https://github.com/idaholab/moose/discussions/17478#discussioncomment-558132",
                  "updatedAt": "2022-12-13T22:11:42Z",
                  "publishedAt": "2021-04-01T15:02:52Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "author": {
                    "login": "joe61vette"
                  },
                  "bodyText": "Hello Again:\nEven better, Cubit can actually do this for you automatically.  Just use:\nset block mixed element output offset\nIt then adds an \"offset\" to the block ID.  One can specify the value of the offset (eg, 1000) for each element type.\nJoe",
                  "url": "https://github.com/idaholab/moose/discussions/17478#discussioncomment-558466",
                  "updatedAt": "2022-12-13T22:11:56Z",
                  "publishedAt": "2021-04-01T15:47:01Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "permcody"
                          },
                          "bodyText": "Yes, I think I remember doing this years ago. Thanks for the reminder Joe!",
                          "url": "https://github.com/idaholab/moose/discussions/17478#discussioncomment-560211",
                          "updatedAt": "2022-12-13T22:12:00Z",
                          "publishedAt": "2021-04-01T21:17:37Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "Shooting methods",
          "author": {
            "login": "ke7kto"
          },
          "bodyText": "It seems that this might be a little out of scope, but is there anything like a shooting method within moose, where one could vary, e.g. a material property, with a boundary condition acting as a constraint? I would imagine this could be highly useful, but also a very heavy lift to implement.",
          "url": "https://github.com/idaholab/moose/discussions/17477",
          "updatedAt": "2021-03-31T21:47:24Z",
          "publishedAt": "2021-03-31T20:33:16Z",
          "category": {
            "name": "Q&A Modules: General"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "GiudGiud"
                  },
                  "bodyText": "Hello\nI have a PR #17420 up for performing small optimization problems like this using the Control system, and more precisely a PID controller in a pseudo-transient calculation.\nMerging is likely to be pretty delayed as I want to add more capability to this but you could try it out.\nGuillaume",
                  "url": "https://github.com/idaholab/moose/discussions/17477#discussioncomment-554705",
                  "updatedAt": "2021-03-31T20:49:01Z",
                  "publishedAt": "2021-03-31T20:48:07Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "ke7kto"
                          },
                          "bodyText": "I'll take a look. Thanks!",
                          "url": "https://github.com/idaholab/moose/discussions/17477#discussioncomment-554902",
                          "updatedAt": "2021-03-31T21:47:10Z",
                          "publishedAt": "2021-03-31T21:47:10Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "Moose install",
          "author": {
            "login": "Draper18"
          },
          "bodyText": "Hello everyone,\nI am trying to install MOOSE on Linux Ubuntu 20.04.2 LTS. I followed the install guide but when I got to run tests at the end they all crashed. In the troubleshooting guide I cannot even get the always ok test to not crash. While working through the trouble shooting guide I was able to get the hello world example to work though. I have tried deactivating and removing MOOSE then going back through the install guide only to end up with the same results. Any help is greatly appreciated.\nThanks,\nAlex Draper",
          "url": "https://github.com/idaholab/moose/discussions/17464",
          "updatedAt": "2022-09-24T11:54:32Z",
          "publishedAt": "2021-03-30T20:10:56Z",
          "category": {
            "name": "Q&A Getting Started"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "GiudGiud"
                  },
                  "bodyText": "Hello\nCould you please post the error messages you are running into?\nGuillaume",
                  "url": "https://github.com/idaholab/moose/discussions/17464#discussioncomment-550071",
                  "updatedAt": "2022-09-24T11:54:36Z",
                  "publishedAt": "2021-03-30T20:23:50Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "author": {
                    "login": "Draper18"
                  },
                  "bodyText": "Here is the error message when running the tests\nMoose Error messages.txt",
                  "url": "https://github.com/idaholab/moose/discussions/17464#discussioncomment-550516",
                  "updatedAt": "2022-09-24T11:54:40Z",
                  "publishedAt": "2021-03-30T22:52:30Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "author": {
                    "login": "GiudGiud"
                  },
                  "bodyText": "It seems you are missing libquadmath. sudo apt install libquadmath or something close should help",
                  "url": "https://github.com/idaholab/moose/discussions/17464#discussioncomment-550618",
                  "updatedAt": "2022-09-24T11:54:41Z",
                  "publishedAt": "2021-03-30T23:36:04Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": []
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "PETSc crash maybe?",
          "author": {
            "login": "makeclean"
          },
          "bodyText": "I have a problem, I#m happy to share - it runs on 1120 MPI tasks when using presplit mode. If I dont pre-split, its a segfault on launch (presumably out of memory). If I run with 20 MPI tasks and 56 threads, it runs until after the 2nd timestep which is great\nmpirun noticed that process rank 5 with PID 226281 on node cpu-p-333 exited on signal 11 (Segmentation fault).\nTime Step 2, time = 0.000585938, dt = 0.000390625\nComputing initial residual ...........................                                     [ 28.34 s]\nUpdating displaced mesh ..........                                                         [ 11.14 s]\n 0 Nonlinear |R| = 5.922167e+02\nUpdating displaced mesh .........                                                          [ 10.98 s]\nAt line 80 of file xerbla.f (unit = 6, file = 'stdout')\nFortran runtime error: Missing initial left parenthesis in format\n\nAt line 80 of file xerbla.f (unit = 6, file = 'stdout')\nFortran runtime error: Missing initial left parenthesis in format\n\nAt line 80 of file xerbla.f (unit = 6, file = 'stdout')\nFortran runtime error: Missing initial left parenthesis in format\n\nAt line 80 of file xerbla.f (unit = 6, file = 'stdout')\nFortran runtime error: Missing initial left parenthesis in format\n\n--------------------------------------------------------------------------\nPrimary job  terminated normally, but 1 process returned\na non-zero exit code. Per user-direction, the job has been aborted.\n--------------------------------------------------------------------------\n--------------------------------------------------------------------------\nmpirun noticed that process rank 5 with PID 226281 on node cpu-p-333 exited on signal 11 (Segmentation fault).\n\nAnyone seen anything like it?",
          "url": "https://github.com/idaholab/moose/discussions/17382",
          "updatedAt": "2022-07-04T07:27:09Z",
          "publishedAt": "2021-03-19T07:48:44Z",
          "category": {
            "name": "Q&A General"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "makeclean"
                  },
                  "bodyText": "When it does run i get some lovely stress fields",
                  "url": "https://github.com/idaholab/moose/discussions/17382#discussioncomment-501985",
                  "updatedAt": "2022-07-04T07:27:07Z",
                  "publishedAt": "2021-03-19T07:50:16Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "author": {
                    "login": "makeclean"
                  },
                  "bodyText": "Ahh its a blas error",
                  "url": "https://github.com/idaholab/moose/discussions/17382#discussioncomment-501992",
                  "updatedAt": "2022-07-04T07:27:20Z",
                  "publishedAt": "2021-03-19T07:53:08Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "dschwen"
                          },
                          "bodyText": "Looks like a runtime error trying to print the actual error.\nhttps://www.netlib.org/lapack/explore-3.1.1-html/xerbla.f.html\nMy guess is, something is going horribly wrong way earlier, leading to bogus data going into some blas call.",
                          "url": "https://github.com/idaholab/moose/discussions/17382#discussioncomment-514970",
                          "updatedAt": "2022-07-04T07:27:21Z",
                          "publishedAt": "2021-03-22T20:02:42Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              },
              {
                "node": {
                  "author": {
                    "login": "fdkong"
                  },
                  "bodyText": "Did you get the error only when using threads?  How did you install blas?",
                  "url": "https://github.com/idaholab/moose/discussions/17382#discussioncomment-526466",
                  "updatedAt": "2022-07-04T07:27:21Z",
                  "publishedAt": "2021-03-24T19:14:23Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "makeclean"
                          },
                          "bodyText": "I couldnt actually run the problem without threads tbh",
                          "url": "https://github.com/idaholab/moose/discussions/17382#discussioncomment-540486",
                          "updatedAt": "2022-07-04T07:27:29Z",
                          "publishedAt": "2021-03-28T13:27:39Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "fdkong"
                          },
                          "bodyText": "Hmmm, I guess you should use a distributed mesh.",
                          "url": "https://github.com/idaholab/moose/discussions/17382#discussioncomment-549935",
                          "updatedAt": "2022-07-04T07:27:29Z",
                          "publishedAt": "2021-03-30T19:41:11Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "makeclean"
                          },
                          "bodyText": "It was running with a pre-splti mesh, but crashes, using mpi tasks, but fine with threading",
                          "url": "https://github.com/idaholab/moose/discussions/17382#discussioncomment-549944",
                          "updatedAt": "2022-07-04T07:27:30Z",
                          "publishedAt": "2021-03-30T19:43:31Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      }
    ]
  }
}