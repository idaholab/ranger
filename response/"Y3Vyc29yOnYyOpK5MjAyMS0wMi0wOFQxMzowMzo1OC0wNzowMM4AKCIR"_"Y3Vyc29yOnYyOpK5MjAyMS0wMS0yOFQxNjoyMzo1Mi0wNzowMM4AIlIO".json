{
  "discussions": {
    "pageInfo": {
      "hasNextPage": true,
      "endCursor": "Y3Vyc29yOnYyOpK5MjAyMS0wMS0yOFQxNjoyMzo1Mi0wNzowMM4AIlIO"
    },
    "edges": [
      {
        "node": {
          "title": "Question about example input file in combined module",
          "author": {
            "login": "Bala-1005"
          },
          "bodyText": "Hello everyone,\nI am trying to understand the example file given in the directory \"/moose/modules/combined/examples/phase_field-mechanics/kks_mechanics_VTS.i\".\nI have a question about how the elasticity tensor is constructed. Does the C_ijkl take values and multiply them with 10^9 to convert it into GPa scale or does it take values as it is?\nThanks,\nBala",
          "url": "https://github.com/idaholab/moose/discussions/16909",
          "updatedAt": "2022-11-01T17:59:28Z",
          "publishedAt": "2021-02-06T22:53:53Z",
          "category": {
            "name": "Q&A Modules: Solid mechanics"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "jessecarterMOOSE"
                  },
                  "bodyText": "Looks like the values in the input file have already been converted from GPa. The unit conversion is in the referenced paper. Right @laagesen ?",
                  "url": "https://github.com/idaholab/moose/discussions/16909#discussioncomment-345978",
                  "updatedAt": "2022-11-01T17:59:27Z",
                  "publishedAt": "2021-02-07T00:07:24Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "laagesen"
                          },
                          "bodyText": "Yes that's right, thanks @jessecarterMOOSE - they are non-dimensionalized by the factor by 2 x 10^9 J/m^3 = 2 GPa (see p.12 of the paper) . So if you multiply the elastic constants in the input file by 2 GPa you will get the numbers in Table 1.",
                          "url": "https://github.com/idaholab/moose/discussions/16909#discussioncomment-349858",
                          "updatedAt": "2022-11-01T17:59:39Z",
                          "publishedAt": "2021-02-08T15:51:55Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "Bala-1005"
                          },
                          "bodyText": "Thank you @laagesen and @jessecarterMOOSE.",
                          "url": "https://github.com/idaholab/moose/discussions/16909#discussioncomment-350243",
                          "updatedAt": "2022-11-01T17:59:41Z",
                          "publishedAt": "2021-02-08T17:22:06Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "Use of PolycrystalVariableAction-created variables in inputfiles",
          "author": {
            "login": "leanderVS"
          },
          "bodyText": "Hi all\nI recently started looking into the possibilities of MOOSE for corrosion modelling using the Phase Field module.\nOne of my very simple ideas would be to adapt the PolycrystalKernelAction. For this I simple assume the electrolyte to be another order parameter within the PolycrystalVariablesAction system, i.e. gr_1/eta_1 refers to the electrolyte. To limit corrosion to the interface, I adapted the GBEvolutionBase.C file, such that L~gr_1 (very simple, but theoretically effective for a first try). So basically I am slightly adapting the available grain_growth_2D_random.i file within the phase field module.\nOn the long term, I would use EBSD input and stitch that input to an electrolyte mesh. For now, however, I am just manually defining two grains and one electrolyte phase (through the FunctionIC system), while still using the abovementioned actions for variable/kernel generation. The thing is, when I try using gr_1 within the inputfile to supply as input for the FunctionIC or GBEvolutionBase.C adaptation, it just doesn't recognize it.\n*** ERROR ***      Variable 'gr_1' requested in initial condition 'eta_electrolyte' does not exist.\nWhich makes me wonder if it is somehow related to the order of the blocks within the inputfile or if you just can't refer to internally/Action-generated variables? Well, I am new, so I might be making a rookie mistake here.\nKind regards\nLeander Van Speybroeck\nGhent University, Belgium",
          "url": "https://github.com/idaholab/moose/discussions/16871",
          "updatedAt": "2022-09-22T07:40:31Z",
          "publishedAt": "2021-02-03T09:23:02Z",
          "category": {
            "name": "Q&A Modules: Phase field"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "SudiptaBiswas"
                  },
                  "bodyText": "The variable name that comes out of the PolycrystalVariableAction are gr0 gr1 .. or eta0 eta1 .. etc., based on the parameter var_name_base. Make sure you are proving the right variable name in your ICs and Materials. To avoid confusion, it might be better to manually add a separate variable in the input file for the electrolyte.",
                  "url": "https://github.com/idaholab/moose/discussions/16871#discussioncomment-342865",
                  "updatedAt": "2022-09-22T07:40:32Z",
                  "publishedAt": "2021-02-05T20:21:39Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "leanderVS"
                          },
                          "bodyText": "Thank you for your reply. Turns out I just kept mixing up the PolycrystalVariableAction source code. Indeed, the generated variables are called gr0, gr1, gr2 instead of gr_1, gr_2, gr_3. Thanks again for the quick fix!\nMy last resort was indeed to implement the (electrolyte) order parameter separately.",
                          "url": "https://github.com/idaholab/moose/discussions/16871#discussioncomment-348392",
                          "updatedAt": "2022-09-22T07:40:32Z",
                          "publishedAt": "2021-02-08T07:33:22Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "PETSc/libMesh issues",
          "author": {
            "login": "gka80"
          },
          "bodyText": "Hello-\nI'm running into a weird issue when trying to update and rebuild PETSc and libMesh per the instructions specified here: https://mooseframework.inl.gov/getting_started/installation/install_moose.html\nI am able to update and rebuild PETSc and run the tests to completion. However, when I try to update and rebuild libMesh, I get the following error:\nchecking whether we can compile a trivial PETSc program... yes checking for TAO support via PETSc... yes configure: error: *** PETSc with Hypre was not found, but --enable-petsc-hypre-required was specified.\nThe interesting thing though is that PETSc runs the ex19 hypre demo successfully. If I set this requirement to 'no', I get the following error:\nIn file included from /gscratch/stf/gkelley/_sw/inl_moose/_projects/moose/scripts/../libmesh/src/numerics/numeric_vector.C:30: ./include/libmesh/petsc_vector.h:1213:32: error: static assertion failed: PETSc and libMesh integer sizes must match! static_assert(sizeof(PetscInt) == sizeof(numeric_index_type), ~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~ make[1]: *** [Makefile:26843: src/numerics/libmesh_opt_la-numeric_vector.lo] Error 1 make[1]: Leaving directory '/gscratch/stf/gkelley/_sw/inl_moose/_projects/moose/libmesh/build' make: *** [Makefile:32014: all-recursive] Error 1\nOther details:\n\nTrying to compile on a compute/HPC cluster. CentOS 7. Will have to log on to give more specifics but will happily provide them.\ngcc: 8.2.1\ncmake 3.11.2. I've used this without issue.\nCompiled/installed mpich 3.3 using the directions specified here: https://mooseframework.inl.gov/getting_started/installation/manual_installation_gcc.html. No issues that I can tell. I've had success following this route before.\n\nAgain, I've had this process work in the past with no issue. The only reason why I'm reinstalling is because it's been awhile since I've used the framework and it's been scrubbed from the cluster.\nAny assistance would be greatly appreciated,\n-Garrett",
          "url": "https://github.com/idaholab/moose/discussions/16913",
          "updatedAt": "2022-06-23T08:46:34Z",
          "publishedAt": "2021-02-07T06:06:14Z",
          "category": {
            "name": "Q&A Getting Started"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "gka80"
                  },
                  "bodyText": "As an update, I went ahead and tried again with a fresh installation this morning. It appears everything went OK. I believe the issue was not unsetting the PETSC_DIR appropriately (may have been a typo on my part).\n-Garrett",
                  "url": "https://github.com/idaholab/moose/discussions/16913#discussioncomment-348022",
                  "updatedAt": "2022-06-23T08:46:35Z",
                  "publishedAt": "2021-02-08T01:15:44Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": []
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "Memory usage in Contact modules",
          "author": {
            "login": "makeclean"
          },
          "bodyText": "Quick question, Ive got a 'toy' problem which resembles our children's favourite Danish building blocks. There are two blocks next to each other, along the long face as seen below.\n\nIn total there are 1583 nodes on each surface (4928 edges and 3346 triangles if that matters - dont think it does) and trying to get this problem setup and running on my desktop, requires more than 128 Gb of memory ?!?! That seems excessive to me, any suggestions here would be appreciated.",
          "url": "https://github.com/idaholab/moose/discussions/16773",
          "updatedAt": "2022-09-26T01:50:38Z",
          "publishedAt": "2021-01-21T09:45:56Z",
          "category": {
            "name": "Q&A Modules: General"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "makeclean"
                  },
                  "bodyText": "So memory usage is around 18.2 Gb until computing initial stateful property values, and then it rockets up fairly quickly to 128 Gb and then is killed.",
                  "url": "https://github.com/idaholab/moose/discussions/16773#discussioncomment-298541",
                  "updatedAt": "2022-09-26T01:50:38Z",
                  "publishedAt": "2021-01-21T09:59:20Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "aeslaughter"
                          },
                          "bodyText": "What type of properties are you using that are stateful? Saving the state requires that values of the material properties are stored for every quadrature point in your mesh. It is common to have a large memory demand with stateful properties.",
                          "url": "https://github.com/idaholab/moose/discussions/16773#discussioncomment-303804",
                          "updatedAt": "2022-09-26T01:50:38Z",
                          "publishedAt": "2021-01-22T23:47:46Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "makeclean"
                          },
                          "bodyText": "nothing of note which makes it weird",
                          "url": "https://github.com/idaholab/moose/discussions/16773#discussioncomment-309018",
                          "updatedAt": "2022-09-26T01:50:38Z",
                          "publishedAt": "2021-01-25T16:18:48Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "lindsayad"
                          },
                          "bodyText": "With your dock_slippy.i input I am not seeing memory usage above about 300 MB",
                          "url": "https://github.com/idaholab/moose/discussions/16773#discussioncomment-318834",
                          "updatedAt": "2022-09-26T01:50:38Z",
                          "publishedAt": "2021-01-28T20:12:25Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "lindsayad"
                          },
                          "bodyText": "Replying on this thread so I can leave the other one to talk about convergence. Congrats @makeclean you've unearthed two large memory issues. Here is this ticket: #16836",
                          "url": "https://github.com/idaholab/moose/discussions/16773#discussioncomment-319384",
                          "updatedAt": "2022-09-26T01:50:38Z",
                          "publishedAt": "2021-01-29T00:20:09Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "lindsayad"
                          },
                          "bodyText": "Ok after #16845, for your lego input, I go from this graph:\n\nwhich was taken from the middle of initing stateful props, and shortly before I canceled the simulation so my computer wouldn't run out of memory to this graph:\n\nwhich was taken after initing stateful properties...because now we can get to that point without running out of memory. So 84 GB for stateful properties (and that number was still growing) to 4GB. I'm a big fan. Thanks for your helpful inputs @makeclean !",
                          "url": "https://github.com/idaholab/moose/discussions/16773#discussioncomment-329220",
                          "updatedAt": "2022-09-26T01:50:38Z",
                          "publishedAt": "2021-02-01T23:34:32Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              },
              {
                "node": {
                  "author": {
                    "login": "makeclean"
                  },
                  "bodyText": "Some progress, it seems the two objects in contact must be separate mesh blocks, is that true MOOSE folks?",
                  "url": "https://github.com/idaholab/moose/discussions/16773#discussioncomment-300765",
                  "updatedAt": "2022-09-26T01:50:39Z",
                  "publishedAt": "2021-01-21T21:29:09Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "makeclean"
                          },
                          "bodyText": "If two surfaces were part of a contact group, and those surfaces also had nodes that were part of a fixed 0 displacement boundary, what would happen?",
                          "url": "https://github.com/idaholab/moose/discussions/16773#discussioncomment-300857",
                          "updatedAt": "2025-02-24T22:19:43Z",
                          "publishedAt": "2021-01-21T22:19:47Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "aeslaughter"
                          },
                          "bodyText": "@lindsayad Can you answer this contact question?",
                          "url": "https://github.com/idaholab/moose/discussions/16773#discussioncomment-303805",
                          "updatedAt": "2025-02-24T22:19:42Z",
                          "publishedAt": "2021-01-22T23:48:51Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "makeclean"
                          },
                          "bodyText": "Ill try and formulate a minimum viable problem that shows the issue.",
                          "url": "https://github.com/idaholab/moose/discussions/16773#discussioncomment-309044",
                          "updatedAt": "2025-02-24T22:19:43Z",
                          "publishedAt": "2021-01-25T16:27:35Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "lindsayad"
                          },
                          "bodyText": "What contact formulation are you using? With respect to contact vs. dirichlet condition: the dirichlet condition would win because it runs after constraints. A MWE would be great yea, thanks!",
                          "url": "https://github.com/idaholab/moose/discussions/16773#discussioncomment-309053",
                          "updatedAt": "2022-10-04T14:17:28Z",
                          "publishedAt": "2021-01-25T16:30:35Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "makeclean"
                          },
                          "bodyText": "Ok, I can't reproduce the problem with my simple block example, where should I put the mesh from the example above?",
                          "url": "https://github.com/idaholab/moose/discussions/16773#discussioncomment-312561",
                          "updatedAt": "2022-10-04T14:17:27Z",
                          "publishedAt": "2021-01-26T20:50:53Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "makeclean"
                          },
                          "bodyText": "Its regular contact not dirichlet",
                          "url": "https://github.com/idaholab/moose/discussions/16773#discussioncomment-312562",
                          "updatedAt": "2022-10-04T14:17:28Z",
                          "publishedAt": "2021-01-26T20:51:05Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "lindsayad"
                          },
                          "bodyText": "If two surfaces were part of a contact group, and those surfaces also had nodes that were part of a fixed 0 displacement boundary, what would happen?\n\nRight here you asked what would happen if you had a surface that was simultaneously designated for contact and was part of a fixed 0 displacement boundary, which is presumably a Dirichlet BC.",
                          "url": "https://github.com/idaholab/moose/discussions/16773#discussioncomment-312681",
                          "updatedAt": "2022-10-04T14:17:27Z",
                          "publishedAt": "2021-01-26T21:38:22Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "makeclean"
                          },
                          "bodyText": "oh i see, sorry, bit slow tonight :)",
                          "url": "https://github.com/idaholab/moose/discussions/16773#discussioncomment-312722",
                          "updatedAt": "2022-10-04T14:17:28Z",
                          "publishedAt": "2021-01-26T21:46:36Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              },
              {
                "node": {
                  "author": {
                    "login": "makeclean"
                  },
                  "bodyText": "Also, further weirdness, I have what I'm calling a 'docking' problem - but basically I have a 'rubber' hollow sphere (as shown in the image) and a stainless steel 'sphere' I am forcing the displacement as a function of time so that they start seperate and then get into contact later. In this case gravity is acting along the +ve z axis, there is a 0 displacement condition on the flat bottom of the rubber hollow sphere. I also constrain the x,y movement of the sphere with 0 displacement condition, such that the sphere only moves along the z axis. There are 3 contact surfaces; the outside part of the stainless sphere (a), the entry part into the hollow sphere (b) and the inside of the hollow sphere (c) and I have frictional contacts setup for ac and bc. All is great, contact is made the rubber deforms, but eventually we get a convergence failure at the minimum timestep.\n\nI've tried turning on AMR, but this leads to segfaults and also some weird deformations that you'll see in the next image, and some oddly connected mesh elements.\n\nSo my questions are manifold, but\n\nshould contact and AMR work concurrently?\nIve tried taking both to second order but this leads to both PETSC segfault-ing\nshould I try just a finer mesh?\n\nHappy to share inputs, can I attach them here?",
                  "url": "https://github.com/idaholab/moose/discussions/16773#discussioncomment-312589",
                  "updatedAt": "2022-10-04T14:17:27Z",
                  "publishedAt": "2021-01-26T21:04:00Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "lindsayad"
                          },
                          "bodyText": "Happy to share inputs, can I attach them here?\n\nIf they are MOOSE-only",
                          "url": "https://github.com/idaholab/moose/discussions/16773#discussioncomment-312684",
                          "updatedAt": "2023-01-27T23:17:46Z",
                          "publishedAt": "2021-01-26T21:39:15Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "makeclean"
                          },
                          "bodyText": "no, exodus meshes from Cubit im afraid",
                          "url": "https://github.com/idaholab/moose/discussions/16773#discussioncomment-312721",
                          "updatedAt": "2023-01-27T23:17:46Z",
                          "publishedAt": "2021-01-26T21:46:07Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "lindsayad"
                          },
                          "bodyText": "Oh I just meant MOOSE-only objects in the input file. How big are the meshes?",
                          "url": "https://github.com/idaholab/moose/discussions/16773#discussioncomment-312903",
                          "updatedAt": "2023-01-27T23:17:46Z",
                          "publishedAt": "2021-01-26T23:00:21Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "makeclean"
                          },
                          "bodyText": "Not huge, only 50k ish elements - runs in around 30 mins to failure",
                          "url": "https://github.com/idaholab/moose/discussions/16773#discussioncomment-312911",
                          "updatedAt": "2023-01-27T23:17:47Z",
                          "publishedAt": "2021-01-26T23:05:32Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "makeclean"
                          },
                          "bodyText": "on one core",
                          "url": "https://github.com/idaholab/moose/discussions/16773#discussioncomment-312912",
                          "updatedAt": "2023-01-27T23:17:46Z",
                          "publishedAt": "2021-01-26T23:05:55Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "lindsayad"
                          },
                          "bodyText": "If they are not ginormous, you can send them to alexander.lindsay@inl.gov. (I don't think you can attach them here on github...if you can, then just do that)",
                          "url": "https://github.com/idaholab/moose/discussions/16773#discussioncomment-312915",
                          "updatedAt": "2023-01-27T23:17:47Z",
                          "publishedAt": "2021-01-26T23:06:27Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "lindsayad"
                          },
                          "bodyText": "The dock problem should also show the memory usage problem right? I  see that you are using finite strain",
                          "url": "https://github.com/idaholab/moose/discussions/16773#discussioncomment-318829",
                          "updatedAt": "2023-01-27T23:17:46Z",
                          "publishedAt": "2021-01-28T20:09:02Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "makeclean"
                          },
                          "bodyText": "Dock slippy has no memory problems and runs fine. Only the original lego problem had that issue, which I can't reproduce in a small problem. I'll forward on the original file, its not that huge either, hence the original question re: memory usage. The issue with dock_slippy.i is eventually a convergence fail, and the fact that going to 2nd order is an immediate segfault.",
                          "url": "https://github.com/idaholab/moose/discussions/16773#discussioncomment-318989",
                          "updatedAt": "2023-01-27T23:17:47Z",
                          "publishedAt": "2021-01-28T20:40:49Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "lindsayad"
                          },
                          "bodyText": "Ok yes I would like to have the really bad memory input. FWIW even dock-slippy, though it only resulted in 300 MB of peak memory usage, showed us a potential bug that I am investigating a fix for right now. Once I am done investigating the memory usage, I will think about the other issues.",
                          "url": "https://github.com/idaholab/moose/discussions/16773#discussioncomment-319087",
                          "updatedAt": "2023-01-27T23:18:05Z",
                          "publishedAt": "2021-01-28T21:21:43Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "makeclean"
                          },
                          "bodyText": "Oh is that bug the one about the stress in the moving part comes and goes away?",
                          "url": "https://github.com/idaholab/moose/discussions/16773#discussioncomment-319106",
                          "updatedAt": "2023-01-27T23:18:16Z",
                          "publishedAt": "2021-01-28T21:31:39Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              },
              {
                "node": {
                  "author": {
                    "login": "makeclean"
                  },
                  "bodyText": "No, that problem runs fine. I cant'reproduce the contact memory  usage\nproblem, except in the original geometry.\n\u2026\nOn Thu, 2021-01-28 at 12:09 -0800, Alex Lindsay wrote:\n The dock problem should also show the memory usage problem right? I\n see that you are using finite strain\n \u2014\n You are receiving this because you authored the thread.\n Reply to this email directly, view it on GitHub, or unsubscribe.",
                  "url": "https://github.com/idaholab/moose/discussions/16773#discussioncomment-318987",
                  "updatedAt": "2022-10-04T14:17:13Z",
                  "publishedAt": "2021-01-28T20:38:35Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "author": {
                    "login": "bwspenc"
                  },
                  "bodyText": "I'm jumping into this pretty late. It sounds like some of the memory issues have been resolved. I'd just add here that the patch_size parameter in the Mesh block can affect memory usage. That controls the size of the set of nodes on the primary face nearest to the secondary node that contains the faces that are considered for contact with that node. Back in the day, you had to set this really large when you had large sliding between the surfaces, because that set of nodes was static, but now that we have the patch_update_strategy=iteration option, that is dynamically updated, so you can get by with a pretty small patch. If I remember right, the set of candidate faces consists of all of the faces that contain the nodes that are found in the patch. That means that you can probably set it to something close to the number of nodes on a face. Maybe you can get by with a patch size of 10 or less.",
                  "url": "https://github.com/idaholab/moose/discussions/16773#discussioncomment-343425",
                  "updatedAt": "2022-10-04T13:44:44Z",
                  "publishedAt": "2021-02-06T01:07:31Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": []
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "Incoming Network Connection on macOS",
          "author": {
            "login": "dogrady2"
          },
          "bodyText": "Hi All,\nWhenever I run sam on my macOS Catalina laptop I get the following pop-up\n\nThe pop-up occurs regardless of the model that is being run, it also occurs when running --dump. Other sam developer/users do not report getting the pop-up. I have not been able to traceback what is causing the network connection. I am not sure if the cause of the pop-up is in the compilation environment, sam level or moose level. Does anyone have any suggestions for disabling the pop-up?\nThanks,\nDan O'Grady",
          "url": "https://github.com/idaholab/moose/discussions/16876",
          "updatedAt": "2022-09-21T21:45:01Z",
          "publishedAt": "2021-02-03T17:41:25Z",
          "category": {
            "name": "Q&A General"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "permcody"
                  },
                  "bodyText": "Hi Dan, To the best of my knowledge there are two ways around this:\n\nTurn off your firewall - easy to do, but maybe not the best way since it could open you up to potential security issues.\nSign your binary with an Apple Developer certificate - This of course means you have to register and become an Apple Developer. If you have a signed binary, it won't be flagged by Mac OS's firewall. The issue with this is that you have to do this every time you build. We already have a line in our Makefile that makes MacOS binaries debuggable. It would be easy to add a line if we could do this generically for everyone, but I'm not aware of a solution that will work for everyone since you (as the end-developer) are creating the binary as you so you have to be the one that signs it each time it is created.",
                  "url": "https://github.com/idaholab/moose/discussions/16876#discussioncomment-335699",
                  "updatedAt": "2022-09-21T21:45:02Z",
                  "publishedAt": "2021-02-03T18:44:11Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "travismui"
                          },
                          "bodyText": "Hi @permcody, thanks for your notes on this. Just to add onto @dogrady2, I've also started experiencing this pop-up issue this week (I think he noticed this back in November 2020), so I've tried some troubleshooting.\n\nThis seems to affect any Moose app, I noticed this with Bison and also ex01-opt in the Moose examples, so I'm curious if others in the Moose community have noticed the pop-ups recently.\nWe suspect it's rooted in the latest macOS Security Update 2021-001 from Feb 1 (see Apple) that has triggered this 'bug'.\nThe incessant pop-ups occur only when the macOS firewall is on and the first time after you build your executable. After a restart, the pop-ups don't show up but they do after you re-build.\n\nA couple details on what I checked to diagnose the error:\n\nOur work machines are on macOS Catalina, but I reproduced this issue on Mojave too (see below)\nTurning off the firewall fixes the issue\u2013 but this may not be an option for some users.\nWe are not enrolled in the Apple Developer program so I don't think we can sign with a certificate. It does seem that Sam is not signed when I checked with codesign.\nOn a personal machine using Mojave, before applying the Security Update I did not experience the pop-up dialogue. After applying the Security Update, I get the pop-up issue as described above. Unfortunately, I don't know of any easy way to unroll a macOS Security Update without restoring to a backup image.",
                          "url": "https://github.com/idaholab/moose/discussions/16876#discussioncomment-339853",
                          "updatedAt": "2022-09-21T21:45:03Z",
                          "publishedAt": "2021-02-05T00:02:46Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "Memory error: Falcon Moose",
          "author": {
            "login": "pranayasai"
          },
          "bodyText": "Hello Everyone,\nI am trying to run a big mesh (4Million cells) simulation using Falcon/Kerstel (MOOSE) on Sawtooth (at INL HPC) but the simulation keeps crashing.\nSometimes it crashes without finishing any iterations and sometimes it runs one or two iterations and then crashes.\nI have tried running them on the compute node and also using PBS script but the error still persists.\nThe errors and number of processors used are listed below.\nI have tried running the simulation in multiple combinations for the number of processors requested/used:\n7200 requested: 3600 used (did not work, crashes with Error 1 (see below))\n1000 requested: 500 used (did not work, crashes with Error 1)\n1000 requested: 100 used (did not work, crashes with Error 1)\n500 requested: 100 used (did not work crashes with Error 1)\n500 requested: 75 used (works up to one iteration and then crashes with Error 2(see below))\n144 requested: 50 used (works up to one iteration and then crashes with Error 3(see below))\nError 1:\n[asaipran][~/Desktop/Forge/DFN/full2]> mpirun -np 150 ~/projects/kestrel/kestrel-opt -i fullDFN_PA_tran_PT.i\nBuilding mesh ..........................                                                   [ 27.39 s]\nCaching mesh information ....                                                              [  5.20 s]\nInitializing equation system ...........                                                   [ 12.94 s]\nCaching mesh information ....                                                              [  5.62 s]\nCopying variables from Exodus ...                                                          [  4.82 s]\nRunning App: main\nFramework Information:\nMOOSE Version:           git commit e3fb9a7 on 2020-08-10\nLibMesh Version:         8d10d4aff7dc56cb100ab27450120fd522449f40\nPETSc Version:           3.12.5\nSLEPc Version:           3.12.1\nCurrent Time:            Wed Feb  3 09:37:41 2021\nExecutable Timestamp:    Thu Sep 24 16:05:15 2020\nParallelism:\nNum Processors:          150\nNum Threads:             1\nMesh:\nParallel Type:           replicated\nMesh Dimension:          3\nSpatial Dimension:       3\nNodes:\nTotal:                 2050401\nLocal:                 15289\nElems:\nTotal:                 2000000\nLocal:                 13315\nNum Subdomains:          1\nNum Partitions:          150\nPartitioner:             metis\nNonlinear System:\nNum DOFs:                4100802\nNum Local DOFs:          30578\nVariables:               { \"pressure\" \"temperature\" }\nFinite Element Types:    \"LAGRANGE\"\nApproximation Orders:    \"FIRST\"\nAuxiliary System:\nNum DOFs:                18000000\nNum Local DOFs:          119835\nVariables:               { \"vel_x\" \"vel_y\" \"vel_z\" \"fluid_density\" \"viscosity\" \"porosity\" \"perm_x\"\n\"perm_y\" \"perm_z\" }\nFinite Element Types:    \"MONOMIAL\"\nApproximation Orders:    \"CONSTANT\"\nExecution Information:\nExecutioner:             Transient\nTimeStepper:             SolutionTimeAdaptiveDT\nSolver Mode:             NEWTON\nPETSc Preconditioner:    asm\nMOOSE Preconditioner:    SMP\nLEGACY MODES ENABLED:\nThis application uses the legacy material output option: material properties are output only on TIMESTEP_END, not INITIAL. To remove this message, set 'use_legacy_material_output' to false in this application. If there are gold output files that contain material property output for which output occurs on INITIAL, then these will generate diffs due to zero values being stored, and these tests should be re-golded.\nCaching mesh information ....                                                              [  5.33 s]\n[cli_131]: aborting job:\napplication called MPI_Abort(MPI_COMM_WORLD, 1) - process 131\n[asaipran][~/Desktop/Forge/DFN/full2]>\nError 2:\nComputing initial residual .....                                                           [  6.09 s]\n0 Nonlinear |R| = 1.826232e+09\n===================================================================================\n=   BAD TERMINATION OF ONE OF YOUR APPLICATION PROCESSES\n=   PID 125496 RUNNING AT r6i2n19.ib0.sawtooth.inl.gov\n=   EXIT CODE: 9\n=   CLEANING UP REMAINING PROCESSES\n=   YOU CAN IGNORE THE BELOW CLEANUP MESSAGES\n[proxy:0:1@r6i2n22] HYD_pmcd_pmip_control_cmd_cb (pm/pmiserv/pmip_cb.c:911): assert (!closed) failed\n[proxy:0:1@r6i2n22] HYDT_dmxu_poll_wait_for_event (tools/demux/demux_poll.c:76): callback returned error status\n[proxy:0:1@r6i2n22] main (pm/pmiserv/pmip.c:202): demux engine error waiting for event\n[proxy:0:2@r6i2n20] HYD_pmcd_pmip_control_cmd_cb (pm/pmiserv/pmip_cb.c:911): assert (!closed) failed\n[proxy:0:2@r6i2n20] HYDT_dmxu_poll_wait_for_event (tools/demux/demux_poll.c:76): callback returned error status\n[proxy:0:2@r6i2n20] main (pm/pmiserv/pmip.c:202): demux engine error waiting for event\n[mpiexec@r6i2n19] HYDT_bscu_wait_for_completion (tools/bootstrap/utils/bscu_wait.c:75): one of the processes terminated badly; aborting\n[mpiexec@r6i2n19] HYDT_bsci_wait_for_completion (tools/bootstrap/src/bsci_wait.c:23): launcher returned error waiting for completion\n[mpiexec@r6i2n19] HYD_pmci_wait_for_completion (pm/pmiserv/pmiserv_pmci.c:218): launcher returned error waiting for completion\n[mpiexec@r6i2n19] main (ui/mpich/mpiexec.c:340): process manager error waiting for completion\nError 3:\nComputing initial residual ......                                                          [  7.05 s]\n0 Nonlinear |R| = 6.311744e-01\n[0]PETSC ERROR: --------------------- Error Message --------------------------------------------------------------\n[0]PETSC ERROR: Petsc has generated inconsistent data\n[0]PETSC ERROR: is not a subset of lis\n[0]PETSC ERROR: See https://www.mcs.anl.gov/petsc/documentation/faq.html for trouble shooting.\n[0]PETSC ERROR: Petsc Release Version 3.12.5, Mar, 29, 2020\n[0]PETSC ERROR: /home/asaipran/projects/kestrel/kestrel-opt on a  named r2i3n26 by asaipran Tue Feb  2 22:58:16 2021\n[0]PETSC ERROR: Configure options --COPTFLAGS=-O3 --CXXOPTFLAGS=-O3 --FOPTFLAGS=-O3 --with-x=0 --with-mpi=1 --with-ssl=0 --with-openmp=1 --with-debugging=0 --with-64-bit-indices=1 --with-cxx-dialect=C++11 --with-shared-libraries=1 --with-fortran-bindings=0 --with-cxxlib-autodetect=0 --download-hypre=1 --download-metis=1 --download-slepc=1 --download-ptscotch=1 --download-parmetis=1 --download-scalapack=1 --download-fblaslapack=1 --download-superlu_dist=1 AR=ar CC=mpicc CXX=mpicxx FC=mpifort FC=mpifort FC=mpifort --prefix=/apps/moose/stack/petsc-3.12.5_mvapich2-2.3.3_gcc-9.2.0\n[0]PETSC ERROR: #1 PCSetUp_ASM() line 378 in /tmp/tmp.yuC9vViIq5/petsc-3.12.5/src/ksp/pc/impls/asm/asm.c\n[0]PETSC ERROR: #2 PCSetUp() line 894 in /tmp/tmp.yuC9vViIq5/petsc-3.12.5/src/ksp/pc/interface/precon.c\n[0]PETSC ERROR: #3 KSPSetUp() line 376 in /tmp/tmp.yuC9vViIq5/petsc-3.12.5/src/ksp/ksp/interface/itfunc.c\n[0]PETSC ERROR: #4 KSPSolve() line 703 in /tmp/tmp.yuC9vViIq5/petsc-3.12.5/src/ksp/ksp/interface/itfunc.c\n[0]PETSC ERROR: #5 SNESSolve_NEWTONLS() line 225 in /tmp/tmp.yuC9vViIq5/petsc-3.12.5/src/snes/impls/ls/ls.c\n[0]PETSC ERROR: #6 SNESSolve() line 4482 in /tmp/tmp.yuC9vViIq5/petsc-3.12.5/src/snes/interface/snes.c\n[cli_0]: aborting job:\napplication called MPI_Abort(MPI_COMM_WORLD, 1) - process 0\nA similar input deck runs perfectly fine with a smaller mesh size.\nI am not entirely sure where does the problem lie.\nCan you please provide me any guidance to fix or to be able to run this simulation?\nThank you\nPranay",
          "url": "https://github.com/idaholab/moose/discussions/16878",
          "updatedAt": "2022-05-31T15:07:50Z",
          "publishedAt": "2021-02-03T17:53:41Z",
          "category": {
            "name": "Q&A Meshing"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "GiudGiud"
                  },
                  "bodyText": "Hi Pranay\nYou should request a number of nodes directly, and specify the maximum amount of memory available per node.\nCan you paste your PBS script here? The part where you are requesting ressources especially.\nGuillaume",
                  "url": "https://github.com/idaholab/moose/discussions/16878#discussioncomment-335646",
                  "updatedAt": "2022-07-28T13:54:19Z",
                  "publishedAt": "2021-02-03T18:17:22Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "pranayasai"
                          },
                          "bodyText": "Hello Guillaume,\nI believe the available memory per node is around 4GB\nHere is the PBS script.\n#!/bin/bash\n#PBS -N full5\n#PBS -l select=5:ncpus=48:mpiprocs=48\n#PBS -l walltime=48:00:00\n#PBS -j oe\nmodule load use.moose PETSc\necho\necho PBS_NODEFILE is $PBS_NODEFILE\necho PBS_QUEUE is $PBS_QUEUE\necho\nhostname\nNPROCS=wc -l < $PBS_NODEFILE\necho\necho NPROCS: $NPROCS\necho\ncd /home/asaipran/Desktop/Forge/DFN/full5/\nmpirun -np 150 ~/projects/kestrel/kestrel-opt -i fullDFN_PA_tran_PT.i\n-Pranay",
                          "url": "https://github.com/idaholab/moose/discussions/16878#discussioncomment-335815",
                          "updatedAt": "2022-07-28T13:54:19Z",
                          "publishedAt": "2021-02-03T19:29:18Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "Falcon nodes should have closer to 120 GB on-node ( so close to 4GB per core ). I dont know the exact number.\nAnd they have 2 x 18 cores per node, with no hyper-threading I think.\nWe don't recommend using more MPI ranks than CPUs on Falcon.\nSo to run 150 MPI processes, I would recommend asking for 5 nodes, and using 30 cores on each node.\nSo #PBS -l select=5:ncpus=180:mpiprocs=150:mem=115gb\n180 (=5 x 36) cores is to book the nodes entirely. You can also indicate you want exclusivity with another flag (saw it in discussions earlier on, dont use it myself) or by requesting all the memory.\nNow an issue that may come up is that the MPI processes are not placed equitably on each node. To help with that, you have to pass a hostfile to mpirun / mpiexec to tell it which hosts to spawn processes on.\nIf your job is too memory intensive, you should first update to the latest moose since there was a memory reducing PR lately, and you can try booking more and more nodes to spread your problem over.",
                          "url": "https://github.com/idaholab/moose/discussions/16878#discussioncomment-335880",
                          "updatedAt": "2022-07-28T13:54:25Z",
                          "publishedAt": "2021-02-03T19:56:14Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "pranayasai"
                          },
                          "bodyText": "I just checked, Sawtooth has 192GB on the node with 48 processors. No hyper-threading.",
                          "url": "https://github.com/idaholab/moose/discussions/16878#discussioncomment-335927",
                          "updatedAt": "2022-07-28T13:54:27Z",
                          "publishedAt": "2021-02-03T20:09:11Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "oh my bad, sorry I thought you meant Falcon the cluster! Ok Same advice, just adapt the numbers.",
                          "url": "https://github.com/idaholab/moose/discussions/16878#discussioncomment-336010",
                          "updatedAt": "2022-07-28T13:54:30Z",
                          "publishedAt": "2021-02-03T20:44:27Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "Reduce the time to simulate grain growth",
          "author": {
            "login": "PengWei97"
          },
          "bodyText": "Dear MOOSE experts,\nI am trying to simulate a grain growth simulation of 1000 grains. I set end_time = 10000, but it took 58 hours. How can I optimize the input file to reduce the running time?\nThe following are the basic parameters and related files used in my simulation:\nNumber of cpu cores: 20\nNumber of initial grids: 409600\nGrid adaptation and time adaptation are used\nInput file: grain_growth_2D_graintracker_1000_output.txt\nPart of the information output to the terminal:\ngrain_growth_2D_graintracker_1000_output.log\nAfter adapting the grid, the initial model diagram\uff1a\n\nAny suggestions or recommendations to fix these problems would be greatly appreciated.\nThank you\nWei Peng",
          "url": "https://github.com/idaholab/moose/discussions/16592",
          "updatedAt": "2022-06-28T05:24:16Z",
          "publishedAt": "2020-12-26T04:50:20Z",
          "category": {
            "name": "Q&A Modules: Phase field"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "laagesen"
                  },
                  "bodyText": "A couple of days is not unreasonable for a 1000-grain simulation. There are a couple of things you could try:\n-increase optimal_iterations to 8 or 10 in the TimeStepper block. This will likely give you larger time steps. You should check to make sure the results are consistent with the initial run you did with that parameter set to 6\n-Add a NumDOFs postprocessor so you know how many DOFs are in your problem as a function of time. You generally want about 10,000 to 20,000 DOF per core, so you can choose your # of cores to try to maintain this. When you say Number of initial grids: 409600 I am not sure if you mean number of elements in the mesh or number of DOFs. If it is # of elements in the mesh, the number of DOFs is probably significantly larger, so you are probably much larger that 20,000 DOF/core since you are using 20 cores. So you would need more cores.",
                  "url": "https://github.com/idaholab/moose/discussions/16592#discussioncomment-261165",
                  "updatedAt": "2022-06-28T05:24:17Z",
                  "publishedAt": "2021-01-04T20:57:38Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "PengWei97"
                          },
                          "bodyText": "Hi laagesen,\nThank you very much for your response. Yes, Number of initial grids: 409,600 means number of elements. And the number of DOFs: 4,108,810, which is displayed in the log file at the end. According to your suggestion, the number of cores used is about 205, which is a very large number!\nThe question I want to ask is, is 205 the optimal number of cores to run this example?\nThanks again for your time. Finally, do you have some suggestions to optimize the input file to shorten the simulation time for a beginner like me? For example, whether to use a distributed mesh or a replicated mesh, etc.\nKind regards,\nWei Peng\nDetails are as follows,\nFramework Information:\nMOOSE Version:           git commit 54c00d0775 on 2020-12-17\nLibMesh Version:         c176405e538983b35afc4f6827e29e155141e42e\nPETSc Version:           3.14.2\nSLEPc Version:           3.14.0\nCurrent Time:            Wed Dec 23 22:33:21 2020\nExecutable Timestamp:    Sun Dec 20 22:02:49 2020\n\nParallelism:\n  Num Processors:          10\n  Num Threads:             1\n\nMesh: \n  Parallel Type:           replicated\n  Mesh Dimension:          2\n  Spatial Dimension:       2\n  Nodes:                   \n    Total:                 410881\n    Local:                 41401\n  Elems:                   \n    Total:                 409600\n    Local:                 40973\n  Num Subdomains:          1\n  Num Partitions:          10\n  Partitioner:             metis\n\nNonlinear System:\n  Num DOFs:                4108810\n  Num Local DOFs:          414010\n  Variables:               { \"gr0\" \"gr1\" \"gr2\" \"gr3\" \"gr4\" \"gr5\" \"gr6\" \"gr7\" \"disp_x\" \"disp_y\" } \n  Finite Element Types:    \"LAGRANGE\" \n  Approximation Orders:    \"FIRST\" \n\nAuxiliary System:\n  Num DOFs:                3687681\n  Num Local DOFs:          369185\n  Variables:               \"bnds\" { \"elastic_strain11\" \"elastic_strain22\" \"elastic_strain12\" \"unique_grains\" \n                             \"var_indices\" \"vonmises_stress\" \"C1111\" \"euler_angle\" } \n  Finite Element Types:    \"LAGRANGE\" \"MONOMIAL\" \n  Approximation Orders:    \"FIRST\" \"CONSTANT\" \n\nExecution Information:\n  Executioner:             Transient\n  TimeStepper:             IterationAdaptiveDT\n  Solver Mode:             Preconditioned JFNK\n  MOOSE Preconditioner:    SMP",
                          "url": "https://github.com/idaholab/moose/discussions/16592#discussioncomment-262161",
                          "updatedAt": "2022-06-28T05:24:17Z",
                          "publishedAt": "2021-01-05T09:34:44Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              },
              {
                "node": {
                  "author": {
                    "login": "friedmud"
                  },
                  "bodyText": "I agree with @laagesen : the best way to speed this up is to use more processors.  As he mentioned, you could easily use 200 procs with 4M dofs.\nAs for \"optimal\" - that really depends.  We recommend about 20k dofs/proc in order to keep parallel efficiency high.  You may be able to go well beyond that and still get speedup (I would expect to see speedup on this problem out to 500 cores or so)... but your parallel efficiency will start to drop off (the amount of speed increase won't be commensurate with the number of procs you're using).\nAnother thing you may want to try is to use the DT2 timestepper... you will have to play with the parameters to see what works for your problem - but there is a possibility of greatly increasing the timestep size.",
                  "url": "https://github.com/idaholab/moose/discussions/16592#discussioncomment-264985",
                  "updatedAt": "2022-06-28T05:24:18Z",
                  "publishedAt": "2021-01-06T15:22:16Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "PengWei97"
                          },
                          "bodyText": "Thank friedmud for your information. Regarding the second suggestion you gave, I don\u2019t quite understand it. I don't quite understand your second suggestion. You mean to add the TimeStepper module to increase the size of the time step, right?\nFinally, if I change the Mesh type to a distributed mesh, will this help reduce simulation time? And, in MOOSE, which aspects of the calculation are affected by the mesh type?",
                          "url": "https://github.com/idaholab/moose/discussions/16592#discussioncomment-266024",
                          "updatedAt": "2022-06-28T05:24:18Z",
                          "publishedAt": "2021-01-07T01:11:33Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "The DT2 time stepper is an adaptive time stepper that will increase the time step through the simulation, based on comparing the solution with time steps of dt and dt/2. This is usually more effective than trying to uniformly increase the time step.\nUsing a distributed mesh is typically done to reduce the memory footprint, as it avoids duplicating the mesh for every process. I don't foresee a large impact on simulation time.\nEDIT: Maybe with the mesh adaptivity, there could be an impact\nYou could try running your simulation with the --timing flag (EDIT add PerfGraphOutput) to see which parts of the simulation are the most computationally expensive.",
                          "url": "https://github.com/idaholab/moose/discussions/16592#discussioncomment-266710",
                          "updatedAt": "2022-06-28T05:24:18Z",
                          "publishedAt": "2021-01-07T11:06:37Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "PengWei97"
                          },
                          "bodyText": "After adding PerfGraphOutput to the output, it displays the proportion of each calculation part on the terminal as follows,\n\n\nAfter adding PerfGraphOutput to the output, it displays the proportion of each calculation part on the terminal as follows,\nIn this regard, would you have any good suggestions for moose beginners like me?",
                          "url": "https://github.com/idaholab/moose/discussions/16592#discussioncomment-266831",
                          "updatedAt": "2022-06-28T05:24:18Z",
                          "publishedAt": "2021-01-07T12:18:13Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "The previous advice given by @laagesen and @friedmud still applies.\nIn addition, it seems to spend a significant amount of time in mesh adaptivity. Maybe using a distributed mesh is a good idea? I am not sure how the modifications to the mesh are spread across processes.\nSince the problem is converging with no issues, you could use the skip_exception_check parameter in your executioner to gain 5% runtime here.\nEDIT: It's probably not really that function causing the 5% overhead, it's probably just work imbalance between nodes that's felt at this synchronization step",
                          "url": "https://github.com/idaholab/moose/discussions/16592#discussioncomment-266864",
                          "updatedAt": "2022-06-28T05:24:21Z",
                          "publishedAt": "2021-01-07T12:38:34Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "PengWei97"
                          },
                          "bodyText": "Thank you for your suggestion. I will try to use a distributed mesh and hope it will help reduce the calculation time.",
                          "url": "https://github.com/idaholab/moose/discussions/16592#discussioncomment-326393",
                          "updatedAt": "2022-06-28T05:24:21Z",
                          "publishedAt": "2021-02-01T05:49:52Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "How to add App to \"External App tests\"",
          "author": {
            "login": "WilkAndy"
          },
          "bodyText": "Hi,\n@josebastiase and i have made a small MOOSE app called RHEA, https://github.com/josebastiase/RHEA.   It has two Materials and two tests associated with it.   How can we add it to the \"External App tests\" ?\na",
          "url": "https://github.com/idaholab/moose/discussions/16837",
          "updatedAt": "2022-07-06T07:21:02Z",
          "publishedAt": "2021-01-29T04:12:33Z",
          "category": {
            "name": "Q&A Tools"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "loganharbour"
                  },
                  "bodyText": "Go ahead and shoot me an email, @WilkAndy, and we'll discuss the process of setting this up.\nFor anyone else curious about having your applications tested: Providing that your application is in active development and you're willing to contribute to keeping it up to date, we're glad to add it to testing!\nNote that there are other requirements for approval, but those will be discussed one-on-one when making the request.",
                  "url": "https://github.com/idaholab/moose/discussions/16837#discussioncomment-319641",
                  "updatedAt": "2022-07-06T07:21:01Z",
                  "publishedAt": "2021-01-29T04:19:42Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": []
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "Segfault while executing a test input file",
          "author": {
            "login": "HeejaeJu"
          },
          "bodyText": "Hello Moose team.\nI'was following the tutorial for app development tutorial and contact a segmentation fault error message while executing simple_diffusion.i using peacock.\nThe message is as bellow.\nFound executable: /Users/heejaeju/Moose/tutorial/tutorial-opt\n[1]    13124 segmentation fault  ~/Moose/moose/python/peacock/peacock -i simple_diffusion.i\nHow can I fix it?\nThanks in advance for any help!",
          "url": "https://github.com/idaholab/moose/discussions/16827",
          "updatedAt": "2022-07-04T08:37:46Z",
          "publishedAt": "2021-01-28T08:28:33Z",
          "category": {
            "name": "Q&A General"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "GiudGiud"
                  },
                  "bodyText": "Hello\nCan you please give us more details on your environment? Is this a Linux machine or Windows Subsystem for Linux?\nDoes it work when you run the input file without peacock ? (/Users/heejaeju/Moose/tutorial/tutorial-opt -i simple_diffusion.i)\nDoes it work when you start peacock without an input file and load the input file through the GUI ?\nThis is simple_diffusion.i from the tests for step 1 right?\nHopefully this will give some insights.\nTagging @aeslaughter since he is the most knowledgeable about peacock.\nBest,\nGuillaume",
                  "url": "https://github.com/idaholab/moose/discussions/16827#discussioncomment-317870",
                  "updatedAt": "2022-07-04T08:37:46Z",
                  "publishedAt": "2021-01-28T14:33:41Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "aeslaughter"
                          },
                          "bodyText": "@GiudGiud is correct, we need some information on your system and environment. Also, if you just run Peacock without any arguments, does it still fail?",
                          "url": "https://github.com/idaholab/moose/discussions/16827#discussioncomment-317948",
                          "updatedAt": "2022-07-04T08:37:46Z",
                          "publishedAt": "2021-01-28T15:05:46Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "HeejaeJu"
                          },
                          "bodyText": "Thank you for the reply.\nYes, this is the simple_diffuion.i.\nMy environment is Macintosh(OS : BigSur). Execution without peacock works well.\nAnd I found that the same error message is printed when I try to start peacock.exe.\nIn addition, double clicking the peacock.exe file shows me the terminal window as bellow.\n\nIs there any solution for this?\nThanks.",
                          "url": "https://github.com/idaholab/moose/discussions/16827#discussioncomment-318015",
                          "updatedAt": "2022-07-04T08:37:46Z",
                          "publishedAt": "2021-01-28T15:27:10Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "aeslaughter"
                          },
                          "bodyText": "I wonder if this is the problem: https://keremkoseoglu.com/2020/11/14/pyqt5-problem-on-macos-big-sur-solved\nDid you install the MOOSE environment with conda or manually?\nIf you are using conda, try searching for the available options and install one of the older ones. I am running 5.12.\nconda search pyqt\nconda install pyqt=5.12 # or whatever version you want to try out",
                          "url": "https://github.com/idaholab/moose/discussions/16827#discussioncomment-318108",
                          "updatedAt": "2022-07-04T08:37:47Z",
                          "publishedAt": "2021-01-28T15:59:58Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "aeslaughter"
                          },
                          "bodyText": "It seems that Peacock is not working on BigSur, I have two other reports of failure. I will need to investigate the problem, it will be next week at the earliest before I get to this.",
                          "url": "https://github.com/idaholab/moose/discussions/16827#discussioncomment-318178",
                          "updatedAt": "2022-07-04T08:37:44Z",
                          "publishedAt": "2021-01-28T16:24:14Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "HeejaeJu"
                          },
                          "bodyText": "Thanks for your help. I will wait for solution.\nHave a nice weekend!",
                          "url": "https://github.com/idaholab/moose/discussions/16827#discussioncomment-319475",
                          "updatedAt": "2022-07-04T08:37:45Z",
                          "publishedAt": "2021-01-29T01:19:54Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "Registering Objects",
          "author": {
            "login": "Leni-Yeo"
          },
          "bodyText": "Hello, I am a student and new user for MOOSE. I was doing the workshop and trying the registration for the \"DarcyPressure\" kernel. The step do not specifically tell where and how to specifically register. It is initially registered under \"DarcyThermoMechApp\" in the workshop section, but I keep getting a \" 'DarcyPressure' is not a registered object \" error. I tried registering under \"MooseApp\" and got the same trouble. I was just trying to run the tutorial input file step2.i . I was told that I do not need to create a  new application to run it (Which I am not sure either). It would be helpful if you could provide locations where to save the .h and .C files or the general steps to do in the case I need to save/register a new object. Thank you.",
          "url": "https://github.com/idaholab/moose/discussions/16833",
          "updatedAt": "2022-06-10T18:27:29Z",
          "publishedAt": "2021-01-28T22:26:08Z",
          "category": {
            "name": "Q&A Getting Started"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "aeslaughter"
                  },
                  "bodyText": "We have detailed instructions that might help.\nhttps://mooseframework.inl.gov/getting_started/examples_and_tutorials/tutorial01_app_development/index.html",
                  "url": "https://github.com/idaholab/moose/discussions/16833#discussioncomment-319285",
                  "updatedAt": "2022-06-10T18:27:29Z",
                  "publishedAt": "2021-01-28T23:09:03Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "aeslaughter"
                          },
                          "bodyText": "I recommend going through each step carefully. You will find some help specific to your question in Step 5 of this new tutorial.",
                          "url": "https://github.com/idaholab/moose/discussions/16833#discussioncomment-319290",
                          "updatedAt": "2022-06-10T18:27:31Z",
                          "publishedAt": "2021-01-28T23:10:44Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "Leni-Yeo"
                          },
                          "bodyText": "Thank you, that worked!",
                          "url": "https://github.com/idaholab/moose/discussions/16833#discussioncomment-319309",
                          "updatedAt": "2022-06-10T18:27:31Z",
                          "publishedAt": "2021-01-28T23:23:52Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      }
    ]
  }
}